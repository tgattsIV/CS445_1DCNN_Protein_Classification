{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from MotifExtraction import *\n",
    "from Network import *\n",
    "from Preprocessing import *\n",
    "from TrainAndTest import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Motivation:\n",
    "\n",
    "Subcellular location is a major factor in determining function, evolution, and importance for many proteins across the animal kingdom. Multicellular life generally transcribes and translates proteins from DNA and RNA around the nucleus involving ribosomes. However, most proteins around the cell do not operate around the nucleus or in the region where they were translated. Instead, these protein strands are targeted and shepherded around the cell, crossing cellular membranes in order to be localized at their final destinations (mitochondria, chloroplasts, lysosomes, vacuoles, etc). Because proteins that are localized to specific subcellular compartments often share in a common purpose, they also share in a common evolution. Simply knowing where a protein operates gives researchers a great deal of information about that protein’s purpose and potentially a shared evolutionary history with other proteins. Before the rise of machine learning classifiers, protein localization assays were often a first step in studying any particular gene in any given model organism. Localization assays often involved tagging the protein with GFP (Green Fluorescent Protein) and using confocal microscopy to determine location. This, however, does have some drawbacks. The first is that it is obviously manual work and could not be automated. The gene in question would have to be spliced with GFP and then the model organism grown, harvested, and sectioned for microscopy; A labor intensive task. The second is that GFP is an incredibly large chunk of protein and often could introduce aberrant behavior for the protein in study. GFP could cause the protein to fail to be localized correctly or interfere with the overall protein function / folding. Because proteins often share targeting motifs in their coding regions, this is a ripe area of study for machine learning. Instead of dealing with the hassle of GFP, it is possible to build, train, and use a neural network to identify these motif regions within proteins and classify protein subcellular location at rates impossible to compete with using experimental localization assays. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "Because of my previous experience and work in the field of cell biology and biotechnology, this is a project that is incredibly interesting to me, to see if I can build a broad classifier which could identify targeting motifs is hugely exciting. I am also planning on moving into the realm of bioinformatics after graduating and so a project like this gives me ample opportunity to work on projects that may be very similar to the kind of work I’ll be doing in my career. \n",
    "\n",
    "The data I intend to use for this work is from Dan Sloan’s lab in the CSU department of Biology. Sloan’s lab has built a targeting database for Arabidopsis thaliana including thousands of genes. The sequences for these genes can be found from Phytozome, an open source genetic library for plants developed by the DoE (Department of Energy). In order to complete this analysis, I will use two convolutional networks, 1D CNN and a 2D CNN. The 2D CNN is taken from Dr. Asa Ben-Hur, who built it off of the Basset framework while the 1D CNN was provided in this class. Part I of this analyses will recapitulate the Basset paper pipeline, but use the Arabidopsis thaliana dataset I acquired from the Sloan lab. This part of the analysis will be to see how well the Basset framework can recognize and pull out targeting motifs, rather than the DNA binding motifs it was originally built to analyze. Part II of this analysis will be a simple classification problem, using the same dataset and a 1D CNN with the idea of being able to predict whether or not a protein is localized either to the mitochondria or the plastid by sequence alone. \n",
    "\n",
    "It is worth noting that this is, in part, an extension of a previous machine learning project where the same data was used, but only very simple classifiers were used (Perceptron, RandomForest, SVM, etc). To expand on this project I will be using some of the same approaches used in the previous project, but only as a baseline for exploring how well a neural network manages this classification problem. Almost nothing from the previous project will simply be copy-pasted into this project as many of the algorithms and data management functions have entirely been rewritten to allow for more flexibility. Regardless a baseline notebook will be provided along with the project proposal. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I\n",
    "\n",
    "\n",
    "#### Project Sources and Contributions \n",
    "This part of the project will focus on motif extraction for both mitochondrially and plastid (chloroplast) located proteins from Arabidopsis thaliana. This pipeline was largely inspired and used from the Basset paper published in 2016 (https://pubmed.ncbi.nlm.nih.gov/27197224/). Many of the function baselines used for this pipeline were built from the Basset code base available here: https://github.com/davek44/Basset and here: https://github.com/MedChaabane/deepRAM. The pipeline was largely built by Ahmed Addaoud, a graduate student of Asa Ben-Hur in the CS department. Further details about which functions were written personally or barrowed can be found in the accompanying python scripts, however it is worth noting that while I personally did not develop the flow of this pipeline I am responsible for its current organization. As part of our 525 project my responsibility was organizing the code base for this pipeline and in doing so I augmented each of these functions such that they could be broken out into different scripts and files. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Extraction\n",
    "\n",
    "Like stated above, this part of the project will use the Basset pipeline in an attempt to find DNA targeting motifs for mitochondrially or plastid located proteins. Originally this pipeline used CHIPseq peak data to find regions of DNA binding and so has been altered slightly for the difference in function and data inputs. \n",
    "\n",
    "The general flow of the pipeline is as follows: \n",
    "* Define variables used throughout the pipeline\n",
    "* Import data \n",
    "* Preprocess Data and organize it into dataframes\n",
    "    * Pad and OneHotEncode DNA transcripts\n",
    "* Split the data into Train, Validate, Test, and Calibrate data sets. \n",
    "* Load the data through an imported Dataset Loader. \n",
    "* Calibrate the CNN model using hyperparemeter tuning\n",
    "* Train and Test the best model\n",
    "* Extract Motifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup variables used for the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global device\n",
    "global model_dir\n",
    "global results_dir\n",
    "global data_dir\n",
    "global verbose\n",
    "\n",
    "motif_len = 24\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda' \n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "model_dir = 'model'\n",
    "results_dir = 'results'\n",
    "data_dir = 'Data'\n",
    "verbose = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data import\n",
    "The CyMIRA_Target_Only.csv file is an augmented database file provided from Dan Sloan's lab, developed by Evan Forsythe. It is a large database file for Arabidopsis thaliana which includes protein functional information and location. The dataset has been stripped to only include geneIDs and Location. \n",
    "The Atha_Tran.fa file is a fasta file downloaded from Phytozome, an open source genomic database for plants. The file in quest contains DNA / nucleotide basepair sequences rather than protein sequences. Often protein sequences are preferred for motif extraction since they are both shorter than DNA (due to 3 nucleotides encoding for a single amino acid. For example, the DNA nucleotide sequence 'CAA' encodes for the single amino acid Glutamine) and depict a coding only region of DNA. However the Basset paper and architecture originally used CHIPseq data which finds peak binding activity of open DNA (DNA available to be transcribed and translated) and specifically uses nucleotide profiles in their neural network. In order to keep as much of the pipeline intact without major rewrite, I have also decided to use a DNA profile for my data as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&gt;ATCG00500.1 pacid=37375748 polypeptide=ATCG00500.1 locus=ATCG00500 ID=ATCG00500.1.Araport11.447 annot-version=Araport11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGGAAAAATCGTGGTTCAATTTTATGTTTTCTAAGGGAGAATTGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTTTGCTCCTGGTGAAAAGACTACTATAAGTCAAGACCGTTTTATA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCGTTCTAGTTATTCTTCTAGTTATTCCAATAATGTTGATCTTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GATGACACCTTTTTTGTTAGGGATAGTAATAAGAATAGTTATTCTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGACAATGATTTTAGTGACCTAGAAAAATTTTTTTATAGTTATTGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462247</th>\n",
       "      <td>ATGTATATAAAAAGTTATCATATCGATAATAAATATGACATTGTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462248</th>\n",
       "      <td>CATTTGGGCGATACAAGCTTCCTATGGCTTCGGGCATAAGAAGGTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462249</th>\n",
       "      <td>TGATAAACACAAAGTCATCTAATCCAAGGCTACAACACTTTCTCGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462250</th>\n",
       "      <td>ATAGAATTTTCTTTCAAACATCGAGAGCAGAACGGATGTGCGGATT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462251</th>\n",
       "      <td>ATGGTCTCTGTTTCATTCTTGTCCTTATTTTCTGAGTCCATATGTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462252 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       >ATCG00500.1 pacid=37375748 polypeptide=ATCG00500.1 locus=ATCG00500 ID=ATCG00500.1.Araport11.447 annot-version=Araport11\n",
       "0       ATGGAAAAATCGTGGTTCAATTTTATGTTTTCTAAGGGAGAATTGG...                                                                      \n",
       "1       TTTTGCTCCTGGTGAAAAGACTACTATAAGTCAAGACCGTTTTATA...                                                                      \n",
       "2       AGCGTTCTAGTTATTCTTCTAGTTATTCCAATAATGTTGATCTTTT...                                                                      \n",
       "3       GATGACACCTTTTTTGTTAGGGATAGTAATAAGAATAGTTATTCTA...                                                                      \n",
       "4       TGACAATGATTTTAGTGACCTAGAAAAATTTTTTTATAGTTATTGT...                                                                      \n",
       "...                                                   ...                                                                      \n",
       "462247  ATGTATATAAAAAGTTATCATATCGATAATAAATATGACATTGTAG...                                                                      \n",
       "462248  CATTTGGGCGATACAAGCTTCCTATGGCTTCGGGCATAAGAAGGTT...                                                                      \n",
       "462249  TGATAAACACAAAGTCATCTAATCCAAGGCTACAACACTTTCTCGA...                                                                      \n",
       "462250  ATAGAATTTTCTTTCAAACATCGAGAGCAGAACGGATGTGCGGATT...                                                                      \n",
       "462251  ATGGTCTCTGTTTCATTCTTGTCCTTATTTTCTGAGTCCATATGTA...                                                                      \n",
       "\n",
       "[462252 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the data\n",
    "dnaTranscripts = pd.read_csv('Atha_Tran.fa', delimiter='\\t')\n",
    "geneLocations = pd.read_csv('CyMIRA_Target_Only.csv', delimiter= ',')\\\n",
    "\n",
    "#Convert to DataFrame for easy manipulation\n",
    "protTranscripts = pd.DataFrame(dnaTranscripts)\n",
    "\n",
    "protTranscripts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beginning of Data Preprocessing\n",
    "Here we use several functions built by me to strip, organize, and combine the two data files into a dataframe that contains the GeneID (gene name), GeneLoc (gene location), and GeneSeq (DNA sequence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein Localization Data trimmed down to shape: (4268, 3)\n",
      "Returning DataFrame of Mitochondrial targeted proteins with shape: (1337, 3)\n",
      "Returning DataFrame of Plastid targeted proteins with shape: (2495, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           GeneID       GeneLoc  \\\n",
       " 1     AT1G01170.1  Mitochondria   \n",
       " 2     AT1G01290.1  Mitochondria   \n",
       " 3     AT1G01970.1  Mitochondria   \n",
       " 4     AT1G02160.2  Mitochondria   \n",
       " 5     AT1G02370.1  Mitochondria   \n",
       " ...           ...           ...   \n",
       " 1333  AT5G66658.1  Mitochondria   \n",
       " 1334  AT5G66760.1  Mitochondria   \n",
       " 1335  AT5G66860.1  Mitochondria   \n",
       " 1336  AT5G67490.1  Mitochondria   \n",
       " 1337  AT5G67590.1  Mitochondria   \n",
       " \n",
       "                                                 GeneSeq  \n",
       " 1     (A, T, G, G, C, A, T, C, A, G, G, A, G, G, T, ...  \n",
       " 2     (A, T, G, A, T, T, T, C, G, A, C, G, C, T, C, ...  \n",
       " 3     (A, T, G, G, G, A, A, T, T, T, A, T, A, G, C, ...  \n",
       " 4     (A, T, G, T, C, G, A, C, G, A, A, A, G, G, C, ...  \n",
       " 5     (A, T, G, A, A, T, T, T, C, C, G, T, A, A, T, ...  \n",
       " ...                                                 ...  \n",
       " 1333  (A, T, G, A, T, T, G, C, T, T, T, C, T, T, C, ...  \n",
       " 1334  (A, T, G, T, G, G, C, G, C, T, G, C, G, T, C, ...  \n",
       " 1335  (A, T, G, G, C, G, A, A, A, T, G, G, T, G, G, ...  \n",
       " 1336  (A, T, G, G, C, G, A, C, G, A, A, C, A, A, C, ...  \n",
       " 1337  (A, T, G, G, C, G, C, T, T, T, G, T, G, C, T, ...  \n",
       " \n",
       " [1337 rows x 3 columns],\n",
       "            GeneID  GeneLoc                                            GeneSeq\n",
       " 1     AT1G01080.2  Plastid  (A, T, G, G, C, G, G, C, C, T, C, C, T, G, C, ...\n",
       " 2     AT1G01090.1  Plastid  (A, T, G, G, C, G, A, C, G, G, C, T, T, T, C, ...\n",
       " 3     AT1G01550.2  Plastid  (A, T, G, G, C, T, C, G, T, C, C, A, C, A, A, ...\n",
       " 4     AT1G01620.1  Plastid  (A, T, G, G, A, A, G, G, G, A, A, A, G, A, A, ...\n",
       " 5     AT1G01790.1  Plastid  (A, T, G, G, A, G, T, A, T, G, C, G, T, C, T, ...\n",
       " ...           ...      ...                                                ...\n",
       " 2491  AT5G67290.1  Plastid  (A, T, G, G, C, G, G, T, G, A, T, C, T, C, A, ...\n",
       " 2492  AT5G67370.1  Plastid  (A, T, G, C, T, C, A, G, G, T, T, A, A, T, C, ...\n",
       " 2493  AT5G67520.1  Plastid  (A, T, G, G, A, T, G, T, T, G, C, C, G, C, G, ...\n",
       " 2494  AT5G67570.1  Plastid  (A, T, G, G, A, T, G, C, T, T, C, G, G, T, G, ...\n",
       " 2495  AT5G67630.1  Plastid  (A, T, G, G, C, G, G, A, A, C, T, A, A, A, G, ...\n",
       " \n",
       " [2495 rows x 3 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out unknowns and null values inside DataFrame. Then get specific filtered DataFrames of Mito/Plastid\n",
    "filteredGenes = getTargetedProteins(geneLocations)\n",
    "mitoGenes = getMitoProteins(filteredGenes)\n",
    "plastidGenes = getPlastidProteins(filteredGenes)\n",
    "\n",
    "#Converts .fa file to a python dictionary with key:value pair (geneID:protSequence)\n",
    "source_dict = SeqIO.to_dict(SeqIO.parse('Atha_Tran.fa', 'fasta'))\n",
    "\n",
    "#Merges the arrays of location data and sequence data\n",
    "plastidData = getPlastidSeqs(plastidGenes, source_dict)\n",
    "mitoData = getMitoSeqs(mitoGenes, source_dict)\n",
    "\n",
    "mitoData,plastidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1337, 3)\n",
      "(2495, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.34890396659707723, 0.6510960334029228)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mitoData.shape)\n",
    "print(plastidData.shape)\n",
    "\n",
    "mitoBalance = mitoData.shape[0] / (plastidData.shape[0] + mitoData.shape[0])\n",
    "plastidBalance = plastidData.shape[0] / (plastidData.shape[0] + mitoData.shape[0])\n",
    "\n",
    "dataBalance = (mitoBalance, plastidBalance)\n",
    "dataBalance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad and OneHotEncode DNA transcripts\n",
    "\n",
    "The first part of this motif extraction phase will focus on Mitochondrially encoded proteins. Here I get a list of the DNA sequences and create a OneHotEncoded vector of that data. The generate_onehot_data function does several things at once. First it takes in the sequence and encodes each nucleotide as a 4 by 1 by X vector where each nucleotide position is maintained and encoded as a 1 in a 4 by 1 matrix. These vectors are then padded to ensure that each sequence is both exactly the same in length and that the scanning window of the CNN used for this analysis doesn't 'run off he edge of the map.' In addition to encoding and padding the data this function does one other important feature which is to generate a negative dataset and encode positive and negative datasets. \n",
    "\n",
    "Because the sequence data provided are all positive examples (IE, each sequence *has* a targeting motif which sends it to the subcellular compartment in question) we must generate a negative sequence to show the CNN bad examples as well. To do this, the sequence data set is copied and then each sequence is randomly shuffled and listed as a negative example. Positive and negative examples are encoded as 1's and 0's respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitoSeqBioList = mitoData['GeneSeq'].values.tolist()\n",
    "mitoSeqList = []\n",
    "\n",
    "for seq in mitoSeqBioList:\n",
    "    mitoSeqList.append(str(seq[-100:]))\n",
    "\n",
    "mitoPaddedData = generate_onehot_data(mitoSeqList,motif_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plastidSeqBioList = plastidData['GeneSeq'].values.tolist()\n",
    "plastidSeqList = []\n",
    "\n",
    "for seq in plastidSeqBioList:\n",
    "    plastidSeqList.append(str(seq[-100:]))\n",
    "\n",
    "plastidPaddedData = generate_onehot_data(plastidSeqList,motif_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 1.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 1.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 1.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  ,\n",
       "         0.  , 1.  , 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 1.  , 1.  , 1.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 1.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  ,\n",
       "         0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "         0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "         0.  , 1.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 1.  , 1.  , 0.  , 0.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "         1.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "         0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ,\n",
       "         0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25],\n",
       "        [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ,\n",
       "         0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 1.  , 1.  , 0.  , 1.  , 1.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 1.  , 1.  , 0.  ,\n",
       "         0.  , 1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "         1.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "         0.  , 0.  , 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,\n",
       "         0.25, 0.25, 0.25]]),\n",
       " [1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitoPaddedData[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into Train, Validate, Test, and Calibrate data sets. \n",
    "\n",
    "Here I am setting the data up into train, val, and test splits. The data matrix is shuffled and then divided up into 3 partitions. Training takes the largest with half the data set while validation and testing are both 25% of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 668, 669)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitoTrainPart = int(len(mitoPaddedData) * 0.5)\n",
    "mitoValPart = int(len(mitoPaddedData) * 0.25)\n",
    "mitoTestPart = int(len(mitoPaddedData) * 0.25)\n",
    "\n",
    "mitoPaddedData = pd.DataFrame(mitoPaddedData)\n",
    "mitoPaddedData = mitoPaddedData.sample(frac=1)\n",
    "mitoPaddedData = mitoPaddedData.values.tolist()\n",
    "\n",
    "mitoTrainData = mitoPaddedData[0:mitoTrainPart]\n",
    "mitoValData = mitoPaddedData[mitoTrainPart:mitoValPart+mitoTrainPart]\n",
    "mitoTestData = mitoPaddedData[mitoTrainPart+mitoValPart:]\n",
    "len(mitoTrainData),len(mitoValData), len(mitoTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2495, 1247, 1248)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plastidTrainPart = int(len(plastidPaddedData) * 0.5)\n",
    "plastidValPart = int(len(plastidPaddedData) * 0.25)\n",
    "plastidTestPart = int(len(plastidPaddedData) * 0.25)\n",
    "\n",
    "plastidPaddedData = pd.DataFrame(plastidPaddedData)\n",
    "plastidPaddedData = plastidPaddedData.sample(frac=1)\n",
    "plastidPaddedData = plastidPaddedData.values.tolist()\n",
    "\n",
    "plastidTrainData = plastidPaddedData[0:plastidTrainPart]\n",
    "plastidValData = plastidPaddedData[plastidTrainPart:plastidValPart+plastidTrainPart]\n",
    "plastidTestData = plastidPaddedData[plastidTrainPart+plastidValPart:]\n",
    "len(plastidTrainData),len(plastidValData), len(plastidTestData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data through an imported Dataset Loader. \n",
    "\n",
    "The datasets are then loaded through a DataLoader package for use in the model. The calibration loader, which is used for hyperparameter searching, is just set to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainDataset = dataset(mitoTrainData)\n",
    "valDataset = dataset(mitoValData)\n",
    "testDataset = dataset(mitoTestData)\n",
    "\n",
    "train_loader = DataLoader(dataset=trainDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "test_loader = DataLoader(dataset=testDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "calib_loader = train_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibrate the CNN model using hyperparemeter tuning\n",
    "\n",
    "Due to the stochastic nature of CNNs (this one in particular) I opt to calibrate the model first by running around 50 test models and grading their performance on a validation set. The model that performs the best has their hyperparameters taken and used for the final training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  cuda\n",
      "model 1 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7019229531288147\n",
      "Validation loss decreased from inf to 0.6945747624744069\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6884593963623047\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.693234384059906\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6953338980674744\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6947900056838989\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6963605284690857\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6961467862129211\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7005724906921387\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6878142952919006\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6880508661270142\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6906930208206177\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.7016303539276123\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6840526461601257\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6891876459121704\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7009810209274292\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6918966770172119\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6888473033905029\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6918492317199707\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6941479444503784\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6873611807823181\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6911766529083252\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6827530264854431\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6925320625305176\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6987081170082092\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6844774484634399\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.696823000907898\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6883300542831421\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6961395740509033\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6965827345848083\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6869286298751831\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6885491609573364\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6971762776374817\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6929659843444824\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6881660223007202\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6921176910400391\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6916539669036865\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6935272812843323\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.69125896692276\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6913319826126099\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6955424547195435\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6928670406341553\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6858669519424438\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6956645846366882\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6895343661308289\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6901798248291016\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6875519156455994\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6947624087333679\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.689181387424469\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6878483295440674\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6876659393310547\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6886396408081055\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5318018819596106\n",
      "model 2 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6937963962554932\n",
      "Validation loss decreased from inf to 0.6923843459649519\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6929539442062378\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6984124779701233\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6893037557601929\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6967971324920654\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6904837489128113\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6926164031028748\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.690812349319458\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6889950037002563\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.687697172164917\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6894078850746155\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.68626469373703\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6948942542076111\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6918256282806396\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6884271502494812\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6859244704246521\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6876819133758545\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6933651566505432\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6910915970802307\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6920275688171387\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6908842325210571\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6921472549438477\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6885059475898743\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6955153942108154\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6896114945411682\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6872891783714294\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.692636251449585\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6937301158905029\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6938368082046509\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6892828941345215\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6926343441009521\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6896328926086426\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6892035007476807\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6911086440086365\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6893925666809082\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6891534924507141\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6903946399688721\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6946172118186951\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6919621229171753\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6910731792449951\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6902377605438232\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6898192167282104\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6921182870864868\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6947401762008667\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6913533806800842\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6912819743156433\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6899930834770203\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6902438998222351\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6879254579544067\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6908910870552063\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.69240802526474\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.47395454177788554\n",
      "model 3 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7040606141090393\n",
      "Validation loss decreased from inf to 0.6971855001016096\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6986714601516724\n",
      "Validation loss decreased from 0.6971855001016096 to 0.696872586553747\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6860830187797546\n",
      "Validation loss decreased from 0.696872586553747 to 0.695729521187869\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6863243579864502\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6879374980926514\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6861834526062012\n",
      "Validation loss decreased from 0.695729521187869 to 0.6948806860230186\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6904929876327515\n",
      "Validation loss decreased from 0.6948806860230186 to 0.6941463947296143\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6909404397010803\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6964091062545776\n",
      "Validation loss decreased from 0.6941463947296143 to 0.6925620815970681\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6910508871078491\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6833325624465942\n",
      "Validation loss decreased from 0.6925620815970681 to 0.6920385523275896\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6928319334983826\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6824765205383301\n",
      "Validation loss decreased from 0.6920385523275896 to 0.6914073824882507\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6849910616874695\n",
      "Validation loss decreased from 0.6914073824882507 to 0.6909651268612255\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6802597641944885\n",
      "Validation loss decreased from 0.6909651268612255 to 0.6886448155749928\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6733452081680298\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6765701174736023\n",
      "Validation loss decreased from 0.6886448155749928 to 0.6867801763794639\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6719080209732056\n",
      "Validation loss decreased from 0.6867801763794639 to 0.6849866617809642\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6579471826553345\n",
      "Validation loss decreased from 0.6849866617809642 to 0.681174944747578\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6594253182411194\n",
      "Validation loss decreased from 0.681174944747578 to 0.6779022921215404\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6410179138183594\n",
      "Validation loss decreased from 0.6779022921215404 to 0.6729624542323026\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6328814625740051\n",
      "Validation loss decreased from 0.6729624542323026 to 0.6679342985153198\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.631560742855072\n",
      "Validation loss decreased from 0.6679342985153198 to 0.6566484678875316\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6107357144355774\n",
      "Validation loss decreased from 0.6566484678875316 to 0.6454141194170172\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.5913558006286621\n",
      "Validation loss decreased from 0.6454141194170172 to 0.63012910972942\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.5942401885986328\n",
      "Validation loss decreased from 0.63012910972942 to 0.6154671582308683\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.544190526008606\n",
      "Validation loss decreased from 0.6154671582308683 to 0.5977801247076555\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.5030916333198547\n",
      "Validation loss decreased from 0.5977801247076555 to 0.5814324888316068\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.44939547777175903\n",
      "Validation loss decreased from 0.5814324888316068 to 0.5643163919448853\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.4595082700252533\n",
      "Validation loss decreased from 0.5643163919448853 to 0.5496378811922941\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.40954864025115967\n",
      "Validation loss decreased from 0.5496378811922941 to 0.5413175089792772\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.36498764157295227\n",
      "Validation loss decreased from 0.5413175089792772 to 0.5299227725375782\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.3511398136615753\n",
      "Validation loss decreased from 0.5299227725375782 to 0.5234366980465975\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.28375521302223206\n",
      "Validation loss decreased from 0.5234366980465975 to 0.5207330747084185\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.27149876952171326\n",
      "Validation loss decreased from 0.5207330747084185 to 0.511532190171155\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.2361491322517395\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.2167505919933319\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.20037218928337097\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.15014030039310455\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.17070947587490082\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.14798972010612488\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.11627288907766342\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.10270188748836517\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.13068267703056335\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.10902255773544312\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.10344941914081573\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.06993027031421661\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.08547516912221909\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.07489375025033951\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.08064253628253937\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.06574099510908127\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.06959076225757599\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.05770731717348099\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.05107657238841057\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.059417884796857834\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.06314440816640854\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.05421534553170204\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.08056462556123734\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.06338506191968918\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.06576753407716751\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.05359992757439613\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.046371836215257645\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.05445067957043648\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.047928985208272934\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.05762491747736931\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.04399094730615616\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.07392672449350357\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.03756159916520119\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.05728888884186745\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.043996091932058334\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.05639933422207832\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.05173259600996971\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.05960659310221672\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.053559545427560806\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.05050608143210411\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05439929664134979\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.042473576962947845\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.05736431106925011\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.044839173555374146\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.04384276643395424\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.06134185194969177\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.06003649905323982\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.05593930184841156\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.04328914359211922\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.047208234667778015\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  35\n",
      "AUC on test data  0.8249525915141057\n",
      "model 4 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6823204755783081\n",
      "Validation loss decreased from inf to 0.6962791085243225\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6943108439445496\n",
      "Validation loss decreased from 0.6962791085243225 to 0.6962762420827692\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6911843419075012\n",
      "Validation loss decreased from 0.6962762420827692 to 0.6962721998041327\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6957709193229675\n",
      "Validation loss decreased from 0.6962721998041327 to 0.6962689486416903\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6904033422470093\n",
      "Validation loss decreased from 0.6962689486416903 to 0.6962654482234608\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.700893223285675\n",
      "Validation loss decreased from 0.6962654482234608 to 0.6962623162703081\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6982254385948181\n",
      "Validation loss decreased from 0.6962623162703081 to 0.6962594823403792\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6907110214233398\n",
      "Validation loss decreased from 0.6962594823403792 to 0.6962576942010359\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.695775032043457\n",
      "Validation loss decreased from 0.6962576942010359 to 0.6962546706199646\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.689419686794281\n",
      "Validation loss decreased from 0.6962546706199646 to 0.6962525194341486\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6953651905059814\n",
      "Validation loss decreased from 0.6962525194341486 to 0.6962505795738914\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.695313572883606\n",
      "Validation loss decreased from 0.6962505795738914 to 0.6962483362718062\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6864811182022095\n",
      "Validation loss decreased from 0.6962483362718062 to 0.69624647769061\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6979236602783203\n",
      "Validation loss decreased from 0.69624647769061 to 0.6962447166442871\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.691346287727356\n",
      "Validation loss decreased from 0.6962447166442871 to 0.6962425437840548\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.7021007537841797\n",
      "Validation loss decreased from 0.6962425437840548 to 0.696239633993669\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6865719556808472\n",
      "Validation loss decreased from 0.696239633993669 to 0.6962372498078779\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6850159168243408\n",
      "Validation loss decreased from 0.6962372498078779 to 0.6962355754592202\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.692780613899231\n",
      "Validation loss decreased from 0.6962355754592202 to 0.6962318528782238\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6936362981796265\n",
      "Validation loss decreased from 0.6962318528782238 to 0.6962281465530396\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6884725093841553\n",
      "Validation loss decreased from 0.6962281465530396 to 0.6962247111580588\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6921086311340332\n",
      "Validation loss decreased from 0.6962247111580588 to 0.6962220343676481\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6955990791320801\n",
      "Validation loss decreased from 0.6962220343676481 to 0.6962199807167053\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6858552098274231\n",
      "Validation loss decreased from 0.6962199807167053 to 0.6962181600657377\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.689142107963562\n",
      "Validation loss decreased from 0.6962181600657377 to 0.6962150172753767\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6873081922531128\n",
      "Validation loss decreased from 0.6962150172753767 to 0.6962107907642018\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.696219801902771\n",
      "Validation loss decreased from 0.6962107907642018 to 0.6962089050899852\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6962458491325378\n",
      "Validation loss decreased from 0.6962089050899852 to 0.6962060711600564\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6969218850135803\n",
      "Validation loss decreased from 0.6962060711600564 to 0.6962032643231478\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.692600429058075\n",
      "Validation loss decreased from 0.6962032643231478 to 0.6962008747187528\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6968972682952881\n",
      "Validation loss decreased from 0.6962008747187528 to 0.6961993629282172\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.685257077217102\n",
      "Validation loss decreased from 0.6961993629282172 to 0.6961973146958784\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6970107555389404\n",
      "Validation loss decreased from 0.6961973146958784 to 0.6961934729055925\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6910315155982971\n",
      "Validation loss decreased from 0.6961934729055925 to 0.6961904547431252\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6921713352203369\n",
      "Validation loss decreased from 0.6961904547431252 to 0.6961893059990623\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6976262927055359\n",
      "Validation loss decreased from 0.6961893059990623 to 0.6961870301853527\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6948758959770203\n",
      "Validation loss decreased from 0.6961870301853527 to 0.6961852312088013\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6928343772888184\n",
      "Validation loss decreased from 0.6961852312088013 to 0.6961833184415643\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6943897008895874\n",
      "Validation loss decreased from 0.6961833184415643 to 0.6961819963021711\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6842493414878845\n",
      "Validation loss decreased from 0.6961819963021711 to 0.6961808367209001\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6898486614227295\n",
      "Validation loss decreased from 0.6961808367209001 to 0.6961784904653375\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6922922134399414\n",
      "Validation loss decreased from 0.6961784904653375 to 0.6961756511168047\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6871614456176758\n",
      "Validation loss decreased from 0.6961756511168047 to 0.6961738304658369\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.693841814994812\n",
      "Validation loss decreased from 0.6961738304658369 to 0.6961715600707314\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7008229494094849\n",
      "Validation loss decreased from 0.6961715600707314 to 0.6961689970710061\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6909933686256409\n",
      "Validation loss decreased from 0.6961689970710061 to 0.6961662715131586\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6876144409179688\n",
      "Validation loss decreased from 0.6961662715131586 to 0.6961634159088135\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.685464084148407\n",
      "Validation loss decreased from 0.6961634159088135 to 0.6961615735834296\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6856387257575989\n",
      "Validation loss decreased from 0.6961615735834296 to 0.6961581598628651\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6891508102416992\n",
      "Validation loss decreased from 0.6961581598628651 to 0.6961549899794839\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6848326325416565\n",
      "Validation loss decreased from 0.6961549899794839 to 0.6961535757238214\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.7012922763824463\n",
      "Validation loss decreased from 0.6961535757238214 to 0.696153537793593\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6944036483764648\n",
      "Validation loss decreased from 0.696153537793593 to 0.6961531910029325\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6941826343536377\n",
      "Validation loss decreased from 0.6961531910029325 to 0.6961510018868879\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6887573003768921\n",
      "Validation loss decreased from 0.6961510018868879 to 0.6961494846777483\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6998492479324341\n",
      "Validation loss decreased from 0.6961494846777483 to 0.6961480920965021\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6911947727203369\n",
      "Validation loss decreased from 0.6961480920965021 to 0.6961458867246454\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6823426485061646\n",
      "Validation loss decreased from 0.6961458867246454 to 0.6961453773758628\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6830987930297852\n",
      "Validation loss decreased from 0.6961453773758628 to 0.6961443207480691\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6878327131271362\n",
      "Validation loss decreased from 0.6961443207480691 to 0.6961419690739025\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6907090544700623\n",
      "Validation loss decreased from 0.6961419690739025 to 0.6961391297253695\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.696365237236023\n",
      "Validation loss decreased from 0.6961391297253695 to 0.6961369243535128\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6953698992729187\n",
      "Validation loss decreased from 0.6961369243535128 to 0.6961350007490679\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6907522678375244\n",
      "Validation loss decreased from 0.6961350007490679 to 0.6961339170282538\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6918790340423584\n",
      "Validation loss decreased from 0.6961339170282538 to 0.6961325786330483\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6988311409950256\n",
      "Validation loss decreased from 0.6961325786330483 to 0.6961301510984247\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6930784583091736\n",
      "Validation loss decreased from 0.6961301510984247 to 0.6961271058429371\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6925912499427795\n",
      "Validation loss decreased from 0.6961271058429371 to 0.6961239576339722\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6973548531532288\n",
      "Validation loss decreased from 0.6961239576339722 to 0.6961219852620905\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.687280535697937\n",
      "Validation loss decreased from 0.6961219852620905 to 0.6961201537739147\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6919919848442078\n",
      "Validation loss decreased from 0.6961201537739147 to 0.6961176720532504\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.695679247379303\n",
      "Validation loss decreased from 0.6961176720532504 to 0.6961142474954779\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6925046443939209\n",
      "Validation loss decreased from 0.6961142474954779 to 0.6961103677749634\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6885828971862793\n",
      "Validation loss decreased from 0.6961103677749634 to 0.6961081732403148\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6964521408081055\n",
      "Validation loss decreased from 0.6961081732403148 to 0.6961076205426996\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6884275674819946\n",
      "Validation loss decreased from 0.6961076205426996 to 0.6961055831475691\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6940335631370544\n",
      "Validation loss decreased from 0.6961055831475691 to 0.6961029767990112\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6928034424781799\n",
      "Validation loss decreased from 0.6961029767990112 to 0.6961003867062655\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6868576407432556\n",
      "Validation loss decreased from 0.6961003867062655 to 0.6960989128459584\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6905825734138489\n",
      "Validation loss decreased from 0.6960989128459584 to 0.6960966803810813\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6901589035987854\n",
      "Validation loss decreased from 0.6960966803810813 to 0.6960953744975004\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6956104636192322\n",
      "Validation loss decreased from 0.6960953744975004 to 0.6960936947302385\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.7020366787910461\n",
      "Validation loss decreased from 0.6960936947302385 to 0.6960921124978499\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6960937976837158\n",
      "Validation loss decreased from 0.6960921124978499 to 0.6960905681956898\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6995386481285095\n",
      "Validation loss decreased from 0.6960905681956898 to 0.6960891647772356\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6894904971122742\n",
      "Validation loss decreased from 0.6960891647772356 to 0.6960874958471819\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6896637678146362\n",
      "Validation loss decreased from 0.6960874958471819 to 0.696084819056771\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6877212524414062\n",
      "Validation loss decreased from 0.696084819056771 to 0.6960834644057534\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6843057870864868\n",
      "Validation loss decreased from 0.6960834644057534 to 0.6960821801965887\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6866039037704468\n",
      "Validation loss decreased from 0.6960821801965887 to 0.6960801698944785\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.689558207988739\n",
      "Validation loss decreased from 0.6960801698944785 to 0.6960779428482056\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6942747831344604\n",
      "Validation loss decreased from 0.6960779428482056 to 0.6960750222206116\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6939425468444824\n",
      "Validation loss decreased from 0.6960750222206116 to 0.6960735375230963\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6944349408149719\n",
      "Validation loss decreased from 0.6960735375230963 to 0.6960726055231962\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6982334852218628\n",
      "Validation loss decreased from 0.6960726055231962 to 0.696071749383753\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6822814345359802\n",
      "Validation loss decreased from 0.696071749383753 to 0.6960709907791831\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6854104995727539\n",
      "Validation loss decreased from 0.6960709907791831 to 0.6960698203607039\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6810124516487122\n",
      "Validation loss decreased from 0.6960698203607039 to 0.6960674090818926\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6988040208816528\n",
      "Validation loss decreased from 0.6960674090818926 to 0.6960662603378296\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6965399384498596\n",
      "Validation loss decreased from 0.6960662603378296 to 0.6960643800822172\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6866055130958557\n",
      "Validation loss decreased from 0.6960643800822172 to 0.6960617954080756\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6834405064582825\n",
      "Validation loss decreased from 0.6960617954080756 to 0.6960608579895713\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6936693787574768\n",
      "Validation loss decreased from 0.6960608579895713 to 0.6960600018501282\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.7018048763275146\n",
      "Validation loss decreased from 0.6960600018501282 to 0.696058143268932\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6908736824989319\n",
      "Validation loss decreased from 0.696058143268932 to 0.6960569674318487\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6856155395507812\n",
      "Validation loss decreased from 0.6960569674318487 to 0.6960549788041548\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6823541522026062\n",
      "Validation loss decreased from 0.6960549788041548 to 0.6960533044554971\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6941115856170654\n",
      "Validation loss decreased from 0.6960533044554971 to 0.6960509148511019\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6895115375518799\n",
      "Validation loss decreased from 0.6960509148511019 to 0.6960484818978743\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6900017857551575\n",
      "Validation loss decreased from 0.6960484818978743 to 0.696045691316778\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6927305459976196\n",
      "Validation loss decreased from 0.696045691316778 to 0.6960428628054532\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6904781460762024\n",
      "Validation loss decreased from 0.6960428628054532 to 0.6960407224568453\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6855915784835815\n",
      "Validation loss decreased from 0.6960407224568453 to 0.696038695898923\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6908644437789917\n",
      "Validation loss decreased from 0.696038695898923 to 0.6960377476432107\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6913754940032959\n",
      "Validation loss decreased from 0.6960377476432107 to 0.6960368264805187\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6979173421859741\n",
      "Validation loss decreased from 0.6960368264805187 to 0.6960358294573697\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6908932328224182\n",
      "Validation loss decreased from 0.6960358294573697 to 0.6960352225737139\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6920247077941895\n",
      "Validation loss decreased from 0.6960352225737139 to 0.6960323886437849\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6894623637199402\n",
      "Validation loss decreased from 0.6960323886437849 to 0.6960309256206859\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6935880184173584\n",
      "Validation loss decreased from 0.6960309256206859 to 0.6960298039696433\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.694101870059967\n",
      "Validation loss decreased from 0.6960298039696433 to 0.6960285847837274\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6977123022079468\n",
      "Validation loss decreased from 0.6960285847837274 to 0.6960271488536488\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6902821660041809\n",
      "Validation loss decreased from 0.6960271488536488 to 0.6960250247608532\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6894848942756653\n",
      "Validation loss decreased from 0.6960250247608532 to 0.6960241361097856\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6992883682250977\n",
      "Validation loss decreased from 0.6960241361097856 to 0.6960231228308245\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6901982426643372\n",
      "Validation loss decreased from 0.6960231228308245 to 0.6960210529240695\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6994998455047607\n",
      "Validation loss decreased from 0.6960210529240695 to 0.6960188042033802\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6824870705604553\n",
      "Validation loss decreased from 0.6960188042033802 to 0.6960174116221342\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.687656581401825\n",
      "Validation loss decreased from 0.6960174116221342 to 0.696016707203605\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6927340626716614\n",
      "Validation loss decreased from 0.696016707203605 to 0.6960155367851257\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6819910407066345\n",
      "Validation loss decreased from 0.6960155367851257 to 0.6960135156458075\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6934045553207397\n",
      "Validation loss decreased from 0.6960135156458075 to 0.6960121935064142\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6894568204879761\n",
      "Validation loss decreased from 0.6960121935064142 to 0.6960094679485668\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6797574162483215\n",
      "Validation loss decreased from 0.6960094679485668 to 0.6960075389255177\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6932021975517273\n",
      "Validation loss decreased from 0.6960075389255177 to 0.6960057453675703\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6933679580688477\n",
      "Validation loss decreased from 0.6960057453675703 to 0.6960038922049783\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6998271942138672\n",
      "Validation loss decreased from 0.6960038922049783 to 0.696001881902868\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6876400113105774\n",
      "Validation loss decreased from 0.696001881902868 to 0.6960007548332214\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.689535915851593\n",
      "Validation loss decreased from 0.6960007548332214 to 0.6959996006705544\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6959809064865112\n",
      "Validation loss decreased from 0.6959996006705544 to 0.6959977962753989\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6929410099983215\n",
      "Validation loss decreased from 0.6959977962753989 to 0.6959946534850381\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6984313726425171\n",
      "Validation loss decreased from 0.6959946534850381 to 0.6959936076944525\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6975939869880676\n",
      "Validation loss decreased from 0.6959936076944525 to 0.6959920633922924\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6807695627212524\n",
      "Validation loss decreased from 0.6959920633922924 to 0.6959902969273654\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6979831457138062\n",
      "Validation loss decreased from 0.6959902969273654 to 0.6959888447414745\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6944916248321533\n",
      "Validation loss decreased from 0.6959888447414745 to 0.6959875496951017\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.695223867893219\n",
      "Validation loss decreased from 0.6959875496951017 to 0.6959860270673578\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6849715709686279\n",
      "Validation loss decreased from 0.6959860270673578 to 0.6959838758815419\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6956348419189453\n",
      "Validation loss decreased from 0.6959838758815419 to 0.6959820552305742\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6954764127731323\n",
      "Validation loss decreased from 0.6959820552305742 to 0.695980196649378\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.692818820476532\n",
      "Validation loss decreased from 0.695980196649378 to 0.6959787498820912\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6901630163192749\n",
      "Validation loss decreased from 0.6959787498820912 to 0.6959783651612022\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6923354864120483\n",
      "Validation loss decreased from 0.6959783651612022 to 0.695976501161402\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.7062774896621704\n",
      "Validation loss decreased from 0.695976501161402 to 0.6959761652079496\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6970868110656738\n",
      "Validation loss decreased from 0.6959761652079496 to 0.6959745829755609\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6916829943656921\n",
      "Validation loss decreased from 0.6959745829755609 to 0.6959734613245184\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6869267225265503\n",
      "Validation loss decreased from 0.6959734613245184 to 0.6959713047200983\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6940369009971619\n",
      "Validation loss decreased from 0.6959713047200983 to 0.6959695653481917\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6894890069961548\n",
      "Validation loss decreased from 0.6959695653481917 to 0.6959677880460565\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6900075078010559\n",
      "Validation loss decreased from 0.6959677880460565 to 0.6959662708369169\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.7036218643188477\n",
      "Validation loss decreased from 0.6959662708369169 to 0.6959647048603405\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.689541220664978\n",
      "Validation loss decreased from 0.6959647048603405 to 0.6959634314883839\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6951270699501038\n",
      "Validation loss decreased from 0.6959634314883839 to 0.6959619901397012\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6863292455673218\n",
      "Validation loss decreased from 0.6959619901397012 to 0.6959608847444708\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6882289052009583\n",
      "Validation loss decreased from 0.6959608847444708 to 0.6959591833027926\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6942968368530273\n",
      "Validation loss decreased from 0.6959591833027926 to 0.6959566148844633\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6925373673439026\n",
      "Validation loss decreased from 0.6959566148844633 to 0.6959551085125316\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6889640688896179\n",
      "Validation loss decreased from 0.6959551085125316 to 0.695953829721971\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6983057856559753\n",
      "Validation loss decreased from 0.695953829721971 to 0.6959531523964622\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6938223242759705\n",
      "Validation loss decreased from 0.6959531523964622 to 0.6959514346989718\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6907227039337158\n",
      "Validation loss decreased from 0.6959514346989718 to 0.6959501125595786\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6829151511192322\n",
      "Validation loss decreased from 0.6959501125595786 to 0.6959487741643732\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.7012689113616943\n",
      "Validation loss decreased from 0.6959487741643732 to 0.6959467476064508\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6912388205528259\n",
      "Validation loss decreased from 0.6959467476064508 to 0.6959435018626127\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6996347308158875\n",
      "Validation loss decreased from 0.6959435018626127 to 0.695940532467582\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6908408999443054\n",
      "Validation loss decreased from 0.695940532467582 to 0.6959387280724265\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6929750442504883\n",
      "Validation loss decreased from 0.6959387280724265 to 0.6959371241656217\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6941747665405273\n",
      "Validation loss decreased from 0.6959371241656217 to 0.6959358074448325\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6867772340774536\n",
      "Validation loss decreased from 0.6959358074448325 to 0.6959353035146539\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6906136274337769\n",
      "Validation loss decreased from 0.6959353035146539 to 0.6959333690730009\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6997445821762085\n",
      "Validation loss decreased from 0.6959333690730009 to 0.6959312016313727\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6947870850563049\n",
      "Validation loss decreased from 0.6959312016313727 to 0.6959292455153032\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6857041120529175\n",
      "Validation loss decreased from 0.6959292455153032 to 0.6959270997480913\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.698600709438324\n",
      "Validation loss decreased from 0.6959270997480913 to 0.6959249160506509\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6962317824363708\n",
      "Validation loss decreased from 0.6959249160506509 to 0.6959236426786943\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6927257180213928\n",
      "Validation loss decreased from 0.6959236426786943 to 0.6959228190508756\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6908530592918396\n",
      "Validation loss decreased from 0.6959228190508756 to 0.6959211176091974\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6941664814949036\n",
      "Validation loss decreased from 0.6959211176091974 to 0.6959185220978477\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6964194774627686\n",
      "Validation loss decreased from 0.6959185220978477 to 0.6959168206561696\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6907767653465271\n",
      "Validation loss decreased from 0.6959168206561696 to 0.695915016261014\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6937432885169983\n",
      "Validation loss decreased from 0.695915016261014 to 0.6959143389355053\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6944721937179565\n",
      "Validation loss decreased from 0.6959143389355053 to 0.6959138079123064\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6949363946914673\n",
      "Validation loss decreased from 0.6959138079123064 to 0.695913249796087\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6986273527145386\n",
      "Validation loss decreased from 0.695913249796087 to 0.6959116458892822\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6994126439094543\n",
      "Validation loss decreased from 0.6959116458892822 to 0.6959091912616383\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.690088152885437\n",
      "Validation loss decreased from 0.6959091912616383 to 0.6959064927968112\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6945270895957947\n",
      "Validation loss decreased from 0.6959064927968112 to 0.6959045691923662\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6889268159866333\n",
      "Validation loss decreased from 0.6959045691923662 to 0.6959042224017057\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.694040060043335\n",
      "Validation loss decreased from 0.6959042224017057 to 0.6959032253785566\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6921641826629639\n",
      "Validation loss decreased from 0.6959032253785566 to 0.6959011608904059\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.690735399723053\n",
      "Validation loss decreased from 0.6959011608904059 to 0.6959000500765714\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6908653974533081\n",
      "Validation loss decreased from 0.6959000500765714 to 0.6958993944254789\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6902647614479065\n",
      "Validation loss decreased from 0.6958993944254789 to 0.6958990530534224\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6889911890029907\n",
      "Validation loss decreased from 0.6958990530534224 to 0.6958965334025297\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6970319151878357\n",
      "Validation loss decreased from 0.6958965334025297 to 0.6958941221237183\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6898645162582397\n",
      "Validation loss decreased from 0.6958941221237183 to 0.6958925507285378\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6878913640975952\n",
      "Validation loss decreased from 0.6958925507285378 to 0.695892025123943\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6931325793266296\n",
      "Validation loss decreased from 0.695892025123943 to 0.6958911256356672\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6924751996994019\n",
      "Validation loss decreased from 0.6958911256356672 to 0.6958904157985341\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6927313804626465\n",
      "Validation loss decreased from 0.6958904157985341 to 0.6958892291242426\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6876697540283203\n",
      "Validation loss decreased from 0.6958892291242426 to 0.6958875493569807\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6940639615058899\n",
      "Validation loss decreased from 0.6958875493569807 to 0.6958862326361916\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6877577900886536\n",
      "Validation loss decreased from 0.6958862326361916 to 0.695884720845656\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6851746439933777\n",
      "Validation loss decreased from 0.695884720845656 to 0.6958829056132924\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6866664886474609\n",
      "Validation loss decreased from 0.6958829056132924 to 0.6958820386366411\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6854492425918579\n",
      "Validation loss decreased from 0.6958820386366411 to 0.6958810470320962\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.690188467502594\n",
      "Validation loss decreased from 0.6958810470320962 to 0.695879193869504\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6875641345977783\n",
      "Validation loss decreased from 0.695879193869504 to 0.69587641954422\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.7046502828598022\n",
      "Validation loss decreased from 0.69587641954422 to 0.695874577218836\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6869588494300842\n",
      "Validation loss decreased from 0.695874577218836 to 0.695871271870353\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.696855366230011\n",
      "Validation loss decreased from 0.695871271870353 to 0.6958696679635481\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6958866119384766\n",
      "Validation loss decreased from 0.6958696679635481 to 0.6958678744056008\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6812388300895691\n",
      "Validation loss decreased from 0.6958678744056008 to 0.6958651813593778\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.686051070690155\n",
      "Validation loss decreased from 0.6958651813593778 to 0.6958648724989458\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6948148012161255\n",
      "Validation loss decreased from 0.6958648724989458 to 0.6958622715689919\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6910526156425476\n",
      "Validation loss decreased from 0.6958622715689919 to 0.6958602883599021\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6860935091972351\n",
      "Validation loss decreased from 0.6958602883599021 to 0.6958584135228937\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6923002600669861\n",
      "Validation loss decreased from 0.6958584135228937 to 0.6958574544299733\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6925578117370605\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.697418212890625\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6951755881309509\n",
      "Validation loss decreased from 0.6958574544299733 to 0.6958567716858604\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6909696459770203\n",
      "Validation loss decreased from 0.6958567716858604 to 0.6958553736860101\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6982570886611938\n",
      "Validation loss decreased from 0.6958553736860101 to 0.6958528865467418\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6925024390220642\n",
      "Validation loss decreased from 0.6958528865467418 to 0.6958508816632357\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6902355551719666\n",
      "Validation loss decreased from 0.6958508816632357 to 0.6958488930355419\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.696243941783905\n",
      "Validation loss decreased from 0.6958488930355419 to 0.6958454305475409\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6958256959915161\n",
      "Validation loss decreased from 0.6958454305475409 to 0.6958429650826887\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6957860589027405\n",
      "Validation loss decreased from 0.6958429650826887 to 0.6958423961292614\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6813161969184875\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6947309970855713\n",
      "Validation loss decreased from 0.6958423961292614 to 0.6958421956409108\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6870534420013428\n",
      "Validation loss decreased from 0.6958421956409108 to 0.6958404291759838\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6916400194168091\n",
      "Validation loss decreased from 0.6958404291759838 to 0.695838825269179\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.698900043964386\n",
      "Validation loss decreased from 0.695838825269179 to 0.6958378770134666\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6967389583587646\n",
      "Validation loss decreased from 0.6958378770134666 to 0.6958367607810281\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6912732124328613\n",
      "Validation loss decreased from 0.6958367607810281 to 0.6958347829905424\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6899890899658203\n",
      "Validation loss decreased from 0.6958347829905424 to 0.6958334608511492\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6978996992111206\n",
      "Validation loss decreased from 0.6958334608511492 to 0.6958314126188104\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6912638545036316\n",
      "Validation loss decreased from 0.6958314126188104 to 0.6958297707817771\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6949706673622131\n",
      "Validation loss decreased from 0.6958297707817771 to 0.6958284432237799\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6911971569061279\n",
      "Validation loss decreased from 0.6958284432237799 to 0.6958263733170249\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6975403428077698\n",
      "Validation loss decreased from 0.6958263733170249 to 0.6958246447823264\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6872621774673462\n",
      "Validation loss decreased from 0.6958246447823264 to 0.6958225586197593\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6963883638381958\n",
      "Validation loss decreased from 0.6958225586197593 to 0.6958207867362283\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6888164281845093\n",
      "Validation loss decreased from 0.6958207867362283 to 0.6958193399689414\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6868146061897278\n",
      "Validation loss decreased from 0.6958193399689414 to 0.6958170804110441\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6948686838150024\n",
      "Validation loss decreased from 0.6958170804110441 to 0.6958153681321577\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.693674623966217\n",
      "Validation loss decreased from 0.6958153681321577 to 0.6958143277601763\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6898009777069092\n",
      "Validation loss decreased from 0.6958143277601763 to 0.6958132494579662\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6944080591201782\n",
      "Validation loss decreased from 0.6958132494579662 to 0.6958117593418468\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.7022781372070312\n",
      "Validation loss decreased from 0.6958117593418468 to 0.6958107948303223\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6990771293640137\n",
      "Validation loss decreased from 0.6958107948303223 to 0.6958092288537459\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6888094544410706\n",
      "Validation loss decreased from 0.6958092288537459 to 0.6958070722493258\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6891787648200989\n",
      "Validation loss decreased from 0.6958070722493258 to 0.6958048343658447\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6880678534507751\n",
      "Validation loss decreased from 0.6958048343658447 to 0.6958035555752841\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.702928900718689\n",
      "Validation loss decreased from 0.6958035555752841 to 0.6958028349009427\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6982176899909973\n",
      "Validation loss decreased from 0.6958028349009427 to 0.6958020058545199\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6955795288085938\n",
      "Validation loss decreased from 0.6958020058545199 to 0.6958012526685541\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6854949593544006\n",
      "Validation loss decreased from 0.6958012526685541 to 0.6957988630641591\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6821292042732239\n",
      "Validation loss decreased from 0.6957988630641591 to 0.6957972049713135\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6905344724655151\n",
      "Validation loss decreased from 0.6957972049713135 to 0.6957971887155012\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6881657838821411\n",
      "Validation loss decreased from 0.6957971887155012 to 0.69579632173885\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6834450960159302\n",
      "Validation loss decreased from 0.69579632173885 to 0.6957946853204207\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6948866248130798\n",
      "Validation loss decreased from 0.6957946853204207 to 0.6957942897623236\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6995102167129517\n",
      "Validation loss decreased from 0.6957942897623236 to 0.6957932927391746\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.693296492099762\n",
      "Validation loss decreased from 0.6957932927391746 to 0.6957918026230552\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6977856159210205\n",
      "Validation loss decreased from 0.6957918026230552 to 0.6957902799953114\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6890902519226074\n",
      "Validation loss decreased from 0.6957902799953114 to 0.6957878091118552\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6874534487724304\n",
      "Validation loss decreased from 0.6957878091118552 to 0.6957863406701521\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.7019920349121094\n",
      "Validation loss decreased from 0.6957863406701521 to 0.6957836205309088\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.696421205997467\n",
      "Validation loss decreased from 0.6957836205309088 to 0.6957809003916654\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6967877149581909\n",
      "Validation loss decreased from 0.6957809003916654 to 0.6957786841826006\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6835895776748657\n",
      "Validation loss decreased from 0.6957786841826006 to 0.6957762295549567\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6890738010406494\n",
      "Validation loss decreased from 0.6957762295549567 to 0.695775183764371\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6915115118026733\n",
      "Validation loss decreased from 0.695775183764371 to 0.6957742734388872\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6958439946174622\n",
      "Validation loss decreased from 0.6957742734388872 to 0.6957723931832747\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6898316740989685\n",
      "Validation loss decreased from 0.6957723931832747 to 0.6957716887647455\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6960712671279907\n",
      "Validation loss decreased from 0.6957716887647455 to 0.6957706050439314\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6896103620529175\n",
      "Validation loss decreased from 0.6957706050439314 to 0.6957702474160627\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6969837546348572\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6862838268280029\n",
      "Validation loss decreased from 0.6957702474160627 to 0.6957687085325067\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6983820796012878\n",
      "Validation loss decreased from 0.6957687085325067 to 0.6957669095559553\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6992948651313782\n",
      "Validation loss decreased from 0.6957669095559553 to 0.6957650943235918\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6885161399841309\n",
      "Validation loss decreased from 0.6957650943235918 to 0.6957636583935131\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6909785866737366\n",
      "Validation loss decreased from 0.6957636583935131 to 0.6957625204866583\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6899191737174988\n",
      "Validation loss decreased from 0.6957625204866583 to 0.6957616751844232\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6881003975868225\n",
      "Validation loss decreased from 0.6957616751844232 to 0.6957602121613242\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.683744490146637\n",
      "Validation loss decreased from 0.6957602121613242 to 0.6957575624639337\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.7011706829071045\n",
      "Validation loss decreased from 0.6957575624639337 to 0.695756196975708\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6930965185165405\n",
      "Validation loss decreased from 0.695756196975708 to 0.6957557905804027\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6954253315925598\n",
      "Validation loss decreased from 0.6957557905804027 to 0.695755189115351\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6987550854682922\n",
      "Validation loss decreased from 0.695755189115351 to 0.6957533413713629\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6930770874023438\n",
      "Validation loss decreased from 0.6957533413713629 to 0.695752122185447\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.69261234998703\n",
      "Validation loss decreased from 0.695752122185447 to 0.6957511793483387\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6916331052780151\n",
      "Validation loss decreased from 0.6957511793483387 to 0.6957506266507235\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6981559991836548\n",
      "Validation loss decreased from 0.6957506266507235 to 0.6957504911856218\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6908161044120789\n",
      "Validation loss decreased from 0.6957504911856218 to 0.6957503015344794\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6951727867126465\n",
      "Validation loss decreased from 0.6957503015344794 to 0.6957492882555182\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.7009091377258301\n",
      "Validation loss decreased from 0.6957492882555182 to 0.6957491419532082\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6909157037734985\n",
      "Validation loss decreased from 0.6957491419532082 to 0.6957482533021406\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6903973817825317\n",
      "Validation loss decreased from 0.6957482533021406 to 0.6957458636977456\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.695107102394104\n",
      "Validation loss decreased from 0.6957458636977456 to 0.6957438371398232\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6857410669326782\n",
      "Validation loss decreased from 0.6957438371398232 to 0.6957420327446677\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6890943050384521\n",
      "Validation loss decreased from 0.6957420327446677 to 0.6957393884658813\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.690097451210022\n",
      "Validation loss decreased from 0.6957393884658813 to 0.6957382993264631\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6927075386047363\n",
      "Validation loss decreased from 0.6957382993264631 to 0.6957370313731107\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6961850523948669\n",
      "Validation loss decreased from 0.6957370313731107 to 0.6957353136756204\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6937030553817749\n",
      "Validation loss decreased from 0.6957353136756204 to 0.6957352974198081\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6868451237678528\n",
      "Validation loss decreased from 0.6957352974198081 to 0.6957330161874945\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6920340061187744\n",
      "Validation loss decreased from 0.6957330161874945 to 0.6957310925830494\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6870214939117432\n",
      "Validation loss decreased from 0.6957310925830494 to 0.6957299004901539\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6924278736114502\n",
      "Validation loss decreased from 0.6957299004901539 to 0.6957289251414213\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.689483642578125\n",
      "Validation loss decreased from 0.6957289251414213 to 0.6957273862578652\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6919692158699036\n",
      "Validation loss decreased from 0.6957273862578652 to 0.6957260912114923\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.685778021812439\n",
      "Validation loss decreased from 0.6957260912114923 to 0.6957231543280862\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6966975331306458\n",
      "Validation loss decreased from 0.6957231543280862 to 0.6957226666537198\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.694288969039917\n",
      "Validation loss decreased from 0.6957226666537198 to 0.6957220110026273\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.700228750705719\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6876541972160339\n",
      "Validation loss decreased from 0.6957220110026273 to 0.6957215124910529\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6942363977432251\n",
      "Validation loss decreased from 0.6957215124910529 to 0.695720450444655\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6888439655303955\n",
      "Validation loss decreased from 0.695720450444655 to 0.695718911561099\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6835083365440369\n",
      "Validation loss decreased from 0.695718911561099 to 0.6957172047008168\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6987852454185486\n",
      "Validation loss decreased from 0.6957172047008168 to 0.6957149613987316\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6980068683624268\n",
      "Validation loss decreased from 0.6957149613987316 to 0.6957126422361894\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6950463056564331\n",
      "Validation loss decreased from 0.6957126422361894 to 0.6957110545851968\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6903095245361328\n",
      "Validation loss decreased from 0.6957110545851968 to 0.6957105994224548\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.692182183265686\n",
      "Validation loss decreased from 0.6957105994224548 to 0.6957097324458036\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6858939528465271\n",
      "Validation loss decreased from 0.6957097324458036 to 0.6957090930505232\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6918609142303467\n",
      "Validation loss decreased from 0.6957090930505232 to 0.6957079443064603\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6885252594947815\n",
      "Validation loss decreased from 0.6957079443064603 to 0.6957064650275491\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6920387744903564\n",
      "Validation loss decreased from 0.6957064650275491 to 0.6957057497718118\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6964640021324158\n",
      "Validation loss decreased from 0.6957057497718118 to 0.6957043517719615\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6939479112625122\n",
      "Validation loss decreased from 0.6957043517719615 to 0.6957034522836859\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6943371295928955\n",
      "Validation loss decreased from 0.6957034522836859 to 0.6957021464001049\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6818534731864929\n",
      "Validation loss decreased from 0.6957021464001049 to 0.6957010735164989\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6891088485717773\n",
      "Validation loss decreased from 0.6957010735164989 to 0.6956994154236533\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.691376805305481\n",
      "Validation loss decreased from 0.6956994154236533 to 0.6956984563307329\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6966448426246643\n",
      "Validation loss decreased from 0.6956984563307329 to 0.6956962780518965\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6917106509208679\n",
      "Validation loss decreased from 0.6956962780518965 to 0.6956936066800897\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6886486411094666\n",
      "Validation loss decreased from 0.6956936066800897 to 0.6956924416802146\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6943643093109131\n",
      "Validation loss decreased from 0.6956924416802146 to 0.6956918077035383\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6932665705680847\n",
      "Validation loss decreased from 0.6956918077035383 to 0.6956916993314569\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.7014111876487732\n",
      "Validation loss decreased from 0.6956916993314569 to 0.6956903880292719\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6878523230552673\n",
      "Validation loss decreased from 0.6956903880292719 to 0.6956901008432562\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.703535258769989\n",
      "Validation loss decreased from 0.6956901008432562 to 0.6956897540525957\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6935343146324158\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.7030508518218994\n",
      "Validation loss decreased from 0.6956897540525957 to 0.6956889466805891\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6929215788841248\n",
      "Validation loss decreased from 0.6956889466805891 to 0.695688621564345\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6901029944419861\n",
      "Validation loss decreased from 0.695688621564345 to 0.6956868117505853\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6944499015808105\n",
      "Validation loss decreased from 0.6956868117505853 to 0.6956853649832986\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6954286694526672\n",
      "Validation loss decreased from 0.6956853649832986 to 0.6956842270764437\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6847480535507202\n",
      "Validation loss decreased from 0.6956842270764437 to 0.695683013309132\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.695883572101593\n",
      "Validation loss decreased from 0.695683013309132 to 0.6956824931231412\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6939385533332825\n",
      "Validation loss decreased from 0.6956824931231412 to 0.6956815827976573\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.693405270576477\n",
      "Validation loss decreased from 0.6956815827976573 to 0.6956806995651938\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6948960423469543\n",
      "Validation loss decreased from 0.6956806995651938 to 0.6956790252165361\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6957991719245911\n",
      "Validation loss decreased from 0.6956790252165361 to 0.695678402077068\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6835739612579346\n",
      "Validation loss decreased from 0.695678402077068 to 0.6956782124259255\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6999557018280029\n",
      "Validation loss decreased from 0.6956782124259255 to 0.6956772750074213\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6881381869316101\n",
      "Validation loss decreased from 0.6956772750074213 to 0.6956768415190957\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6947940587997437\n",
      "Validation loss decreased from 0.6956768415190957 to 0.6956754760308699\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6961184144020081\n",
      "Validation loss decreased from 0.6956754760308699 to 0.6956740942868319\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6891626715660095\n",
      "Validation loss decreased from 0.6956740942868319 to 0.6956727450544183\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6950743794441223\n",
      "Validation loss decreased from 0.6956727450544183 to 0.6956719268452037\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6979454755783081\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6914908289909363\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6934415102005005\n",
      "Validation loss decreased from 0.6956719268452037 to 0.6956702633337541\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6890769600868225\n",
      "Validation loss decreased from 0.6956702633337541 to 0.6956686431711371\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6956526637077332\n",
      "Validation loss decreased from 0.6956686431711371 to 0.6956680579618975\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6985589265823364\n",
      "Validation loss decreased from 0.6956680579618975 to 0.6956664269620721\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6896410584449768\n",
      "Validation loss decreased from 0.6956664269620721 to 0.6956652023575522\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6896916031837463\n",
      "Validation loss decreased from 0.6956652023575522 to 0.695664335380901\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6936625242233276\n",
      "Validation loss decreased from 0.695664335380901 to 0.6956632137298584\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6972643136978149\n",
      "Validation loss decreased from 0.6956632137298584 to 0.6956618861718611\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6886816024780273\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.692935585975647\n",
      "Validation loss decreased from 0.6956618861718611 to 0.6956611221486871\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6860578060150146\n",
      "Validation loss decreased from 0.6956611221486871 to 0.695659951730208\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6898643374443054\n",
      "Validation loss decreased from 0.695659951730208 to 0.695658412846652\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6917391419410706\n",
      "Validation loss decreased from 0.695658412846652 to 0.6956564079631459\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6951281428337097\n",
      "Validation loss decreased from 0.6956564079631459 to 0.695654419335452\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.696776807308197\n",
      "Validation loss decreased from 0.695654419335452 to 0.6956527233123779\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6910378932952881\n",
      "Validation loss decreased from 0.6956527233123779 to 0.6956504041498358\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6910594701766968\n",
      "Validation loss decreased from 0.6956504041498358 to 0.6956481987779791\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6878899335861206\n",
      "Validation loss decreased from 0.6956481987779791 to 0.6956477436152372\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6952399015426636\n",
      "Validation loss decreased from 0.6956477436152372 to 0.6956466869874434\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6998012661933899\n",
      "Validation loss decreased from 0.6956466869874434 to 0.6956462047316812\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6904144287109375\n",
      "Validation loss decreased from 0.6956462047316812 to 0.6956452348015525\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6961818337440491\n",
      "Validation loss decreased from 0.6956452348015525 to 0.6956446821039374\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6884662508964539\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6902379989624023\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6933703422546387\n",
      "Validation loss decreased from 0.6956446821039374 to 0.6956436850807883\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6852735877037048\n",
      "Validation loss decreased from 0.6956436850807883 to 0.6956429048018022\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6900665760040283\n",
      "Validation loss decreased from 0.6956429048018022 to 0.6956419728019021\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6927651166915894\n",
      "Validation loss decreased from 0.6956419728019021 to 0.6956407156857577\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6891518235206604\n",
      "Validation loss decreased from 0.6956407156857577 to 0.6956389979882673\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6912376284599304\n",
      "Validation loss decreased from 0.6956389979882673 to 0.6956377896395597\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6890134811401367\n",
      "Validation loss decreased from 0.6956377896395597 to 0.6956372206861322\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6816939115524292\n",
      "Validation loss decreased from 0.6956372206861322 to 0.6956363428722728\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6917652487754822\n",
      "Validation loss decreased from 0.6956363428722728 to 0.6956354758956216\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6928792595863342\n",
      "Validation loss decreased from 0.6956354758956216 to 0.695633741942319\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.7006090879440308\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6866020560264587\n",
      "Validation loss decreased from 0.695633741942319 to 0.6956334601749073\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6898699402809143\n",
      "Validation loss decreased from 0.6956334601749073 to 0.6956325335936113\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6888094544410706\n",
      "Validation loss decreased from 0.6956325335936113 to 0.6956316341053356\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6950191855430603\n",
      "Validation loss decreased from 0.6956316341053356 to 0.695630051872947\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.687912106513977\n",
      "Validation loss decreased from 0.695630051872947 to 0.6956285455010154\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6960849761962891\n",
      "Validation loss decreased from 0.6956285455010154 to 0.6956281391057101\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.689951479434967\n",
      "Validation loss decreased from 0.6956281391057101 to 0.6956272992220792\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6945229172706604\n",
      "Validation loss decreased from 0.6956272992220792 to 0.695627055384896\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6876636147499084\n",
      "Validation loss decreased from 0.695627055384896 to 0.6956264593384482\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6861681938171387\n",
      "Validation loss decreased from 0.6956264593384482 to 0.6956258036873557\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.7025920748710632\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6954033970832825\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6831697225570679\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6932803988456726\n",
      "Validation loss decreased from 0.6956258036873557 to 0.6956250288269736\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6918407678604126\n",
      "Validation loss decreased from 0.6956250288269736 to 0.695623820478266\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6901528835296631\n",
      "Validation loss decreased from 0.695623820478266 to 0.6956229589202187\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6890028715133667\n",
      "Validation loss decreased from 0.6956229589202187 to 0.695622677152807\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.7002279162406921\n",
      "Validation loss decreased from 0.695622677152807 to 0.6956214904785156\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6963667273521423\n",
      "Validation loss decreased from 0.6956214904785156 to 0.6956206235018644\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6861090660095215\n",
      "Validation loss decreased from 0.6956206235018644 to 0.6956195614554666\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6863661408424377\n",
      "Validation loss decreased from 0.6956195614554666 to 0.6956181092695757\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6896809339523315\n",
      "Validation loss decreased from 0.6956181092695757 to 0.6956167817115784\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6852489709854126\n",
      "Validation loss decreased from 0.6956167817115784 to 0.6956162235953591\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6890352368354797\n",
      "Validation loss decreased from 0.6956162235953591 to 0.6956156546419318\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6857366561889648\n",
      "Validation loss decreased from 0.6956156546419318 to 0.6956151127815247\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6885744333267212\n",
      "Validation loss decreased from 0.6956151127815247 to 0.6956143162467263\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.688995361328125\n",
      "Validation loss decreased from 0.6956143162467263 to 0.6956136876886542\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6898847818374634\n",
      "Validation loss decreased from 0.6956136876886542 to 0.6956130591305819\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6893744468688965\n",
      "Validation loss decreased from 0.6956130591305819 to 0.6956114823167975\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6926714181900024\n",
      "Validation loss decreased from 0.6956114823167975 to 0.6956107128750194\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6894674897193909\n",
      "Validation loss decreased from 0.6956107128750194 to 0.695609526200728\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6920979619026184\n",
      "Validation loss decreased from 0.695609526200728 to 0.6956082528287714\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6919010877609253\n",
      "Validation loss decreased from 0.6956082528287714 to 0.6956073804335161\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6995086669921875\n",
      "Validation loss decreased from 0.6956073804335161 to 0.6956061124801636\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6860283613204956\n",
      "Validation loss decreased from 0.6956061124801636 to 0.695604914968664\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6930873394012451\n",
      "Validation loss decreased from 0.695604914968664 to 0.695604302666404\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.694532573223114\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6874940991401672\n",
      "Validation loss decreased from 0.695604302666404 to 0.6956037228757684\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6946446895599365\n",
      "Validation loss decreased from 0.6956037228757684 to 0.6956023357131265\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6885354518890381\n",
      "Validation loss decreased from 0.6956023357131265 to 0.695601918480613\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.690032422542572\n",
      "Validation loss decreased from 0.695601918480613 to 0.6956003633412448\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6843364834785461\n",
      "Validation loss decreased from 0.6956003633412448 to 0.6955991333181207\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6899127960205078\n",
      "Validation loss decreased from 0.6955991333181207 to 0.6955978653647683\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6851438879966736\n",
      "Validation loss decreased from 0.6955978653647683 to 0.6955959146673029\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.7004072666168213\n",
      "Validation loss decreased from 0.6955959146673029 to 0.6955941265279596\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6870765686035156\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6923174262046814\n",
      "Validation loss decreased from 0.6955941265279596 to 0.6955931891094554\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6869877576828003\n",
      "Validation loss decreased from 0.6955931891094554 to 0.6955919103188948\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6842843890190125\n",
      "Validation loss decreased from 0.6955919103188948 to 0.695591086691076\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.690224826335907\n",
      "Validation loss decreased from 0.695591086691076 to 0.6955903226679022\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6939391493797302\n",
      "Validation loss decreased from 0.6955903226679022 to 0.6955895369703119\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.68027663230896\n",
      "Validation loss decreased from 0.6955895369703119 to 0.695589461109855\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6927245855331421\n",
      "Validation loss decreased from 0.695589461109855 to 0.6955892985517328\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6956836581230164\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6938114762306213\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6897379755973816\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6914726495742798\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6948994398117065\n",
      "Validation loss decreased from 0.6955892985517328 to 0.6955888000401583\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6957752704620361\n",
      "Validation loss decreased from 0.6955888000401583 to 0.6955881877378984\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6938709616661072\n",
      "Validation loss decreased from 0.6955881877378984 to 0.6955876025286588\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6889275312423706\n",
      "Validation loss decreased from 0.6955876025286588 to 0.6955850503661416\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6905583143234253\n",
      "Validation loss decreased from 0.6955850503661416 to 0.6955834410407327\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6867952942848206\n",
      "Validation loss decreased from 0.6955834410407327 to 0.6955817612734708\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6967208385467529\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6844856142997742\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6863259077072144\n",
      "Validation loss decreased from 0.6955817612734708 to 0.6955817125060342\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.693498432636261\n",
      "Validation loss decreased from 0.6955817125060342 to 0.6955805366689508\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6886112689971924\n",
      "Validation loss decreased from 0.6955805366689508 to 0.6955802278085188\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6881085634231567\n",
      "Validation loss decreased from 0.6955802278085188 to 0.6955785155296326\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6959574818611145\n",
      "Validation loss decreased from 0.6955785155296326 to 0.6955767273902893\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6892322897911072\n",
      "Validation loss decreased from 0.6955767273902893 to 0.695575936274095\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6958047747612\n",
      "Validation loss decreased from 0.695575936274095 to 0.6955752752043984\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6886317729949951\n",
      "Validation loss decreased from 0.6955752752043984 to 0.6955750747160478\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.691185712814331\n",
      "Validation loss decreased from 0.6955750747160478 to 0.69557340036739\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6977193355560303\n",
      "Validation loss decreased from 0.69557340036739 to 0.6955719861117277\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6966992616653442\n",
      "Validation loss decreased from 0.6955719861117277 to 0.6955713033676147\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.693162739276886\n",
      "Validation loss decreased from 0.6955713033676147 to 0.6955698078328912\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.7001144886016846\n",
      "Validation loss decreased from 0.6955698078328912 to 0.6955691467631947\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6906268000602722\n",
      "Validation loss decreased from 0.6955691467631947 to 0.6955677704377607\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.697553277015686\n",
      "Validation loss decreased from 0.6955677704377607 to 0.6955668330192566\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6908788681030273\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6900156736373901\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6994156241416931\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6935489177703857\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.687099814414978\n",
      "Validation loss decreased from 0.6955668330192566 to 0.6955656084147367\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6983208060264587\n",
      "Validation loss decreased from 0.6955656084147367 to 0.6955648281357505\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6927698254585266\n",
      "Validation loss decreased from 0.6955648281357505 to 0.6955646655776284\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6929084658622742\n",
      "Validation loss decreased from 0.6955646655776284 to 0.6955641128800132\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.691498875617981\n",
      "Validation loss decreased from 0.6955641128800132 to 0.6955623843453147\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6936585307121277\n",
      "Validation loss decreased from 0.6955623843453147 to 0.6955610459501093\n",
      "no early stopping\n",
      "AUC on test data  0.5216910674323924\n",
      "model 5 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6885039806365967\n",
      "Validation loss decreased from inf to 0.698295073075728\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6850910782814026\n",
      "Validation loss decreased from 0.698295073075728 to 0.6975467909466136\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6935741901397705\n",
      "Validation loss decreased from 0.6975467909466136 to 0.69642019813711\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6934059858322144\n",
      "Validation loss decreased from 0.69642019813711 to 0.6963322108442133\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6875425577163696\n",
      "Validation loss decreased from 0.6963322108442133 to 0.6958817189390009\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6899358034133911\n",
      "Validation loss decreased from 0.6958817189390009 to 0.6951874223622408\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6863335371017456\n",
      "Validation loss decreased from 0.6951874223622408 to 0.6949873458255421\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6863316297531128\n",
      "Validation loss decreased from 0.6949873458255421 to 0.6949451457370411\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6865866184234619\n",
      "Validation loss decreased from 0.6949451457370411 to 0.694232848557559\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6847915649414062\n",
      "Validation loss decreased from 0.694232848557559 to 0.6940685131333091\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6871131062507629\n",
      "Validation loss decreased from 0.6940685131333091 to 0.6937908638607372\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6907427906990051\n",
      "Validation loss decreased from 0.6937908638607372 to 0.6934926780787382\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6860579252243042\n",
      "Validation loss decreased from 0.6934926780787382 to 0.6932208646427501\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6812394857406616\n",
      "Validation loss decreased from 0.6932208646427501 to 0.6929666887630116\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6859440207481384\n",
      "Validation loss decreased from 0.6929666887630116 to 0.6925106807188555\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6790846586227417\n",
      "Validation loss decreased from 0.6925106807188555 to 0.6914984908970919\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6820107698440552\n",
      "Validation loss decreased from 0.6914984908970919 to 0.6913584741679105\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6779758334159851\n",
      "Validation loss decreased from 0.6913584741679105 to 0.6903343742544\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6786535382270813\n",
      "Validation loss decreased from 0.6903343742544 to 0.6892289248379794\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6769101619720459\n",
      "Validation loss decreased from 0.6892289248379794 to 0.6890081004662947\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6707665920257568\n",
      "Validation loss decreased from 0.6890081004662947 to 0.6879236806522716\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6714735627174377\n",
      "Validation loss decreased from 0.6879236806522716 to 0.6861002174290743\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6681727170944214\n",
      "Validation loss decreased from 0.6861002174290743 to 0.6840187202800404\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6634677052497864\n",
      "Validation loss decreased from 0.6840187202800404 to 0.6823468695987355\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6588937640190125\n",
      "Validation loss decreased from 0.6823468695987355 to 0.6800537759607489\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6521060466766357\n",
      "Validation loss decreased from 0.6800537759607489 to 0.6753033128651705\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6443578004837036\n",
      "Validation loss decreased from 0.6753033128651705 to 0.6696037541736256\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6140998601913452\n",
      "Validation loss decreased from 0.6696037541736256 to 0.6647548242048784\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6065252423286438\n",
      "Validation loss decreased from 0.6647548242048784 to 0.6560505520213734\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6047911047935486\n",
      "Validation loss decreased from 0.6560505520213734 to 0.6441474611108954\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.5856460928916931\n",
      "Validation loss decreased from 0.6441474611108954 to 0.6311477856202559\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.565429151058197\n",
      "Validation loss decreased from 0.6311477856202559 to 0.6183948083357378\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.5388795733451843\n",
      "Validation loss decreased from 0.6183948083357378 to 0.6058040261268616\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.5329198837280273\n",
      "Validation loss decreased from 0.6058040261268616 to 0.5939522223039106\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.4920833110809326\n",
      "Validation loss decreased from 0.5939522223039106 to 0.583532141013579\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.45703446865081787\n",
      "Validation loss decreased from 0.583532141013579 to 0.5737101842056621\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.46107569336891174\n",
      "Validation loss decreased from 0.5737101842056621 to 0.569406888701699\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.3861001133918762\n",
      "Validation loss decreased from 0.569406888701699 to 0.5653051652691581\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.3789445459842682\n",
      "Validation loss decreased from 0.5653051652691581 to 0.5587929839437659\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.3326300382614136\n",
      "Validation loss decreased from 0.5587929839437659 to 0.5566539926962419\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.3391876220703125\n",
      "Validation loss decreased from 0.5566539926962419 to 0.5539792992851951\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.2969062924385071\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.24969401955604553\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.25376054644584656\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.22590355575084686\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.1774439513683319\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.19704541563987732\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.19570572674274445\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.14844970405101776\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.15503638982772827\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.13483262062072754\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.12512098252773285\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.10882552713155746\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.12409166991710663\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.10945534706115723\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.09679628163576126\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.09564841538667679\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.09864659607410431\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.09808321297168732\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.07739236205816269\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.08842010051012039\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.06921970099210739\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.07945902645587921\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.09084468334913254\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.06963447481393814\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.06987255066633224\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.0687943696975708\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.06177320331335068\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.07222980260848999\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.07414234429597855\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.06547027826309204\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.06489623337984085\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.0668296292424202\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.08411763608455658\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.04932362586259842\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05730917677283287\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.06192563846707344\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.06124433875083923\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.06542795896530151\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.07745756208896637\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.05376449599862099\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.05889725685119629\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.0632425844669342\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.0631420761346817\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.07302737236022949\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.049331799149513245\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.05568185821175575\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.08343887329101562\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.06089738756418228\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.056200455874204636\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.0543600395321846\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  41\n",
      "AUC on test data  0.8051533698221396\n",
      "model 6 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7042303681373596\n",
      "Validation loss decreased from inf to 0.6930937333540483\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.7037003040313721\n",
      "Validation loss decreased from 0.6930937333540483 to 0.6929514787413857\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7031750679016113\n",
      "Validation loss decreased from 0.6929514787413857 to 0.6928189125928012\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7026749849319458\n",
      "Validation loss decreased from 0.6928189125928012 to 0.6926998766985807\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7021994590759277\n",
      "Validation loss decreased from 0.6926998766985807 to 0.6925935095006769\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.7017470002174377\n",
      "Validation loss decreased from 0.6925935095006769 to 0.6924993070689115\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7013172507286072\n",
      "Validation loss decreased from 0.6924993070689115 to 0.6924172639846802\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7009086012840271\n",
      "Validation loss decreased from 0.6924172639846802 to 0.6923470388759266\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.7005200386047363\n",
      "Validation loss decreased from 0.6923470388759266 to 0.6922877647659995\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7001490592956543\n",
      "Validation loss decreased from 0.6922877647659995 to 0.692238368771293\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6997934579849243\n",
      "Validation loss decreased from 0.692238368771293 to 0.6921978159384294\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6994553804397583\n",
      "Validation loss decreased from 0.6921978159384294 to 0.6921650984070518\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6991324424743652\n",
      "Validation loss decreased from 0.6921650984070518 to 0.6921392191540111\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.698824942111969\n",
      "Validation loss decreased from 0.6921392191540111 to 0.6921201348304749\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6985312104225159\n",
      "Validation loss decreased from 0.6921201348304749 to 0.6921072060411627\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6982520818710327\n",
      "Validation loss decreased from 0.6921072060411627 to 0.6920992515303872\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6979858875274658\n",
      "Validation loss decreased from 0.6920992515303872 to 0.692096168344671\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6977326273918152\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6974906921386719\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6972597241401672\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6970403790473938\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.696832001209259\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6966341733932495\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.696445107460022\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6962628960609436\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6960875391960144\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6959196329116821\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6957586407661438\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6956048607826233\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.695458173751831\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6953179836273193\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6951832175254822\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6950541734695435\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.694930374622345\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6948115229606628\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6946972012519836\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6945872902870178\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6944819688796997\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6943807601928711\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6942835450172424\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6941898465156555\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6940997838973999\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6940129399299622\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.69392991065979\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6938503980636597\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6937741041183472\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6937006711959839\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6936301589012146\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6935616135597229\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6934956908226013\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6934325695037842\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6933714747428894\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.69331294298172\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6932564377784729\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6932020783424377\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.693149745464325\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6930992007255554\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6930501461029053\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6930025219917297\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.692956805229187\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6929126977920532\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6928696036338806\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6928263902664185\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6927840709686279\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6927427649497986\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6927027106285095\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6926640868186951\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  17\n",
      "AUC on test data  0.5002875965021075\n",
      "model 7 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6881495118141174\n",
      "Validation loss decreased from inf to 0.6951044472781095\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6931572556495667\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6934845447540283\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6891033053398132\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6890130639076233\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.691743016242981\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6903926730155945\n",
      "Validation loss decreased from 0.6951044472781095 to 0.6950790286064148\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6901453137397766\n",
      "Validation loss decreased from 0.6950790286064148 to 0.6950434012846514\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6893203258514404\n",
      "Validation loss decreased from 0.6950434012846514 to 0.6949488087133928\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.688277542591095\n",
      "Validation loss decreased from 0.6949488087133928 to 0.694743730805137\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6891166567802429\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6883733868598938\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6912633776664734\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6893941760063171\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6894297003746033\n",
      "Validation loss decreased from 0.694743730805137 to 0.6942305998368696\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.690243124961853\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6898016333580017\n",
      "Validation loss decreased from 0.6942305998368696 to 0.6940868551080878\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6875323057174683\n",
      "Validation loss decreased from 0.6940868551080878 to 0.6940550153905695\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6877580285072327\n",
      "Validation loss decreased from 0.6940550153905695 to 0.6939384937286377\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6875377893447876\n",
      "Validation loss decreased from 0.6939384937286377 to 0.6930638443339955\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6894142031669617\n",
      "Validation loss decreased from 0.6930638443339955 to 0.6924778927456249\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6848684549331665\n",
      "Validation loss decreased from 0.6924778927456249 to 0.6924426826563749\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6895740628242493\n",
      "Validation loss decreased from 0.6924426826563749 to 0.6917986382137645\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6779758930206299\n",
      "Validation loss decreased from 0.6917986382137645 to 0.6917964003302834\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6857909560203552\n",
      "Validation loss decreased from 0.6917964003302834 to 0.6913732561198148\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.684203028678894\n",
      "Validation loss decreased from 0.6913732561198148 to 0.6909682263027538\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6860494017601013\n",
      "Validation loss decreased from 0.6909682263027538 to 0.6903556097637523\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6787716150283813\n",
      "Validation loss decreased from 0.6903556097637523 to 0.6900687434456565\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6792207360267639\n",
      "Validation loss decreased from 0.6900687434456565 to 0.6882014382969249\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6812635660171509\n",
      "Validation loss decreased from 0.6882014382969249 to 0.6869440241293474\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6735566854476929\n",
      "Validation loss decreased from 0.6869440241293474 to 0.6859562722119418\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6735196113586426\n",
      "Validation loss decreased from 0.6859562722119418 to 0.6843872287056663\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6646976470947266\n",
      "Validation loss decreased from 0.6843872287056663 to 0.6825088641860269\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6633726358413696\n",
      "Validation loss decreased from 0.6825088641860269 to 0.6789675517515703\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6599783301353455\n",
      "Validation loss decreased from 0.6789675517515703 to 0.6764888221567328\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6518169045448303\n",
      "Validation loss decreased from 0.6764888221567328 to 0.672220300544392\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6583275198936462\n",
      "Validation loss decreased from 0.672220300544392 to 0.66796490279111\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.636544406414032\n",
      "Validation loss decreased from 0.66796490279111 to 0.6615243662487377\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6019715070724487\n",
      "Validation loss decreased from 0.6615243662487377 to 0.6553291407498446\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.5806742906570435\n",
      "Validation loss decreased from 0.6553291407498446 to 0.6439052982763811\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6210564374923706\n",
      "Validation loss decreased from 0.6439052982763811 to 0.6332240538163618\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.593000054359436\n",
      "Validation loss decreased from 0.6332240538163618 to 0.6216240741989829\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.5454186797142029\n",
      "Validation loss decreased from 0.6216240741989829 to 0.6100334037433971\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.5831834077835083\n",
      "Validation loss decreased from 0.6100334037433971 to 0.6008685610511086\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.47505882382392883\n",
      "Validation loss decreased from 0.6008685610511086 to 0.5883027531883933\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.5255329608917236\n",
      "Validation loss decreased from 0.5883027531883933 to 0.5831906470385465\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.48441603779792786\n",
      "Validation loss decreased from 0.5831906470385465 to 0.570855671709234\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.4312089681625366\n",
      "Validation loss decreased from 0.570855671709234 to 0.5624513951214877\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.4766142666339874\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.4093799591064453\n",
      "Validation loss decreased from 0.5624513951214877 to 0.5524037642912432\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.4601224958896637\n",
      "Validation loss decreased from 0.5524037642912432 to 0.5480238822373477\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.3740750849246979\n",
      "Validation loss decreased from 0.5480238822373477 to 0.542514521967281\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.40047094225883484\n",
      "Validation loss decreased from 0.542514521967281 to 0.5379741246050055\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.3770560324192047\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.3590615391731262\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.3305222988128662\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.278082937002182\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.2864314615726471\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.20937828719615936\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.24966634809970856\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.23127590119838715\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.18583108484745026\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.21118131279945374\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.1982937902212143\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.1356675773859024\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.13608494400978088\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.1574876308441162\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.141372948884964\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.14275020360946655\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.11828076094388962\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.11488492786884308\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.12785746157169342\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.08522307127714157\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.1091599240899086\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.09126198291778564\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.12076716125011444\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.09018953144550323\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.10155133903026581\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.11807472258806229\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.06639401614665985\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.08062615245580673\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.09196669608354568\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.11428048461675644\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.08483905345201492\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.0849103331565857\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.08499976992607117\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.08375462144613266\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.08957800269126892\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.08499998599290848\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.07304270565509796\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.06578424572944641\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.08575032651424408\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.08216294646263123\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.0704931989312172\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.08157516270875931\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.08590129762887955\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.06265603750944138\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.07541726529598236\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.07032570987939835\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.08020590245723724\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.06071818992495537\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.06176456809043884\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.06330511718988419\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  53\n",
      "AUC on test data  0.8111928963663979\n",
      "model 8 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6834548115730286\n",
      "Validation loss decreased from inf to 0.693726349960674\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6823089122772217\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6788432598114014\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6890448331832886\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6892881989479065\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6902912855148315\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6829365491867065\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7013090252876282\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.695299506187439\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6955561637878418\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6883729696273804\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6839016079902649\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6905406713485718\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6862985491752625\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6906407475471497\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6936272382736206\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6930509209632874\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6884498000144958\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6964329481124878\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6908723711967468\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6966879367828369\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6897410154342651\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6861363649368286\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6885152459144592\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.682744562625885\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.696251630783081\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6879521012306213\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6962398290634155\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6927129626274109\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6843866109848022\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6864356398582458\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6887964606285095\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6928214430809021\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6959071755409241\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6896368861198425\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6812083125114441\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6926469206809998\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6911230683326721\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6862617135047913\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6927148699760437\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6967279314994812\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6832167506217957\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6932637691497803\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6939646601676941\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6951303482055664\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.68392014503479\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6926238536834717\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6826763153076172\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6816470623016357\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6875894665718079\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.701341450214386\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.555434225781229\n",
      "model 9 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.690041184425354\n",
      "Validation loss decreased from inf to 0.7031404701146212\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6885079145431519\n",
      "Validation loss decreased from 0.7031404701146212 to 0.6953024593266574\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6876239776611328\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6867669224739075\n",
      "Validation loss decreased from 0.6953024593266574 to 0.6948093284260143\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6857960820198059\n",
      "Validation loss decreased from 0.6948093284260143 to 0.6940941377119585\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6845976114273071\n",
      "Validation loss decreased from 0.6940941377119585 to 0.6935085600072687\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6832608580589294\n",
      "Validation loss decreased from 0.6935085600072687 to 0.6928587881001559\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6816502809524536\n",
      "Validation loss decreased from 0.6928587881001559 to 0.6921613920818676\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6797392964363098\n",
      "Validation loss decreased from 0.6921613920818676 to 0.6913506551222368\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6776064038276672\n",
      "Validation loss decreased from 0.6913506551222368 to 0.6903980591080405\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.675170361995697\n",
      "Validation loss decreased from 0.6903980591080405 to 0.6892782829024575\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6722461581230164\n",
      "Validation loss decreased from 0.6892782829024575 to 0.6878537102179094\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6684455871582031\n",
      "Validation loss decreased from 0.6878537102179094 to 0.6861521818421104\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6637650728225708\n",
      "Validation loss decreased from 0.6861521818421104 to 0.6839120929891412\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6584554314613342\n",
      "Validation loss decreased from 0.6839120929891412 to 0.6813449642874978\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.651900589466095\n",
      "Validation loss decreased from 0.6813449642874978 to 0.6781305724924261\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6435765027999878\n",
      "Validation loss decreased from 0.6781305724924261 to 0.6739466352896257\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6326054334640503\n",
      "Validation loss decreased from 0.6739466352896257 to 0.6683180657300082\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6191877722740173\n",
      "Validation loss decreased from 0.6683180657300082 to 0.6603143323551525\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.602135956287384\n",
      "Validation loss decreased from 0.6603143323551525 to 0.6489445783875205\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.581624448299408\n",
      "Validation loss decreased from 0.6489445783875205 to 0.6340419921008024\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.5578248500823975\n",
      "Validation loss decreased from 0.6340419921008024 to 0.6182683489539407\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.529658854007721\n",
      "Validation loss decreased from 0.6182683489539407 to 0.6024854562499307\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.49522849917411804\n",
      "Validation loss decreased from 0.6024854562499307 to 0.5868850350379944\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.4598527252674103\n",
      "Validation loss decreased from 0.5868850350379944 to 0.5724320790984414\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.4229505658149719\n",
      "Validation loss decreased from 0.5724320790984414 to 0.5595066466114738\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.38856223225593567\n",
      "Validation loss decreased from 0.5595066466114738 to 0.5507988604632291\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.3571856915950775\n",
      "Validation loss decreased from 0.5507988604632291 to 0.544693570245396\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.32645294070243835\n",
      "Validation loss decreased from 0.544693570245396 to 0.5408544567498293\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.29555076360702515\n",
      "Validation loss decreased from 0.5408544567498293 to 0.5403166765516455\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.2670566737651825\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.2433534413576126\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.22086642682552338\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.2006492018699646\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.18114550411701202\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.16178999841213226\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.14826661348342896\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.13494014739990234\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.12412051111459732\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.11248504370450974\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.10401894897222519\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.0946124866604805\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.08842257410287857\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.08132168650627136\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.07571573555469513\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.07202484458684921\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.06811953336000443\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.06538520753383636\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.06310401856899261\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.06095987185835838\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.05897188559174538\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.057340070605278015\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.05591506510972977\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.05451635643839836\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.05346158519387245\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.05230337008833885\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.05144896358251572\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.05028439313173294\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.04995369911193848\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.048755109310150146\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.04873109981417656\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.04803226888179779\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.04803599789738655\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.047496695071458817\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.0476887971162796\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.04733659699559212\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.04709703102707863\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.047029659152030945\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.04687229171395302\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.04679673910140991\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.04620653763413429\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.04616757482290268\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.04607011750340462\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.045847583562135696\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.04585294425487518\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.04540272057056427\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.04534827545285225\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.045600276440382004\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.04552153870463371\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.04531347006559372\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  30\n",
      "AUC on test data  0.8304438872262216\n",
      "model 10 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6932676434516907\n",
      "Validation loss decreased from inf to 0.6937960711392489\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6930072903633118\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6928207874298096\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6926782727241516\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6925586462020874\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6924517750740051\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6923540234565735\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6922623515129089\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6921760439872742\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6920953392982483\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6920188665390015\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6919459104537964\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6918732523918152\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6918032765388489\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6917347311973572\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6916676759719849\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6916036009788513\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6915425062179565\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6914830803871155\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6914240717887878\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6913660168647766\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.691308856010437\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6912527084350586\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6911970376968384\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6911419034004211\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6910868883132935\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6910329461097717\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6909806728363037\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6909294724464417\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6908804774284363\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6908321976661682\n",
      "Validation loss decreased from 0.6937960711392489 to 0.6937923973256891\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6907826662063599\n",
      "Validation loss decreased from 0.6937923973256891 to 0.6937624270265753\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6907346248626709\n",
      "Validation loss decreased from 0.6937624270265753 to 0.6937330744483254\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6906875967979431\n",
      "Validation loss decreased from 0.6937330744483254 to 0.6937045129862699\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6906406283378601\n",
      "Validation loss decreased from 0.6937045129862699 to 0.693676157431169\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6905937194824219\n",
      "Validation loss decreased from 0.693676157431169 to 0.6936477422714233\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6905466914176941\n",
      "Validation loss decreased from 0.6936477422714233 to 0.6936197226697748\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6904999017715454\n",
      "Validation loss decreased from 0.6936197226697748 to 0.6935927163470875\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6904539465904236\n",
      "Validation loss decreased from 0.6935927163470875 to 0.693566008047624\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6904087066650391\n",
      "Validation loss decreased from 0.693566008047624 to 0.6935385248877786\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6903639435768127\n",
      "Validation loss decreased from 0.6935385248877786 to 0.6935112313790754\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6903188824653625\n",
      "Validation loss decreased from 0.6935112313790754 to 0.6934833526611328\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6902740001678467\n",
      "Validation loss decreased from 0.6934833526611328 to 0.6934560320594094\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6902281641960144\n",
      "Validation loss decreased from 0.6934560320594094 to 0.6934287006204779\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6901812553405762\n",
      "Validation loss decreased from 0.6934287006204779 to 0.6934014721350237\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6901344060897827\n",
      "Validation loss decreased from 0.6934014721350237 to 0.6933739727193658\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6900878548622131\n",
      "Validation loss decreased from 0.6933739727193658 to 0.6933454058387063\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6900423765182495\n",
      "Validation loss decreased from 0.6933454058387063 to 0.6933171803301031\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6899973750114441\n",
      "Validation loss decreased from 0.6933171803301031 to 0.693289502100511\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6899501085281372\n",
      "Validation loss decreased from 0.693289502100511 to 0.6932613199407404\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6899024844169617\n",
      "Validation loss decreased from 0.6932613199407404 to 0.6932332136414268\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6898553371429443\n",
      "Validation loss decreased from 0.6932332136414268 to 0.6932053403420881\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6898095607757568\n",
      "Validation loss decreased from 0.6932053403420881 to 0.6931775916706432\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6897635459899902\n",
      "Validation loss decreased from 0.6931775916706432 to 0.6931504011154175\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6897173523902893\n",
      "Validation loss decreased from 0.6931504011154175 to 0.6931225494904951\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6896716356277466\n",
      "Validation loss decreased from 0.6931225494904951 to 0.6930955214933916\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6896248459815979\n",
      "Validation loss decreased from 0.6930955214933916 to 0.6930686723102223\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6895767450332642\n",
      "Validation loss decreased from 0.6930686723102223 to 0.6930414275689558\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6895294189453125\n",
      "Validation loss decreased from 0.6930414275689558 to 0.6930146542462435\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.689481258392334\n",
      "Validation loss decreased from 0.6930146542462435 to 0.6929875178770586\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6894327998161316\n",
      "Validation loss decreased from 0.6929875178770586 to 0.6929598504846747\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6893849968910217\n",
      "Validation loss decreased from 0.6929598504846747 to 0.6929324540224943\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6893368363380432\n",
      "Validation loss decreased from 0.6929324540224943 to 0.6929048462347551\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6892873048782349\n",
      "Validation loss decreased from 0.6929048462347551 to 0.6928764906796542\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.689237117767334\n",
      "Validation loss decreased from 0.6928764906796542 to 0.6928465583107688\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6891870498657227\n",
      "Validation loss decreased from 0.6928465583107688 to 0.6928167180581526\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6891354322433472\n",
      "Validation loss decreased from 0.6928167180581526 to 0.692786617712541\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6890823841094971\n",
      "Validation loss decreased from 0.692786617712541 to 0.6927559809251265\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.689028799533844\n",
      "Validation loss decreased from 0.6927559809251265 to 0.6927252953702753\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6889740824699402\n",
      "Validation loss decreased from 0.6927252953702753 to 0.6926939595829357\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6889188289642334\n",
      "Validation loss decreased from 0.6926939595829357 to 0.6926625533537432\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6888624429702759\n",
      "Validation loss decreased from 0.6926625533537432 to 0.6926308707757429\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6888054609298706\n",
      "Validation loss decreased from 0.6926308707757429 to 0.6925989551977678\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.688748836517334\n",
      "Validation loss decreased from 0.6925989551977678 to 0.6925662485035983\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6886915564537048\n",
      "Validation loss decreased from 0.6925662485035983 to 0.6925327344374224\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6886338591575623\n",
      "Validation loss decreased from 0.6925327344374224 to 0.692498423836448\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6885758638381958\n",
      "Validation loss decreased from 0.692498423836448 to 0.6924638477238741\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6885168552398682\n",
      "Validation loss decreased from 0.6924638477238741 to 0.6924284208904613\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6884565949440002\n",
      "Validation loss decreased from 0.6924284208904613 to 0.6923925443129106\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6883938312530518\n",
      "Validation loss decreased from 0.6923925443129106 to 0.6923562505028464\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6883285045623779\n",
      "Validation loss decreased from 0.6923562505028464 to 0.6923188892277804\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6882616281509399\n",
      "Validation loss decreased from 0.6923188892277804 to 0.6922812190922824\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6881936192512512\n",
      "Validation loss decreased from 0.6922812190922824 to 0.692242752421986\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.688126266002655\n",
      "Validation loss decreased from 0.692242752421986 to 0.6922037980773232\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6880597472190857\n",
      "Validation loss decreased from 0.6922037980773232 to 0.6921650875698436\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.687991738319397\n",
      "Validation loss decreased from 0.6921650875698436 to 0.6921256509694186\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.68792325258255\n",
      "Validation loss decreased from 0.6921256509694186 to 0.692085862159729\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6878547072410583\n",
      "Validation loss decreased from 0.692085862159729 to 0.6920455910942771\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6877868175506592\n",
      "Validation loss decreased from 0.6920455910942771 to 0.692004994912581\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6877180337905884\n",
      "Validation loss decreased from 0.692004994912581 to 0.6919641223820773\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.687648355960846\n",
      "Validation loss decreased from 0.6919641223820773 to 0.6919234178282998\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6875767111778259\n",
      "Validation loss decreased from 0.6919234178282998 to 0.6918808980421587\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6875048875808716\n",
      "Validation loss decreased from 0.6918808980421587 to 0.6918381723490629\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6874330639839172\n",
      "Validation loss decreased from 0.6918381723490629 to 0.691794297911904\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.687360405921936\n",
      "Validation loss decreased from 0.691794297911904 to 0.6917499087073586\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6872866749763489\n",
      "Validation loss decreased from 0.6917499087073586 to 0.6917041919448159\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6872116923332214\n",
      "Validation loss decreased from 0.6917041919448159 to 0.6916579712520946\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.687134861946106\n",
      "Validation loss decreased from 0.6916579712520946 to 0.6916106072339144\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6870564222335815\n",
      "Validation loss decreased from 0.6916106072339144 to 0.6915631673552773\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6869761943817139\n",
      "Validation loss decreased from 0.6915631673552773 to 0.691514481197704\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6868950724601746\n",
      "Validation loss decreased from 0.691514481197704 to 0.691465291109952\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.686812698841095\n",
      "Validation loss decreased from 0.691465291109952 to 0.69141531532461\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.68673175573349\n",
      "Validation loss decreased from 0.69141531532461 to 0.6913647976788607\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6866505742073059\n",
      "Validation loss decreased from 0.6913647976788607 to 0.6913132884285667\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.686568558216095\n",
      "Validation loss decreased from 0.6913132884285667 to 0.6912609934806824\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6864867806434631\n",
      "Validation loss decreased from 0.6912609934806824 to 0.6912080862305381\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6864045858383179\n",
      "Validation loss decreased from 0.6912080862305381 to 0.6911542469804938\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6863210797309875\n",
      "Validation loss decreased from 0.6911542469804938 to 0.6910983378236945\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.686235785484314\n",
      "Validation loss decreased from 0.6910983378236945 to 0.6910412040623751\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6861477494239807\n",
      "Validation loss decreased from 0.6910412040623751 to 0.6909827264872465\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.686056911945343\n",
      "Validation loss decreased from 0.6909827264872465 to 0.6909224878657948\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6859644651412964\n",
      "Validation loss decreased from 0.6909224878657948 to 0.6908603256398981\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6858717799186707\n",
      "Validation loss decreased from 0.6908603256398981 to 0.690797280181538\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6857790946960449\n",
      "Validation loss decreased from 0.690797280181538 to 0.6907340721650557\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6856847405433655\n",
      "Validation loss decreased from 0.6907340721650557 to 0.6906700080091303\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6855882406234741\n",
      "Validation loss decreased from 0.6906700080091303 to 0.6906054670160467\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6854890584945679\n",
      "Validation loss decreased from 0.6906054670160467 to 0.6905399560928345\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6853882670402527\n",
      "Validation loss decreased from 0.6905399560928345 to 0.6904735565185547\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6852840185165405\n",
      "Validation loss decreased from 0.6904735565185547 to 0.6904054121537642\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6851760745048523\n",
      "Validation loss decreased from 0.6904054121537642 to 0.6903343363241716\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6850658059120178\n",
      "Validation loss decreased from 0.6903343363241716 to 0.690261656587774\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6849556565284729\n",
      "Validation loss decreased from 0.690261656587774 to 0.6901876601305875\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.684842586517334\n",
      "Validation loss decreased from 0.6901876601305875 to 0.6901129700920798\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6847281455993652\n",
      "Validation loss decreased from 0.6901129700920798 to 0.6900363672863353\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6846110224723816\n",
      "Validation loss decreased from 0.6900363672863353 to 0.6899586482481523\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6844890713691711\n",
      "Validation loss decreased from 0.6899586482481523 to 0.6898783878846602\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6843643188476562\n",
      "Validation loss decreased from 0.6898783878846602 to 0.6897954507307573\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6842366456985474\n",
      "Validation loss decreased from 0.6897954507307573 to 0.6897107850421559\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6841062903404236\n",
      "Validation loss decreased from 0.6897107850421559 to 0.6896257292140614\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6839751601219177\n",
      "Validation loss decreased from 0.6896257292140614 to 0.6895393675023859\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6838427186012268\n",
      "Validation loss decreased from 0.6895393675023859 to 0.6894512718374078\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6837078332901001\n",
      "Validation loss decreased from 0.6894512718374078 to 0.6893621141260321\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6835693717002869\n",
      "Validation loss decreased from 0.6893621141260321 to 0.6892707022753629\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6834296584129333\n",
      "Validation loss decreased from 0.6892707022753629 to 0.689176922494715\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6832872033119202\n",
      "Validation loss decreased from 0.689176922494715 to 0.6890816959467801\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6831420063972473\n",
      "Validation loss decreased from 0.6890816959467801 to 0.6889852014454928\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6829918622970581\n",
      "Validation loss decreased from 0.6889852014454928 to 0.6888870922001925\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6828382611274719\n",
      "Validation loss decreased from 0.6888870922001925 to 0.6887857751412825\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6826810240745544\n",
      "Validation loss decreased from 0.6887857751412825 to 0.6886817758733575\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6825214624404907\n",
      "Validation loss decreased from 0.6886817758733575 to 0.6885751214894381\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6823601126670837\n",
      "Validation loss decreased from 0.6885751214894381 to 0.6884663917801597\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6821954250335693\n",
      "Validation loss decreased from 0.6884663917801597 to 0.6883556680245833\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6820287108421326\n",
      "Validation loss decreased from 0.6883556680245833 to 0.6882437142458829\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6818587779998779\n",
      "Validation loss decreased from 0.6882437142458829 to 0.6881282275373285\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6816872358322144\n",
      "Validation loss decreased from 0.6881282275373285 to 0.688009337945418\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6815100312232971\n",
      "Validation loss decreased from 0.688009337945418 to 0.6878885193304582\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6813298463821411\n",
      "Validation loss decreased from 0.6878885193304582 to 0.6877657987854697\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6811463832855225\n",
      "Validation loss decreased from 0.6877657987854697 to 0.6876402334733442\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6809601187705994\n",
      "Validation loss decreased from 0.6876402334733442 to 0.6875122352079912\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6807693839073181\n",
      "Validation loss decreased from 0.6875122352079912 to 0.6873816089196638\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6805726289749146\n",
      "Validation loss decreased from 0.6873816089196638 to 0.6872483708641746\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6803702116012573\n",
      "Validation loss decreased from 0.6872483708641746 to 0.6871128028089349\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.680162787437439\n",
      "Validation loss decreased from 0.6871128028089349 to 0.6869736422191967\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6799522638320923\n",
      "Validation loss decreased from 0.6869736422191967 to 0.6868307753042742\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6797327399253845\n",
      "Validation loss decreased from 0.6868307753042742 to 0.6866835409944708\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6795066595077515\n",
      "Validation loss decreased from 0.6866835409944708 to 0.6865324974060059\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6792708039283752\n",
      "Validation loss decreased from 0.6865324974060059 to 0.6863786253062162\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6790264844894409\n",
      "Validation loss decreased from 0.6863786253062162 to 0.6862213990905068\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6787761449813843\n",
      "Validation loss decreased from 0.6862213990905068 to 0.6860590252009305\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6785176396369934\n",
      "Validation loss decreased from 0.6860590252009305 to 0.68589294498617\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6782522201538086\n",
      "Validation loss decreased from 0.68589294498617 to 0.68572213974866\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6779797077178955\n",
      "Validation loss decreased from 0.68572213974866 to 0.6855462735349481\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6776951551437378\n",
      "Validation loss decreased from 0.6855462735349481 to 0.685366381298412\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6773990392684937\n",
      "Validation loss decreased from 0.685366381298412 to 0.6851834112947638\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6770936846733093\n",
      "Validation loss decreased from 0.6851834112947638 to 0.6849975802681663\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6767805218696594\n",
      "Validation loss decreased from 0.6849975802681663 to 0.6848052144050598\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6764611601829529\n",
      "Validation loss decreased from 0.6848052144050598 to 0.6846068555658514\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6761366128921509\n",
      "Validation loss decreased from 0.6846068555658514 to 0.6844028667970137\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6758056879043579\n",
      "Validation loss decreased from 0.6844028667970137 to 0.6841949170286005\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.675460159778595\n",
      "Validation loss decreased from 0.6841949170286005 to 0.6839825077490373\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6751055121421814\n",
      "Validation loss decreased from 0.6839825077490373 to 0.6837654926560142\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6747409701347351\n",
      "Validation loss decreased from 0.6837654926560142 to 0.6835446628657255\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6743671298027039\n",
      "Validation loss decreased from 0.6835446628657255 to 0.6833185932853005\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6739773750305176\n",
      "Validation loss decreased from 0.6833185932853005 to 0.6830878745425831\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6735735535621643\n",
      "Validation loss decreased from 0.6830878745425831 to 0.6828559095209296\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.673166811466217\n",
      "Validation loss decreased from 0.6828559095209296 to 0.682619495825334\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6727468967437744\n",
      "Validation loss decreased from 0.682619495825334 to 0.6823781512000344\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6723167300224304\n",
      "Validation loss decreased from 0.6823781512000344 to 0.6821308081800287\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6718786954879761\n",
      "Validation loss decreased from 0.6821308081800287 to 0.6818776401606473\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6714292764663696\n",
      "Validation loss decreased from 0.6818776401606473 to 0.681618105281483\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6709719300270081\n",
      "Validation loss decreased from 0.681618105281483 to 0.6813548586585305\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6705092191696167\n",
      "Validation loss decreased from 0.6813548586585305 to 0.6810821999203075\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6700407266616821\n",
      "Validation loss decreased from 0.6810821999203075 to 0.680802350694483\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6695590615272522\n",
      "Validation loss decreased from 0.680802350694483 to 0.6805155873298645\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6690608263015747\n",
      "Validation loss decreased from 0.6805155873298645 to 0.680219980803403\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6685505509376526\n",
      "Validation loss decreased from 0.680219980803403 to 0.6799171512777155\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6680250763893127\n",
      "Validation loss decreased from 0.6799171512777155 to 0.6796045953577216\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6674866080284119\n",
      "Validation loss decreased from 0.6796045953577216 to 0.6792835864153776\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6669313311576843\n",
      "Validation loss decreased from 0.6792835864153776 to 0.6789553707296198\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6663541197776794\n",
      "Validation loss decreased from 0.6789553707296198 to 0.6786194931377064\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6657644510269165\n",
      "Validation loss decreased from 0.6786194931377064 to 0.6782727566632357\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6651650071144104\n",
      "Validation loss decreased from 0.6782727566632357 to 0.6779185262593356\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.664551854133606\n",
      "Validation loss decreased from 0.6779185262593356 to 0.6775533665310253\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6639260053634644\n",
      "Validation loss decreased from 0.6775533665310253 to 0.6771756139668551\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6632918119430542\n",
      "Validation loss decreased from 0.6771756139668551 to 0.6767901832407172\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.66264408826828\n",
      "Validation loss decreased from 0.6767901832407172 to 0.6763933138413862\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.661988377571106\n",
      "Validation loss decreased from 0.6763933138413862 to 0.6759906465357001\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6613140106201172\n",
      "Validation loss decreased from 0.6759906465357001 to 0.6755748607895591\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.660616934299469\n",
      "Validation loss decreased from 0.6755748607895591 to 0.6751449595798146\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.659906804561615\n",
      "Validation loss decreased from 0.6751449595798146 to 0.6747016364877875\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6591721773147583\n",
      "Validation loss decreased from 0.6747016364877875 to 0.6742469722574408\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.658412754535675\n",
      "Validation loss decreased from 0.6742469722574408 to 0.6737789511680603\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6576380133628845\n",
      "Validation loss decreased from 0.6737789511680603 to 0.6732943003827875\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6568384170532227\n",
      "Validation loss decreased from 0.6732943003827875 to 0.6728011803193525\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6560185551643372\n",
      "Validation loss decreased from 0.6728011803193525 to 0.672301942651922\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.655173122882843\n",
      "Validation loss decreased from 0.672301942651922 to 0.6717921061949297\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6543058753013611\n",
      "Validation loss decreased from 0.6717921061949297 to 0.6712644262747332\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.653408944606781\n",
      "Validation loss decreased from 0.6712644262747332 to 0.6707295233553107\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6524830460548401\n",
      "Validation loss decreased from 0.6707295233553107 to 0.6701806241815741\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6515386700630188\n",
      "Validation loss decreased from 0.6701806241815741 to 0.6696179617534984\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6505765318870544\n",
      "Validation loss decreased from 0.6696179617534984 to 0.6690401380712335\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6495692133903503\n",
      "Validation loss decreased from 0.6690401380712335 to 0.6684490171345797\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6485402584075928\n",
      "Validation loss decreased from 0.6684490171345797 to 0.6678449348969893\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.647469699382782\n",
      "Validation loss decreased from 0.6678449348969893 to 0.6672163172201677\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6463645696640015\n",
      "Validation loss decreased from 0.6672163172201677 to 0.6665723107077859\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.645248532295227\n",
      "Validation loss decreased from 0.6665723107077859 to 0.665902853012085\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6440957188606262\n",
      "Validation loss decreased from 0.665902853012085 to 0.6652130376208912\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6429075598716736\n",
      "Validation loss decreased from 0.6652130376208912 to 0.6645164327187971\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.641693651676178\n",
      "Validation loss decreased from 0.6645164327187971 to 0.6637901284477927\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6404229998588562\n",
      "Validation loss decreased from 0.6637901284477927 to 0.6630288795991377\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6391150951385498\n",
      "Validation loss decreased from 0.6630288795991377 to 0.662253434007818\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6377629637718201\n",
      "Validation loss decreased from 0.662253434007818 to 0.6614529111168601\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6363623738288879\n",
      "Validation loss decreased from 0.6614529111168601 to 0.6606238538568671\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6349009275436401\n",
      "Validation loss decreased from 0.6606238538568671 to 0.6597707921808417\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6333927512168884\n",
      "Validation loss decreased from 0.6597707921808417 to 0.6588872671127319\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6318497061729431\n",
      "Validation loss decreased from 0.6588872671127319 to 0.6579813632098112\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6302878260612488\n",
      "Validation loss decreased from 0.6579813632098112 to 0.6570394310084257\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6286929845809937\n",
      "Validation loss decreased from 0.6570394310084257 to 0.6560572223229841\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6270579099655151\n",
      "Validation loss decreased from 0.6560572223229841 to 0.6550494432449341\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6253733038902283\n",
      "Validation loss decreased from 0.6550494432449341 to 0.6540186080065641\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6236549019813538\n",
      "Validation loss decreased from 0.6540186080065641 to 0.6529584093527361\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.621894896030426\n",
      "Validation loss decreased from 0.6529584093527361 to 0.6518690857020292\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6200466156005859\n",
      "Validation loss decreased from 0.6518690857020292 to 0.650767982006073\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6181505918502808\n",
      "Validation loss decreased from 0.650767982006073 to 0.6496195793151855\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6161983609199524\n",
      "Validation loss decreased from 0.6496195793151855 to 0.6484525474635038\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6141689419746399\n",
      "Validation loss decreased from 0.6484525474635038 to 0.6472319635477933\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6120675206184387\n",
      "Validation loss decreased from 0.6472319635477933 to 0.6459767872636969\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6098954677581787\n",
      "Validation loss decreased from 0.6459767872636969 to 0.6447011124004017\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6076750755310059\n",
      "Validation loss decreased from 0.6447011124004017 to 0.643389409238642\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6054095029830933\n",
      "Validation loss decreased from 0.643389409238642 to 0.6420352079651572\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6031023263931274\n",
      "Validation loss decreased from 0.6420352079651572 to 0.6406521201133728\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6007253527641296\n",
      "Validation loss decreased from 0.6406521201133728 to 0.6392344344745983\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.5982692837715149\n",
      "Validation loss decreased from 0.6392344344745983 to 0.6377883878621188\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.5957479476928711\n",
      "Validation loss decreased from 0.6377883878621188 to 0.6363145275549456\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.5931679010391235\n",
      "Validation loss decreased from 0.6363145275549456 to 0.6348085674372587\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.5905419588088989\n",
      "Validation loss decreased from 0.6348085674372587 to 0.6332873539491133\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.5878620147705078\n",
      "Validation loss decreased from 0.6332873539491133 to 0.6317143331874501\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.585136353969574\n",
      "Validation loss decreased from 0.6317143331874501 to 0.6301029107787393\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.5823196172714233\n",
      "Validation loss decreased from 0.6301029107787393 to 0.6284294345162131\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.5794394016265869\n",
      "Validation loss decreased from 0.6284294345162131 to 0.6267236416990106\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.576459527015686\n",
      "Validation loss decreased from 0.6267236416990106 to 0.6249958547678861\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.5733744502067566\n",
      "Validation loss decreased from 0.6249958547678861 to 0.6232304952361367\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.5702741742134094\n",
      "Validation loss decreased from 0.6232304952361367 to 0.6214328570799394\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.5671659111976624\n",
      "Validation loss decreased from 0.6214328570799394 to 0.6195887652310458\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.5640259385108948\n",
      "Validation loss decreased from 0.6195887652310458 to 0.6177309047092091\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.5607346892356873\n",
      "Validation loss decreased from 0.6177309047092091 to 0.6158344854008068\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.557400107383728\n",
      "Validation loss decreased from 0.6158344854008068 to 0.6139103932814165\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.5539975166320801\n",
      "Validation loss decreased from 0.6139103932814165 to 0.6119678128849376\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.5505510568618774\n",
      "Validation loss decreased from 0.6119678128849376 to 0.6099842678416859\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.5470770597457886\n",
      "Validation loss decreased from 0.6099842678416859 to 0.6079919663342562\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.5435842275619507\n",
      "Validation loss decreased from 0.6079919663342562 to 0.6059625799005682\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.5400421023368835\n",
      "Validation loss decreased from 0.6059625799005682 to 0.6039246862584894\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.5364180207252502\n",
      "Validation loss decreased from 0.6039246862584894 to 0.6018528667363253\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.532720148563385\n",
      "Validation loss decreased from 0.6018528667363253 to 0.5997845422137867\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.5289573669433594\n",
      "Validation loss decreased from 0.5997845422137867 to 0.5977061336690729\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.525104820728302\n",
      "Validation loss decreased from 0.5977061336690729 to 0.5956075191497803\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.5212245583534241\n",
      "Validation loss decreased from 0.5956075191497803 to 0.5935091809792952\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.5172586441040039\n",
      "Validation loss decreased from 0.5935091809792952 to 0.5913567326285623\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.5133753418922424\n",
      "Validation loss decreased from 0.5913567326285623 to 0.5892115289514716\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.5094451904296875\n",
      "Validation loss decreased from 0.5892115289514716 to 0.5870730876922607\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.5054813623428345\n",
      "Validation loss decreased from 0.5870730876922607 to 0.5849052938548002\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.5015938878059387\n",
      "Validation loss decreased from 0.5849052938548002 to 0.5827439860864119\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.4975459575653076\n",
      "Validation loss decreased from 0.5827439860864119 to 0.580579400062561\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.4934307038784027\n",
      "Validation loss decreased from 0.580579400062561 to 0.5784060575745322\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.48924049735069275\n",
      "Validation loss decreased from 0.5784060575745322 to 0.5762583179907366\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.4850456416606903\n",
      "Validation loss decreased from 0.5762583179907366 to 0.5740987766872753\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.48085257411003113\n",
      "Validation loss decreased from 0.5740987766872753 to 0.5719037272713401\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.47662872076034546\n",
      "Validation loss decreased from 0.5719037272713401 to 0.569697992368178\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.4724399447441101\n",
      "Validation loss decreased from 0.569697992368178 to 0.5675464380871166\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.4682954251766205\n",
      "Validation loss decreased from 0.5675464380871166 to 0.5654227896170183\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.4642408788204193\n",
      "Validation loss decreased from 0.5654227896170183 to 0.5632983066818931\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.4601408541202545\n",
      "Validation loss decreased from 0.5632983066818931 to 0.5612041841853749\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.4559840261936188\n",
      "Validation loss decreased from 0.5612041841853749 to 0.5591374039649963\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.4517221450805664\n",
      "Validation loss decreased from 0.5591374039649963 to 0.5571033304387872\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.4475780129432678\n",
      "Validation loss decreased from 0.5571033304387872 to 0.5551180460236289\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.44329938292503357\n",
      "Validation loss decreased from 0.5551180460236289 to 0.5531393072821877\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.4390634000301361\n",
      "Validation loss decreased from 0.5531393072821877 to 0.551188815723766\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.4348091781139374\n",
      "Validation loss decreased from 0.551188815723766 to 0.5493039163676176\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.4305935800075531\n",
      "Validation loss decreased from 0.5493039163676176 to 0.5474276921965859\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.42653849720954895\n",
      "Validation loss decreased from 0.5474276921965859 to 0.5456136139956388\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.42241984605789185\n",
      "Validation loss decreased from 0.5456136139956388 to 0.5438857810063795\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.4182837903499603\n",
      "Validation loss decreased from 0.5438857810063795 to 0.542186441746625\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.41420742869377136\n",
      "Validation loss decreased from 0.542186441746625 to 0.5405183055184104\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.4100625216960907\n",
      "Validation loss decreased from 0.5405183055184104 to 0.5389101694930684\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.406044602394104\n",
      "Validation loss decreased from 0.5389101694930684 to 0.5373295762322166\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.402083158493042\n",
      "Validation loss decreased from 0.5373295762322166 to 0.5357916463505138\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.3982415497303009\n",
      "Validation loss decreased from 0.5357916463505138 to 0.5343105576255105\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.39440569281578064\n",
      "Validation loss decreased from 0.5343105576255105 to 0.5328386669809168\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.3906312882900238\n",
      "Validation loss decreased from 0.5328386669809168 to 0.5314013361930847\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.3869456946849823\n",
      "Validation loss decreased from 0.5314013361930847 to 0.5300589420578696\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.3832645118236542\n",
      "Validation loss decreased from 0.5300589420578696 to 0.5287846733223308\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.3795831799507141\n",
      "Validation loss decreased from 0.5287846733223308 to 0.5275274813175201\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.37598273158073425\n",
      "Validation loss decreased from 0.5275274813175201 to 0.5263260711323131\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.3725340962409973\n",
      "Validation loss decreased from 0.5263260711323131 to 0.5252232389016585\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.36896079778671265\n",
      "Validation loss decreased from 0.5252232389016585 to 0.5241323628208854\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.36549291014671326\n",
      "Validation loss decreased from 0.5241323628208854 to 0.5231326547535983\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.36192262172698975\n",
      "Validation loss decreased from 0.5231326547535983 to 0.5220977718179877\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.358443945646286\n",
      "Validation loss decreased from 0.5220977718179877 to 0.5211087194356051\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.3548978865146637\n",
      "Validation loss decreased from 0.5211087194356051 to 0.5202431597492911\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.35122373700141907\n",
      "Validation loss decreased from 0.5202431597492911 to 0.519363896413283\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.34763583540916443\n",
      "Validation loss decreased from 0.519363896413283 to 0.5184664374048059\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.34411492943763733\n",
      "Validation loss decreased from 0.5184664374048059 to 0.5176647928628054\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.3406544625759125\n",
      "Validation loss decreased from 0.5176647928628054 to 0.5168664347041737\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.33732885122299194\n",
      "Validation loss decreased from 0.5168664347041737 to 0.516077307137576\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.3340732455253601\n",
      "Validation loss decreased from 0.516077307137576 to 0.5153232650323347\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.33075329661369324\n",
      "Validation loss decreased from 0.5153232650323347 to 0.5145722817290913\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.327287495136261\n",
      "Validation loss decreased from 0.5145722817290913 to 0.5139207352291454\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.3240538537502289\n",
      "Validation loss decreased from 0.5139207352291454 to 0.5133312940597534\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.3210620582103729\n",
      "Validation loss decreased from 0.5133312940597534 to 0.512685854326595\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.31810399889945984\n",
      "Validation loss decreased from 0.512685854326595 to 0.5121180062944238\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.31489288806915283\n",
      "Validation loss decreased from 0.5121180062944238 to 0.5115979666059668\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.3118516802787781\n",
      "Validation loss decreased from 0.5115979666059668 to 0.5110755535689268\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.3089231550693512\n",
      "Validation loss decreased from 0.5110755535689268 to 0.5105661451816559\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.30575332045555115\n",
      "Validation loss decreased from 0.5105661451816559 to 0.5101244043220173\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.30283433198928833\n",
      "Validation loss decreased from 0.5101244043220173 to 0.5097239478067919\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.29993659257888794\n",
      "Validation loss decreased from 0.5097239478067919 to 0.509356745264747\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.29711225628852844\n",
      "Validation loss decreased from 0.509356745264747 to 0.5090172534639185\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.2940361201763153\n",
      "Validation loss decreased from 0.5090172534639185 to 0.5087230395187031\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.291080504655838\n",
      "Validation loss decreased from 0.5087230395187031 to 0.5084099905057387\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.287997305393219\n",
      "Validation loss decreased from 0.5084099905057387 to 0.5081796727397225\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.28498604893684387\n",
      "Validation loss decreased from 0.5081796727397225 to 0.5079208476976915\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.28207820653915405\n",
      "Validation loss decreased from 0.5079208476976915 to 0.5077567317269065\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.2788143455982208\n",
      "Validation loss decreased from 0.5077567317269065 to 0.5077002807097002\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.27586832642555237\n",
      "Validation loss decreased from 0.5077002807097002 to 0.5076460648666729\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.27290448546409607\n",
      "Validation loss decreased from 0.5076460648666729 to 0.5076146071607416\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.2697758078575134\n",
      "Validation loss decreased from 0.5076146071607416 to 0.50755729729479\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.26677435636520386\n",
      "Validation loss decreased from 0.50755729729479 to 0.5075281750072133\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.263766348361969\n",
      "Validation loss decreased from 0.5075281750072133 to 0.5074788928031921\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.2605656087398529\n",
      "Validation loss decreased from 0.5074788928031921 to 0.5074236772277139\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.25747478008270264\n",
      "Validation loss decreased from 0.5074236772277139 to 0.5073917318474163\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.25442948937416077\n",
      "Validation loss decreased from 0.5073917318474163 to 0.5073149556463415\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.2514576315879822\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.2486366480588913\n",
      "Validation loss decreased from 0.5073149556463415 to 0.5073011192408475\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.24595709145069122\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.24332207441329956\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.24066051840782166\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.23797288537025452\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.23531574010849\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.23276305198669434\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.230337455868721\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.22808700799942017\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.22571101784706116\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.2233753502368927\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.22114965319633484\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.21886317431926727\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.21670077741146088\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.21431425213813782\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.21219578385353088\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.20992286503314972\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.20777684450149536\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.2057294398546219\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.2037496715784073\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.20168861746788025\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.1996171921491623\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.1974530816078186\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.195256769657135\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.19313110411167145\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.19080406427383423\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.18855102360248566\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.18650144338607788\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.1844465732574463\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.18247409164905548\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.18041658401489258\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.17840076982975006\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.17640644311904907\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.1746080368757248\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.17277474701404572\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.17095153033733368\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.16909629106521606\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.16736000776290894\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.16563855111598969\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.1639430969953537\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.1622859090566635\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.16072112321853638\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.1591433882713318\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.1575690507888794\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.15592695772647858\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.15425582230091095\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.15275008976459503\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.15107880532741547\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.1495436578989029\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.14805573225021362\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.1465851366519928\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  343\n",
      "AUC on test data  0.826417536196716\n",
      "model 11 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7124438285827637\n",
      "Validation loss decreased from inf to 0.7369077584960244\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.718098521232605\n",
      "Validation loss decreased from 0.7369077584960244 to 0.7352745478803461\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7120669484138489\n",
      "Validation loss decreased from 0.7352745478803461 to 0.7336470322175459\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7166282534599304\n",
      "Validation loss decreased from 0.7336470322175459 to 0.7321193976835771\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7149690985679626\n",
      "Validation loss decreased from 0.7321193976835771 to 0.7306421778418801\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6979270577430725\n",
      "Validation loss decreased from 0.7306421778418801 to 0.7292098782279275\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7117902636528015\n",
      "Validation loss decreased from 0.7292098782279275 to 0.7278831276026639\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7078065276145935\n",
      "Validation loss decreased from 0.7278831276026639 to 0.726625074039806\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6955181360244751\n",
      "Validation loss decreased from 0.726625074039806 to 0.7253919406370684\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7028392553329468\n",
      "Validation loss decreased from 0.7253919406370684 to 0.7242245186458934\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.7056231498718262\n",
      "Validation loss decreased from 0.7242245186458934 to 0.7231461351568048\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.695064902305603\n",
      "Validation loss decreased from 0.7231461351568048 to 0.7220929806882684\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6947305202484131\n",
      "Validation loss decreased from 0.7220929806882684 to 0.7210582819851962\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.7017637491226196\n",
      "Validation loss decreased from 0.7210582819851962 to 0.7200818278572776\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7033885717391968\n",
      "Validation loss decreased from 0.7200818278572776 to 0.7191595326770436\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.702340841293335\n",
      "Validation loss decreased from 0.7191595326770436 to 0.7182816917246039\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6963335275650024\n",
      "Validation loss decreased from 0.7182816917246039 to 0.7174712419509888\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.7054112553596497\n",
      "Validation loss decreased from 0.7174712419509888 to 0.7167025641961531\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6988890767097473\n",
      "Validation loss decreased from 0.7167025641961531 to 0.7159434936263345\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6995354294776917\n",
      "Validation loss decreased from 0.7159434936263345 to 0.7152098417282104\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6978285908699036\n",
      "Validation loss decreased from 0.7152098417282104 to 0.7145047025247053\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.7022750377655029\n",
      "Validation loss decreased from 0.7145047025247053 to 0.7138180461796847\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.7020231485366821\n",
      "Validation loss decreased from 0.7138180461796847 to 0.7131825902245261\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.697024405002594\n",
      "Validation loss decreased from 0.7131825902245261 to 0.7125899087299\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6968306303024292\n",
      "Validation loss decreased from 0.7125899087299 to 0.7120112885128368\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6971174478530884\n",
      "Validation loss decreased from 0.7120112885128368 to 0.7114259167151018\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7011483311653137\n",
      "Validation loss decreased from 0.7114259167151018 to 0.7108753757043318\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6983119249343872\n",
      "Validation loss decreased from 0.7108753757043318 to 0.7103450515053489\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6940439343452454\n",
      "Validation loss decreased from 0.7103450515053489 to 0.7098305496302518\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.7057326436042786\n",
      "Validation loss decreased from 0.7098305496302518 to 0.7093547799370505\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6917193531990051\n",
      "Validation loss decreased from 0.7093547799370505 to 0.708869831128554\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6940011978149414\n",
      "Validation loss decreased from 0.708869831128554 to 0.7084349122914401\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6967284679412842\n",
      "Validation loss decreased from 0.7084349122914401 to 0.7080192132429644\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7001386880874634\n",
      "Validation loss decreased from 0.7080192132429644 to 0.7076070037755099\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6957712173461914\n",
      "Validation loss decreased from 0.7076070037755099 to 0.7072143771431663\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.7018749713897705\n",
      "Validation loss decreased from 0.7072143771431663 to 0.706831303509799\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6899886131286621\n",
      "Validation loss decreased from 0.706831303509799 to 0.7064739140597257\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6932095885276794\n",
      "Validation loss decreased from 0.7064739140597257 to 0.7061275406317278\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7011801600456238\n",
      "Validation loss decreased from 0.7061275406317278 to 0.7057717442512512\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.7021615505218506\n",
      "Validation loss decreased from 0.7057717442512512 to 0.7054370804266497\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6964340209960938\n",
      "Validation loss decreased from 0.7054370804266497 to 0.7051117528568615\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.696405291557312\n",
      "Validation loss decreased from 0.7051117528568615 to 0.7047924616120078\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6982378959655762\n",
      "Validation loss decreased from 0.7047924616120078 to 0.7044893232258883\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6959733963012695\n",
      "Validation loss decreased from 0.7044893232258883 to 0.7041881788860668\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6981488466262817\n",
      "Validation loss decreased from 0.7041881788860668 to 0.7038981210101735\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6951975226402283\n",
      "Validation loss decreased from 0.7038981210101735 to 0.7036394693634727\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6893511414527893\n",
      "Validation loss decreased from 0.7036394693634727 to 0.7033765749497847\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6949870586395264\n",
      "Validation loss decreased from 0.7033765749497847 to 0.7031155553731051\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.691825807094574\n",
      "Validation loss decreased from 0.7031155553731051 to 0.7028685537251559\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6927047371864319\n",
      "Validation loss decreased from 0.7028685537251559 to 0.7026382793079723\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6987614035606384\n",
      "Validation loss decreased from 0.7026382793079723 to 0.7024141550064087\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.7032433152198792\n",
      "Validation loss decreased from 0.7024141550064087 to 0.7022167986089533\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6888580322265625\n",
      "Validation loss decreased from 0.7022167986089533 to 0.7019990194927562\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6904798746109009\n",
      "Validation loss decreased from 0.7019990194927562 to 0.7017795877023176\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6960259079933167\n",
      "Validation loss decreased from 0.7017795877023176 to 0.7015879479321566\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6894028782844543\n",
      "Validation loss decreased from 0.7015879479321566 to 0.7013965845108032\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6952677965164185\n",
      "Validation loss decreased from 0.7013965845108032 to 0.7012229074131359\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6933995485305786\n",
      "Validation loss decreased from 0.7012229074131359 to 0.7010489214550365\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6986232995986938\n",
      "Validation loss decreased from 0.7010489214550365 to 0.7008634914051403\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6968110203742981\n",
      "Validation loss decreased from 0.7008634914051403 to 0.7006983377716758\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.690455973148346\n",
      "Validation loss decreased from 0.7006983377716758 to 0.7005488709969954\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6915016770362854\n",
      "Validation loss decreased from 0.7005488709969954 to 0.7003948959437284\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6942662000656128\n",
      "Validation loss decreased from 0.7003948959437284 to 0.7002445947040211\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6936832666397095\n",
      "Validation loss decreased from 0.7002445947040211 to 0.7000951712781732\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6900906562805176\n",
      "Validation loss decreased from 0.7000951712781732 to 0.6999393538995222\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6854538321495056\n",
      "Validation loss decreased from 0.6999393538995222 to 0.6998059803789313\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6934378147125244\n",
      "Validation loss decreased from 0.6998059803789313 to 0.6996844248338179\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6955180764198303\n",
      "Validation loss decreased from 0.6996844248338179 to 0.699555369940671\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6893927454948425\n",
      "Validation loss decreased from 0.699555369940671 to 0.6994238333268599\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6881332397460938\n",
      "Validation loss decreased from 0.6994238333268599 to 0.6992978941310536\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6972951889038086\n",
      "Validation loss decreased from 0.6992978941310536 to 0.699170546098189\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6948930025100708\n",
      "Validation loss decreased from 0.699170546098189 to 0.6990555958314375\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.7005283236503601\n",
      "Validation loss decreased from 0.6990555958314375 to 0.6989618648182262\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6947360038757324\n",
      "Validation loss decreased from 0.6989618648182262 to 0.6988566355271773\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6916367411613464\n",
      "Validation loss decreased from 0.6988566355271773 to 0.6987570524215698\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6919664740562439\n",
      "Validation loss decreased from 0.6987570524215698 to 0.6986407149921764\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6953354477882385\n",
      "Validation loss decreased from 0.6986407149921764 to 0.6985390186309814\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6984231472015381\n",
      "Validation loss decreased from 0.6985390186309814 to 0.6984491944313049\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.695968747138977\n",
      "Validation loss decreased from 0.6984491944313049 to 0.698355723511089\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6909341216087341\n",
      "Validation loss decreased from 0.698355723511089 to 0.6982651352882385\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.7011052370071411\n",
      "Validation loss decreased from 0.6982651352882385 to 0.6981715722517534\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6874977946281433\n",
      "Validation loss decreased from 0.6981715722517534 to 0.6980821273543618\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6985177993774414\n",
      "Validation loss decreased from 0.6980821273543618 to 0.6979966055263173\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6932138800621033\n",
      "Validation loss decreased from 0.6979966055263173 to 0.697906954721971\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6935871839523315\n",
      "Validation loss decreased from 0.697906954721971 to 0.6978266455910422\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6953997611999512\n",
      "Validation loss decreased from 0.6978266455910422 to 0.6977528116919778\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.7000939846038818\n",
      "Validation loss decreased from 0.6977528116919778 to 0.6976770108396356\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6890318393707275\n",
      "Validation loss decreased from 0.6976770108396356 to 0.6976006410338662\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6941401362419128\n",
      "Validation loss decreased from 0.6976006410338662 to 0.6975251544605602\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6937404870986938\n",
      "Validation loss decreased from 0.6975251544605602 to 0.6974416917020624\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6910250782966614\n",
      "Validation loss decreased from 0.6974416917020624 to 0.6973651810125872\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6880013942718506\n",
      "Validation loss decreased from 0.6973651810125872 to 0.697305522181771\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6938180923461914\n",
      "Validation loss decreased from 0.697305522181771 to 0.6972448609092019\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6872653961181641\n",
      "Validation loss decreased from 0.6972448609092019 to 0.6971837282180786\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6904711723327637\n",
      "Validation loss decreased from 0.6971837282180786 to 0.6971272121776234\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.700007438659668\n",
      "Validation loss decreased from 0.6971272121776234 to 0.6970731778578325\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6884589791297913\n",
      "Validation loss decreased from 0.6970731778578325 to 0.6970125220038674\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.690887451171875\n",
      "Validation loss decreased from 0.6970125220038674 to 0.6969424865462563\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6975467205047607\n",
      "Validation loss decreased from 0.6969424865462563 to 0.6968932314352556\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6873424053192139\n",
      "Validation loss decreased from 0.6968932314352556 to 0.6968410231850364\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.686096727848053\n",
      "Validation loss decreased from 0.6968410231850364 to 0.6967897090044889\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6879534125328064\n",
      "Validation loss decreased from 0.6967897090044889 to 0.6967330845919523\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6902958154678345\n",
      "Validation loss decreased from 0.6967330845919523 to 0.6966802857138894\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.695896565914154\n",
      "Validation loss decreased from 0.6966802857138894 to 0.6966399983926252\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6923825740814209\n",
      "Validation loss decreased from 0.6966399983926252 to 0.6966023065827109\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6893530488014221\n",
      "Validation loss decreased from 0.6966023065827109 to 0.6965723687952216\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6957467198371887\n",
      "Validation loss decreased from 0.6965723687952216 to 0.6965273239395835\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6938855648040771\n",
      "Validation loss decreased from 0.6965273239395835 to 0.6964907917109403\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6900131702423096\n",
      "Validation loss decreased from 0.6964907917109403 to 0.6964503255757418\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.7023676633834839\n",
      "Validation loss decreased from 0.6964503255757418 to 0.6964158361608331\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6993680596351624\n",
      "Validation loss decreased from 0.6964158361608331 to 0.6963796615600586\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6953303813934326\n",
      "Validation loss decreased from 0.6963796615600586 to 0.6963398998433893\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6925357580184937\n",
      "Validation loss decreased from 0.6963398998433893 to 0.6963061907074668\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6909725666046143\n",
      "Validation loss decreased from 0.6963061907074668 to 0.6962635950608687\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6905909180641174\n",
      "Validation loss decreased from 0.6962635950608687 to 0.6962163610891863\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6916684508323669\n",
      "Validation loss decreased from 0.6962163610891863 to 0.6961852583018217\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6835452914237976\n",
      "Validation loss decreased from 0.6961852583018217 to 0.6961467103524641\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6912955641746521\n",
      "Validation loss decreased from 0.6961467103524641 to 0.6961124431003224\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6882539987564087\n",
      "Validation loss decreased from 0.6961124431003224 to 0.6960871761495416\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6907108426094055\n",
      "Validation loss decreased from 0.6960871761495416 to 0.6960583329200745\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.694979727268219\n",
      "Validation loss decreased from 0.6960583329200745 to 0.6960244395516135\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6878262162208557\n",
      "Validation loss decreased from 0.6960244395516135 to 0.6959976879033175\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6948493123054504\n",
      "Validation loss decreased from 0.6959976879033175 to 0.6959630955349315\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6856027245521545\n",
      "Validation loss decreased from 0.6959630955349315 to 0.6959401098164645\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.694186270236969\n",
      "Validation loss decreased from 0.6959401098164645 to 0.6959221633997831\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6924285888671875\n",
      "Validation loss decreased from 0.6959221633997831 to 0.695896181193265\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6920095086097717\n",
      "Validation loss decreased from 0.695896181193265 to 0.6958674625916914\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6918603181838989\n",
      "Validation loss decreased from 0.6958674625916914 to 0.695841908454895\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6977320313453674\n",
      "Validation loss decreased from 0.695841908454895 to 0.6958198547363281\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6899546384811401\n",
      "Validation loss decreased from 0.6958198547363281 to 0.6958007704127919\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.695905327796936\n",
      "Validation loss decreased from 0.6958007704127919 to 0.6957839998331937\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6928742527961731\n",
      "Validation loss decreased from 0.6957839998331937 to 0.6957664381374012\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6967952251434326\n",
      "Validation loss decreased from 0.6957664381374012 to 0.6957406022331931\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6900959014892578\n",
      "Validation loss decreased from 0.6957406022331931 to 0.6957139318639581\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6874287724494934\n",
      "Validation loss decreased from 0.6957139318639581 to 0.69569331407547\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.692886471748352\n",
      "Validation loss decreased from 0.69569331407547 to 0.695673330263658\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6875952482223511\n",
      "Validation loss decreased from 0.695673330263658 to 0.695648962801153\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.694074809551239\n",
      "Validation loss decreased from 0.695648962801153 to 0.6956307888031006\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6977931261062622\n",
      "Validation loss decreased from 0.6956307888031006 to 0.6956162777813998\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.696755588054657\n",
      "Validation loss decreased from 0.6956162777813998 to 0.6955978274345398\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6980384588241577\n",
      "Validation loss decreased from 0.6955978274345398 to 0.6955709294839338\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6975254416465759\n",
      "Validation loss decreased from 0.6955709294839338 to 0.6955556652762673\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6878481507301331\n",
      "Validation loss decreased from 0.6955556652762673 to 0.6955250880934976\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6952178478240967\n",
      "Validation loss decreased from 0.6955250880934976 to 0.6955096288160845\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.695679247379303\n",
      "Validation loss decreased from 0.6955096288160845 to 0.6954950907013633\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6885519027709961\n",
      "Validation loss decreased from 0.6954950907013633 to 0.6954807584935968\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6913006901741028\n",
      "Validation loss decreased from 0.6954807584935968 to 0.6954658356579867\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.691506028175354\n",
      "Validation loss decreased from 0.6954658356579867 to 0.6954500675201416\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.695286214351654\n",
      "Validation loss decreased from 0.6954500675201416 to 0.6954368407076056\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6929618716239929\n",
      "Validation loss decreased from 0.6954368407076056 to 0.6954130530357361\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6891867518424988\n",
      "Validation loss decreased from 0.6954130530357361 to 0.6953972523862665\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6991340517997742\n",
      "Validation loss decreased from 0.6953972523862665 to 0.6953787045045332\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.690180778503418\n",
      "Validation loss decreased from 0.6953787045045332 to 0.6953583684834567\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6894146203994751\n",
      "Validation loss decreased from 0.6953583684834567 to 0.6953398910435763\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6863040924072266\n",
      "Validation loss decreased from 0.6953398910435763 to 0.6953221993012861\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6974038481712341\n",
      "Validation loss decreased from 0.6953221993012861 to 0.6953090483492071\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6991690993309021\n",
      "Validation loss decreased from 0.6953090483492071 to 0.6952955560250715\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6918118596076965\n",
      "Validation loss decreased from 0.6952955560250715 to 0.6952857971191406\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6945313811302185\n",
      "Validation loss decreased from 0.6952857971191406 to 0.6952756805853411\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6919777393341064\n",
      "Validation loss decreased from 0.6952756805853411 to 0.6952601725404913\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6862819194793701\n",
      "Validation loss decreased from 0.6952601725404913 to 0.6952424916354093\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.690339207649231\n",
      "Validation loss decreased from 0.6952424916354093 to 0.6952289017764005\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6981502771377563\n",
      "Validation loss decreased from 0.6952289017764005 to 0.6952092864296653\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6997054219245911\n",
      "Validation loss decreased from 0.6952092864296653 to 0.6952018412676725\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6971092224121094\n",
      "Validation loss decreased from 0.6952018412676725 to 0.6951944502917203\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6886350512504578\n",
      "Validation loss decreased from 0.6951944502917203 to 0.6951834667812694\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6978153586387634\n",
      "Validation loss decreased from 0.6951834667812694 to 0.6951794407584451\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6908100843429565\n",
      "Validation loss decreased from 0.6951794407584451 to 0.6951712424104864\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6941074132919312\n",
      "Validation loss decreased from 0.6951712424104864 to 0.6951613372022455\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.690039873123169\n",
      "Validation loss decreased from 0.6951613372022455 to 0.6951456232504412\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6887763738632202\n",
      "Validation loss decreased from 0.6951456232504412 to 0.6951216025785967\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6868641972541809\n",
      "Validation loss decreased from 0.6951216025785967 to 0.6951085816730153\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.7005137205123901\n",
      "Validation loss decreased from 0.6951085816730153 to 0.6950989744879983\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6903722882270813\n",
      "Validation loss decreased from 0.6950989744879983 to 0.6950933879072015\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6974421739578247\n",
      "Validation loss decreased from 0.6950933879072015 to 0.6950783133506775\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.694718599319458\n",
      "Validation loss decreased from 0.6950783133506775 to 0.6950721686536615\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6887932419776917\n",
      "Validation loss decreased from 0.6950721686536615 to 0.695062285119837\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6920895576477051\n",
      "Validation loss decreased from 0.695062285119837 to 0.6950591585852883\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6927047371864319\n",
      "Validation loss decreased from 0.6950591585852883 to 0.6950445446101102\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6920538544654846\n",
      "Validation loss decreased from 0.6950445446101102 to 0.6950378092852506\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6951413154602051\n",
      "Validation loss decreased from 0.6950378092852506 to 0.6950334689833901\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6949220895767212\n",
      "Validation loss decreased from 0.6950334689833901 to 0.6950139186599038\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6871050596237183\n",
      "Validation loss decreased from 0.6950139186599038 to 0.6949971318244934\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6940829753875732\n",
      "Validation loss decreased from 0.6949971318244934 to 0.6949885975230824\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.686943531036377\n",
      "Validation loss decreased from 0.6949885975230824 to 0.6949771751057018\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6912543177604675\n",
      "Validation loss decreased from 0.6949771751057018 to 0.6949616453864358\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6890324950218201\n",
      "Validation loss decreased from 0.6949616453864358 to 0.6949535283175382\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6930776238441467\n",
      "Validation loss decreased from 0.6949535283175382 to 0.6949441703883085\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6952036619186401\n",
      "Validation loss decreased from 0.6949441703883085 to 0.6949269554831765\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6942768096923828\n",
      "Validation loss decreased from 0.6949269554831765 to 0.6949205832047896\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.693881630897522\n",
      "Validation loss decreased from 0.6949205832047896 to 0.6949111494151029\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6923362612724304\n",
      "Validation loss decreased from 0.6949111494151029 to 0.6949061263691295\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6919322609901428\n",
      "Validation loss decreased from 0.6949061263691295 to 0.6948984915559943\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6974464654922485\n",
      "Validation loss decreased from 0.6948984915559943 to 0.6948899247429587\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.695732593536377\n",
      "Validation loss decreased from 0.6948899247429587 to 0.6948823224414479\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6852196455001831\n",
      "Validation loss decreased from 0.6948823224414479 to 0.694871642372825\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6929971575737\n",
      "Validation loss decreased from 0.694871642372825 to 0.6948680281639099\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6933403611183167\n",
      "Validation loss decreased from 0.6948680281639099 to 0.694863579489968\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6899069547653198\n",
      "Validation loss decreased from 0.694863579489968 to 0.6948616721413352\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6972309350967407\n",
      "Validation loss decreased from 0.6948616721413352 to 0.6948599977926775\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6937255859375\n",
      "Validation loss decreased from 0.6948599977926775 to 0.6948491443287242\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.685608446598053\n",
      "Validation loss decreased from 0.6948491443287242 to 0.6948480931195345\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6985891461372375\n",
      "Validation loss decreased from 0.6948480931195345 to 0.6948350830511614\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6966960430145264\n",
      "Validation loss decreased from 0.6948350830511614 to 0.6948301033540205\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.689313530921936\n",
      "Validation loss decreased from 0.6948301033540205 to 0.6948203227736733\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.690507173538208\n",
      "Validation loss decreased from 0.6948203227736733 to 0.694806841286746\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6931610107421875\n",
      "Validation loss decreased from 0.694806841286746 to 0.6947945139624856\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6919297575950623\n",
      "Validation loss decreased from 0.6947945139624856 to 0.6947848200798035\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6882414221763611\n",
      "Validation loss decreased from 0.6947848200798035 to 0.6947726065462286\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.7009915709495544\n",
      "Validation loss decreased from 0.6947726065462286 to 0.6947681632908908\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6906850934028625\n",
      "Validation loss decreased from 0.6947681632908908 to 0.6947671608491377\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6913226246833801\n",
      "Validation loss decreased from 0.6947671608491377 to 0.6947645436633717\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6937230229377747\n",
      "Validation loss decreased from 0.6947645436633717 to 0.6947622407566417\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6920044422149658\n",
      "Validation loss decreased from 0.6947622407566417 to 0.6947518153624102\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6912477612495422\n",
      "Validation loss decreased from 0.6947518153624102 to 0.6947424195029519\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6963860988616943\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6860677599906921\n",
      "Validation loss decreased from 0.6947424195029519 to 0.6947379112243652\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6972438097000122\n",
      "Validation loss decreased from 0.6947379112243652 to 0.6947354240850969\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6943752765655518\n",
      "Validation loss decreased from 0.6947354240850969 to 0.6947323192249645\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6898787617683411\n",
      "Validation loss decreased from 0.6947323192249645 to 0.6947261962023649\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6933697462081909\n",
      "Validation loss decreased from 0.6947261962023649 to 0.6947128989479758\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6940497159957886\n",
      "Validation loss decreased from 0.6947128989479758 to 0.694702229716561\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6960529685020447\n",
      "Validation loss decreased from 0.694702229716561 to 0.6946940692988309\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6913157105445862\n",
      "Validation loss decreased from 0.6946940692988309 to 0.694692920554768\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6941179037094116\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6907736659049988\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6962568163871765\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6890907883644104\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6923215985298157\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6950699687004089\n",
      "Validation loss decreased from 0.694692920554768 to 0.6946889703924005\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6918957233428955\n",
      "Validation loss decreased from 0.6946889703924005 to 0.6946798942305825\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6937848925590515\n",
      "Validation loss decreased from 0.6946798942305825 to 0.6946796991608359\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6911818981170654\n",
      "Validation loss decreased from 0.6946796991608359 to 0.6946780193935741\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6911773681640625\n",
      "Validation loss decreased from 0.6946780193935741 to 0.6946699023246765\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6967921853065491\n",
      "Validation loss decreased from 0.6946699023246765 to 0.6946651231158864\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6947862505912781\n",
      "Validation loss decreased from 0.6946651231158864 to 0.6946647600694136\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6935182809829712\n",
      "Validation loss decreased from 0.6946647600694136 to 0.6946613355116411\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6920361518859863\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6988188624382019\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6901540160179138\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6958667635917664\n",
      "Validation loss decreased from 0.6946613355116411 to 0.6946496692570773\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6897212266921997\n",
      "Validation loss decreased from 0.6946496692570773 to 0.6946402788162231\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.692270040512085\n",
      "Validation loss decreased from 0.6946402788162231 to 0.6946355917237022\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6935383081436157\n",
      "Validation loss decreased from 0.6946355917237022 to 0.6946346434679899\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.687553882598877\n",
      "Validation loss decreased from 0.6946346434679899 to 0.6946329095146873\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6911900043487549\n",
      "Validation loss decreased from 0.6946329095146873 to 0.6946312460032377\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6937772035598755\n",
      "Validation loss decreased from 0.6946312460032377 to 0.6946304332126271\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6894120573997498\n",
      "Validation loss decreased from 0.6946304332126271 to 0.6946253722364252\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6911291480064392\n",
      "Validation loss decreased from 0.6946253722364252 to 0.6946197964928367\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6931215524673462\n",
      "Validation loss decreased from 0.6946197964928367 to 0.6946103464473378\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6921171545982361\n",
      "Validation loss decreased from 0.6946103464473378 to 0.6946004195646807\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6933072209358215\n",
      "Validation loss decreased from 0.6946004195646807 to 0.6945960250767794\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6912388205528259\n",
      "Validation loss decreased from 0.6945960250767794 to 0.6945884390310808\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6893473863601685\n",
      "Validation loss decreased from 0.6945884390310808 to 0.6945831287990917\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6918163895606995\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6940781474113464\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6957904696464539\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6930839419364929\n",
      "Validation loss decreased from 0.6945831287990917 to 0.694579845125025\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6943355202674866\n",
      "Validation loss decreased from 0.694579845125025 to 0.6945765831253745\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6933941841125488\n",
      "Validation loss decreased from 0.6945765831253745 to 0.6945743344046853\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6978938579559326\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.69317227602005\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6939828395843506\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.693690299987793\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6951513290405273\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6957040429115295\n",
      "Validation loss decreased from 0.6945743344046853 to 0.6945726763118397\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6916843056678772\n",
      "Validation loss decreased from 0.6945726763118397 to 0.6945698152888905\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.69609135389328\n",
      "Validation loss decreased from 0.6945698152888905 to 0.6945678374984048\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6907201409339905\n",
      "Validation loss decreased from 0.6945678374984048 to 0.6945645158941095\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.691067099571228\n",
      "Validation loss decreased from 0.6945645158941095 to 0.6945550658486106\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.693565845489502\n",
      "Validation loss decreased from 0.6945550658486106 to 0.6945487748492848\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6919531226158142\n",
      "Validation loss decreased from 0.6945487748492848 to 0.6945433183149858\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6962626576423645\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6934168934822083\n",
      "Validation loss decreased from 0.6945433183149858 to 0.6945429444313049\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6911560893058777\n",
      "Validation loss decreased from 0.6945429444313049 to 0.6945404843850569\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.692278265953064\n",
      "Validation loss decreased from 0.6945404843850569 to 0.6945372007109902\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6912189722061157\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6919333338737488\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6946043372154236\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6904791593551636\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6886576414108276\n",
      "Validation loss decreased from 0.6945372007109902 to 0.6945348436182196\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6948301196098328\n",
      "Validation loss decreased from 0.6945348436182196 to 0.6945218172940341\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6917901635169983\n",
      "Validation loss decreased from 0.6945218172940341 to 0.6945128278298811\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6950123310089111\n",
      "Validation loss decreased from 0.6945128278298811 to 0.6945099072022871\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6892482042312622\n",
      "Validation loss decreased from 0.6945099072022871 to 0.6945067264816978\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6930744647979736\n",
      "Validation loss decreased from 0.6945067264816978 to 0.6945004083893516\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6913037300109863\n",
      "Validation loss decreased from 0.6945004083893516 to 0.6944984468546781\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.693454384803772\n",
      "Validation loss decreased from 0.6944984468546781 to 0.6944942420179193\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6900466084480286\n",
      "Validation loss decreased from 0.6944942420179193 to 0.6944937326691367\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6905370354652405\n",
      "Validation loss decreased from 0.6944937326691367 to 0.6944884115999396\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6915319561958313\n",
      "Validation loss decreased from 0.6944884115999396 to 0.6944799748334017\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6910467743873596\n",
      "Validation loss decreased from 0.6944799748334017 to 0.6944774660197172\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6897632479667664\n",
      "Validation loss decreased from 0.6944774660197172 to 0.6944658268581737\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6925220489501953\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6917166709899902\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6890929341316223\n",
      "Validation loss decreased from 0.6944658268581737 to 0.6944581053473733\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6912255883216858\n",
      "Validation loss decreased from 0.6944581053473733 to 0.694451093673706\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.695819079875946\n",
      "Validation loss decreased from 0.694451093673706 to 0.6944454474882646\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6879578232765198\n",
      "Validation loss decreased from 0.6944454474882646 to 0.6944426135583357\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6932491064071655\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6916112899780273\n",
      "Validation loss decreased from 0.6944426135583357 to 0.6944402835585854\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6886345148086548\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6924941539764404\n",
      "Validation loss decreased from 0.6944402835585854 to 0.6944343014196916\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6933919787406921\n",
      "Validation loss decreased from 0.6944343014196916 to 0.6944267424670133\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6939878463745117\n",
      "Validation loss decreased from 0.6944267424670133 to 0.6944266991181807\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6896596550941467\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6889774203300476\n",
      "Validation loss decreased from 0.6944266991181807 to 0.6944214972582731\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6995874643325806\n",
      "Validation loss decreased from 0.6944214972582731 to 0.6944180239330638\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.693343460559845\n",
      "Validation loss decreased from 0.6944180239330638 to 0.6944174441424283\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6942461729049683\n",
      "Validation loss decreased from 0.6944174441424283 to 0.694410194050182\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.689757227897644\n",
      "Validation loss decreased from 0.694410194050182 to 0.6944046453996138\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6945511698722839\n",
      "Validation loss decreased from 0.6944046453996138 to 0.6944002509117126\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6910724639892578\n",
      "Validation loss decreased from 0.6944002509117126 to 0.6943977258422158\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6863193511962891\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6937255263328552\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6960402131080627\n",
      "Validation loss decreased from 0.6943977258422158 to 0.694390519098802\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6950013637542725\n",
      "Validation loss decreased from 0.694390519098802 to 0.6943880427967418\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6901434063911438\n",
      "Validation loss decreased from 0.6943880427967418 to 0.6943871378898621\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6951004862785339\n",
      "Validation loss decreased from 0.6943871378898621 to 0.6943860324946317\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.693044126033783\n",
      "Validation loss decreased from 0.6943860324946317 to 0.6943810419602827\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.691555380821228\n",
      "Validation loss decreased from 0.6943810419602827 to 0.6943747509609569\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6938292980194092\n",
      "Validation loss decreased from 0.6943747509609569 to 0.6943729303099893\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.694485604763031\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6910818815231323\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.691154956817627\n",
      "Validation loss decreased from 0.6943729303099893 to 0.6943713480776007\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6967799067497253\n",
      "Validation loss decreased from 0.6943713480776007 to 0.6943677392872897\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6884899735450745\n",
      "Validation loss decreased from 0.6943677392872897 to 0.6943614482879639\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6984251737594604\n",
      "Validation loss decreased from 0.6943614482879639 to 0.6943601369857788\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6882098317146301\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.689053475856781\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6928098201751709\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6938498020172119\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6927566528320312\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6910988092422485\n",
      "Validation loss decreased from 0.6943601369857788 to 0.6943592591719194\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6928256154060364\n",
      "Validation loss decreased from 0.6943592591719194 to 0.694353694265539\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6944112777709961\n",
      "Validation loss decreased from 0.694353694265539 to 0.6943474249406294\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6891264915466309\n",
      "Validation loss decreased from 0.6943474249406294 to 0.6943424831737172\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6934864521026611\n",
      "Validation loss decreased from 0.6943424831737172 to 0.6943339542909102\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.693284273147583\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6894528865814209\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6954513192176819\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6855456233024597\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6930863857269287\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6917266845703125\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6918020248413086\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6930645704269409\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6943259239196777\n",
      "Validation loss decreased from 0.6943339542909102 to 0.6943288445472717\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6892896294593811\n",
      "Validation loss decreased from 0.6943288445472717 to 0.6943265308033336\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6924492120742798\n",
      "Validation loss decreased from 0.6943265308033336 to 0.6943264386870645\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6915083527565002\n",
      "Validation loss decreased from 0.6943264386870645 to 0.6943248618732799\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6953151822090149\n",
      "Validation loss decreased from 0.6943248618732799 to 0.69431302764199\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6890420317649841\n",
      "Validation loss decreased from 0.69431302764199 to 0.6943032145500183\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6930563449859619\n",
      "Validation loss decreased from 0.6943032145500183 to 0.6942989121783864\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6928948163986206\n",
      "Validation loss decreased from 0.6942989121783864 to 0.6942887739701704\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.693844735622406\n",
      "Validation loss decreased from 0.6942887739701704 to 0.694279058413072\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6898351907730103\n",
      "Validation loss decreased from 0.694279058413072 to 0.6942781426689841\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.689734697341919\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6937680840492249\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6949796080589294\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6940420866012573\n",
      "Validation loss decreased from 0.6942781426689841 to 0.6942763978784735\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6961337924003601\n",
      "Validation loss decreased from 0.6942763978784735 to 0.6942738511345603\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.692347526550293\n",
      "Validation loss decreased from 0.6942738511345603 to 0.6942699551582336\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6848649382591248\n",
      "Validation loss decreased from 0.6942699551582336 to 0.6942596110430631\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6890823245048523\n",
      "Validation loss decreased from 0.6942596110430631 to 0.6942503398114984\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6910434365272522\n",
      "Validation loss decreased from 0.6942503398114984 to 0.694245847788724\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.692298948764801\n",
      "Validation loss decreased from 0.694245847788724 to 0.6942444552074779\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6963154077529907\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6895549893379211\n",
      "Validation loss decreased from 0.6942444552074779 to 0.6942405321381309\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6893466711044312\n",
      "Validation loss decreased from 0.6942405321381309 to 0.6942387873476202\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.687301754951477\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.691657543182373\n",
      "Validation loss decreased from 0.6942387873476202 to 0.6942365115339105\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6916146874427795\n",
      "Validation loss decreased from 0.6942365115339105 to 0.694226086139679\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6901000142097473\n",
      "Validation loss decreased from 0.694226086139679 to 0.6942248452793468\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6987478733062744\n",
      "Validation loss decreased from 0.6942248452793468 to 0.6942245472561229\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6921373605728149\n",
      "Validation loss decreased from 0.6942245472561229 to 0.6942221522331238\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6880363821983337\n",
      "Validation loss decreased from 0.6942221522331238 to 0.694213477048007\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6936060190200806\n",
      "Validation loss decreased from 0.694213477048007 to 0.694206877188249\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6880286931991577\n",
      "Validation loss decreased from 0.694206877188249 to 0.6942005753517151\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6896433234214783\n",
      "Validation loss decreased from 0.6942005753517151 to 0.6942004507238214\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6900259852409363\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6922323107719421\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6912868618965149\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6939969658851624\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6954222321510315\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6943577527999878\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6938247084617615\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6874186396598816\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6914184093475342\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6930037140846252\n",
      "Validation loss decreased from 0.6942004507238214 to 0.6941990635611794\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6873655319213867\n",
      "Validation loss decreased from 0.6941990635611794 to 0.6941941001198508\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6862471699714661\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.690093994140625\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6912289261817932\n",
      "Validation loss decreased from 0.6941941001198508 to 0.6941873864694075\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6978569030761719\n",
      "Validation loss decreased from 0.6941873864694075 to 0.6941845687952909\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6915656924247742\n",
      "Validation loss decreased from 0.6941845687952909 to 0.6941839781674471\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6887006163597107\n",
      "Validation loss decreased from 0.6941839781674471 to 0.6941791339354082\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6901146769523621\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6934286952018738\n",
      "Validation loss decreased from 0.6941791339354082 to 0.6941763975403525\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6909206509590149\n",
      "Validation loss decreased from 0.6941763975403525 to 0.694169895215468\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6924141645431519\n",
      "Validation loss decreased from 0.694169895215468 to 0.6941618756814436\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6916161179542542\n",
      "Validation loss decreased from 0.6941618756814436 to 0.6941540783101862\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6921520233154297\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6917867064476013\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6922479271888733\n",
      "Validation loss decreased from 0.6941540783101862 to 0.6941520734266802\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6889953017234802\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6890916228294373\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6910511255264282\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6898963451385498\n",
      "Validation loss decreased from 0.6941520734266802 to 0.6941496675664728\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.688858151435852\n",
      "Validation loss decreased from 0.6941496675664728 to 0.6941428834741766\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6906555891036987\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6908676624298096\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6946104764938354\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6918267607688904\n",
      "Validation loss decreased from 0.6941428834741766 to 0.6941410790790211\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6925641894340515\n",
      "Validation loss decreased from 0.6941410790790211 to 0.6941349398006093\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6931378841400146\n",
      "Validation loss decreased from 0.6941349398006093 to 0.6941276463595304\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6916006803512573\n",
      "Validation loss decreased from 0.6941276463595304 to 0.6941186135465448\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6919332146644592\n",
      "Validation loss decreased from 0.6941186135465448 to 0.6941125013611533\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.694311797618866\n",
      "Validation loss decreased from 0.6941125013611533 to 0.6941052241758867\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6915483474731445\n",
      "Validation loss decreased from 0.6941052241758867 to 0.6940995725718412\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6932738423347473\n",
      "Validation loss decreased from 0.6940995725718412 to 0.6940944953398271\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6922226548194885\n",
      "Validation loss decreased from 0.6940944953398271 to 0.6940919377587058\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6893875598907471\n",
      "Validation loss decreased from 0.6940919377587058 to 0.6940865950150923\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6932547092437744\n",
      "Validation loss decreased from 0.6940865950150923 to 0.694082568992268\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6868507862091064\n",
      "Validation loss decreased from 0.694082568992268 to 0.6940813335505399\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6882451176643372\n",
      "Validation loss decreased from 0.6940813335505399 to 0.6940701874819669\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6948453783988953\n",
      "Validation loss decreased from 0.6940701874819669 to 0.6940612196922302\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6926738619804382\n",
      "Validation loss decreased from 0.6940612196922302 to 0.6940471584146674\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6939313411712646\n",
      "Validation loss decreased from 0.6940471584146674 to 0.6940404122525995\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6910515427589417\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6911096572875977\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6903396844863892\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6902400851249695\n",
      "Validation loss decreased from 0.6940404122525995 to 0.6940403363921426\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6884641051292419\n",
      "Validation loss decreased from 0.6940403363921426 to 0.694029298695651\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6880835294723511\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6890096664428711\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6893737316131592\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6860248446464539\n",
      "Validation loss decreased from 0.694029298695651 to 0.6940283829515631\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6922143697738647\n",
      "Validation loss decreased from 0.6940283829515631 to 0.6940248283472928\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6908866763114929\n",
      "Validation loss decreased from 0.6940248283472928 to 0.6940158063715155\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6957640647888184\n",
      "Validation loss decreased from 0.6940158063715155 to 0.6940043622797186\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.690994143486023\n",
      "Validation loss decreased from 0.6940043622797186 to 0.6939951127225702\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6963245272636414\n",
      "Validation loss decreased from 0.6939951127225702 to 0.6939928423274647\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6928988099098206\n",
      "Validation loss decreased from 0.6939928423274647 to 0.693983338095925\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6946112513542175\n",
      "Validation loss decreased from 0.693983338095925 to 0.6939805475148287\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6931813359260559\n",
      "Validation loss decreased from 0.6939805475148287 to 0.6939803903753107\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6913330554962158\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6917804479598999\n",
      "Validation loss decreased from 0.6939803903753107 to 0.6939757845618508\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6939302682876587\n",
      "Validation loss decreased from 0.6939757845618508 to 0.6939686211672697\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.688172459602356\n",
      "Validation loss decreased from 0.6939686211672697 to 0.6939635872840881\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.690579891204834\n",
      "Validation loss decreased from 0.6939635872840881 to 0.6939589489590038\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6934845447540283\n",
      "Validation loss decreased from 0.6939589489590038 to 0.6939522678201849\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6863279938697815\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6910185217857361\n",
      "Validation loss decreased from 0.6939522678201849 to 0.6939494230530479\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6899533867835999\n",
      "Validation loss decreased from 0.6939494230530479 to 0.6939429098909552\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.69148850440979\n",
      "Validation loss decreased from 0.6939429098909552 to 0.693939669565721\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6899271607398987\n",
      "Validation loss decreased from 0.693939669565721 to 0.6939368085427717\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6918134093284607\n",
      "Validation loss decreased from 0.6939368085427717 to 0.6939257925206964\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6868793368339539\n",
      "Validation loss decreased from 0.6939257925206964 to 0.6939168138937517\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6922124028205872\n",
      "Validation loss decreased from 0.6939168138937517 to 0.6939102573828264\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6874810457229614\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6901355981826782\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.689724862575531\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6944312453269958\n",
      "Validation loss decreased from 0.6939102573828264 to 0.6939088051969354\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6930307745933533\n",
      "Validation loss decreased from 0.6939088051969354 to 0.6939010132442821\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6947827339172363\n",
      "Validation loss decreased from 0.6939010132442821 to 0.6938926740126177\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.684994101524353\n",
      "Validation loss decreased from 0.6938926740126177 to 0.6938833269205961\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6941595077514648\n",
      "Validation loss decreased from 0.6938833269205961 to 0.6938811432231556\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6957449913024902\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6944982409477234\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.68818598985672\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6900107264518738\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6929420232772827\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6933284401893616\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6904096007347107\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6914256811141968\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6991212368011475\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6922528743743896\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6924895644187927\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6965293288230896\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6933656930923462\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6921784281730652\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6951413154602051\n",
      "Validation loss decreased from 0.6938811432231556 to 0.6938728527589277\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.688132107257843\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6893320083618164\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6909055113792419\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6905957460403442\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.68907231092453\n",
      "Validation loss decreased from 0.6938728527589277 to 0.6938657814806158\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6975544095039368\n",
      "Validation loss decreased from 0.6938657814806158 to 0.6938567649234425\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6968132257461548\n",
      "Validation loss decreased from 0.6938567649234425 to 0.6938565535978838\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6948589086532593\n",
      "Validation loss decreased from 0.6938565535978838 to 0.693855578249151\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6869750022888184\n",
      "Validation loss decreased from 0.693855578249151 to 0.6938405741344799\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6893895268440247\n",
      "Validation loss decreased from 0.6938405741344799 to 0.6938298832286488\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6902440190315247\n",
      "Validation loss decreased from 0.6938298832286488 to 0.6938290379264138\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.691485583782196\n",
      "Validation loss decreased from 0.6938290379264138 to 0.6938273093917153\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6923195123672485\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6997101306915283\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.690596342086792\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6915178298950195\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6909325122833252\n",
      "Validation loss decreased from 0.6938273093917153 to 0.6938250281594016\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6915921568870544\n",
      "Counter for early stopping: 1 out of 50\n",
      "no early stopping\n",
      "AUC on test data  0.5789272650471389\n",
      "model 12 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6810122132301331\n",
      "Validation loss decreased from inf to 0.6980386809869246\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.7039512395858765\n",
      "Validation loss decreased from 0.6980386809869246 to 0.6948047930544073\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6881847977638245\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6921799182891846\n",
      "Validation loss decreased from 0.6948047930544073 to 0.6944620446725325\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6908856630325317\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6890516877174377\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6906480193138123\n",
      "Validation loss decreased from 0.6944620446725325 to 0.694185966795141\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6895925998687744\n",
      "Validation loss decreased from 0.694185966795141 to 0.6940182989293878\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6864694356918335\n",
      "Validation loss decreased from 0.6940182989293878 to 0.6935465010729703\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6899027228355408\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6886070966720581\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6841850876808167\n",
      "Validation loss decreased from 0.6935465010729703 to 0.6926037614995783\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6836024522781372\n",
      "Validation loss decreased from 0.6926037614995783 to 0.6919672218236056\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6849045157432556\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6814823150634766\n",
      "Validation loss decreased from 0.6919672218236056 to 0.6917212442918257\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.682725191116333\n",
      "Validation loss decreased from 0.6917212442918257 to 0.6913221911950544\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.674476146697998\n",
      "Validation loss decreased from 0.6913221911950544 to 0.6896317709576\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6725202202796936\n",
      "Validation loss decreased from 0.6896317709576 to 0.6889808882366527\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6676875948905945\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6717154383659363\n",
      "Validation loss decreased from 0.6889808882366527 to 0.6881176883524115\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6665698885917664\n",
      "Validation loss decreased from 0.6881176883524115 to 0.6858499212698503\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6640076041221619\n",
      "Validation loss decreased from 0.6858499212698503 to 0.6840100234205072\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6583036780357361\n",
      "Validation loss decreased from 0.6840100234205072 to 0.6827111515131864\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6589783430099487\n",
      "Validation loss decreased from 0.6827111515131864 to 0.6775831092487682\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6584579944610596\n",
      "Validation loss decreased from 0.6775831092487682 to 0.6741725368933245\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6400094628334045\n",
      "Validation loss decreased from 0.6741725368933245 to 0.6685526912862604\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6227748394012451\n",
      "Validation loss decreased from 0.6685526912862604 to 0.661323834549297\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.605316698551178\n",
      "Validation loss decreased from 0.661323834549297 to 0.6487005949020386\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.5998964309692383\n",
      "Validation loss decreased from 0.6487005949020386 to 0.6346000758084384\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.580947995185852\n",
      "Validation loss decreased from 0.6346000758084384 to 0.6216457973827015\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.5006313323974609\n",
      "Validation loss decreased from 0.6216457973827015 to 0.6046552441336892\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.4816220700740814\n",
      "Validation loss decreased from 0.6046552441336892 to 0.5879990295930342\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.44922950863838196\n",
      "Validation loss decreased from 0.5879990295930342 to 0.5714581662958319\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.4130571186542511\n",
      "Validation loss decreased from 0.5714581662958319 to 0.5563189008019187\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.3845372796058655\n",
      "Validation loss decreased from 0.5563189008019187 to 0.54945615475828\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.37233027815818787\n",
      "Validation loss decreased from 0.54945615475828 to 0.5369763726537878\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.30163249373435974\n",
      "Validation loss decreased from 0.5369763726537878 to 0.5310873687267303\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.26814648509025574\n",
      "Validation loss decreased from 0.5310873687267303 to 0.5232665511694822\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.2612130641937256\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.281686007976532\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.20926377177238464\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.1905606985092163\n",
      "Validation loss decreased from 0.5232665511694822 to 0.5160207016901537\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.18794377148151398\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.15932393074035645\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.1349312961101532\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.1644243597984314\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.12360375374555588\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.10636711120605469\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.11546347290277481\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.11342192441225052\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.09561483561992645\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.10047093033790588\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.07682157307863235\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.10474719852209091\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.0783364474773407\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.06747383624315262\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.058268770575523376\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.09355611354112625\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.06572692096233368\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.08659709244966507\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.06545896828174591\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.05739855766296387\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.06991518288850784\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.04858233779668808\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.07062996178865433\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.0524103045463562\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.07456052303314209\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.07841115444898605\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06213204190135002\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.053349804133176804\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.04848286136984825\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.04876185208559036\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.0790768712759018\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.05924707278609276\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.05200444161891937\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.0652913749217987\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.06306617707014084\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.049363430589437485\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.05581004172563553\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.07758508622646332\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.05910981446504593\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.044765654951334\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.03943368047475815\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.05134657397866249\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.04537266492843628\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.05179242789745331\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.04820289835333824\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.056120865046978\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.06140277162194252\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.054447486996650696\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.059193000197410583\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.04530571773648262\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  42\n",
      "AUC on test data  0.8280532413024526\n",
      "model 13 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7085570096969604\n",
      "Validation loss decreased from inf to 0.6932051181793213\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6965081691741943\n",
      "Validation loss decreased from 0.6932051181793213 to 0.6931104985150424\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6923083066940308\n",
      "Validation loss decreased from 0.6931104985150424 to 0.6930374123833396\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7012540698051453\n",
      "Validation loss decreased from 0.6930374123833396 to 0.6929867701096968\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6864726543426514\n",
      "Validation loss decreased from 0.6929867701096968 to 0.6929549629038031\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6961560249328613\n",
      "Validation loss decreased from 0.6929549629038031 to 0.6929393464868719\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7144916653633118\n",
      "Validation loss decreased from 0.6929393464868719 to 0.6929364041848616\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6990459561347961\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.7021089196205139\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6986997127532959\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6983414888381958\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.685299277305603\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.7017597556114197\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6975915431976318\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7059991359710693\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6911342740058899\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6877869367599487\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6890961527824402\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6928547620773315\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.7029122710227966\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6937136650085449\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6925660371780396\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.705475389957428\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6950815916061401\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.691745400428772\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6950806975364685\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6877224445343018\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.701747477054596\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6929442882537842\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6897768974304199\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.7069466710090637\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6959692239761353\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6940205693244934\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.692920446395874\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6984118223190308\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6925278902053833\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6797992587089539\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.7035548686981201\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6869178414344788\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6880509853363037\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6933074593544006\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6818739175796509\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.685390293598175\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6950746774673462\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.693118691444397\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6913382411003113\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6921687126159668\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6928608417510986\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6848347187042236\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6896628737449646\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6998796463012695\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.7031638622283936\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6926073431968689\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6895173788070679\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6939804553985596\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6977612972259521\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6925118565559387\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  7\n",
      "AUC on test data  0.4625540366865287\n",
      "model 14 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6909462213516235\n",
      "Validation loss decreased from inf to 0.6968681595542214\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6909915804862976\n",
      "Validation loss decreased from 0.6968681595542214 to 0.6941627372394908\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6904096007347107\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6900038123130798\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6896806359291077\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6893322467803955\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6889196038246155\n",
      "Validation loss decreased from 0.6941627372394908 to 0.6939515634016558\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6884655356407166\n",
      "Validation loss decreased from 0.6939515634016558 to 0.693698910149661\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6879338026046753\n",
      "Validation loss decreased from 0.693698910149661 to 0.6934160535985773\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6873093843460083\n",
      "Validation loss decreased from 0.6934160535985773 to 0.6930918585170399\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6865576505661011\n",
      "Validation loss decreased from 0.6930918585170399 to 0.6927116404880177\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6857172250747681\n",
      "Validation loss decreased from 0.6927116404880177 to 0.6922778703949668\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6847744584083557\n",
      "Validation loss decreased from 0.6922778703949668 to 0.6917844739827242\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6836571097373962\n",
      "Validation loss decreased from 0.6917844739827242 to 0.691237287087874\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6822918057441711\n",
      "Validation loss decreased from 0.691237287087874 to 0.690612023526972\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6807320713996887\n",
      "Validation loss decreased from 0.690612023526972 to 0.6898519776084207\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6789768934249878\n",
      "Validation loss decreased from 0.6898519776084207 to 0.6888863877816633\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6768852472305298\n",
      "Validation loss decreased from 0.6888863877816633 to 0.6877681504596364\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6744570136070251\n",
      "Validation loss decreased from 0.6877681504596364 to 0.6864873658527028\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6715146899223328\n",
      "Validation loss decreased from 0.6864873658527028 to 0.6848736622116782\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6679205298423767\n",
      "Validation loss decreased from 0.6848736622116782 to 0.6829946908083829\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6633253693580627\n",
      "Validation loss decreased from 0.6829946908083829 to 0.6807009523565118\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6575162410736084\n",
      "Validation loss decreased from 0.6807009523565118 to 0.6778386235237122\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6501017808914185\n",
      "Validation loss decreased from 0.6778386235237122 to 0.674207866191864\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6405107378959656\n",
      "Validation loss decreased from 0.674207866191864 to 0.669618471102281\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6292932629585266\n",
      "Validation loss decreased from 0.669618471102281 to 0.6637858585877852\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6157287359237671\n",
      "Validation loss decreased from 0.6637858585877852 to 0.6558902155269276\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.5999912619590759\n",
      "Validation loss decreased from 0.6558902155269276 to 0.6448463905941356\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.5819979310035706\n",
      "Validation loss decreased from 0.6448463905941356 to 0.6304476857185364\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.5630929470062256\n",
      "Validation loss decreased from 0.6304476857185364 to 0.6142854419621554\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.5438764095306396\n",
      "Validation loss decreased from 0.6142854419621554 to 0.599309113892642\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.5221590399742126\n",
      "Validation loss decreased from 0.599309113892642 to 0.585470898584886\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.4991576373577118\n",
      "Validation loss decreased from 0.585470898584886 to 0.5730039531534369\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.47657695412635803\n",
      "Validation loss decreased from 0.5730039531534369 to 0.5635088059035215\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.45499956607818604\n",
      "Validation loss decreased from 0.5635088059035215 to 0.5556855689395558\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.42923468351364136\n",
      "Validation loss decreased from 0.5556855689395558 to 0.5484279665079984\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.4046410024166107\n",
      "Validation loss decreased from 0.5484279665079984 to 0.5417296073653481\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.3787221312522888\n",
      "Validation loss decreased from 0.5417296073653481 to 0.536629630760713\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.34780970215797424\n",
      "Validation loss decreased from 0.536629630760713 to 0.5349731851707805\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.31809180974960327\n",
      "Validation loss decreased from 0.5349731851707805 to 0.5343785231763666\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.29535436630249023\n",
      "Validation loss decreased from 0.5343785231763666 to 0.5328486534682187\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.2771868109703064\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.2527850270271301\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.2383277416229248\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.219511479139328\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.20233210921287537\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.1872219443321228\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.17623628675937653\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.16088533401489258\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.15091073513031006\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.13594625890254974\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.12670192122459412\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.11921628564596176\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.11147996038198471\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.10414020717144012\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.09840806573629379\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.09640049934387207\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.09039819985628128\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.08853136748075485\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.08328858762979507\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.08174724131822586\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.07965290546417236\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.0775376483798027\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.07592974603176117\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.073143370449543\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.07204798609018326\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.0700133889913559\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.06903518736362457\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06722963601350784\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.06732794642448425\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.06659083813428879\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.06627671420574188\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.06502647697925568\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.06525355577468872\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.0638417899608612\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.06351886689662933\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.06282534450292587\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.06285988539457321\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.06192736327648163\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.06247171387076378\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.06125207245349884\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.061010658740997314\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.061016324907541275\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.060472507029771805\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.06043402478098869\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.059521667659282684\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.05971382185816765\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.05892081931233406\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.05928545817732811\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.05882769823074341\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.058705251663923264\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  41\n",
      "AUC on test data  0.8102671951252393\n",
      "model 15 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6882196068763733\n",
      "Validation loss decreased from inf to 0.6935540925372731\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6870501637458801\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6902487277984619\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6961817145347595\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6834096908569336\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6889125108718872\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.689675509929657\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6890724897384644\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6903942823410034\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6917004585266113\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6874374747276306\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6888540387153625\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6906208395957947\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6869509816169739\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6843497157096863\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6892629265785217\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6911935806274414\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6888071894645691\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6889170408248901\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6919807195663452\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6902512907981873\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6927391290664673\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6891729235649109\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6872178316116333\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6938884854316711\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6956401467323303\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.691586434841156\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6957706809043884\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6845173239707947\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.692646861076355\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6905685067176819\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6944783329963684\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6885690689086914\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.68653804063797\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6892812252044678\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6866064667701721\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6883087754249573\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6885350346565247\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6881320476531982\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6918325424194336\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6923624873161316\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6903448104858398\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6858009696006775\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6929735541343689\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6873117089271545\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.686674952507019\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6880930066108704\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6915189027786255\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6836434602737427\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6909528970718384\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.692245364189148\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.581987471577377\n",
      "model 16 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6973190903663635\n",
      "Validation loss decreased from inf to 0.6911931688135321\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6983533501625061\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7013729214668274\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.686125636100769\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6911787390708923\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6926230788230896\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6920661330223083\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.692371129989624\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6935511231422424\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6933668255805969\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6948061585426331\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6984180212020874\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6892969012260437\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.693253755569458\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6876351237297058\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6927971243858337\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6923770904541016\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6976830959320068\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7008561491966248\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6908566951751709\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.685088038444519\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6908978819847107\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6946702599525452\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.691290557384491\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6934971213340759\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.692315399646759\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6929708123207092\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6925830841064453\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6854135394096375\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6891402006149292\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6950128078460693\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6945181488990784\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6907528042793274\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6914541721343994\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6920608878135681\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6914076805114746\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.682950496673584\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6912739872932434\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6918025612831116\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6868379712104797\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6910131573677063\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6898221373558044\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6911523938179016\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6924287676811218\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6924147009849548\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6939826011657715\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6920085549354553\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.689271092414856\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6810714602470398\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6945064067840576\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.683329164981842\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5853577430864497\n",
      "model 17 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6971337795257568\n",
      "Validation loss decreased from inf to 0.6915233026851307\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6822091341018677\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6930113434791565\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.685617208480835\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.688902735710144\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6895244717597961\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6882627010345459\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.695365309715271\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6922144293785095\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6933112740516663\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6997349262237549\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6906456351280212\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6944066286087036\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6826199889183044\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6911227107048035\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6863211989402771\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.695426344871521\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6957707405090332\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6894108057022095\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6954401731491089\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.693996012210846\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6848995685577393\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6890106797218323\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6885890960693359\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6876747012138367\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6890323162078857\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6964345574378967\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6879352927207947\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6934338808059692\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6897098422050476\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6954764127731323\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6839843988418579\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6901042461395264\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6925044655799866\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6896070837974548\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6881842613220215\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6895697116851807\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6977028250694275\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6905739903450012\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6894441246986389\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6888757348060608\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6910428404808044\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.69038325548172\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6932409405708313\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6978656053543091\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6860473155975342\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6947947144508362\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.693216860294342\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6961417198181152\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6892895698547363\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6976169943809509\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.512330700027861\n",
      "model 18 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6958773732185364\n",
      "Validation loss decreased from inf to 0.7246823527596213\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6996830105781555\n",
      "Validation loss decreased from 0.7246823527596213 to 0.7245152809403159\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6949424147605896\n",
      "Validation loss decreased from 0.7245152809403159 to 0.7243325385180387\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7039098739624023\n",
      "Validation loss decreased from 0.7243325385180387 to 0.7241581732576544\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.692736804485321\n",
      "Validation loss decreased from 0.7241581732576544 to 0.7239915566010908\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.7164487838745117\n",
      "Validation loss decreased from 0.7239915566010908 to 0.7238215153867548\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.703110933303833\n",
      "Validation loss decreased from 0.7238215153867548 to 0.7236464023590088\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.695097029209137\n",
      "Validation loss decreased from 0.7236464023590088 to 0.7234736572612416\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6846871972084045\n",
      "Validation loss decreased from 0.7234736572612416 to 0.7233072952790693\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7001974582672119\n",
      "Validation loss decreased from 0.7233072952790693 to 0.7231440110640093\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.7058255672454834\n",
      "Validation loss decreased from 0.7231440110640093 to 0.7229782451282848\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.7080059051513672\n",
      "Validation loss decreased from 0.7229782451282848 to 0.7228111949833956\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.701530933380127\n",
      "Validation loss decreased from 0.7228111949833956 to 0.7226438955827192\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6967270970344543\n",
      "Validation loss decreased from 0.7226438955827192 to 0.7224749380891974\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7089232206344604\n",
      "Validation loss decreased from 0.7224749380891974 to 0.7223089716651223\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.7093216776847839\n",
      "Validation loss decreased from 0.7223089716651223 to 0.7221490957520225\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.7103116512298584\n",
      "Validation loss decreased from 0.7221490957520225 to 0.7219860553741455\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6962522864341736\n",
      "Validation loss decreased from 0.7219860553741455 to 0.7218275720422919\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7114802002906799\n",
      "Validation loss decreased from 0.7218275720422919 to 0.721668850291859\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.7070352435112\n",
      "Validation loss decreased from 0.721668850291859 to 0.7215051054954529\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.7076528668403625\n",
      "Validation loss decreased from 0.7215051054954529 to 0.7213495211167769\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.711405336856842\n",
      "Validation loss decreased from 0.7213495211167769 to 0.7211909781802784\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.7066274285316467\n",
      "Validation loss decreased from 0.7211909781802784 to 0.7210310643369501\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.7051746249198914\n",
      "Validation loss decreased from 0.7210310643369501 to 0.7208796739578247\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6999530792236328\n",
      "Validation loss decreased from 0.7208796739578247 to 0.7207283269275319\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7141308784484863\n",
      "Validation loss decreased from 0.7207283269275319 to 0.7205755818973888\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7129815220832825\n",
      "Validation loss decreased from 0.7205755818973888 to 0.7204288135875355\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.7110825777053833\n",
      "Validation loss decreased from 0.7204288135875355 to 0.7202739986506376\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.706454873085022\n",
      "Validation loss decreased from 0.7202739986506376 to 0.7201265638524835\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.7039598822593689\n",
      "Validation loss decreased from 0.7201265638524835 to 0.7199762084267356\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.7021194696426392\n",
      "Validation loss decreased from 0.7199762084267356 to 0.7198278307914734\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.7063488960266113\n",
      "Validation loss decreased from 0.7198278307914734 to 0.7196837392720309\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.7009264230728149\n",
      "Validation loss decreased from 0.7196837392720309 to 0.7195455919612538\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7121132612228394\n",
      "Validation loss decreased from 0.7195455919612538 to 0.7194010506976735\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.7176594734191895\n",
      "Validation loss decreased from 0.7194010506976735 to 0.7192622260613875\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6974202394485474\n",
      "Validation loss decreased from 0.7192622260613875 to 0.719126121564345\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6949476599693298\n",
      "Validation loss decreased from 0.719126121564345 to 0.7189901796254244\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6974346041679382\n",
      "Validation loss decreased from 0.7189901796254244 to 0.7188564213839445\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7201569676399231\n",
      "Validation loss decreased from 0.7188564213839445 to 0.7187263044443998\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.7000394463539124\n",
      "Validation loss decreased from 0.7187263044443998 to 0.7185917279937051\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.7065321207046509\n",
      "Validation loss decreased from 0.7185917279937051 to 0.7184567234732888\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.691805899143219\n",
      "Validation loss decreased from 0.7184567234732888 to 0.7183227809992704\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6932961940765381\n",
      "Validation loss decreased from 0.7183227809992704 to 0.7181869745254517\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6873248219490051\n",
      "Validation loss decreased from 0.7181869745254517 to 0.7180629968643188\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7027518153190613\n",
      "Validation loss decreased from 0.7180629968643188 to 0.7179403142495588\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.7094905972480774\n",
      "Validation loss decreased from 0.7179403142495588 to 0.7178079594265331\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.7025418877601624\n",
      "Validation loss decreased from 0.7178079594265331 to 0.7176747755570845\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.7010836601257324\n",
      "Validation loss decreased from 0.7176747755570845 to 0.7175479368730024\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.7008582949638367\n",
      "Validation loss decreased from 0.7175479368730024 to 0.7174255902116949\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.7069016695022583\n",
      "Validation loss decreased from 0.7174255902116949 to 0.7172957929697904\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.698832094669342\n",
      "Validation loss decreased from 0.7172957929697904 to 0.7171618667515841\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6939014792442322\n",
      "Validation loss decreased from 0.7171618667515841 to 0.7170307798819109\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6952519416809082\n",
      "Validation loss decreased from 0.7170307798819109 to 0.7169080972671509\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6918861865997314\n",
      "Validation loss decreased from 0.7169080972671509 to 0.7167830629782244\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6997613310813904\n",
      "Validation loss decreased from 0.7167830629782244 to 0.7166618488051675\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.708984911441803\n",
      "Validation loss decreased from 0.7166618488051675 to 0.7165418483994224\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6959730386734009\n",
      "Validation loss decreased from 0.7165418483994224 to 0.7164251154119318\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6893358826637268\n",
      "Validation loss decreased from 0.7164251154119318 to 0.7163059928200461\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.7056688070297241\n",
      "Validation loss decreased from 0.7163059928200461 to 0.7161852825771678\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.718244731426239\n",
      "Validation loss decreased from 0.7161852825771678 to 0.716061917218295\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.7175842523574829\n",
      "Validation loss decreased from 0.716061917218295 to 0.7159409902312539\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.698165237903595\n",
      "Validation loss decreased from 0.7159409902312539 to 0.7158251946622675\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.7097794413566589\n",
      "Validation loss decreased from 0.7158251946622675 to 0.7157177058133212\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.7053337693214417\n",
      "Validation loss decreased from 0.7157177058133212 to 0.7156131917780096\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6988933682441711\n",
      "Validation loss decreased from 0.7156131917780096 to 0.7155050526965748\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.710035502910614\n",
      "Validation loss decreased from 0.7155050526965748 to 0.7153913107785311\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.7000468969345093\n",
      "Validation loss decreased from 0.7153913107785311 to 0.7152790752324191\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6898376941680908\n",
      "Validation loss decreased from 0.7152790752324191 to 0.7151671593839471\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6901509761810303\n",
      "Validation loss decreased from 0.7151671593839471 to 0.7150541977448897\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.7072027921676636\n",
      "Validation loss decreased from 0.7150541977448897 to 0.7149334062229503\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6837941408157349\n",
      "Validation loss decreased from 0.7149334062229503 to 0.7148191441189159\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.7049379944801331\n",
      "Validation loss decreased from 0.7148191441189159 to 0.7147163477810946\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.7164542078971863\n",
      "Validation loss decreased from 0.7147163477810946 to 0.7146106579086997\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.7037341594696045\n",
      "Validation loss decreased from 0.7146106579086997 to 0.7144981676881964\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6934589743614197\n",
      "Validation loss decreased from 0.7144981676881964 to 0.7143883813511241\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6962649822235107\n",
      "Validation loss decreased from 0.7143883813511241 to 0.7142843495715748\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.7012681365013123\n",
      "Validation loss decreased from 0.7142843495715748 to 0.7141798680478876\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.72052401304245\n",
      "Validation loss decreased from 0.7141798680478876 to 0.714078507640145\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6895526051521301\n",
      "Validation loss decreased from 0.714078507640145 to 0.7139726823026483\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.7044743299484253\n",
      "Validation loss decreased from 0.7139726823026483 to 0.7138709154996005\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6975002288818359\n",
      "Validation loss decreased from 0.7138709154996005 to 0.7137668295340105\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.7099398374557495\n",
      "Validation loss decreased from 0.7137668295340105 to 0.7136644937775352\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.696061909198761\n",
      "Validation loss decreased from 0.7136644937775352 to 0.7135574167424982\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.7156874537467957\n",
      "Validation loss decreased from 0.7135574167424982 to 0.7134581099856984\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6871362924575806\n",
      "Validation loss decreased from 0.7134581099856984 to 0.7133635932748968\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.7123109102249146\n",
      "Validation loss decreased from 0.7133635932748968 to 0.7132666219364513\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.7051229476928711\n",
      "Validation loss decreased from 0.7132666219364513 to 0.713166518644853\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.7113836407661438\n",
      "Validation loss decreased from 0.713166518644853 to 0.7130702137947083\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6905935406684875\n",
      "Validation loss decreased from 0.7130702137947083 to 0.7129740227352489\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6976025104522705\n",
      "Validation loss decreased from 0.7129740227352489 to 0.7128706249323759\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.693602979183197\n",
      "Validation loss decreased from 0.7128706249323759 to 0.7127701640129089\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6905226707458496\n",
      "Validation loss decreased from 0.7127701640129089 to 0.7126748290928927\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.7056766748428345\n",
      "Validation loss decreased from 0.7126748290928927 to 0.7125821492888711\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6902984976768494\n",
      "Validation loss decreased from 0.7125821492888711 to 0.7124914743683555\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.7080541849136353\n",
      "Validation loss decreased from 0.7124914743683555 to 0.712400496006012\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.69926518201828\n",
      "Validation loss decreased from 0.712400496006012 to 0.712302337993275\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6980584263801575\n",
      "Validation loss decreased from 0.712302337993275 to 0.7122048139572144\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6995172500610352\n",
      "Validation loss decreased from 0.7122048139572144 to 0.7121081948280334\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6996899247169495\n",
      "Validation loss decreased from 0.7121081948280334 to 0.7120167938145724\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.681766152381897\n",
      "Validation loss decreased from 0.7120167938145724 to 0.7119286493821577\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.7017205357551575\n",
      "Validation loss decreased from 0.7119286493821577 to 0.7118390310894359\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6865818500518799\n",
      "Validation loss decreased from 0.7118390310894359 to 0.7117501063780352\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.7103155255317688\n",
      "Validation loss decreased from 0.7117501063780352 to 0.7116639180616899\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6964671015739441\n",
      "Validation loss decreased from 0.7116639180616899 to 0.7115764455361799\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6945637464523315\n",
      "Validation loss decreased from 0.7115764455361799 to 0.7114888483827765\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6987288594245911\n",
      "Validation loss decreased from 0.7114888483827765 to 0.7114015221595764\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6923482418060303\n",
      "Validation loss decreased from 0.7114015221595764 to 0.7113134048201821\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.7200759053230286\n",
      "Validation loss decreased from 0.7113134048201821 to 0.7112238732251254\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.7102681398391724\n",
      "Validation loss decreased from 0.7112238732251254 to 0.7111308032816107\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6913653612136841\n",
      "Validation loss decreased from 0.7111308032816107 to 0.7110438726165078\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.7026307582855225\n",
      "Validation loss decreased from 0.7110438726165078 to 0.7109612822532654\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6956351399421692\n",
      "Validation loss decreased from 0.7109612822532654 to 0.7108797647736289\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6821364164352417\n",
      "Validation loss decreased from 0.7108797647736289 to 0.7107944813641635\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.7077280879020691\n",
      "Validation loss decreased from 0.7107944813641635 to 0.7107164643027566\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6908878087997437\n",
      "Validation loss decreased from 0.7107164643027566 to 0.7106318907304243\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6961017847061157\n",
      "Validation loss decreased from 0.7106318907304243 to 0.7105480974370783\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.7051074504852295\n",
      "Validation loss decreased from 0.7105480974370783 to 0.7104661952365529\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.7019428014755249\n",
      "Validation loss decreased from 0.7104661952365529 to 0.7103829112919894\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6893520355224609\n",
      "Validation loss decreased from 0.7103829112919894 to 0.7103002829985186\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6925983428955078\n",
      "Validation loss decreased from 0.7103002829985186 to 0.7102213447744196\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6945609450340271\n",
      "Validation loss decreased from 0.7102213447744196 to 0.710143343968825\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.7053293585777283\n",
      "Validation loss decreased from 0.710143343968825 to 0.7100615989078175\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.709420919418335\n",
      "Validation loss decreased from 0.7100615989078175 to 0.7099782228469849\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.7008229494094849\n",
      "Validation loss decreased from 0.7099782228469849 to 0.7098900675773621\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6980526447296143\n",
      "Validation loss decreased from 0.7098900675773621 to 0.7098091298883612\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6895460486412048\n",
      "Validation loss decreased from 0.7098091298883612 to 0.7097248001532122\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6928536891937256\n",
      "Validation loss decreased from 0.7097248001532122 to 0.7096440087665211\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6980509161949158\n",
      "Validation loss decreased from 0.7096440087665211 to 0.7095707654953003\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6984032988548279\n",
      "Validation loss decreased from 0.7095707654953003 to 0.7094961946660822\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6881420612335205\n",
      "Validation loss decreased from 0.7094961946660822 to 0.7094251946969465\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6888797879219055\n",
      "Validation loss decreased from 0.7094251946969465 to 0.7093493017283353\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.7042547464370728\n",
      "Validation loss decreased from 0.7093493017283353 to 0.7092746983874928\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.7051260471343994\n",
      "Validation loss decreased from 0.7092746983874928 to 0.7091967842795632\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6989297866821289\n",
      "Validation loss decreased from 0.7091967842795632 to 0.7091199159622192\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.7073325514793396\n",
      "Validation loss decreased from 0.7091199159622192 to 0.7090463042259216\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6721726655960083\n",
      "Validation loss decreased from 0.7090463042259216 to 0.7089662714438005\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.7020191550254822\n",
      "Validation loss decreased from 0.7089662714438005 to 0.7088989236138084\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6948670744895935\n",
      "Validation loss decreased from 0.7088989236138084 to 0.7088290832259438\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6970953941345215\n",
      "Validation loss decreased from 0.7088290832259438 to 0.7087578665126454\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.7036598920822144\n",
      "Validation loss decreased from 0.7087578665126454 to 0.7086897763338956\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.693193793296814\n",
      "Validation loss decreased from 0.7086897763338956 to 0.7086194862018932\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6951899528503418\n",
      "Validation loss decreased from 0.7086194862018932 to 0.7085481069304727\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.7003308534622192\n",
      "Validation loss decreased from 0.7085481069304727 to 0.7084769877520475\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6926068067550659\n",
      "Validation loss decreased from 0.7084769877520475 to 0.7084034356203947\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6999210715293884\n",
      "Validation loss decreased from 0.7084034356203947 to 0.7083299051631581\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.7030113935470581\n",
      "Validation loss decreased from 0.7083299051631581 to 0.7082609805193815\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6951055526733398\n",
      "Validation loss decreased from 0.7082609805193815 to 0.7081893086433411\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6939091086387634\n",
      "Validation loss decreased from 0.7081893086433411 to 0.7081195170229132\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6864622831344604\n",
      "Validation loss decreased from 0.7081195170229132 to 0.708050630309365\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6958319544792175\n",
      "Validation loss decreased from 0.708050630309365 to 0.707983363758434\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.687605619430542\n",
      "Validation loss decreased from 0.707983363758434 to 0.7079173109748147\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.694614589214325\n",
      "Validation loss decreased from 0.7079173109748147 to 0.707848234610124\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6863420605659485\n",
      "Validation loss decreased from 0.707848234610124 to 0.7077797542918812\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.7094939351081848\n",
      "Validation loss decreased from 0.7077797542918812 to 0.7077080336484042\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.681837797164917\n",
      "Validation loss decreased from 0.7077080336484042 to 0.7076373425397006\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.7038726806640625\n",
      "Validation loss decreased from 0.7076373425397006 to 0.707568038593639\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.7090417742729187\n",
      "Validation loss decreased from 0.707568038593639 to 0.7075048251585527\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.698583722114563\n",
      "Validation loss decreased from 0.7075048251585527 to 0.7074385664679788\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6979673504829407\n",
      "Validation loss decreased from 0.7074385664679788 to 0.7073765071955594\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6947042942047119\n",
      "Validation loss decreased from 0.7073765071955594 to 0.7073118469931863\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6873810291290283\n",
      "Validation loss decreased from 0.7073118469931863 to 0.7072480646046725\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6918156743049622\n",
      "Validation loss decreased from 0.7072480646046725 to 0.7071850570765409\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6955918073654175\n",
      "Validation loss decreased from 0.7071850570765409 to 0.7071226510134611\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6991398930549622\n",
      "Validation loss decreased from 0.7071226510134611 to 0.707056381485679\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.7114049792289734\n",
      "Validation loss decreased from 0.707056381485679 to 0.7069930380040949\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6977438926696777\n",
      "Validation loss decreased from 0.7069930380040949 to 0.7069326043128967\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6904718279838562\n",
      "Validation loss decreased from 0.7069326043128967 to 0.7068701007149436\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6942448019981384\n",
      "Validation loss decreased from 0.7068701007149436 to 0.7068050070242449\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.7067528367042542\n",
      "Validation loss decreased from 0.7068050070242449 to 0.70674513686787\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6992977261543274\n",
      "Validation loss decreased from 0.70674513686787 to 0.7066819938746366\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.7127947807312012\n",
      "Validation loss decreased from 0.7066819938746366 to 0.706620530648665\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.689839780330658\n",
      "Validation loss decreased from 0.706620530648665 to 0.7065595388412476\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6956977248191833\n",
      "Validation loss decreased from 0.7065595388412476 to 0.7065041227774187\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6886765956878662\n",
      "Validation loss decreased from 0.7065041227774187 to 0.7064486200159247\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6932259798049927\n",
      "Validation loss decreased from 0.7064486200159247 to 0.7063907113942233\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6878325939178467\n",
      "Validation loss decreased from 0.7063907113942233 to 0.7063311013308439\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.7003456950187683\n",
      "Validation loss decreased from 0.7063311013308439 to 0.706271149895408\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6873111724853516\n",
      "Validation loss decreased from 0.706271149895408 to 0.7062082669951699\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6959476470947266\n",
      "Validation loss decreased from 0.7062082669951699 to 0.7061499357223511\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6945746541023254\n",
      "Validation loss decreased from 0.7061499357223511 to 0.706091815775091\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6927347779273987\n",
      "Validation loss decreased from 0.706091815775091 to 0.7060305855490945\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.70206618309021\n",
      "Validation loss decreased from 0.7060305855490945 to 0.7059752670201388\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.7070972323417664\n",
      "Validation loss decreased from 0.7059752670201388 to 0.7059179544448853\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.7104828357696533\n",
      "Validation loss decreased from 0.7059179544448853 to 0.7058566971258684\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.7076991200447083\n",
      "Validation loss decreased from 0.7058566971258684 to 0.7058001431551847\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6943141222000122\n",
      "Validation loss decreased from 0.7058001431551847 to 0.7057418931614269\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.7096784114837646\n",
      "Validation loss decreased from 0.7057418931614269 to 0.705687018958005\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.7071979641914368\n",
      "Validation loss decreased from 0.705687018958005 to 0.7056362412192605\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6950092315673828\n",
      "Validation loss decreased from 0.7056362412192605 to 0.7055822123180736\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.686571478843689\n",
      "Validation loss decreased from 0.7055822123180736 to 0.7055290287191217\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.701198935508728\n",
      "Validation loss decreased from 0.7055290287191217 to 0.7054783972826871\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6935341954231262\n",
      "Validation loss decreased from 0.7054783972826871 to 0.7054245526140387\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.7053185105323792\n",
      "Validation loss decreased from 0.7054245526140387 to 0.7053687301549044\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6993856430053711\n",
      "Validation loss decreased from 0.7053687301549044 to 0.7053156061605974\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.7046014070510864\n",
      "Validation loss decreased from 0.7053156061605974 to 0.7052608565850691\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6855159401893616\n",
      "Validation loss decreased from 0.7052608565850691 to 0.7052104852416299\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6867359280586243\n",
      "Validation loss decreased from 0.7052104852416299 to 0.7051567326892506\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.7032583355903625\n",
      "Validation loss decreased from 0.7051567326892506 to 0.7051017663695596\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.7023919224739075\n",
      "Validation loss decreased from 0.7051017663695596 to 0.7050485123287548\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6903344988822937\n",
      "Validation loss decreased from 0.7050485123287548 to 0.7050006660548124\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6926968097686768\n",
      "Validation loss decreased from 0.7050006660548124 to 0.7049520936879244\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6877716779708862\n",
      "Validation loss decreased from 0.7049520936879244 to 0.7049048163674094\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.7042899131774902\n",
      "Validation loss decreased from 0.7049048163674094 to 0.704854900186712\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6948012113571167\n",
      "Validation loss decreased from 0.704854900186712 to 0.7048031525178389\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6844379901885986\n",
      "Validation loss decreased from 0.7048031525178389 to 0.7047528299418363\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6891539096832275\n",
      "Validation loss decreased from 0.7047528299418363 to 0.7047043280168013\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6924952268600464\n",
      "Validation loss decreased from 0.7047043280168013 to 0.7046549916267395\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6852161884307861\n",
      "Validation loss decreased from 0.7046549916267395 to 0.7046069665388628\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6882600784301758\n",
      "Validation loss decreased from 0.7046069665388628 to 0.7045565789396112\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.7062356472015381\n",
      "Validation loss decreased from 0.7045565789396112 to 0.7045074430379\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.7055036425590515\n",
      "Validation loss decreased from 0.7045074430379 to 0.7044596346941862\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6890206933021545\n",
      "Validation loss decreased from 0.7044596346941862 to 0.7044112899086692\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.7022307515144348\n",
      "Validation loss decreased from 0.7044112899086692 to 0.7043663263320923\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6947609186172485\n",
      "Validation loss decreased from 0.7043663263320923 to 0.7043176076628945\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6808965802192688\n",
      "Validation loss decreased from 0.7043176076628945 to 0.7042683796449141\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.686988353729248\n",
      "Validation loss decreased from 0.7042683796449141 to 0.7042240717194297\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.7037467956542969\n",
      "Validation loss decreased from 0.7042240717194297 to 0.7041779648173939\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6866090297698975\n",
      "Validation loss decreased from 0.7041779648173939 to 0.7041345238685608\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6978872418403625\n",
      "Validation loss decreased from 0.7041345238685608 to 0.7040897716175426\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6890159845352173\n",
      "Validation loss decreased from 0.7040897716175426 to 0.7040432908318259\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.697861909866333\n",
      "Validation loss decreased from 0.7040432908318259 to 0.7040023803710938\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6992882490158081\n",
      "Validation loss decreased from 0.7040023803710938 to 0.7039618708870627\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6996230483055115\n",
      "Validation loss decreased from 0.7039618708870627 to 0.703919150612571\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6942934989929199\n",
      "Validation loss decreased from 0.703919150612571 to 0.7038781263611533\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.7034289836883545\n",
      "Validation loss decreased from 0.7038781263611533 to 0.7038289200175892\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.7062337398529053\n",
      "Validation loss decreased from 0.7038289200175892 to 0.7037843574177135\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6980850696563721\n",
      "Validation loss decreased from 0.7037843574177135 to 0.7037395726550709\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6968897581100464\n",
      "Validation loss decreased from 0.7037395726550709 to 0.7036930485205217\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6864147782325745\n",
      "Validation loss decreased from 0.7036930485205217 to 0.7036447850140658\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.7023550868034363\n",
      "Validation loss decreased from 0.7036447850140658 to 0.7036040425300598\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6995524168014526\n",
      "Validation loss decreased from 0.7036040425300598 to 0.7035617882555182\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.7031795978546143\n",
      "Validation loss decreased from 0.7035617882555182 to 0.703516342423179\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6913130879402161\n",
      "Validation loss decreased from 0.703516342423179 to 0.7034710428931497\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.691952109336853\n",
      "Validation loss decreased from 0.7034710428931497 to 0.7034309777346525\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6997584104537964\n",
      "Validation loss decreased from 0.7034309777346525 to 0.7033865235068582\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6924663186073303\n",
      "Validation loss decreased from 0.7033865235068582 to 0.7033469947901639\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6875810027122498\n",
      "Validation loss decreased from 0.7033469947901639 to 0.7033120231194929\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6983276009559631\n",
      "Validation loss decreased from 0.7033120231194929 to 0.7032715678215027\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6746788024902344\n",
      "Validation loss decreased from 0.7032715678215027 to 0.7032304026863792\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6914111971855164\n",
      "Validation loss decreased from 0.7032304026863792 to 0.7031881592490457\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6893083453178406\n",
      "Validation loss decreased from 0.7031881592490457 to 0.7031485492532904\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6980298161506653\n",
      "Validation loss decreased from 0.7031485492532904 to 0.7031104998155073\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6829136610031128\n",
      "Validation loss decreased from 0.7031104998155073 to 0.7030704346570101\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6795279383659363\n",
      "Validation loss decreased from 0.7030704346570101 to 0.703032520684329\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6956226825714111\n",
      "Validation loss decreased from 0.703032520684329 to 0.7029944116419012\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6900835633277893\n",
      "Validation loss decreased from 0.7029944116419012 to 0.7029556794600054\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6980627775192261\n",
      "Validation loss decreased from 0.7029556794600054 to 0.702915679324757\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6863489747047424\n",
      "Validation loss decreased from 0.702915679324757 to 0.7028768170963634\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6916735768318176\n",
      "Validation loss decreased from 0.7028768170963634 to 0.7028407021002336\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6972827911376953\n",
      "Validation loss decreased from 0.7028407021002336 to 0.7027996344999834\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.7073755264282227\n",
      "Validation loss decreased from 0.7027996344999834 to 0.7027607451785695\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6970463395118713\n",
      "Validation loss decreased from 0.7027607451785695 to 0.7027253942056135\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6984812617301941\n",
      "Validation loss decreased from 0.7027253942056135 to 0.7026865103028037\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.691267192363739\n",
      "Validation loss decreased from 0.7026865103028037 to 0.7026476643302224\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.7013130187988281\n",
      "Validation loss decreased from 0.7026476643302224 to 0.7026073336601257\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6996436715126038\n",
      "Validation loss decreased from 0.7026073336601257 to 0.702570297501304\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6863553524017334\n",
      "Validation loss decreased from 0.702570297501304 to 0.7025347514586016\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6933103799819946\n",
      "Validation loss decreased from 0.7025347514586016 to 0.7024967128580267\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.7086970806121826\n",
      "Validation loss decreased from 0.7024967128580267 to 0.7024589235132391\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6981779336929321\n",
      "Validation loss decreased from 0.7024589235132391 to 0.7024222829125144\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6952826380729675\n",
      "Validation loss decreased from 0.7024222829125144 to 0.7023860974745317\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.7057685852050781\n",
      "Validation loss decreased from 0.7023860974745317 to 0.702347603711215\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.7090791463851929\n",
      "Validation loss decreased from 0.702347603711215 to 0.7023109305988658\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6933059692382812\n",
      "Validation loss decreased from 0.7023109305988658 to 0.702273818579587\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6941826939582825\n",
      "Validation loss decreased from 0.702273818579587 to 0.7022437615828081\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.695921003818512\n",
      "Validation loss decreased from 0.7022437615828081 to 0.7022110657258467\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6999741792678833\n",
      "Validation loss decreased from 0.7022110657258467 to 0.7021771994504061\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6918777823448181\n",
      "Validation loss decreased from 0.7021771994504061 to 0.7021439508958296\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.7082197070121765\n",
      "Validation loss decreased from 0.7021439508958296 to 0.7021101388064298\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6969585418701172\n",
      "Validation loss decreased from 0.7021101388064298 to 0.7020748853683472\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.694654107093811\n",
      "Validation loss decreased from 0.7020748853683472 to 0.7020392363721674\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.707603394985199\n",
      "Validation loss decreased from 0.7020392363721674 to 0.7020035548643633\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.7027599811553955\n",
      "Validation loss decreased from 0.7020035548643633 to 0.7019663236357949\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6895652413368225\n",
      "Validation loss decreased from 0.7019663236357949 to 0.7019306475465948\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.7037386894226074\n",
      "Validation loss decreased from 0.7019306475465948 to 0.7018949389457703\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6991017460823059\n",
      "Validation loss decreased from 0.7018949389457703 to 0.70185786485672\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6931297183036804\n",
      "Validation loss decreased from 0.70185786485672 to 0.7018220641396262\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6791664361953735\n",
      "Validation loss decreased from 0.7018220641396262 to 0.7017910101196982\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6960229873657227\n",
      "Validation loss decreased from 0.7017910101196982 to 0.701761310750788\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6936817169189453\n",
      "Validation loss decreased from 0.701761310750788 to 0.7017288695682179\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.7058613896369934\n",
      "Validation loss decreased from 0.7017288695682179 to 0.7016923861070112\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6870952248573303\n",
      "Validation loss decreased from 0.7016923861070112 to 0.7016551819714633\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6928886771202087\n",
      "Validation loss decreased from 0.7016551819714633 to 0.7016190344637091\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6998434066772461\n",
      "Validation loss decreased from 0.7016190344637091 to 0.7015855041417208\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6977447867393494\n",
      "Validation loss decreased from 0.7015855041417208 to 0.7015532471916892\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6916857361793518\n",
      "Validation loss decreased from 0.7015532471916892 to 0.7015184272419323\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.7045510411262512\n",
      "Validation loss decreased from 0.7015184272419323 to 0.7014841816642068\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6845702528953552\n",
      "Validation loss decreased from 0.7014841816642068 to 0.7014520330862566\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6929508447647095\n",
      "Validation loss decreased from 0.7014520330862566 to 0.7014224962754683\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6994459629058838\n",
      "Validation loss decreased from 0.7014224962754683 to 0.7013937126506459\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6940149664878845\n",
      "Validation loss decreased from 0.7013937126506459 to 0.7013659856536172\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6930286884307861\n",
      "Validation loss decreased from 0.7013659856536172 to 0.7013372020287947\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6960607171058655\n",
      "Validation loss decreased from 0.7013372020287947 to 0.701308315450495\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6944054365158081\n",
      "Validation loss decreased from 0.701308315450495 to 0.7012807347557761\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.7023188471794128\n",
      "Validation loss decreased from 0.7012807347557761 to 0.7012505585497076\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6920096278190613\n",
      "Validation loss decreased from 0.7012505585497076 to 0.7012190439484336\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.685815691947937\n",
      "Validation loss decreased from 0.7012190439484336 to 0.7011903524398804\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6959270238876343\n",
      "Validation loss decreased from 0.7011903524398804 to 0.7011599107222124\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.7011118531227112\n",
      "Validation loss decreased from 0.7011599107222124 to 0.7011281251907349\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6959846019744873\n",
      "Validation loss decreased from 0.7011281251907349 to 0.7010965293103998\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6912803053855896\n",
      "Validation loss decreased from 0.7010965293103998 to 0.7010661580345847\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6970779895782471\n",
      "Validation loss decreased from 0.7010661580345847 to 0.7010398615490306\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6957042813301086\n",
      "Validation loss decreased from 0.7010398615490306 to 0.7010122808543119\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6922975778579712\n",
      "Validation loss decreased from 0.7010122808543119 to 0.700983155857433\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6941700577735901\n",
      "Validation loss decreased from 0.700983155857433 to 0.7009553421627391\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.7063056826591492\n",
      "Validation loss decreased from 0.7009553421627391 to 0.7009242393753745\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6936722993850708\n",
      "Validation loss decreased from 0.7009242393753745 to 0.7008946212855253\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6915766596794128\n",
      "Validation loss decreased from 0.7008946212855253 to 0.7008649056608026\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.7016964554786682\n",
      "Validation loss decreased from 0.7008649056608026 to 0.7008367343382402\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.695825457572937\n",
      "Validation loss decreased from 0.7008367343382402 to 0.7008092565969988\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6867308020591736\n",
      "Validation loss decreased from 0.7008092565969988 to 0.7007787986235186\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.7095763087272644\n",
      "Validation loss decreased from 0.7007787986235186 to 0.7007505785335194\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.699923574924469\n",
      "Validation loss decreased from 0.7007505785335194 to 0.7007203264669939\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6988138556480408\n",
      "Validation loss decreased from 0.7007203264669939 to 0.700690361586484\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.689848005771637\n",
      "Validation loss decreased from 0.700690361586484 to 0.7006618868220936\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6794684529304504\n",
      "Validation loss decreased from 0.7006618868220936 to 0.7006334283135154\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6995643377304077\n",
      "Validation loss decreased from 0.7006334283135154 to 0.7006037181073969\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.7000899910926819\n",
      "Validation loss decreased from 0.7006037181073969 to 0.7005750862034884\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6850695610046387\n",
      "Validation loss decreased from 0.7005750862034884 to 0.7005439129742709\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.7025356888771057\n",
      "Validation loss decreased from 0.7005439129742709 to 0.7005126693032004\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.690247118473053\n",
      "Validation loss decreased from 0.7005126693032004 to 0.7004838369109414\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6919373869895935\n",
      "Validation loss decreased from 0.7004838369109414 to 0.7004539804025129\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6939446926116943\n",
      "Validation loss decreased from 0.7004539804025129 to 0.7004231756383722\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6976006627082825\n",
      "Validation loss decreased from 0.7004231756383722 to 0.7003960717808116\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6918051242828369\n",
      "Validation loss decreased from 0.7003960717808116 to 0.700370582667264\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6904521584510803\n",
      "Validation loss decreased from 0.700370582667264 to 0.700342904437672\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6813046932220459\n",
      "Validation loss decreased from 0.700342904437672 to 0.7003172473473982\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6978224515914917\n",
      "Validation loss decreased from 0.7003172473473982 to 0.7002915143966675\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6893108487129211\n",
      "Validation loss decreased from 0.7002915143966675 to 0.7002667513760653\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.706620454788208\n",
      "Validation loss decreased from 0.7002667513760653 to 0.7002440311691978\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6935216188430786\n",
      "Validation loss decreased from 0.7002440311691978 to 0.7002177346836437\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6917731165885925\n",
      "Validation loss decreased from 0.7002177346836437 to 0.700191692872481\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.7042139172554016\n",
      "Validation loss decreased from 0.700191692872481 to 0.700167487968098\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6953374147415161\n",
      "Validation loss decreased from 0.700167487968098 to 0.7001418579708446\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6999451518058777\n",
      "Validation loss decreased from 0.7001418579708446 to 0.7001171274618669\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6961591839790344\n",
      "Validation loss decreased from 0.7001171274618669 to 0.7000896605578336\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6877252459526062\n",
      "Validation loss decreased from 0.7000896605578336 to 0.7000644152814691\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.7001080513000488\n",
      "Validation loss decreased from 0.7000644152814691 to 0.7000389911911704\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6982743740081787\n",
      "Validation loss decreased from 0.7000389911911704 to 0.7000129818916321\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6933271288871765\n",
      "Validation loss decreased from 0.7000129818916321 to 0.6999878937547858\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6907702088356018\n",
      "Validation loss decreased from 0.6999878937547858 to 0.6999613696878607\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6962375640869141\n",
      "Validation loss decreased from 0.6999613696878607 to 0.6999369101090864\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.7043533325195312\n",
      "Validation loss decreased from 0.6999369101090864 to 0.6999094106934287\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.687106192111969\n",
      "Validation loss decreased from 0.6999094106934287 to 0.6998848048123446\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6868516206741333\n",
      "Validation loss decreased from 0.6998848048123446 to 0.699857462536205\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.7067935466766357\n",
      "Validation loss decreased from 0.699857462536205 to 0.6998343467712402\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6823031306266785\n",
      "Validation loss decreased from 0.6998343467712402 to 0.6998104127970609\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6879053115844727\n",
      "Validation loss decreased from 0.6998104127970609 to 0.6997883319854736\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6906248927116394\n",
      "Validation loss decreased from 0.6997883319854736 to 0.6997660344297235\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.7001772522926331\n",
      "Validation loss decreased from 0.6997660344297235 to 0.6997412822463296\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6932383179664612\n",
      "Validation loss decreased from 0.6997412822463296 to 0.6997158527374268\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6923292875289917\n",
      "Validation loss decreased from 0.6997158527374268 to 0.6996915611353788\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6905340552330017\n",
      "Validation loss decreased from 0.6996915611353788 to 0.6996701088818637\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.698049783706665\n",
      "Validation loss decreased from 0.6996701088818637 to 0.6996508078141646\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6986090540885925\n",
      "Validation loss decreased from 0.6996508078141646 to 0.6996285427700389\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.7077488899230957\n",
      "Validation loss decreased from 0.6996285427700389 to 0.6996031674471769\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6988672614097595\n",
      "Validation loss decreased from 0.6996031674471769 to 0.6995784152637828\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6985692977905273\n",
      "Validation loss decreased from 0.6995784152637828 to 0.6995572501962836\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6827309727668762\n",
      "Validation loss decreased from 0.6995572501962836 to 0.6995336359197443\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.7035890817642212\n",
      "Validation loss decreased from 0.6995336359197443 to 0.6995126063173468\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6959254145622253\n",
      "Validation loss decreased from 0.6995126063173468 to 0.6994903575290333\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.7025083899497986\n",
      "Validation loss decreased from 0.6994903575290333 to 0.6994687806476246\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6998929381370544\n",
      "Validation loss decreased from 0.6994687806476246 to 0.6994441097432916\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6867082715034485\n",
      "Validation loss decreased from 0.6994441097432916 to 0.699422072280537\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6948464512825012\n",
      "Validation loss decreased from 0.699422072280537 to 0.6994000781666149\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6972082257270813\n",
      "Validation loss decreased from 0.6994000781666149 to 0.6993770707737316\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6978880763053894\n",
      "Validation loss decreased from 0.6993770707737316 to 0.6993579051711343\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6966010928153992\n",
      "Validation loss decreased from 0.6993579051711343 to 0.6993400671265342\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6917687058448792\n",
      "Validation loss decreased from 0.6993400671265342 to 0.699321221221577\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6926742792129517\n",
      "Validation loss decreased from 0.699321221221577 to 0.6992979483170942\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.699969470500946\n",
      "Validation loss decreased from 0.6992979483170942 to 0.699274789203297\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6964672803878784\n",
      "Validation loss decreased from 0.699274789203297 to 0.6992525133219633\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6878830194473267\n",
      "Validation loss decreased from 0.6992525133219633 to 0.6992316300218756\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6771017909049988\n",
      "Validation loss decreased from 0.6992316300218756 to 0.6992117166519165\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.685576856136322\n",
      "Validation loss decreased from 0.6992117166519165 to 0.6991868398406289\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6825251579284668\n",
      "Validation loss decreased from 0.6991868398406289 to 0.6991635777733543\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6943865418434143\n",
      "Validation loss decreased from 0.6991635777733543 to 0.6991431062871759\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6911004185676575\n",
      "Validation loss decreased from 0.6991431062871759 to 0.6991246938705444\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.7041923403739929\n",
      "Validation loss decreased from 0.6991246938705444 to 0.6991036913611672\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.690151572227478\n",
      "Validation loss decreased from 0.6991036913611672 to 0.6990820982239463\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6939412355422974\n",
      "Validation loss decreased from 0.6990820982239463 to 0.699063469063152\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6941816210746765\n",
      "Validation loss decreased from 0.699063469063152 to 0.699044942855835\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6840358376502991\n",
      "Validation loss decreased from 0.699044942855835 to 0.6990278850902211\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.690018892288208\n",
      "Validation loss decreased from 0.6990278850902211 to 0.6990097110921686\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6785110831260681\n",
      "Validation loss decreased from 0.6990097110921686 to 0.6989892992106351\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6768646240234375\n",
      "Validation loss decreased from 0.6989892992106351 to 0.6989691420034929\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.7015810608863831\n",
      "Validation loss decreased from 0.6989691420034929 to 0.6989522197029807\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6769428849220276\n",
      "Validation loss decreased from 0.6989522197029807 to 0.698935026472265\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6798138618469238\n",
      "Validation loss decreased from 0.698935026472265 to 0.698917643590407\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6965243816375732\n",
      "Validation loss decreased from 0.698917643590407 to 0.6988988735459067\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6980154514312744\n",
      "Validation loss decreased from 0.6988988735459067 to 0.6988793882456693\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6936139464378357\n",
      "Validation loss decreased from 0.6988793882456693 to 0.6988614580848\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6915871500968933\n",
      "Validation loss decreased from 0.6988614580848 to 0.6988428018309853\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6898767352104187\n",
      "Validation loss decreased from 0.6988428018309853 to 0.6988249258561567\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6911716461181641\n",
      "Validation loss decreased from 0.6988249258561567 to 0.6988072503696788\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6926929950714111\n",
      "Validation loss decreased from 0.6988072503696788 to 0.6987890709530223\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6906449198722839\n",
      "Validation loss decreased from 0.6987890709530223 to 0.698771433396773\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.697324812412262\n",
      "Validation loss decreased from 0.698771433396773 to 0.6987523815848611\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6916062235832214\n",
      "Validation loss decreased from 0.6987523815848611 to 0.6987346952611749\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6821304559707642\n",
      "Validation loss decreased from 0.6987346952611749 to 0.6987132159146395\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.7037035226821899\n",
      "Validation loss decreased from 0.6987132159146395 to 0.6986925005912781\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.692671537399292\n",
      "Validation loss decreased from 0.6986925005912781 to 0.6986741315234791\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6997694373130798\n",
      "Validation loss decreased from 0.6986741315234791 to 0.6986555240371011\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6946897506713867\n",
      "Validation loss decreased from 0.6986555240371011 to 0.6986370520158247\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.683442234992981\n",
      "Validation loss decreased from 0.6986370520158247 to 0.6986172686923634\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6913455128669739\n",
      "Validation loss decreased from 0.6986172686923634 to 0.698601858182387\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6928703188896179\n",
      "Validation loss decreased from 0.698601858182387 to 0.6985845403237776\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6913309693336487\n",
      "Validation loss decreased from 0.6985845403237776 to 0.6985669894651934\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6920258402824402\n",
      "Validation loss decreased from 0.6985669894651934 to 0.6985495849089189\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6973108649253845\n",
      "Validation loss decreased from 0.6985495849089189 to 0.6985318010503595\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6894656419754028\n",
      "Validation loss decreased from 0.6985318010503595 to 0.6985151388428428\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6943283081054688\n",
      "Validation loss decreased from 0.6985151388428428 to 0.6984964229843833\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6874637603759766\n",
      "Validation loss decreased from 0.6984964229843833 to 0.6984783952886408\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6941718459129333\n",
      "Validation loss decreased from 0.6984783952886408 to 0.6984602808952332\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.7072862386703491\n",
      "Validation loss decreased from 0.6984602808952332 to 0.6984414295716719\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6862947344779968\n",
      "Validation loss decreased from 0.6984414295716719 to 0.6984277205033735\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6844378113746643\n",
      "Validation loss decreased from 0.6984277205033735 to 0.6984140602025118\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6809970736503601\n",
      "Validation loss decreased from 0.6984140602025118 to 0.6983995654366233\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.7083226442337036\n",
      "Validation loss decreased from 0.6983995654366233 to 0.6983864307403564\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.7010857462882996\n",
      "Validation loss decreased from 0.6983864307403564 to 0.6983690695329146\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6948262453079224\n",
      "Validation loss decreased from 0.6983690695329146 to 0.6983532797206532\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6895924806594849\n",
      "Validation loss decreased from 0.6983532797206532 to 0.6983387036757036\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6945542097091675\n",
      "Validation loss decreased from 0.6983387036757036 to 0.6983231522820212\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6877908706665039\n",
      "Validation loss decreased from 0.6983231522820212 to 0.6983089717951688\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6960530877113342\n",
      "Validation loss decreased from 0.6983089717951688 to 0.6982914155179804\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6893402338027954\n",
      "Validation loss decreased from 0.6982914155179804 to 0.6982762596823953\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6916414499282837\n",
      "Validation loss decreased from 0.6982762596823953 to 0.6982619979164817\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.7078639268875122\n",
      "Validation loss decreased from 0.6982619979164817 to 0.6982452435926958\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6969667673110962\n",
      "Validation loss decreased from 0.6982452435926958 to 0.6982298710129478\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.7064943313598633\n",
      "Validation loss decreased from 0.6982298710129478 to 0.6982143087820574\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6885949969291687\n",
      "Validation loss decreased from 0.6982143087820574 to 0.6981981667605314\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6917027235031128\n",
      "Validation loss decreased from 0.6981981667605314 to 0.6981801119717684\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6876737475395203\n",
      "Validation loss decreased from 0.6981801119717684 to 0.6981633847410028\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6942338347434998\n",
      "Validation loss decreased from 0.6981633847410028 to 0.6981463974172418\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6927250623703003\n",
      "Validation loss decreased from 0.6981463974172418 to 0.6981317942792719\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.682325005531311\n",
      "Validation loss decreased from 0.6981317942792719 to 0.6981152079322122\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6996133923530579\n",
      "Validation loss decreased from 0.6981152079322122 to 0.698101357980208\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6975564956665039\n",
      "Validation loss decreased from 0.698101357980208 to 0.6980884725397284\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6943017840385437\n",
      "Validation loss decreased from 0.6980884725397284 to 0.6980729699134827\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.7010640501976013\n",
      "Validation loss decreased from 0.6980729699134827 to 0.6980614391240206\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6934613585472107\n",
      "Validation loss decreased from 0.6980614391240206 to 0.6980492364276539\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6918626427650452\n",
      "Validation loss decreased from 0.6980492364276539 to 0.6980341401967135\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6982063055038452\n",
      "Validation loss decreased from 0.6980341401967135 to 0.6980172395706177\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6995822787284851\n",
      "Validation loss decreased from 0.6980172395706177 to 0.6980022571303628\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6911382079124451\n",
      "Validation loss decreased from 0.6980022571303628 to 0.6979877352714539\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6944357752799988\n",
      "Validation loss decreased from 0.6979877352714539 to 0.6979749798774719\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6937925219535828\n",
      "Validation loss decreased from 0.6979749798774719 to 0.697962143204429\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6833217740058899\n",
      "Validation loss decreased from 0.697962143204429 to 0.6979514306241815\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6896306276321411\n",
      "Validation loss decreased from 0.6979514306241815 to 0.6979392225092108\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.696692168712616\n",
      "Validation loss decreased from 0.6979392225092108 to 0.6979237415573813\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6983576416969299\n",
      "Validation loss decreased from 0.6979237415573813 to 0.6979109699075873\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.7002999782562256\n",
      "Validation loss decreased from 0.6979109699075873 to 0.6979011188853871\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6871780157089233\n",
      "Validation loss decreased from 0.6979011188853871 to 0.6978876915845004\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6920298337936401\n",
      "Validation loss decreased from 0.6978876915845004 to 0.6978704116561196\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.696876049041748\n",
      "Validation loss decreased from 0.6978704116561196 to 0.6978544376113198\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6975515484809875\n",
      "Validation loss decreased from 0.6978544376113198 to 0.6978399970314719\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6932376027107239\n",
      "Validation loss decreased from 0.6978399970314719 to 0.697825784032995\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6956363320350647\n",
      "Validation loss decreased from 0.697825784032995 to 0.6978145675225691\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6892834305763245\n",
      "Validation loss decreased from 0.6978145675225691 to 0.697801801291379\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6887880563735962\n",
      "Validation loss decreased from 0.697801801291379 to 0.697789652781053\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.7023971080780029\n",
      "Validation loss decreased from 0.697789652781053 to 0.6977755264802412\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.699553370475769\n",
      "Validation loss decreased from 0.6977755264802412 to 0.6977610425515608\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6992998719215393\n",
      "Validation loss decreased from 0.6977610425515608 to 0.6977444887161255\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6884055137634277\n",
      "Validation loss decreased from 0.6977444887161255 to 0.6977298693223433\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.7015925049781799\n",
      "Validation loss decreased from 0.6977298693223433 to 0.6977151686495001\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6943565607070923\n",
      "Validation loss decreased from 0.6977151686495001 to 0.6976988749070601\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6955087184906006\n",
      "Validation loss decreased from 0.6976988749070601 to 0.697683719071475\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6929382085800171\n",
      "Validation loss decreased from 0.697683719071475 to 0.6976687420498241\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6838720440864563\n",
      "Validation loss decreased from 0.6976687420498241 to 0.6976535807956349\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6959033012390137\n",
      "Validation loss decreased from 0.6976535807956349 to 0.6976407441225919\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6919416785240173\n",
      "Validation loss decreased from 0.6976407441225919 to 0.697627685286782\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6974043250083923\n",
      "Validation loss decreased from 0.697627685286782 to 0.6976145831021395\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6940171122550964\n",
      "Validation loss decreased from 0.6976145831021395 to 0.6976006518710743\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6983804702758789\n",
      "Validation loss decreased from 0.6976006518710743 to 0.697585100477392\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6854455471038818\n",
      "Validation loss decreased from 0.697585100477392 to 0.6975708495486866\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6810172200202942\n",
      "Validation loss decreased from 0.6975708495486866 to 0.6975605433637445\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6926384568214417\n",
      "Validation loss decreased from 0.6975605433637445 to 0.6975479667836969\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6865882277488708\n",
      "Validation loss decreased from 0.6975479667836969 to 0.6975341222502969\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6947070956230164\n",
      "Validation loss decreased from 0.6975341222502969 to 0.6975211230191317\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6961449980735779\n",
      "Validation loss decreased from 0.6975211230191317 to 0.6975107789039612\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6896240711212158\n",
      "Validation loss decreased from 0.6975107789039612 to 0.697496847672896\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6864631175994873\n",
      "Validation loss decreased from 0.697496847672896 to 0.6974836479533802\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6933607459068298\n",
      "Validation loss decreased from 0.6974836479533802 to 0.6974743658846075\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6938795447349548\n",
      "Validation loss decreased from 0.6974743658846075 to 0.6974620385603472\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6964819431304932\n",
      "Validation loss decreased from 0.6974620385603472 to 0.6974504806778647\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.689395546913147\n",
      "Validation loss decreased from 0.6974504806778647 to 0.697440196167339\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6867148876190186\n",
      "Validation loss decreased from 0.697440196167339 to 0.6974275545640425\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6982613205909729\n",
      "Validation loss decreased from 0.6974275545640425 to 0.6974133361469615\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6991084814071655\n",
      "Validation loss decreased from 0.6974133361469615 to 0.6973999196832831\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6845214366912842\n",
      "Validation loss decreased from 0.6973999196832831 to 0.6973840865221891\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6959702372550964\n",
      "Validation loss decreased from 0.6973840865221891 to 0.697370008988814\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6931524276733398\n",
      "Validation loss decreased from 0.697370008988814 to 0.6973578984087164\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.7007356882095337\n",
      "Validation loss decreased from 0.6973578984087164 to 0.6973461292006753\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6955718398094177\n",
      "Validation loss decreased from 0.6973461292006753 to 0.6973336176438765\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6940339803695679\n",
      "Validation loss decreased from 0.6973336176438765 to 0.6973232735287059\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.694719672203064\n",
      "Validation loss decreased from 0.6973232735287059 to 0.697311439297416\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6908929944038391\n",
      "Validation loss decreased from 0.697311439297416 to 0.697296679019928\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.7108153104782104\n",
      "Validation loss decreased from 0.697296679019928 to 0.6972852511839434\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.7035133242607117\n",
      "Validation loss decreased from 0.6972852511839434 to 0.6972717480225996\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6932159066200256\n",
      "Validation loss decreased from 0.6972717480225996 to 0.6972583153031089\n",
      "no early stopping\n",
      "AUC on test data  0.5383716645546298\n",
      "model 19 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6910812854766846\n",
      "Validation loss decreased from inf to 0.6946322647008029\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6904167532920837\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6898595094680786\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6895890831947327\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6893051862716675\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6890203952789307\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6887129545211792\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.688371479511261\n",
      "Validation loss decreased from 0.6946322647008029 to 0.6945796988227151\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.687987208366394\n",
      "Validation loss decreased from 0.6945796988227151 to 0.6944011395627802\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6875379085540771\n",
      "Validation loss decreased from 0.6944011395627802 to 0.6941858259114352\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6869770288467407\n",
      "Validation loss decreased from 0.6941858259114352 to 0.6939051097089594\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6863602995872498\n",
      "Validation loss decreased from 0.6939051097089594 to 0.6935901912775907\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6857286095619202\n",
      "Validation loss decreased from 0.6935901912775907 to 0.6932564973831177\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6850203275680542\n",
      "Validation loss decreased from 0.6932564973831177 to 0.6929038546302102\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.684158444404602\n",
      "Validation loss decreased from 0.6929038546302102 to 0.6924724524671381\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6831957697868347\n",
      "Validation loss decreased from 0.6924724524671381 to 0.6919428543611006\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6820807456970215\n",
      "Validation loss decreased from 0.6919428543611006 to 0.6913074417547747\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6806997656822205\n",
      "Validation loss decreased from 0.6913074417547747 to 0.6905401132323525\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6791078448295593\n",
      "Validation loss decreased from 0.6905401132323525 to 0.6895901344039224\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6772143840789795\n",
      "Validation loss decreased from 0.6895901344039224 to 0.6884152889251709\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6749241948127747\n",
      "Validation loss decreased from 0.6884152889251709 to 0.6870012012394991\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6719880700111389\n",
      "Validation loss decreased from 0.6870012012394991 to 0.6852975541895087\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6682325601577759\n",
      "Validation loss decreased from 0.6852975541895087 to 0.6831261623989452\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6637974381446838\n",
      "Validation loss decreased from 0.6831261623989452 to 0.6805121248418634\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6583340167999268\n",
      "Validation loss decreased from 0.6805121248418634 to 0.6774202585220337\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.651271641254425\n",
      "Validation loss decreased from 0.6774202585220337 to 0.6732919595458291\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6426689028739929\n",
      "Validation loss decreased from 0.6732919595458291 to 0.6680609475482594\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6317014098167419\n",
      "Validation loss decreased from 0.6680609475482594 to 0.6613052053885027\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6184849739074707\n",
      "Validation loss decreased from 0.6613052053885027 to 0.6522551666606556\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6027414202690125\n",
      "Validation loss decreased from 0.6522551666606556 to 0.6402202411131426\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.5855318307876587\n",
      "Validation loss decreased from 0.6402202411131426 to 0.6260873512788252\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.5682044625282288\n",
      "Validation loss decreased from 0.6260873512788252 to 0.6119260625405745\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.5487545132637024\n",
      "Validation loss decreased from 0.6119260625405745 to 0.5994175618345087\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.5261257886886597\n",
      "Validation loss decreased from 0.5994175618345087 to 0.5871692083098672\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.5007911920547485\n",
      "Validation loss decreased from 0.5871692083098672 to 0.5771104747598822\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.4751436412334442\n",
      "Validation loss decreased from 0.5771104747598822 to 0.5685353495857932\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.44892916083335876\n",
      "Validation loss decreased from 0.5685353495857932 to 0.5618839914148505\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.42050492763519287\n",
      "Validation loss decreased from 0.5618839914148505 to 0.5570197999477386\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.3888266682624817\n",
      "Validation loss decreased from 0.5570197999477386 to 0.5520092763684012\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.36097800731658936\n",
      "Validation loss decreased from 0.5520092763684012 to 0.5498731596903368\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.32942500710487366\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.30408474802970886\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.2763431668281555\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.25425392389297485\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.23026753962039948\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.21956908702850342\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.199569970369339\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.1862560361623764\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.1706402450799942\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.15254804491996765\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.13932263851165771\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.12962406873703003\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.11744704097509384\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.10713902860879898\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.10224194079637527\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.09453961253166199\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.08862241357564926\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.08349869400262833\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.07909590750932693\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.07625886797904968\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.07224123179912567\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.07017029076814651\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.06779249012470245\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.06601422280073166\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.06547248363494873\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.06411423534154892\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.06247924640774727\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.06185068190097809\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06034412607550621\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.05980201065540314\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.05841026455163956\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.057305771857500076\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.05653458461165428\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.055900800973176956\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.05539539083838463\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05516969412565231\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.05433434993028641\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.054067328572273254\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.053595468401908875\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.05280483141541481\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.05335487425327301\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.05279393866658211\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.05257980525493622\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.052150629460811615\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.05202170088887215\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.0519011914730072\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.05187033861875534\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.051883623003959656\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.05134930461645126\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.05102819204330444\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  40\n",
      "AUC on test data  0.8041108325019996\n",
      "model 20 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6851434707641602\n",
      "Validation loss decreased from inf to 0.6990090662782843\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6889102458953857\n",
      "Validation loss decreased from 0.6990090662782843 to 0.6987859281626615\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.694821298122406\n",
      "Validation loss decreased from 0.6987859281626615 to 0.6985841339284723\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.692876398563385\n",
      "Validation loss decreased from 0.6985841339284723 to 0.6983751058578491\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6969144344329834\n",
      "Validation loss decreased from 0.6983751058578491 to 0.6981856497851285\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6909371018409729\n",
      "Validation loss decreased from 0.6981856497851285 to 0.6980099515481428\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6902837157249451\n",
      "Validation loss decreased from 0.6980099515481428 to 0.697852226820859\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6985201835632324\n",
      "Validation loss decreased from 0.697852226820859 to 0.6976857673038136\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6912463903427124\n",
      "Validation loss decreased from 0.6976857673038136 to 0.6975267150185325\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.698196530342102\n",
      "Validation loss decreased from 0.6975267150185325 to 0.6973745714534413\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6985771059989929\n",
      "Validation loss decreased from 0.6973745714534413 to 0.697231726212935\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6933817267417908\n",
      "Validation loss decreased from 0.697231726212935 to 0.697106659412384\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6918344497680664\n",
      "Validation loss decreased from 0.697106659412384 to 0.6970062797719782\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6904043555259705\n",
      "Validation loss decreased from 0.6970062797719782 to 0.6969057104804299\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6985777616500854\n",
      "Validation loss decreased from 0.6969057104804299 to 0.696807785467668\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6932100653648376\n",
      "Validation loss decreased from 0.696807785467668 to 0.6967147317799655\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6843900084495544\n",
      "Validation loss decreased from 0.6967147317799655 to 0.6966398195786909\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6891608238220215\n",
      "Validation loss decreased from 0.6966398195786909 to 0.696580095724626\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.696928858757019\n",
      "Validation loss decreased from 0.696580095724626 to 0.6965081745927985\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6855500936508179\n",
      "Validation loss decreased from 0.6965081745927985 to 0.6964396455071189\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6906607151031494\n",
      "Validation loss decreased from 0.6964396455071189 to 0.6963681957938455\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6973913311958313\n",
      "Validation loss decreased from 0.6963681957938455 to 0.6963065808469598\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.686267077922821\n",
      "Validation loss decreased from 0.6963065808469598 to 0.6962452639232982\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.7005966901779175\n",
      "Validation loss decreased from 0.6962452639232982 to 0.6961960629983381\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6986327767372131\n",
      "Validation loss decreased from 0.6961960629983381 to 0.6961291107264432\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7019349336624146\n",
      "Validation loss decreased from 0.6961291107264432 to 0.6960808472199873\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6915983557701111\n",
      "Validation loss decreased from 0.6960808472199873 to 0.6960499069907449\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6901684403419495\n",
      "Validation loss decreased from 0.6960499069907449 to 0.6960140575062145\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6908096671104431\n",
      "Validation loss decreased from 0.6960140575062145 to 0.6959727243943648\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6956760287284851\n",
      "Validation loss decreased from 0.6959727243943648 to 0.6959380290725015\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6924432516098022\n",
      "Validation loss decreased from 0.6959380290725015 to 0.6958938403563066\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6956422924995422\n",
      "Validation loss decreased from 0.6958938403563066 to 0.6958551623604514\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6943402886390686\n",
      "Validation loss decreased from 0.6958551623604514 to 0.6958063028075478\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6932344436645508\n",
      "Validation loss decreased from 0.6958063028075478 to 0.6957692991603505\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6865182518959045\n",
      "Validation loss decreased from 0.6957692991603505 to 0.6957335363734852\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6890127062797546\n",
      "Validation loss decreased from 0.6957335363734852 to 0.6957165544683283\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6854763627052307\n",
      "Validation loss decreased from 0.6957165544683283 to 0.6956785321235657\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6923840045928955\n",
      "Validation loss decreased from 0.6956785321235657 to 0.6956444057551298\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6978731751441956\n",
      "Validation loss decreased from 0.6956444057551298 to 0.6956284262917258\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6928265690803528\n",
      "Validation loss decreased from 0.6956284262917258 to 0.6955891359936107\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6931393146514893\n",
      "Validation loss decreased from 0.6955891359936107 to 0.695572782646526\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6895868182182312\n",
      "Validation loss decreased from 0.695572782646526 to 0.6955652832984924\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6917043328285217\n",
      "Validation loss decreased from 0.6955652832984924 to 0.6955371499061584\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6955164074897766\n",
      "Validation loss decreased from 0.6955371499061584 to 0.6955198428847573\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7034251689910889\n",
      "Validation loss decreased from 0.6955198428847573 to 0.6955074071884155\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6911392211914062\n",
      "Validation loss decreased from 0.6955074071884155 to 0.695479772307656\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.700652539730072\n",
      "Validation loss decreased from 0.695479772307656 to 0.695450094613162\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6948766112327576\n",
      "Validation loss decreased from 0.695450094613162 to 0.6954423460093412\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6960081458091736\n",
      "Validation loss decreased from 0.6954423460093412 to 0.6954307827082548\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6913925409317017\n",
      "Validation loss decreased from 0.6954307827082548 to 0.6954116062684492\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6950863003730774\n",
      "Validation loss decreased from 0.6954116062684492 to 0.6953997937115756\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6983746886253357\n",
      "Validation loss decreased from 0.6953997937115756 to 0.6953832723877647\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6908459663391113\n",
      "Validation loss decreased from 0.6953832723877647 to 0.6953508853912354\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6849709153175354\n",
      "Validation loss decreased from 0.6953508853912354 to 0.6953337626023726\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6908758878707886\n",
      "Validation loss decreased from 0.6953337626023726 to 0.6953242258592085\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6923807859420776\n",
      "Validation loss decreased from 0.6953242258592085 to 0.6953215544874017\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6888766288757324\n",
      "Validation loss decreased from 0.6953215544874017 to 0.6953003406524658\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6929664611816406\n",
      "Validation loss decreased from 0.6953003406524658 to 0.6952805681662126\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6843082308769226\n",
      "Validation loss decreased from 0.6952805681662126 to 0.6952680457722057\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6907333731651306\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6913626194000244\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6905291676521301\n",
      "Validation loss decreased from 0.6952680457722057 to 0.6952577775174921\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6915965676307678\n",
      "Validation loss decreased from 0.6952577775174921 to 0.6952419010075656\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6914138793945312\n",
      "Validation loss decreased from 0.6952419010075656 to 0.6952214620330117\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6964471936225891\n",
      "Validation loss decreased from 0.6952214620330117 to 0.6952178478240967\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6971900463104248\n",
      "Validation loss decreased from 0.6952178478240967 to 0.6952089775692333\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6961619853973389\n",
      "Validation loss decreased from 0.6952089775692333 to 0.6952053091742776\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6847037076950073\n",
      "Validation loss decreased from 0.6952053091742776 to 0.6951925158500671\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6921048164367676\n",
      "Validation loss decreased from 0.6951925158500671 to 0.6951797279444608\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.695452094078064\n",
      "Validation loss decreased from 0.6951797279444608 to 0.6951672814109109\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.696782648563385\n",
      "Validation loss decreased from 0.6951672814109109 to 0.6951612450859763\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6975873112678528\n",
      "Validation loss decreased from 0.6951612450859763 to 0.695159299807115\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6971290111541748\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6884863972663879\n",
      "Validation loss decreased from 0.695159299807115 to 0.6951558535749262\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6956608891487122\n",
      "Validation loss decreased from 0.6951558535749262 to 0.6951406869021329\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6889174580574036\n",
      "Validation loss decreased from 0.6951406869021329 to 0.6951185193928805\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6924728751182556\n",
      "Validation loss decreased from 0.6951185193928805 to 0.695117321881381\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6927213668823242\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6946325898170471\n",
      "Validation loss decreased from 0.695117321881381 to 0.6951129057190635\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.696262001991272\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.689039945602417\n",
      "Validation loss decreased from 0.6951129057190635 to 0.6951066743243824\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6905086636543274\n",
      "Validation loss decreased from 0.6951066743243824 to 0.6950925967910073\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6936107277870178\n",
      "Validation loss decreased from 0.6950925967910073 to 0.6950843605128202\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6968567967414856\n",
      "Validation loss decreased from 0.6950843605128202 to 0.6950661865147677\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6931346654891968\n",
      "Validation loss decreased from 0.6950661865147677 to 0.695058053190058\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6882913708686829\n",
      "Validation loss decreased from 0.695058053190058 to 0.6950500282374296\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6968468427658081\n",
      "Validation loss decreased from 0.6950500282374296 to 0.6950441815636375\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6881515979766846\n",
      "Validation loss decreased from 0.6950441815636375 to 0.6950360319831155\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.692481279373169\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6992989182472229\n",
      "Validation loss decreased from 0.6950360319831155 to 0.6950210116126321\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6908853054046631\n",
      "Validation loss decreased from 0.6950210116126321 to 0.6950097409161654\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6951614022254944\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6905536651611328\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6905344724655151\n",
      "Validation loss decreased from 0.6950097409161654 to 0.6950059153816917\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6886434555053711\n",
      "Validation loss decreased from 0.6950059153816917 to 0.6949985894289884\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6900919675827026\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6947776675224304\n",
      "Validation loss decreased from 0.6949985894289884 to 0.6949915614995089\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6958115100860596\n",
      "Validation loss decreased from 0.6949915614995089 to 0.6949755657802928\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6950441002845764\n",
      "Validation loss decreased from 0.6949755657802928 to 0.6949693560600281\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6863750219345093\n",
      "Validation loss decreased from 0.6949693560600281 to 0.6949577819217335\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6905821561813354\n",
      "Validation loss decreased from 0.6949577819217335 to 0.6949491880156777\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6975687146186829\n",
      "Validation loss decreased from 0.6949491880156777 to 0.6949448856440458\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6856518387794495\n",
      "Validation loss decreased from 0.6949448856440458 to 0.6949409246444702\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.688991367816925\n",
      "Validation loss decreased from 0.6949409246444702 to 0.6949386542493646\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6989315152168274\n",
      "Validation loss decreased from 0.6949386542493646 to 0.6949332735755227\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6909308433532715\n",
      "Validation loss decreased from 0.6949332735755227 to 0.6949217590418729\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6942560076713562\n",
      "Validation loss decreased from 0.6949217590418729 to 0.6949122439731251\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.7029765844345093\n",
      "Validation loss decreased from 0.6949122439731251 to 0.694901937788183\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6988275647163391\n",
      "Validation loss decreased from 0.694901937788183 to 0.6949015530672941\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6939541101455688\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6892944574356079\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6962502002716064\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6958880424499512\n",
      "Validation loss decreased from 0.6949015530672941 to 0.6948973048817028\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6955791115760803\n",
      "Validation loss decreased from 0.6948973048817028 to 0.694885172627189\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6974820494651794\n",
      "Validation loss decreased from 0.694885172627189 to 0.6948749639771201\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.7005718946456909\n",
      "Validation loss decreased from 0.6948749639771201 to 0.6948647607456554\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6939539313316345\n",
      "Validation loss decreased from 0.6948647607456554 to 0.69486342235045\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6922999024391174\n",
      "Validation loss decreased from 0.69486342235045 to 0.694860496304252\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6971110105514526\n",
      "Validation loss decreased from 0.694860496304252 to 0.6948562914674933\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6952686309814453\n",
      "Validation loss decreased from 0.6948562914674933 to 0.694848667491566\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6928831338882446\n",
      "Validation loss decreased from 0.694848667491566 to 0.6948439424688165\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6957390904426575\n",
      "Validation loss decreased from 0.6948439424688165 to 0.6948403499343179\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6913948059082031\n",
      "Validation loss decreased from 0.6948403499343179 to 0.6948329589583657\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.689609169960022\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6962875127792358\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6865143179893494\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.690473198890686\n",
      "Validation loss decreased from 0.6948329589583657 to 0.694832828911868\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6924641728401184\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6966466307640076\n",
      "Validation loss decreased from 0.694832828911868 to 0.6948169794949618\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6903290152549744\n",
      "Validation loss decreased from 0.6948169794949618 to 0.6948066245425831\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6981977820396423\n",
      "Validation loss decreased from 0.6948066245425831 to 0.6947937065904791\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6910750865936279\n",
      "Validation loss decreased from 0.6947937065904791 to 0.6947811679406599\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6908016800880432\n",
      "Validation loss decreased from 0.6947811679406599 to 0.694781097498807\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6968799829483032\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6979424953460693\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.684583306312561\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6961641311645508\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6903052926063538\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6924510598182678\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.69459468126297\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6899217367172241\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6949822902679443\n",
      "Validation loss decreased from 0.694781097498807 to 0.69476825540716\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6930862665176392\n",
      "Validation loss decreased from 0.69476825540716 to 0.6947565512223677\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6906241774559021\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6915822625160217\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6968701481819153\n",
      "Validation loss decreased from 0.6947565512223677 to 0.6947550990364768\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6935065984725952\n",
      "Validation loss decreased from 0.6947550990364768 to 0.694739352573048\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6902357339859009\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6903725862503052\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.697161853313446\n",
      "Validation loss decreased from 0.694739352573048 to 0.694734822620045\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6980311870574951\n",
      "Validation loss decreased from 0.694734822620045 to 0.6947345625270497\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6887773275375366\n",
      "Validation loss decreased from 0.6947345625270497 to 0.6947307532483881\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6915632486343384\n",
      "Validation loss decreased from 0.6947307532483881 to 0.6947216120633212\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6953434348106384\n",
      "Validation loss decreased from 0.6947216120633212 to 0.694714524529197\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6916921734809875\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6903498768806458\n",
      "Validation loss decreased from 0.694714524529197 to 0.6947118856690147\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6895485520362854\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6890277862548828\n",
      "Validation loss decreased from 0.6947118856690147 to 0.69471045515754\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6928581595420837\n",
      "Validation loss decreased from 0.69471045515754 to 0.6947099187157371\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6975488066673279\n",
      "Validation loss decreased from 0.6947099187157371 to 0.6947054754603993\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6958106756210327\n",
      "Validation loss decreased from 0.6947054754603993 to 0.6946987130425193\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.695615291595459\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6971099376678467\n",
      "Validation loss decreased from 0.6946987130425193 to 0.6946973096240651\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6905263066291809\n",
      "Validation loss decreased from 0.6946973096240651 to 0.6946904009038751\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6930237412452698\n",
      "Validation loss decreased from 0.6946904009038751 to 0.6946871659972451\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6881555914878845\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6886552572250366\n",
      "Validation loss decreased from 0.6946871659972451 to 0.6946867975321683\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6843985915184021\n",
      "Validation loss decreased from 0.6946867975321683 to 0.6946839636022394\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6884065270423889\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6874919533729553\n",
      "Validation loss decreased from 0.6946839636022394 to 0.6946781548586759\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6850574016571045\n",
      "Validation loss decreased from 0.6946781548586759 to 0.6946735165335916\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6937892436981201\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6927103400230408\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6896494626998901\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6929905414581299\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6921244263648987\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6870750188827515\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6920390725135803\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6827783584594727\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6961937546730042\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6920058727264404\n",
      "Validation loss decreased from 0.6946735165335916 to 0.6946695230223916\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.695186972618103\n",
      "Validation loss decreased from 0.6946695230223916 to 0.6946600458838723\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6890384554862976\n",
      "Validation loss decreased from 0.6946600458838723 to 0.6946460713039745\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6882144808769226\n",
      "Validation loss decreased from 0.6946460713039745 to 0.6946404522115533\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6942436099052429\n",
      "Validation loss decreased from 0.6946404522115533 to 0.6946366646073081\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6900948286056519\n",
      "Validation loss decreased from 0.6946366646073081 to 0.6946335922588002\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6891348958015442\n",
      "Validation loss decreased from 0.6946335922588002 to 0.694625588980588\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6860418915748596\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6881223320960999\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6932607293128967\n",
      "Validation loss decreased from 0.694625588980588 to 0.6946222998879172\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.7007105946540833\n",
      "Validation loss decreased from 0.6946222998879172 to 0.6946191354231401\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6916142702102661\n",
      "Validation loss decreased from 0.6946191354231401 to 0.6946120424704119\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6885203123092651\n",
      "Validation loss decreased from 0.6946120424704119 to 0.6946055347269232\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6932651400566101\n",
      "Validation loss decreased from 0.6946055347269232 to 0.6945966861464761\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6912539601325989\n",
      "Validation loss decreased from 0.6945966861464761 to 0.694585610519756\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6930218935012817\n",
      "Validation loss decreased from 0.694585610519756 to 0.6945807446133007\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6889975070953369\n",
      "Validation loss decreased from 0.6945807446133007 to 0.694571316242218\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6853532195091248\n",
      "Validation loss decreased from 0.694571316242218 to 0.6945688399401578\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6849370002746582\n",
      "Validation loss decreased from 0.6945688399401578 to 0.6945651823824103\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6898623704910278\n",
      "Validation loss decreased from 0.6945651823824103 to 0.6945637518709357\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6904557347297668\n",
      "Validation loss decreased from 0.6945637518709357 to 0.6945616223595359\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6950611472129822\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6895430684089661\n",
      "Validation loss decreased from 0.6945616223595359 to 0.694555098360235\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.692776083946228\n",
      "Validation loss decreased from 0.694555098360235 to 0.6945486556399952\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.693851888179779\n",
      "Validation loss decreased from 0.6945486556399952 to 0.6945403489199552\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6935088634490967\n",
      "Validation loss decreased from 0.6945403489199552 to 0.6945333914323286\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6920976638793945\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6982788443565369\n",
      "Validation loss decreased from 0.6945333914323286 to 0.694530113176866\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6894345879554749\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6899435520172119\n",
      "Validation loss decreased from 0.694530113176866 to 0.6945283087817106\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6914235353469849\n",
      "Validation loss decreased from 0.6945283087817106 to 0.6945229172706604\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.694179117679596\n",
      "Validation loss decreased from 0.6945229172706604 to 0.6945146918296814\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6934216022491455\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.688254714012146\n",
      "Validation loss decreased from 0.6945146918296814 to 0.6945063959468495\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6936395764350891\n",
      "Validation loss decreased from 0.6945063959468495 to 0.6944914676926353\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6956440210342407\n",
      "Validation loss decreased from 0.6944914676926353 to 0.6944732449271462\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6839455366134644\n",
      "Validation loss decreased from 0.6944732449271462 to 0.694472307508642\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6909693479537964\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6904434561729431\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.691708505153656\n",
      "Validation loss decreased from 0.694472307508642 to 0.6944681785323403\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6938292980194092\n",
      "Validation loss decreased from 0.6944681785323403 to 0.6944559866731818\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6933915019035339\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6912514567375183\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6857227087020874\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6889663338661194\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6880298256874084\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6937907934188843\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6927931904792786\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6849616765975952\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6913392543792725\n",
      "Validation loss decreased from 0.6944559866731818 to 0.6944514621387828\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6878805756568909\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6875563263893127\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6880987286567688\n",
      "Validation loss decreased from 0.6944514621387828 to 0.6944500316273082\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6879063248634338\n",
      "Validation loss decreased from 0.6944500316273082 to 0.6944393894889138\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6932635307312012\n",
      "Validation loss decreased from 0.6944393894889138 to 0.694422418420965\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6894873380661011\n",
      "Validation loss decreased from 0.694422418420965 to 0.6944082704457369\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.692351222038269\n",
      "Validation loss decreased from 0.6944082704457369 to 0.6944021636789496\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6901798248291016\n",
      "Validation loss decreased from 0.6944021636789496 to 0.6943939653309908\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6926198601722717\n",
      "Validation loss decreased from 0.6943939653309908 to 0.6943896141919222\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6885026693344116\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6916261911392212\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.694710910320282\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6931847333908081\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.693661093711853\n",
      "Validation loss decreased from 0.6943896141919222 to 0.694381361657923\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6880856156349182\n",
      "Validation loss decreased from 0.694381361657923 to 0.6943663087758151\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6901464462280273\n",
      "Validation loss decreased from 0.6943663087758151 to 0.6943598552183672\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6869969964027405\n",
      "Validation loss decreased from 0.6943598552183672 to 0.6943575468930331\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.691429615020752\n",
      "Validation loss decreased from 0.6943575468930331 to 0.6943572109395807\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6893179416656494\n",
      "Validation loss decreased from 0.6943572109395807 to 0.6943511475216259\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6902251839637756\n",
      "Validation loss decreased from 0.6943511475216259 to 0.6943476037545637\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6874617338180542\n",
      "Validation loss decreased from 0.6943476037545637 to 0.6943453550338745\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6949779391288757\n",
      "Validation loss decreased from 0.6943453550338745 to 0.6943353956395929\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6865774989128113\n",
      "Validation loss decreased from 0.6943353956395929 to 0.694332404570146\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6912739872932434\n",
      "Validation loss decreased from 0.694332404570146 to 0.6943228082223372\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6864224076271057\n",
      "Validation loss decreased from 0.6943228082223372 to 0.694314799525521\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6919804811477661\n",
      "Validation loss decreased from 0.694314799525521 to 0.6943114074793729\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6934317946434021\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.690336287021637\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6997488141059875\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6856650710105896\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6971720457077026\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6960949301719666\n",
      "Validation loss decreased from 0.6943114074793729 to 0.694306189363653\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6881425976753235\n",
      "Validation loss decreased from 0.694306189363653 to 0.6942952600392428\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6945082545280457\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6893167495727539\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6963162422180176\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6935720443725586\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6967710852622986\n",
      "Validation loss decreased from 0.6942952600392428 to 0.6942881399934943\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.694732129573822\n",
      "Validation loss decreased from 0.6942881399934943 to 0.6942779096690092\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6853750944137573\n",
      "Validation loss decreased from 0.6942779096690092 to 0.6942666498097506\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6831691861152649\n",
      "Validation loss decreased from 0.6942666498097506 to 0.69425983320583\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6950328946113586\n",
      "Validation loss decreased from 0.69425983320583 to 0.6942570913921703\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6916323900222778\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6884706616401672\n",
      "Validation loss decreased from 0.6942570913921703 to 0.6942520087415521\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.691916286945343\n",
      "Validation loss decreased from 0.6942520087415521 to 0.6942444497888739\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6882739663124084\n",
      "Validation loss decreased from 0.6942444497888739 to 0.6942441680214622\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6932618021965027\n",
      "Validation loss decreased from 0.6942441680214622 to 0.6942426237193021\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6894400119781494\n",
      "Validation loss decreased from 0.6942426237193021 to 0.6942375139756636\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6896929144859314\n",
      "Validation loss decreased from 0.6942375139756636 to 0.6942370642315258\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6932068467140198\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6922187209129333\n",
      "Validation loss decreased from 0.6942370642315258 to 0.6942356716502797\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6866233348846436\n",
      "Validation loss decreased from 0.6942356716502797 to 0.6942284594882618\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6907135844230652\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.692225456237793\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6882541179656982\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6906461119651794\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6938658356666565\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6981899738311768\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6864455342292786\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6891636252403259\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6937215924263\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6921179890632629\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6905331611633301\n",
      "Validation loss decreased from 0.6942284594882618 to 0.6942180286754261\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6911984086036682\n",
      "Validation loss decreased from 0.6942180286754261 to 0.6942140785130587\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6963059902191162\n",
      "Validation loss decreased from 0.6942140785130587 to 0.6941932548176158\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6929093599319458\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.688998818397522\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6888756155967712\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6917691230773926\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6931604743003845\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6873000264167786\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6916207075119019\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6912308931350708\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6922159194946289\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6920546293258667\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.694257915019989\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6870125532150269\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6889969706535339\n",
      "Validation loss decreased from 0.6941932548176158 to 0.6941877549344843\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6897338032722473\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6884721517562866\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6929219365119934\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6909727454185486\n",
      "Validation loss decreased from 0.6941877549344843 to 0.6941809220747515\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6934025287628174\n",
      "Validation loss decreased from 0.6941809220747515 to 0.6941767118193887\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.693511426448822\n",
      "Validation loss decreased from 0.6941767118193887 to 0.6941720409826799\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6918060779571533\n",
      "Validation loss decreased from 0.6941720409826799 to 0.6941703232851896\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6886613368988037\n",
      "Validation loss decreased from 0.6941703232851896 to 0.6941648125648499\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6955207586288452\n",
      "Validation loss decreased from 0.6941648125648499 to 0.694157827984203\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6903069615364075\n",
      "Validation loss decreased from 0.694157827984203 to 0.694157134402882\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.688636064529419\n",
      "Validation loss decreased from 0.694157134402882 to 0.6941500739617781\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6905315518379211\n",
      "Validation loss decreased from 0.6941500739617781 to 0.6941372589631514\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6840702295303345\n",
      "Validation loss decreased from 0.6941372589631514 to 0.6941200494766235\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6893081665039062\n",
      "Validation loss decreased from 0.6941200494766235 to 0.6941141486167908\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6894527077674866\n",
      "Validation loss decreased from 0.6941141486167908 to 0.6941035281528126\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6944350004196167\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6960545778274536\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6936715245246887\n",
      "Validation loss decreased from 0.6941035281528126 to 0.6940984725952148\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6873151063919067\n",
      "Validation loss decreased from 0.6940984725952148 to 0.6940886378288269\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.685931384563446\n",
      "Validation loss decreased from 0.6940886378288269 to 0.6940874240615151\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6930757761001587\n",
      "Validation loss decreased from 0.6940874240615151 to 0.6940866221081127\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.694057822227478\n",
      "Validation loss decreased from 0.6940866221081127 to 0.6940837448293512\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6950986385345459\n",
      "Validation loss decreased from 0.6940837448293512 to 0.6940825093876232\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.687147855758667\n",
      "Validation loss decreased from 0.6940825093876232 to 0.6940757794813677\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6909669637680054\n",
      "Validation loss decreased from 0.6940757794813677 to 0.6940644925290888\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6819971203804016\n",
      "Validation loss decreased from 0.6940644925290888 to 0.694055356762626\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6897915005683899\n",
      "Validation loss decreased from 0.694055356762626 to 0.6940442052754489\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6874383091926575\n",
      "Validation loss decreased from 0.6940442052754489 to 0.6940431540662592\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6853435635566711\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6903116106987\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6905284523963928\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6879903078079224\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6943012475967407\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6886952519416809\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6938194036483765\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6910498142242432\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6950600743293762\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6892749667167664\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.688656210899353\n",
      "Validation loss decreased from 0.6940431540662592 to 0.6940424821593545\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.686468243598938\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6888782382011414\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6918092966079712\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6845904588699341\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6937740445137024\n",
      "Validation loss decreased from 0.6940424821593545 to 0.6940349990671332\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.7005030512809753\n",
      "Validation loss decreased from 0.6940349990671332 to 0.6940167546272278\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6891146302223206\n",
      "Validation loss decreased from 0.6940167546272278 to 0.6940089084885337\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6919702887535095\n",
      "Validation loss decreased from 0.6940089084885337 to 0.6939956708387895\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6866834163665771\n",
      "Validation loss decreased from 0.6939956708387895 to 0.693990783257918\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.690304160118103\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.687015175819397\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6897640824317932\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6904380321502686\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6888011693954468\n",
      "Validation loss decreased from 0.693990783257918 to 0.6939892931417986\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6958169937133789\n",
      "Validation loss decreased from 0.6939892931417986 to 0.6939842592586171\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6861628293991089\n",
      "Validation loss decreased from 0.6939842592586171 to 0.6939772746779702\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6871688365936279\n",
      "Validation loss decreased from 0.6939772746779702 to 0.6939730210737749\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6876869797706604\n",
      "Validation loss decreased from 0.6939730210737749 to 0.6939706097949635\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.684386670589447\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6849763989448547\n",
      "Validation loss decreased from 0.6939706097949635 to 0.6939701817252419\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6995318531990051\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6923784017562866\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6892210841178894\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6875618696212769\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6908720135688782\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6938229203224182\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6886272430419922\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6893413066864014\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.690331757068634\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6930553317070007\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6916979551315308\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6865625381469727\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6907472014427185\n",
      "Validation loss decreased from 0.6939701817252419 to 0.6939624439586293\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6847317814826965\n",
      "Validation loss decreased from 0.6939624439586293 to 0.6939533407037909\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6878387331962585\n",
      "Validation loss decreased from 0.6939533407037909 to 0.6939478841694918\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.686728298664093\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6888354420661926\n",
      "Validation loss decreased from 0.6939478841694918 to 0.6939409050074491\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6899451613426208\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.68593430519104\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6900211572647095\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6858720183372498\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6913832426071167\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.686860203742981\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6914078593254089\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6890397667884827\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6974018812179565\n",
      "Validation loss decreased from 0.6939409050074491 to 0.6939391222867098\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6898884177207947\n",
      "Validation loss decreased from 0.6939391222867098 to 0.6939324248920787\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6878952383995056\n",
      "Validation loss decreased from 0.6939324248920787 to 0.69393235986883\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6899620294570923\n",
      "Validation loss decreased from 0.69393235986883 to 0.6939237767999823\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6954683065414429\n",
      "Validation loss decreased from 0.6939237767999823 to 0.6939208019863475\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6888220310211182\n",
      "Validation loss decreased from 0.6939208019863475 to 0.6939185424284502\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6878718137741089\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6899830102920532\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6890645027160645\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6940524578094482\n",
      "Validation loss decreased from 0.6939185424284502 to 0.6939155296845869\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6901158094406128\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6864949464797974\n",
      "Validation loss decreased from 0.6939155296845869 to 0.6939132321964611\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6935197114944458\n",
      "Validation loss decreased from 0.6939132321964611 to 0.6939066648483276\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6922876238822937\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6895125508308411\n",
      "Validation loss decreased from 0.6939066648483276 to 0.69390315359289\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6920168995857239\n",
      "Validation loss decreased from 0.69390315359289 to 0.6938888159665194\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6952884793281555\n",
      "Validation loss decreased from 0.6938888159665194 to 0.6938790299675681\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6893374919891357\n",
      "Validation loss decreased from 0.6938790299675681 to 0.6938613653182983\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6880419850349426\n",
      "Validation loss decreased from 0.6938613653182983 to 0.6938533078540455\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6831725835800171\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6857308745384216\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6879275441169739\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.688260555267334\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6860591173171997\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6909093856811523\n",
      "Validation loss decreased from 0.6938533078540455 to 0.6938469464128668\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6966410875320435\n",
      "Validation loss decreased from 0.6938469464128668 to 0.6938406391577288\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6940637230873108\n",
      "Validation loss decreased from 0.6938406391577288 to 0.6938307827169244\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6979919075965881\n",
      "Validation loss decreased from 0.6938307827169244 to 0.6938301433216442\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6898142099380493\n",
      "Validation loss decreased from 0.6938301433216442 to 0.6938234621828253\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6839649677276611\n",
      "Validation loss decreased from 0.6938234621828253 to 0.6938233863223683\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6912472248077393\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6923189163208008\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6912281513214111\n",
      "Validation loss decreased from 0.6938233863223683 to 0.693819907578555\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6900147795677185\n",
      "Validation loss decreased from 0.693819907578555 to 0.6938135461373762\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6896619200706482\n",
      "Validation loss decreased from 0.6938135461373762 to 0.6938045133243907\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.686825156211853\n",
      "Validation loss decreased from 0.6938045133243907 to 0.693801917813041\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6909539103507996\n",
      "Validation loss decreased from 0.693801917813041 to 0.6937982494180853\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6906018853187561\n",
      "Validation loss decreased from 0.6937982494180853 to 0.6937935731627725\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6887640953063965\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6886143088340759\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6877453923225403\n",
      "Validation loss decreased from 0.6937935731627725 to 0.6937920993024652\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6888094544410706\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6915370225906372\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6911254525184631\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6872476935386658\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.689531683921814\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6867517232894897\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6936150193214417\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6902885437011719\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6906927824020386\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.688770055770874\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6860733032226562\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6881439685821533\n",
      "Validation loss decreased from 0.6937920993024652 to 0.6937880353494124\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6891951560974121\n",
      "Validation loss decreased from 0.6937880353494124 to 0.6937834186987444\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6917913556098938\n",
      "Validation loss decreased from 0.6937834186987444 to 0.6937809911641207\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6899122595787048\n",
      "Validation loss decreased from 0.6937809911641207 to 0.6937790729782798\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6965250372886658\n",
      "Validation loss decreased from 0.6937790729782798 to 0.6937775720249523\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6878102421760559\n",
      "Validation loss decreased from 0.6937775720249523 to 0.6937715898860585\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6870192289352417\n",
      "Validation loss decreased from 0.6937715898860585 to 0.693767786026001\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6897466778755188\n",
      "Validation loss decreased from 0.693767786026001 to 0.6937624920498241\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6911048293113708\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6798489093780518\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6985382437705994\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6884989142417908\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.688859760761261\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6898894906044006\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6870704293251038\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6893177032470703\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6894241571426392\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6892127394676208\n",
      "Validation loss decreased from 0.6937624920498241 to 0.6937583901665427\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.692105233669281\n",
      "Validation loss decreased from 0.6937583901665427 to 0.693750571120869\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.692414402961731\n",
      "Validation loss decreased from 0.693750571120869 to 0.6937398206103932\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6899944543838501\n",
      "Validation loss decreased from 0.6937398206103932 to 0.6937273849140514\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.688473105430603\n",
      "Validation loss decreased from 0.6937273849140514 to 0.6937239441004667\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6903114914894104\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.693140983581543\n",
      "Validation loss decreased from 0.6937239441004667 to 0.6937235377051614\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6869534850120544\n",
      "Validation loss decreased from 0.6937235377051614 to 0.693721895868128\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6863718032836914\n",
      "Validation loss decreased from 0.693721895868128 to 0.6937186284498735\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6868312954902649\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6904559135437012\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6872177124023438\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6894373297691345\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6927707195281982\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6888034343719482\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6892387866973877\n",
      "Validation loss decreased from 0.6937186284498735 to 0.69371652061289\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6871936321258545\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6929629445075989\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6874399185180664\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6868453621864319\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6864795684814453\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6844022870063782\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6873082518577576\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6900864839553833\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6844866871833801\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6874375939369202\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6920613646507263\n",
      "Validation loss decreased from 0.69371652061289 to 0.6937130852179094\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6981883645057678\n",
      "Validation loss decreased from 0.6937130852179094 to 0.693704214963046\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6906219124794006\n",
      "Validation loss decreased from 0.693704214963046 to 0.693694840778004\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6938575506210327\n",
      "Validation loss decreased from 0.693694840778004 to 0.6936810287562284\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6867042779922485\n",
      "Validation loss decreased from 0.6936810287562284 to 0.6936763362451033\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6881347298622131\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6946749687194824\n",
      "Validation loss decreased from 0.6936763362451033 to 0.6936735239895907\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6904709339141846\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6898660063743591\n",
      "Validation loss decreased from 0.6936735239895907 to 0.6936573440378363\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6905183792114258\n",
      "Validation loss decreased from 0.6936573440378363 to 0.6936514540152117\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.692828893661499\n",
      "Validation loss decreased from 0.6936514540152117 to 0.6936454556205056\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6910281181335449\n",
      "Validation loss decreased from 0.6936454556205056 to 0.6936372681097551\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6885663866996765\n",
      "Validation loss decreased from 0.6936372681097551 to 0.6936255097389221\n",
      "no early stopping\n",
      "AUC on test data  0.5782307422685973\n",
      "model 21 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7424771785736084\n",
      "Validation loss decreased from inf to 0.7117283777757124\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.7626298666000366\n",
      "Validation loss decreased from 0.7117283777757124 to 0.7114809426394376\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7250527143478394\n",
      "Validation loss decreased from 0.7114809426394376 to 0.7112358862703497\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7505002617835999\n",
      "Validation loss decreased from 0.7112358862703497 to 0.7109950889240612\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7436925172805786\n",
      "Validation loss decreased from 0.7109950889240612 to 0.7107598185539246\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.7098573446273804\n",
      "Validation loss decreased from 0.7107598185539246 to 0.7105213891376149\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7239437699317932\n",
      "Validation loss decreased from 0.7105213891376149 to 0.7102812745354392\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7440330386161804\n",
      "Validation loss decreased from 0.7102812745354392 to 0.7100450884212147\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.7584955096244812\n",
      "Validation loss decreased from 0.7100450884212147 to 0.7098154046318748\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7513619065284729\n",
      "Validation loss decreased from 0.7098154046318748 to 0.7095847400751981\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.7276613116264343\n",
      "Validation loss decreased from 0.7095847400751981 to 0.7093607674945485\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.743219256401062\n",
      "Validation loss decreased from 0.7093607674945485 to 0.7091377540068193\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.7050474882125854\n",
      "Validation loss decreased from 0.7091377540068193 to 0.7089114134961908\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.717404305934906\n",
      "Validation loss decreased from 0.7089114134961908 to 0.7086857936599038\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7384669780731201\n",
      "Validation loss decreased from 0.7086857936599038 to 0.7084701061248779\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.7481176853179932\n",
      "Validation loss decreased from 0.7084701061248779 to 0.7082578377290205\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.7468124032020569\n",
      "Validation loss decreased from 0.7082578377290205 to 0.708050169728019\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.7203307747840881\n",
      "Validation loss decreased from 0.708050169728019 to 0.7078359939835288\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7283331751823425\n",
      "Validation loss decreased from 0.7078359939835288 to 0.7076345357027921\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.7643540501594543\n",
      "Validation loss decreased from 0.7076345357027921 to 0.7074495716528459\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.7681035995483398\n",
      "Validation loss decreased from 0.7074495716528459 to 0.7072568427432667\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.7449944019317627\n",
      "Validation loss decreased from 0.7072568427432667 to 0.7070662433450873\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.7249497771263123\n",
      "Validation loss decreased from 0.7070662433450873 to 0.706875817342238\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.7613455653190613\n",
      "Validation loss decreased from 0.706875817342238 to 0.7066884311762723\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.7424533367156982\n",
      "Validation loss decreased from 0.7066884311762723 to 0.7064978263594888\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7142266035079956\n",
      "Validation loss decreased from 0.7064978263594888 to 0.706312201239846\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7401847243309021\n",
      "Validation loss decreased from 0.706312201239846 to 0.706131246956912\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.7491335868835449\n",
      "Validation loss decreased from 0.706131246956912 to 0.7059498646042563\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.7186394333839417\n",
      "Validation loss decreased from 0.7059498646042563 to 0.7057662064378912\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.7220035791397095\n",
      "Validation loss decreased from 0.7057662064378912 to 0.7055857127363031\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.7359469532966614\n",
      "Validation loss decreased from 0.7055857127363031 to 0.7054059397090565\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.7283908724784851\n",
      "Validation loss decreased from 0.7054059397090565 to 0.7052320187742059\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.7256922125816345\n",
      "Validation loss decreased from 0.7052320187742059 to 0.7050650878386064\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7307702302932739\n",
      "Validation loss decreased from 0.7050650878386064 to 0.7048886689272794\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.7297833561897278\n",
      "Validation loss decreased from 0.7048886689272794 to 0.7047139677134427\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.7387894988059998\n",
      "Validation loss decreased from 0.7047139677134427 to 0.7045412226156755\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.7388909459114075\n",
      "Validation loss decreased from 0.7045412226156755 to 0.7043628421696749\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.7172106504440308\n",
      "Validation loss decreased from 0.7043628421696749 to 0.7041976397687738\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7344316244125366\n",
      "Validation loss decreased from 0.7041976397687738 to 0.7040345072746277\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.7435413002967834\n",
      "Validation loss decreased from 0.7040345072746277 to 0.7038655551997098\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.7540141344070435\n",
      "Validation loss decreased from 0.7038655551997098 to 0.7036990902640603\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.7078769207000732\n",
      "Validation loss decreased from 0.7036990902640603 to 0.7035399025136774\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.7363748550415039\n",
      "Validation loss decreased from 0.7035399025136774 to 0.7033877372741699\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.7239800095558167\n",
      "Validation loss decreased from 0.7033877372741699 to 0.7032349705696106\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7126128077507019\n",
      "Validation loss decreased from 0.7032349705696106 to 0.7030782862143083\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.7104312777519226\n",
      "Validation loss decreased from 0.7030782862143083 to 0.7029279633001848\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.7219963669776917\n",
      "Validation loss decreased from 0.7029279633001848 to 0.7027788270603527\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.7240868210792542\n",
      "Validation loss decreased from 0.7027788270603527 to 0.7026356241919778\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.7395920157432556\n",
      "Validation loss decreased from 0.7026356241919778 to 0.7024951685558666\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.7118479609489441\n",
      "Validation loss decreased from 0.7024951685558666 to 0.7023565660823475\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.7198994159698486\n",
      "Validation loss decreased from 0.7023565660823475 to 0.7022224068641663\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.7196093201637268\n",
      "Validation loss decreased from 0.7022224068641663 to 0.7020819241350348\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.7185173630714417\n",
      "Validation loss decreased from 0.7020819241350348 to 0.7019452290101484\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.744200587272644\n",
      "Validation loss decreased from 0.7019452290101484 to 0.7018175504424355\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.7398747801780701\n",
      "Validation loss decreased from 0.7018175504424355 to 0.7016861763867465\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.7574813365936279\n",
      "Validation loss decreased from 0.7016861763867465 to 0.7015497142618353\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.7019556760787964\n",
      "Validation loss decreased from 0.7015497142618353 to 0.7014207298105414\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.723834216594696\n",
      "Validation loss decreased from 0.7014207298105414 to 0.701294638893821\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.7262986898422241\n",
      "Validation loss decreased from 0.701294638893821 to 0.7011696208607067\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.7265416383743286\n",
      "Validation loss decreased from 0.7011696208607067 to 0.7010408639907837\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.750045895576477\n",
      "Validation loss decreased from 0.7010408639907837 to 0.7009140036322854\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.7202538251876831\n",
      "Validation loss decreased from 0.7009140036322854 to 0.7007884599945762\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.7343546748161316\n",
      "Validation loss decreased from 0.7007884599945762 to 0.7006572539156134\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.7319448590278625\n",
      "Validation loss decreased from 0.7006572539156134 to 0.7005346417427063\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.7254623174667358\n",
      "Validation loss decreased from 0.7005346417427063 to 0.7004140940579501\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.7268004417419434\n",
      "Validation loss decreased from 0.7004140940579501 to 0.7002942724661394\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.7422507405281067\n",
      "Validation loss decreased from 0.7002942724661394 to 0.7001794901761141\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.7138685584068298\n",
      "Validation loss decreased from 0.7001794901761141 to 0.7000651847232472\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.7285833358764648\n",
      "Validation loss decreased from 0.7000651847232472 to 0.6999498063867743\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.7280979156494141\n",
      "Validation loss decreased from 0.6999498063867743 to 0.6998348777944391\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6913948059082031\n",
      "Validation loss decreased from 0.6998348777944391 to 0.6997275244105946\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.7531034350395203\n",
      "Validation loss decreased from 0.6997275244105946 to 0.6996231512589888\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.7425081133842468\n",
      "Validation loss decreased from 0.6996231512589888 to 0.6995167244564403\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.7498419880867004\n",
      "Validation loss decreased from 0.6995167244564403 to 0.6994039633057334\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.723357617855072\n",
      "Validation loss decreased from 0.6994039633057334 to 0.6992933208292181\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.709166407585144\n",
      "Validation loss decreased from 0.6992933208292181 to 0.6991896466775374\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.759949266910553\n",
      "Validation loss decreased from 0.6991896466775374 to 0.6990924315019087\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.7439568638801575\n",
      "Validation loss decreased from 0.6990924315019087 to 0.6989916292103854\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.711027204990387\n",
      "Validation loss decreased from 0.6989916292103854 to 0.6988918618722395\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.7030197978019714\n",
      "Validation loss decreased from 0.6988918618722395 to 0.6987982988357544\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.7025018334388733\n",
      "Validation loss decreased from 0.6987982988357544 to 0.6986999403346669\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.7337230443954468\n",
      "Validation loss decreased from 0.6986999403346669 to 0.6986017823219299\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.7333846092224121\n",
      "Validation loss decreased from 0.6986017823219299 to 0.6985055641694502\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.729033350944519\n",
      "Validation loss decreased from 0.6985055641694502 to 0.6984104243191805\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.71495521068573\n",
      "Validation loss decreased from 0.6984104243191805 to 0.6983129815621809\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.7205355763435364\n",
      "Validation loss decreased from 0.6983129815621809 to 0.6982213908975775\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.7262173295021057\n",
      "Validation loss decreased from 0.6982213908975775 to 0.6981323307210748\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6927697062492371\n",
      "Validation loss decreased from 0.6981323307210748 to 0.6980441158468073\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.708604097366333\n",
      "Validation loss decreased from 0.6980441158468073 to 0.6979561339725148\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.7263765335083008\n",
      "Validation loss decreased from 0.6979561339725148 to 0.6978705687956377\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.726546049118042\n",
      "Validation loss decreased from 0.6978705687956377 to 0.6977806145494635\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.7138539552688599\n",
      "Validation loss decreased from 0.6977806145494635 to 0.697694946419109\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.7302200794219971\n",
      "Validation loss decreased from 0.697694946419109 to 0.6976064822890542\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.7276636362075806\n",
      "Validation loss decreased from 0.6976064822890542 to 0.6975224939259616\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.7380490303039551\n",
      "Validation loss decreased from 0.6975224939259616 to 0.6974391503767534\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.7040179967880249\n",
      "Validation loss decreased from 0.6974391503767534 to 0.6973500956188549\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.7366573810577393\n",
      "Validation loss decreased from 0.6973500956188549 to 0.6972682855345986\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6995781660079956\n",
      "Validation loss decreased from 0.6972682855345986 to 0.6971885561943054\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.7556646466255188\n",
      "Validation loss decreased from 0.6971885561943054 to 0.6971095204353333\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.7265968918800354\n",
      "Validation loss decreased from 0.6971095204353333 to 0.6970302787694064\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.7600185871124268\n",
      "Validation loss decreased from 0.6970302787694064 to 0.6969513513825156\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6971870064735413\n",
      "Validation loss decreased from 0.6969513513825156 to 0.6968718767166138\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.7260168194770813\n",
      "Validation loss decreased from 0.6968718767166138 to 0.6967970728874207\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.7011139392852783\n",
      "Validation loss decreased from 0.6967970728874207 to 0.6967190233143893\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.7157230377197266\n",
      "Validation loss decreased from 0.6967190233143893 to 0.6966434771364386\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.7309101819992065\n",
      "Validation loss decreased from 0.6966434771364386 to 0.6965722170743075\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.7133162617683411\n",
      "Validation loss decreased from 0.6965722170743075 to 0.69650122794238\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.7140841484069824\n",
      "Validation loss decreased from 0.69650122794238 to 0.6964337609030984\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.7285929918289185\n",
      "Validation loss decreased from 0.6964337609030984 to 0.6963631402362477\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6965131163597107\n",
      "Validation loss decreased from 0.6963631402362477 to 0.6962898698720065\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.7266736030578613\n",
      "Validation loss decreased from 0.6962898698720065 to 0.6962192546237599\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.7187874913215637\n",
      "Validation loss decreased from 0.6962192546237599 to 0.6961516033519398\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.7234448194503784\n",
      "Validation loss decreased from 0.6961516033519398 to 0.6960852579637007\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.7221888303756714\n",
      "Validation loss decreased from 0.6960852579637007 to 0.6960178938778964\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.7055032253265381\n",
      "Validation loss decreased from 0.6960178938778964 to 0.6959551193497397\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6959409117698669\n",
      "Validation loss decreased from 0.6959551193497397 to 0.6958899389613759\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.7298775315284729\n",
      "Validation loss decreased from 0.6958899389613759 to 0.6958273649215698\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.7218613028526306\n",
      "Validation loss decreased from 0.6958273649215698 to 0.6957659775560553\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.7139081954956055\n",
      "Validation loss decreased from 0.6957659775560553 to 0.6957049478184093\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.7309684157371521\n",
      "Validation loss decreased from 0.6957049478184093 to 0.6956454027782787\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.7013316750526428\n",
      "Validation loss decreased from 0.6956454027782787 to 0.6955869035287336\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.7168906331062317\n",
      "Validation loss decreased from 0.6955869035287336 to 0.6955236684192311\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.7041928768157959\n",
      "Validation loss decreased from 0.6955236684192311 to 0.6954613111235879\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.704279899597168\n",
      "Validation loss decreased from 0.6954613111235879 to 0.6954038197344\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.7193533778190613\n",
      "Validation loss decreased from 0.6954038197344 to 0.6953476179729808\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6945425868034363\n",
      "Validation loss decreased from 0.6953476179729808 to 0.6952942934903231\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.709243655204773\n",
      "Validation loss decreased from 0.6952942934903231 to 0.6952386606823314\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6909237504005432\n",
      "Validation loss decreased from 0.6952386606823314 to 0.69518212296746\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.7072329521179199\n",
      "Validation loss decreased from 0.69518212296746 to 0.6951303536241705\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.7168638110160828\n",
      "Validation loss decreased from 0.6951303536241705 to 0.6950803561644121\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6921147704124451\n",
      "Validation loss decreased from 0.6950803561644121 to 0.6950299523093484\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.7195512056350708\n",
      "Validation loss decreased from 0.6950299523093484 to 0.6949803016402505\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6994105577468872\n",
      "Validation loss decreased from 0.6949803016402505 to 0.6949306347153403\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.7172687649726868\n",
      "Validation loss decreased from 0.6949306347153403 to 0.6948836283250288\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.7247722744941711\n",
      "Validation loss decreased from 0.6948836283250288 to 0.6948346549814398\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.7226153612136841\n",
      "Validation loss decreased from 0.6948346549814398 to 0.6947816393592141\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.7216166257858276\n",
      "Validation loss decreased from 0.6947816393592141 to 0.6947316310622476\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.7138403654098511\n",
      "Validation loss decreased from 0.6947316310622476 to 0.6946827877651561\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.7187937498092651\n",
      "Validation loss decreased from 0.6946827877651561 to 0.6946333375844088\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.714215874671936\n",
      "Validation loss decreased from 0.6946333375844088 to 0.6945850307291205\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.7151456475257874\n",
      "Validation loss decreased from 0.6945850307291205 to 0.6945362307808616\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6969821453094482\n",
      "Validation loss decreased from 0.6945362307808616 to 0.6944881135767157\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.7273127436637878\n",
      "Validation loss decreased from 0.6944881135767157 to 0.6944413618607954\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6913602352142334\n",
      "Validation loss decreased from 0.6944413618607954 to 0.6943970810283314\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.69261234998703\n",
      "Validation loss decreased from 0.6943970810283314 to 0.6943503834984519\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6977600455284119\n",
      "Validation loss decreased from 0.6943503834984519 to 0.6943054145032709\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.7273452281951904\n",
      "Validation loss decreased from 0.6943054145032709 to 0.6942607922987505\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.7083755731582642\n",
      "Validation loss decreased from 0.6942607922987505 to 0.6942181587219238\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.7118176817893982\n",
      "Validation loss decreased from 0.6942181587219238 to 0.6941768039356578\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.7034425139427185\n",
      "Validation loss decreased from 0.6941768039356578 to 0.6941384727304633\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.702303946018219\n",
      "Validation loss decreased from 0.6941384727304633 to 0.6941003582694314\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.7072265148162842\n",
      "Validation loss decreased from 0.6941003582694314 to 0.6940642432733015\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.7224345803260803\n",
      "Validation loss decreased from 0.6940642432733015 to 0.6940261342308738\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.705040693283081\n",
      "Validation loss decreased from 0.6940261342308738 to 0.6939866326072\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.7052255272865295\n",
      "Validation loss decreased from 0.6939866326072 to 0.6939480846578424\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.704522430896759\n",
      "Validation loss decreased from 0.6939480846578424 to 0.6939107071269642\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.7015995383262634\n",
      "Validation loss decreased from 0.6939107071269642 to 0.6938743808052756\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.7099084258079529\n",
      "Validation loss decreased from 0.6938743808052756 to 0.6938351772048257\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.7053778171539307\n",
      "Validation loss decreased from 0.6938351772048257 to 0.6937966346740723\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.7141446471214294\n",
      "Validation loss decreased from 0.6937966346740723 to 0.6937616955150258\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.7086110711097717\n",
      "Validation loss decreased from 0.6937616955150258 to 0.6937266804955222\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.7081015110015869\n",
      "Validation loss decreased from 0.6937266804955222 to 0.6936919743364508\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.7162296175956726\n",
      "Validation loss decreased from 0.6936919743364508 to 0.6936586932702498\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.710981011390686\n",
      "Validation loss decreased from 0.6936586932702498 to 0.6936228329485113\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.7172961235046387\n",
      "Validation loss decreased from 0.6936228329485113 to 0.6935869509523566\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.695524275302887\n",
      "Validation loss decreased from 0.6935869509523566 to 0.6935513669794257\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6978738307952881\n",
      "Validation loss decreased from 0.6935513669794257 to 0.6935170509598472\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.7224503755569458\n",
      "Validation loss decreased from 0.6935170509598472 to 0.6934839541261847\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.708472490310669\n",
      "Validation loss decreased from 0.6934839541261847 to 0.6934514533389698\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.718302309513092\n",
      "Validation loss decreased from 0.6934514533389698 to 0.6934181451797485\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.7096673250198364\n",
      "Validation loss decreased from 0.6934181451797485 to 0.6933876438574358\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.7114826440811157\n",
      "Validation loss decreased from 0.6933876438574358 to 0.6933574134653265\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.7130630016326904\n",
      "Validation loss decreased from 0.6933574134653265 to 0.6933271613988009\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.7074923515319824\n",
      "Validation loss decreased from 0.6933271613988009 to 0.6932966600764882\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.7098329663276672\n",
      "Validation loss decreased from 0.6932966600764882 to 0.6932690793817694\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.7081766128540039\n",
      "Validation loss decreased from 0.6932690793817694 to 0.6932410597801208\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6898995041847229\n",
      "Validation loss decreased from 0.6932410597801208 to 0.6932115663181652\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.7099060416221619\n",
      "Validation loss decreased from 0.6932115663181652 to 0.6931838555769487\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.7050710320472717\n",
      "Validation loss decreased from 0.6931838555769487 to 0.6931556246497415\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6802215576171875\n",
      "Validation loss decreased from 0.6931556246497415 to 0.6931296316060153\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.7036989331245422\n",
      "Validation loss decreased from 0.6931296316060153 to 0.6931039094924927\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.7048290371894836\n",
      "Validation loss decreased from 0.6931039094924927 to 0.6930801543322477\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6985477805137634\n",
      "Validation loss decreased from 0.6930801543322477 to 0.6930528012188998\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.718248724937439\n",
      "Validation loss decreased from 0.6930528012188998 to 0.693027371709997\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.7068857550621033\n",
      "Validation loss decreased from 0.693027371709997 to 0.6930032914335077\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6958006620407104\n",
      "Validation loss decreased from 0.6930032914335077 to 0.6929784471338446\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.7022007703781128\n",
      "Validation loss decreased from 0.6929784471338446 to 0.6929533156481656\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.7073614597320557\n",
      "Validation loss decreased from 0.6929533156481656 to 0.6929279132322832\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.7187151908874512\n",
      "Validation loss decreased from 0.6929279132322832 to 0.6929039088162509\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6905706524848938\n",
      "Validation loss decreased from 0.6929039088162509 to 0.6928806630047885\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6887264251708984\n",
      "Validation loss decreased from 0.6928806630047885 to 0.6928572763096202\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.716398298740387\n",
      "Validation loss decreased from 0.6928572763096202 to 0.6928326704285361\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.7115681767463684\n",
      "Validation loss decreased from 0.6928326704285361 to 0.6928100694309581\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.7010689377784729\n",
      "Validation loss decreased from 0.6928100694309581 to 0.6927862438288602\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.7159261703491211\n",
      "Validation loss decreased from 0.6927862438288602 to 0.692762862552296\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.7128784656524658\n",
      "Validation loss decreased from 0.692762862552296 to 0.6927425861358643\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.7022225856781006\n",
      "Validation loss decreased from 0.6927425861358643 to 0.692719882184809\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.7204940319061279\n",
      "Validation loss decreased from 0.692719882184809 to 0.6926994269544428\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.7039316296577454\n",
      "Validation loss decreased from 0.6926994269544428 to 0.6926781806078824\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.7100574374198914\n",
      "Validation loss decreased from 0.6926781806078824 to 0.6926584406332537\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.7008158564567566\n",
      "Validation loss decreased from 0.6926584406332537 to 0.6926379962400957\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.7051060795783997\n",
      "Validation loss decreased from 0.6926379962400957 to 0.6926184025677767\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.7226681113243103\n",
      "Validation loss decreased from 0.6926184025677767 to 0.692598510872234\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6849788427352905\n",
      "Validation loss decreased from 0.692598510872234 to 0.6925812471996654\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.7060819864273071\n",
      "Validation loss decreased from 0.6925812471996654 to 0.6925607377832587\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.7227560877799988\n",
      "Validation loss decreased from 0.6925607377832587 to 0.6925405534830961\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.7279518842697144\n",
      "Validation loss decreased from 0.6925405534830961 to 0.6925216262990778\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.707248866558075\n",
      "Validation loss decreased from 0.6925216262990778 to 0.692501880905845\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6820301413536072\n",
      "Validation loss decreased from 0.692501880905845 to 0.6924826773730192\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.7184835076332092\n",
      "Validation loss decreased from 0.6924826773730192 to 0.6924643570726569\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.7136326432228088\n",
      "Validation loss decreased from 0.6924643570726569 to 0.6924460421908986\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.696017324924469\n",
      "Validation loss decreased from 0.6924460421908986 to 0.6924275810068304\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6969882845878601\n",
      "Validation loss decreased from 0.6924275810068304 to 0.6924112384969537\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.7137854099273682\n",
      "Validation loss decreased from 0.6924112384969537 to 0.6923948905684731\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.7069669961929321\n",
      "Validation loss decreased from 0.6923948905684731 to 0.6923785968260332\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.7063550353050232\n",
      "Validation loss decreased from 0.6923785968260332 to 0.6923617720603943\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.71489018201828\n",
      "Validation loss decreased from 0.6923617720603943 to 0.6923444758762013\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.7140236496925354\n",
      "Validation loss decreased from 0.6923444758762013 to 0.692327472296628\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.7057382464408875\n",
      "Validation loss decreased from 0.692327472296628 to 0.6923111948100004\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6976595520973206\n",
      "Validation loss decreased from 0.6923111948100004 to 0.6922959143465216\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.7272321581840515\n",
      "Validation loss decreased from 0.6922959143465216 to 0.6922808993946422\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6889660358428955\n",
      "Validation loss decreased from 0.6922808993946422 to 0.6922658356753263\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.7171390652656555\n",
      "Validation loss decreased from 0.6922658356753263 to 0.6922514059326865\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.7266438007354736\n",
      "Validation loss decreased from 0.6922514059326865 to 0.6922362663529136\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.682328999042511\n",
      "Validation loss decreased from 0.6922362663529136 to 0.6922212188894098\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.7023374438285828\n",
      "Validation loss decreased from 0.6922212188894098 to 0.6922071792862632\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6894388198852539\n",
      "Validation loss decreased from 0.6922071792862632 to 0.6921938441016457\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.7085484266281128\n",
      "Validation loss decreased from 0.6921938441016457 to 0.6921808828007091\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6949702501296997\n",
      "Validation loss decreased from 0.6921808828007091 to 0.6921669840812683\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.7147669792175293\n",
      "Validation loss decreased from 0.6921669840812683 to 0.6921539035710421\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.7264124751091003\n",
      "Validation loss decreased from 0.6921539035710421 to 0.6921408393166282\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.7048072218894958\n",
      "Validation loss decreased from 0.6921408393166282 to 0.692128761248155\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6947524547576904\n",
      "Validation loss decreased from 0.692128761248155 to 0.6921163201332092\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.7234247922897339\n",
      "Validation loss decreased from 0.6921163201332092 to 0.6921047026460821\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.7177129983901978\n",
      "Validation loss decreased from 0.6921047026460821 to 0.6920936216007579\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.7076893448829651\n",
      "Validation loss decreased from 0.6920936216007579 to 0.6920818903229453\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.7073697447776794\n",
      "Validation loss decreased from 0.6920818903229453 to 0.6920702132311735\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.713294267654419\n",
      "Validation loss decreased from 0.6920702132311735 to 0.6920597011392767\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.7129396200180054\n",
      "Validation loss decreased from 0.6920597011392767 to 0.6920486851172014\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.7030745148658752\n",
      "Validation loss decreased from 0.6920486851172014 to 0.6920374252579429\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.7053288221359253\n",
      "Validation loss decreased from 0.6920374252579429 to 0.6920277909799055\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6911004185676575\n",
      "Validation loss decreased from 0.6920277909799055 to 0.6920177990739996\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6951842904090881\n",
      "Validation loss decreased from 0.6920177990739996 to 0.6920074657960371\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.7071345448493958\n",
      "Validation loss decreased from 0.6920074657960371 to 0.6919975985180248\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6955460906028748\n",
      "Validation loss decreased from 0.6919975985180248 to 0.6919875524260781\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.7206498384475708\n",
      "Validation loss decreased from 0.6919875524260781 to 0.6919775225899436\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.712346613407135\n",
      "Validation loss decreased from 0.6919775225899436 to 0.6919693350791931\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6944452524185181\n",
      "Validation loss decreased from 0.6919693350791931 to 0.6919608766382391\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6936893463134766\n",
      "Validation loss decreased from 0.6919608766382391 to 0.6919520063833757\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.7057623863220215\n",
      "Validation loss decreased from 0.6919520063833757 to 0.6919434233145281\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.706365704536438\n",
      "Validation loss decreased from 0.6919434233145281 to 0.6919352087107572\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6910128593444824\n",
      "Validation loss decreased from 0.6919352087107572 to 0.6919261488047513\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.7107223868370056\n",
      "Validation loss decreased from 0.6919261488047513 to 0.6919183297590776\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6989618539810181\n",
      "Validation loss decreased from 0.6919183297590776 to 0.6919110796668313\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6899142265319824\n",
      "Validation loss decreased from 0.6919110796668313 to 0.691903829574585\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6991999745368958\n",
      "Validation loss decreased from 0.691903829574585 to 0.6918961568312212\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.7192304134368896\n",
      "Validation loss decreased from 0.6918961568312212 to 0.6918884244832125\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6951366066932678\n",
      "Validation loss decreased from 0.6918884244832125 to 0.6918809630654075\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.7039183378219604\n",
      "Validation loss decreased from 0.6918809630654075 to 0.6918732252987948\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.7149304747581482\n",
      "Validation loss decreased from 0.6918732252987948 to 0.6918656771833246\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.7094113826751709\n",
      "Validation loss decreased from 0.6918656771833246 to 0.6918586980212819\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.718216061592102\n",
      "Validation loss decreased from 0.6918586980212819 to 0.6918519085103815\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.7064791321754456\n",
      "Validation loss decreased from 0.6918519085103815 to 0.691845254464583\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.7150710225105286\n",
      "Validation loss decreased from 0.691845254464583 to 0.6918388117443431\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6998633742332458\n",
      "Validation loss decreased from 0.6918388117443431 to 0.691832959651947\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.713720977306366\n",
      "Validation loss decreased from 0.691832959651947 to 0.6918269666758451\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.7197158336639404\n",
      "Validation loss decreased from 0.6918269666758451 to 0.6918213204904036\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.7044419646263123\n",
      "Validation loss decreased from 0.6918213204904036 to 0.6918157176537947\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.7085711359977722\n",
      "Validation loss decreased from 0.6918157176537947 to 0.691809659654444\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6866586208343506\n",
      "Validation loss decreased from 0.691809659654444 to 0.6918042464689775\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6871310472488403\n",
      "Validation loss decreased from 0.6918042464689775 to 0.6917992396788164\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.7028722763061523\n",
      "Validation loss decreased from 0.6917992396788164 to 0.6917948614467274\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.72596675157547\n",
      "Validation loss decreased from 0.6917948614467274 to 0.6917900551449169\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.7037758231163025\n",
      "Validation loss decreased from 0.6917900551449169 to 0.6917855197733099\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.7145178318023682\n",
      "Validation loss decreased from 0.6917855197733099 to 0.6917810060761191\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.7121325135231018\n",
      "Validation loss decreased from 0.6917810060761191 to 0.6917766820300709\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.7013137340545654\n",
      "Validation loss decreased from 0.6917766820300709 to 0.6917719136584889\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.7070606350898743\n",
      "Validation loss decreased from 0.6917719136584889 to 0.6917671669613231\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.7022983431816101\n",
      "Validation loss decreased from 0.6917671669613231 to 0.6917627995664423\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.710066020488739\n",
      "Validation loss decreased from 0.6917627995664423 to 0.6917584971948103\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.7107487320899963\n",
      "Validation loss decreased from 0.6917584971948103 to 0.6917545416138389\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.7085548043251038\n",
      "Validation loss decreased from 0.6917545416138389 to 0.6917509003119036\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6964705586433411\n",
      "Validation loss decreased from 0.6917509003119036 to 0.6917469934983687\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.7099515795707703\n",
      "Validation loss decreased from 0.6917469934983687 to 0.6917435093359514\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6868951320648193\n",
      "Validation loss decreased from 0.6917435093359514 to 0.691739943894473\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.7045641541481018\n",
      "Validation loss decreased from 0.691739943894473 to 0.6917365897785533\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6865883469581604\n",
      "Validation loss decreased from 0.6917365897785533 to 0.6917338479648937\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6853041052818298\n",
      "Validation loss decreased from 0.6917338479648937 to 0.6917307539419695\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.7095013856887817\n",
      "Validation loss decreased from 0.6917307539419695 to 0.6917277086864818\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.7085624933242798\n",
      "Validation loss decreased from 0.6917277086864818 to 0.6917249506170099\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6928850412368774\n",
      "Validation loss decreased from 0.6917249506170099 to 0.6917223930358887\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.704952597618103\n",
      "Validation loss decreased from 0.6917223930358887 to 0.6917197921059348\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.710189700126648\n",
      "Validation loss decreased from 0.6917197921059348 to 0.691717342896895\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.7070506811141968\n",
      "Validation loss decreased from 0.691717342896895 to 0.6917151808738708\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.7003848552703857\n",
      "Validation loss decreased from 0.6917151808738708 to 0.6917132030833851\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.7092362642288208\n",
      "Validation loss decreased from 0.6917132030833851 to 0.6917109543626959\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.7015168070793152\n",
      "Validation loss decreased from 0.6917109543626959 to 0.6917090795256875\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.7065343856811523\n",
      "Validation loss decreased from 0.6917090795256875 to 0.691707269711928\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.7092953324317932\n",
      "Validation loss decreased from 0.691707269711928 to 0.6917056224562905\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6972104907035828\n",
      "Validation loss decreased from 0.6917056224562905 to 0.6917039806192572\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6883609294891357\n",
      "Validation loss decreased from 0.6917039806192572 to 0.6917023496194319\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6921898126602173\n",
      "Validation loss decreased from 0.6917023496194319 to 0.6917010816660795\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6934856176376343\n",
      "Validation loss decreased from 0.6917010816660795 to 0.6916997107592496\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.7026339769363403\n",
      "Validation loss decreased from 0.6916997107592496 to 0.6916985728523948\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6945149898529053\n",
      "Validation loss decreased from 0.6916985728523948 to 0.6916976354338906\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6938682794570923\n",
      "Validation loss decreased from 0.6916976354338906 to 0.6916964054107666\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6992044448852539\n",
      "Validation loss decreased from 0.6916964054107666 to 0.6916954679922624\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.7004693746566772\n",
      "Validation loss decreased from 0.6916954679922624 to 0.6916948827830228\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.7029194235801697\n",
      "Validation loss decreased from 0.6916948827830228 to 0.691694135015661\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.710784375667572\n",
      "Validation loss decreased from 0.691694135015661 to 0.6916932626204058\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.7066972255706787\n",
      "Validation loss decreased from 0.6916932626204058 to 0.691692747853019\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6907491087913513\n",
      "Validation loss decreased from 0.691692747853019 to 0.691692287271673\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6960409879684448\n",
      "Validation loss decreased from 0.691692287271673 to 0.691691978411241\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6957024335861206\n",
      "Validation loss decreased from 0.691691978411241 to 0.6916917128996416\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6798998117446899\n",
      "Validation loss decreased from 0.6916917128996416 to 0.6916915882717479\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6901648044586182\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.7043572068214417\n",
      "Validation loss decreased from 0.6916915882717479 to 0.691691517829895\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6944875717163086\n",
      "Validation loss decreased from 0.691691517829895 to 0.6916914907368746\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.7031052112579346\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6903613209724426\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6989511847496033\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.7037448883056641\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.7012472152709961\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6911653280258179\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6939802765846252\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.7203764319419861\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.707377016544342\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6883370876312256\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.704542338848114\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.7060301303863525\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.7076660990715027\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.691291868686676\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.7055695652961731\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6919816732406616\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6856957077980042\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.707123339176178\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.7147191166877747\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.701126217842102\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.716559648513794\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.7021780610084534\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.7053138613700867\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6995951533317566\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.706683874130249\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6928957104682922\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6822333335876465\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6969520449638367\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.7132741212844849\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6997204422950745\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.710554301738739\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6919627785682678\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6896612048149109\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.7013125419616699\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6923782229423523\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.7132039666175842\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6823949813842773\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6980891227722168\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.714934766292572\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6864399313926697\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6964204907417297\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.7000250816345215\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6932833790779114\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6920036673545837\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6966749429702759\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.7000531554222107\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.7009035348892212\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6860755085945129\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.7004660964012146\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.7159187197685242\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  318\n",
      "AUC on test data  0.4867930293797802\n",
      "model 22 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6952155828475952\n",
      "Validation loss decreased from inf to 0.6969340606169268\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6996085047721863\n",
      "Validation loss decreased from 0.6969340606169268 to 0.696477472782135\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6897414326667786\n",
      "Validation loss decreased from 0.696477472782135 to 0.6961850849064913\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.688511848449707\n",
      "Validation loss decreased from 0.6961850849064913 to 0.6958508437330072\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6912840604782104\n",
      "Validation loss decreased from 0.6958508437330072 to 0.6956088759682395\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.683402419090271\n",
      "Validation loss decreased from 0.6956088759682395 to 0.6954361904751171\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6898112893104553\n",
      "Validation loss decreased from 0.6954361904751171 to 0.6952620473774996\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6915354132652283\n",
      "Validation loss decreased from 0.6952620473774996 to 0.6951814077117227\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6859665513038635\n",
      "Validation loss decreased from 0.6951814077117227 to 0.695130088112571\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6928490400314331\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6897993087768555\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6920756101608276\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6926183700561523\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6927441954612732\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6929495334625244\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6971206068992615\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6863586902618408\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6992432475090027\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6862392425537109\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6869021654129028\n",
      "Validation loss decreased from 0.695130088112571 to 0.695120405067097\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6877610087394714\n",
      "Validation loss decreased from 0.695120405067097 to 0.6951140653003346\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6931420564651489\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6916888356208801\n",
      "Validation loss decreased from 0.6951140653003346 to 0.6950952898372303\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6897545456886292\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6879088878631592\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6914116144180298\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6897398829460144\n",
      "Validation loss decreased from 0.6950952898372303 to 0.6950178146362305\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.685591459274292\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6867488622665405\n",
      "Validation loss decreased from 0.6950178146362305 to 0.6950120871717279\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6954518556594849\n",
      "Validation loss decreased from 0.6950120871717279 to 0.6947952942414717\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6962888240814209\n",
      "Validation loss decreased from 0.6947952942414717 to 0.694661557674408\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6916887164115906\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6883755922317505\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6829721331596375\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.690794825553894\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6851052045822144\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6891602277755737\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6871527433395386\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6900922656059265\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.685087263584137\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.689212441444397\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6927133202552795\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6858009099960327\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6875584721565247\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6887838840484619\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6866273283958435\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6849579215049744\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6833109259605408\n",
      "Validation loss decreased from 0.694661557674408 to 0.6944962631572377\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6865894794464111\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6841534972190857\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6886968612670898\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6840088367462158\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6853882074356079\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6917067170143127\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6888377070426941\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.692823588848114\n",
      "Validation loss decreased from 0.6944962631572377 to 0.6944369998845187\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6834068894386292\n",
      "Validation loss decreased from 0.6944369998845187 to 0.6943964307958429\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6887197494506836\n",
      "Validation loss decreased from 0.6943964307958429 to 0.6943787607279691\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6905238628387451\n",
      "Validation loss decreased from 0.6943787607279691 to 0.6943330114538019\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6865537166595459\n",
      "Validation loss decreased from 0.6943330114538019 to 0.6942713965069164\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6865009069442749\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6899734139442444\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6902498006820679\n",
      "Validation loss decreased from 0.6942713965069164 to 0.6942616105079651\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6884962320327759\n",
      "Validation loss decreased from 0.6942616105079651 to 0.6941090713847767\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.688082754611969\n",
      "Validation loss decreased from 0.6941090713847767 to 0.6939742836085233\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6803638935089111\n",
      "Validation loss decreased from 0.6939742836085233 to 0.6939433704723011\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6816673278808594\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6887245774269104\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6824131011962891\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6883049607276917\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6841059923171997\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6881965398788452\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6871293783187866\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6839339137077332\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6825171113014221\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6869520545005798\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6907932162284851\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6941801309585571\n",
      "Validation loss decreased from 0.6939433704723011 to 0.6938083442774686\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6867865324020386\n",
      "Validation loss decreased from 0.6938083442774686 to 0.6937386122616854\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6888798475265503\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6842982172966003\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6824625730514526\n",
      "Validation loss decreased from 0.6937386122616854 to 0.693705520846627\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6869038343429565\n",
      "Validation loss decreased from 0.693705520846627 to 0.6936738870360635\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6865159273147583\n",
      "Validation loss decreased from 0.6936738870360635 to 0.6936492432247509\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6866751313209534\n",
      "Validation loss decreased from 0.6936492432247509 to 0.6935950951142744\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6832422614097595\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6884812712669373\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6789761185646057\n",
      "Validation loss decreased from 0.6935950951142744 to 0.6935497305609963\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.688322901725769\n",
      "Validation loss decreased from 0.6935497305609963 to 0.6935115998441522\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6850029230117798\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6860542893409729\n",
      "Validation loss decreased from 0.6935115998441522 to 0.6934731169180437\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6790714263916016\n",
      "Validation loss decreased from 0.6934731169180437 to 0.6934643550352617\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.685814380645752\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6860139966011047\n",
      "Validation loss decreased from 0.6934643550352617 to 0.6934384541078047\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6855019330978394\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6862806677818298\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.680083155632019\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6822447776794434\n",
      "Validation loss decreased from 0.6934384541078047 to 0.6933661861853166\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6787559390068054\n",
      "Validation loss decreased from 0.6933661861853166 to 0.6932322111996737\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6868610978126526\n",
      "Validation loss decreased from 0.6932322111996737 to 0.6931215145371177\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6801883578300476\n",
      "Validation loss decreased from 0.6931215145371177 to 0.6930828202854503\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6865202188491821\n",
      "Validation loss decreased from 0.6930828202854503 to 0.6929888345978477\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.683255672454834\n",
      "Validation loss decreased from 0.6929888345978477 to 0.6929275718602267\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6864970326423645\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.679717481136322\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6808079481124878\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.684127151966095\n",
      "Validation loss decreased from 0.6929275718602267 to 0.6927757317369635\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.685934841632843\n",
      "Validation loss decreased from 0.6927757317369635 to 0.6926128810102289\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6838557124137878\n",
      "Validation loss decreased from 0.6926128810102289 to 0.6925151619044217\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6823999285697937\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6832907199859619\n",
      "Validation loss decreased from 0.6925151619044217 to 0.6925066005099904\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6799560785293579\n",
      "Validation loss decreased from 0.6925066005099904 to 0.6923825632442128\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6871926784515381\n",
      "Validation loss decreased from 0.6923825632442128 to 0.6922822811386802\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6777704954147339\n",
      "Validation loss decreased from 0.6922822811386802 to 0.692208934913982\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6807512640953064\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6815676093101501\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6850869655609131\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6840447187423706\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6795055866241455\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6857540607452393\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6836404800415039\n",
      "Validation loss decreased from 0.692208934913982 to 0.6921887397766113\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6805326342582703\n",
      "Validation loss decreased from 0.6921887397766113 to 0.6921022100882097\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6863052845001221\n",
      "Validation loss decreased from 0.6921022100882097 to 0.6919794136827643\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6904597878456116\n",
      "Validation loss decreased from 0.6919794136827643 to 0.6917937885631215\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6839788556098938\n",
      "Validation loss decreased from 0.6917937885631215 to 0.6915217692201788\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.684037983417511\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6738040447235107\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6747453212738037\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6822547912597656\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6801148653030396\n",
      "Validation loss decreased from 0.6915217692201788 to 0.6915184205228632\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6808004379272461\n",
      "Validation loss decreased from 0.6915184205228632 to 0.6915115497329019\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6833932399749756\n",
      "Validation loss decreased from 0.6915115497329019 to 0.6914979111064564\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6788144707679749\n",
      "Validation loss decreased from 0.6914979111064564 to 0.691428850997578\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6753454804420471\n",
      "Validation loss decreased from 0.691428850997578 to 0.6913522752848539\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6780710220336914\n",
      "Validation loss decreased from 0.6913522752848539 to 0.691239985552701\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6813152432441711\n",
      "Validation loss decreased from 0.691239985552701 to 0.6911121931943026\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6802579164505005\n",
      "Validation loss decreased from 0.6911121931943026 to 0.6910449212247675\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6762679815292358\n",
      "Validation loss decreased from 0.6910449212247675 to 0.6909442923285745\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6798639297485352\n",
      "Validation loss decreased from 0.6909442923285745 to 0.6908396861769937\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6783173084259033\n",
      "Validation loss decreased from 0.6908396861769937 to 0.690666756846688\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6768919229507446\n",
      "Validation loss decreased from 0.690666756846688 to 0.690551448952068\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6780561804771423\n",
      "Validation loss decreased from 0.690551448952068 to 0.6904336864298041\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6760473251342773\n",
      "Validation loss decreased from 0.6904336864298041 to 0.6903017813509161\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6796445250511169\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6790715456008911\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.678049623966217\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6804537773132324\n",
      "Validation loss decreased from 0.6903017813509161 to 0.6902798630974509\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6785258054733276\n",
      "Validation loss decreased from 0.6902798630974509 to 0.6902625831690702\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6768146753311157\n",
      "Validation loss decreased from 0.6902625831690702 to 0.6900941837917675\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6772971153259277\n",
      "Validation loss decreased from 0.6900941837917675 to 0.6899566108530218\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6722397208213806\n",
      "Validation loss decreased from 0.6899566108530218 to 0.6898774558847601\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.673395037651062\n",
      "Validation loss decreased from 0.6898774558847601 to 0.6898072307760065\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6752026081085205\n",
      "Validation loss decreased from 0.6898072307760065 to 0.6896527734669772\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6699896454811096\n",
      "Validation loss decreased from 0.6896527734669772 to 0.6895268396897749\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6798341274261475\n",
      "Validation loss decreased from 0.6895268396897749 to 0.6893616047772494\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.669413149356842\n",
      "Validation loss decreased from 0.6893616047772494 to 0.6891940181905573\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6785016059875488\n",
      "Validation loss decreased from 0.6891940181905573 to 0.6889822483062744\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6709309220314026\n",
      "Validation loss decreased from 0.6889822483062744 to 0.688953312960538\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6826359033584595\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6735239624977112\n",
      "Validation loss decreased from 0.688953312960538 to 0.6887869401411577\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6727922558784485\n",
      "Validation loss decreased from 0.6887869401411577 to 0.688665357503024\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6769752502441406\n",
      "Validation loss decreased from 0.688665357503024 to 0.6884647661989386\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6688566207885742\n",
      "Validation loss decreased from 0.6884647661989386 to 0.6883473775603555\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6736319065093994\n",
      "Validation loss decreased from 0.6883473775603555 to 0.6882577538490295\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6735025644302368\n",
      "Validation loss decreased from 0.6882577538490295 to 0.6880903569134799\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6706624627113342\n",
      "Validation loss decreased from 0.6880903569134799 to 0.6879033879800276\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6731966137886047\n",
      "Validation loss decreased from 0.6879033879800276 to 0.6877683292735707\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6689877510070801\n",
      "Validation loss decreased from 0.6877683292735707 to 0.6876201683824713\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6710745692253113\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6702086925506592\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6686235666275024\n",
      "Validation loss decreased from 0.6876201683824713 to 0.6876185644756664\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6712536811828613\n",
      "Validation loss decreased from 0.6876185644756664 to 0.6873022859746759\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6757137775421143\n",
      "Validation loss decreased from 0.6873022859746759 to 0.6870099685408853\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6663234829902649\n",
      "Validation loss decreased from 0.6870099685408853 to 0.6865188641981645\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6692867279052734\n",
      "Validation loss decreased from 0.6865188641981645 to 0.6862854849208485\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6660441160202026\n",
      "Validation loss decreased from 0.6862854849208485 to 0.6862742467360063\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6714398860931396\n",
      "Validation loss decreased from 0.6862742467360063 to 0.6860523819923401\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.665618896484375\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6637151837348938\n",
      "Validation loss decreased from 0.6860523819923401 to 0.6859651587226174\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6670493483543396\n",
      "Validation loss decreased from 0.6859651587226174 to 0.6857370083982294\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6673434376716614\n",
      "Validation loss decreased from 0.6857370083982294 to 0.6852711384946649\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6665884852409363\n",
      "Validation loss decreased from 0.6852711384946649 to 0.685253305868669\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6659001111984253\n",
      "Validation loss decreased from 0.685253305868669 to 0.6851803985509005\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6571431159973145\n",
      "Validation loss decreased from 0.6851803985509005 to 0.6851195638830011\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6637181639671326\n",
      "Validation loss decreased from 0.6851195638830011 to 0.6848304813558405\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.656921923160553\n",
      "Validation loss decreased from 0.6848304813558405 to 0.6843242699449713\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6619769334793091\n",
      "Validation loss decreased from 0.6843242699449713 to 0.6842503656040538\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6610827445983887\n",
      "Validation loss decreased from 0.6842503656040538 to 0.68414461070841\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6617538928985596\n",
      "Validation loss decreased from 0.68414461070841 to 0.6837555495175448\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6630762815475464\n",
      "Validation loss decreased from 0.6837555495175448 to 0.683383892882954\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6577790975570679\n",
      "Validation loss decreased from 0.683383892882954 to 0.6832734563133933\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6564534306526184\n",
      "Validation loss decreased from 0.6832734563133933 to 0.683134610002691\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6557480096817017\n",
      "Validation loss decreased from 0.683134610002691 to 0.6827314496040344\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6545213460922241\n",
      "Validation loss decreased from 0.6827314496040344 to 0.68241055987098\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6568588614463806\n",
      "Validation loss decreased from 0.68241055987098 to 0.6819292306900024\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.659162700176239\n",
      "Validation loss decreased from 0.6819292306900024 to 0.6814827756448225\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6561974287033081\n",
      "Validation loss decreased from 0.6814827756448225 to 0.6814454739744013\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6570358872413635\n",
      "Validation loss decreased from 0.6814454739744013 to 0.6812153079292991\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6577029824256897\n",
      "Validation loss decreased from 0.6812153079292991 to 0.6805141134695574\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.647779643535614\n",
      "Validation loss decreased from 0.6805141134695574 to 0.6804030320861123\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6431154012680054\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6467583775520325\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6507639288902283\n",
      "Validation loss decreased from 0.6804030320861123 to 0.6796944574876265\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6503153443336487\n",
      "Validation loss decreased from 0.6796944574876265 to 0.6789781505411322\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6433678269386292\n",
      "Validation loss decreased from 0.6789781505411322 to 0.6784792813387784\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6509876847267151\n",
      "Validation loss decreased from 0.6784792813387784 to 0.6780083775520325\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6563661098480225\n",
      "Validation loss decreased from 0.6780083775520325 to 0.6775868047367443\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6495298743247986\n",
      "Validation loss decreased from 0.6775868047367443 to 0.6772245547988198\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6507954597473145\n",
      "Validation loss decreased from 0.6772245547988198 to 0.6770682226527821\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6532838940620422\n",
      "Validation loss decreased from 0.6770682226527821 to 0.6766375465826555\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6577343940734863\n",
      "Validation loss decreased from 0.6766375465826555 to 0.6760326027870178\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6433062553405762\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6426108479499817\n",
      "Validation loss decreased from 0.6760326027870178 to 0.6753764965317466\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6423116326332092\n",
      "Validation loss decreased from 0.6753764965317466 to 0.674761333248832\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6378254294395447\n",
      "Validation loss decreased from 0.674761333248832 to 0.6741355495019392\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6428865194320679\n",
      "Validation loss decreased from 0.6741355495019392 to 0.6736319715326483\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6438573002815247\n",
      "Validation loss decreased from 0.6736319715326483 to 0.6730288050391457\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.638426661491394\n",
      "Validation loss decreased from 0.6730288050391457 to 0.6726512150330977\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.641385555267334\n",
      "Validation loss decreased from 0.6726512150330977 to 0.672022201798179\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6356142163276672\n",
      "Validation loss decreased from 0.672022201798179 to 0.6712487827647816\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6353161334991455\n",
      "Validation loss decreased from 0.6712487827647816 to 0.6708945415236733\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.636740505695343\n",
      "Validation loss decreased from 0.6708945415236733 to 0.6704451712695035\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.626976490020752\n",
      "Validation loss decreased from 0.6704451712695035 to 0.6696742285381664\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6237797737121582\n",
      "Validation loss decreased from 0.6696742285381664 to 0.6691123192960565\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6343663334846497\n",
      "Validation loss decreased from 0.6691123192960565 to 0.668665425343947\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6313284635543823\n",
      "Validation loss decreased from 0.668665425343947 to 0.6675957549702037\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6226273775100708\n",
      "Validation loss decreased from 0.6675957549702037 to 0.6673138575120405\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6326346397399902\n",
      "Validation loss decreased from 0.6673138575120405 to 0.6666638363491405\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6333335638046265\n",
      "Validation loss decreased from 0.6666638363491405 to 0.665812530300834\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6249080300331116\n",
      "Validation loss decreased from 0.665812530300834 to 0.6650735248218883\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6194444894790649\n",
      "Validation loss decreased from 0.6650735248218883 to 0.6645459695295854\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6211335062980652\n",
      "Validation loss decreased from 0.6645459695295854 to 0.6639223369685087\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6185528039932251\n",
      "Validation loss decreased from 0.6639223369685087 to 0.6632485281337391\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6162768006324768\n",
      "Validation loss decreased from 0.6632485281337391 to 0.6621530597860162\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6160435080528259\n",
      "Validation loss decreased from 0.6621530597860162 to 0.6616473197937012\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6071498990058899\n",
      "Validation loss decreased from 0.6616473197937012 to 0.6608116139065136\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6139596104621887\n",
      "Validation loss decreased from 0.6608116139065136 to 0.6597564653916792\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6178436279296875\n",
      "Validation loss decreased from 0.6597564653916792 to 0.6592583168636669\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6134173274040222\n",
      "Validation loss decreased from 0.6592583168636669 to 0.6582710255276073\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6075857281684875\n",
      "Validation loss decreased from 0.6582710255276073 to 0.6574253602461382\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.628868818283081\n",
      "Validation loss decreased from 0.6574253602461382 to 0.6567593000151895\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6123400926589966\n",
      "Validation loss decreased from 0.6567593000151895 to 0.655548865144903\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6139299273490906\n",
      "Validation loss decreased from 0.655548865144903 to 0.655062279917977\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6094366908073425\n",
      "Validation loss decreased from 0.655062279917977 to 0.6536787369034507\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.590304434299469\n",
      "Validation loss decreased from 0.6536787369034507 to 0.6526286439462141\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.5918564200401306\n",
      "Validation loss decreased from 0.6526286439462141 to 0.6520250493829901\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.599328875541687\n",
      "Validation loss decreased from 0.6520250493829901 to 0.6513116576454856\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.5787981152534485\n",
      "Validation loss decreased from 0.6513116576454856 to 0.6501830166036432\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6045501232147217\n",
      "Validation loss decreased from 0.6501830166036432 to 0.6490887132557955\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.5944216847419739\n",
      "Validation loss decreased from 0.6490887132557955 to 0.6478854363614862\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.5868377089500427\n",
      "Validation loss decreased from 0.6478854363614862 to 0.6466223976828835\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.5879485607147217\n",
      "Validation loss decreased from 0.6466223976828835 to 0.6459172151305459\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.5939353704452515\n",
      "Validation loss decreased from 0.6459172151305459 to 0.6450190923430703\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.5818994045257568\n",
      "Validation loss decreased from 0.6450190923430703 to 0.6439905871044506\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.5847213268280029\n",
      "Validation loss decreased from 0.6439905871044506 to 0.6427380496805365\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.5831449031829834\n",
      "Validation loss decreased from 0.6427380496805365 to 0.6416998397220265\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.5735228657722473\n",
      "Validation loss decreased from 0.6416998397220265 to 0.640602789141915\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.5681461095809937\n",
      "Validation loss decreased from 0.640602789141915 to 0.6392218524759467\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.5702236890792847\n",
      "Validation loss decreased from 0.6392218524759467 to 0.6383141766894947\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.5723168253898621\n",
      "Validation loss decreased from 0.6383141766894947 to 0.637069355357777\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.5696757435798645\n",
      "Validation loss decreased from 0.637069355357777 to 0.6351694789799777\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.5702139735221863\n",
      "Validation loss decreased from 0.6351694789799777 to 0.634501191702756\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.5656063556671143\n",
      "Validation loss decreased from 0.634501191702756 to 0.6333714452656832\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.5552617907524109\n",
      "Validation loss decreased from 0.6333714452656832 to 0.6321560361168601\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.5682722926139832\n",
      "Validation loss decreased from 0.6321560361168601 to 0.6310187198899009\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.5522502064704895\n",
      "Validation loss decreased from 0.6310187198899009 to 0.629437349059365\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.5796059370040894\n",
      "Validation loss decreased from 0.629437349059365 to 0.6277470209381797\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.5324535965919495\n",
      "Validation loss decreased from 0.6277470209381797 to 0.6276473186232827\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.5394494533538818\n",
      "Validation loss decreased from 0.6276473186232827 to 0.6253091205250133\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.5548481941223145\n",
      "Validation loss decreased from 0.6253091205250133 to 0.6236055330796675\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.5557560920715332\n",
      "Validation loss decreased from 0.6236055330796675 to 0.6225476264953613\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.5254607796669006\n",
      "Validation loss decreased from 0.6225476264953613 to 0.6213505864143372\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.5185716152191162\n",
      "Validation loss decreased from 0.6213505864143372 to 0.6201509237289429\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.5370389819145203\n",
      "Validation loss decreased from 0.6201509237289429 to 0.6186384125189348\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.5232691764831543\n",
      "Validation loss decreased from 0.6186384125189348 to 0.6166015375744213\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.5266585946083069\n",
      "Validation loss decreased from 0.6166015375744213 to 0.616078566421162\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.541336178779602\n",
      "Validation loss decreased from 0.616078566421162 to 0.6144268566911871\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.5338048338890076\n",
      "Validation loss decreased from 0.6144268566911871 to 0.6132423931902106\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.5349713563919067\n",
      "Validation loss decreased from 0.6132423931902106 to 0.6114498160102151\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.5238902568817139\n",
      "Validation loss decreased from 0.6114498160102151 to 0.6101946126330983\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.48802852630615234\n",
      "Validation loss decreased from 0.6101946126330983 to 0.6087096008387479\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.4971044361591339\n",
      "Validation loss decreased from 0.6087096008387479 to 0.607589532028545\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.48469337821006775\n",
      "Validation loss decreased from 0.607589532028545 to 0.6069128946824507\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.5094665288925171\n",
      "Validation loss decreased from 0.6069128946824507 to 0.6048330122774298\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.5091750025749207\n",
      "Validation loss decreased from 0.6048330122774298 to 0.6042155948552218\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.4947337806224823\n",
      "Validation loss decreased from 0.6042155948552218 to 0.6032388589598916\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.4778129756450653\n",
      "Validation loss decreased from 0.6032388589598916 to 0.5999586473811757\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.49391162395477295\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.45972055196762085\n",
      "Validation loss decreased from 0.5999586473811757 to 0.5985960960388184\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.47608157992362976\n",
      "Validation loss decreased from 0.5985960960388184 to 0.5984451391480186\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.4820352792739868\n",
      "Validation loss decreased from 0.5984451391480186 to 0.5956109274517406\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.47740092873573303\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.495877206325531\n",
      "Validation loss decreased from 0.5956109274517406 to 0.5928177779371088\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.4829544723033905\n",
      "Validation loss decreased from 0.5928177779371088 to 0.5921758738431063\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.4735361635684967\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.47848397493362427\n",
      "Validation loss decreased from 0.5921758738431063 to 0.5891621112823486\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.46197590231895447\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.47905948758125305\n",
      "Validation loss decreased from 0.5891621112823486 to 0.5865170034495267\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.47877493500709534\n",
      "Validation loss decreased from 0.5865170034495267 to 0.5860652381723578\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.45634573698043823\n",
      "Validation loss decreased from 0.5860652381723578 to 0.5846942663192749\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.4772842526435852\n",
      "Validation loss decreased from 0.5846942663192749 to 0.5840040662071921\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.47461217641830444\n",
      "Validation loss decreased from 0.5840040662071921 to 0.5819296728480946\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.46892622113227844\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.4158024787902832\n",
      "Validation loss decreased from 0.5819296728480946 to 0.5807646567171271\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.4421851933002472\n",
      "Validation loss decreased from 0.5807646567171271 to 0.5792923894795504\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.4223456084728241\n",
      "Validation loss decreased from 0.5792923894795504 to 0.5776169056242163\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.43627697229385376\n",
      "Validation loss decreased from 0.5776169056242163 to 0.57732139934193\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.4471346437931061\n",
      "Validation loss decreased from 0.57732139934193 to 0.5758611099286512\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.4260998070240021\n",
      "Validation loss decreased from 0.5758611099286512 to 0.5743075500835072\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.43981802463531494\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.41094842553138733\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.40827691555023193\n",
      "Validation loss decreased from 0.5743075500835072 to 0.5716076249426062\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.44032639265060425\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.4317176640033722\n",
      "Validation loss decreased from 0.5716076249426062 to 0.5710497606884349\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.4213676452636719\n",
      "Validation loss decreased from 0.5710497606884349 to 0.5691417347301136\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.42668473720550537\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.4312640428543091\n",
      "Validation loss decreased from 0.5691417347301136 to 0.5684697167439894\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.3790069818496704\n",
      "Validation loss decreased from 0.5684697167439894 to 0.5676476386460391\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.40573254227638245\n",
      "Validation loss decreased from 0.5676476386460391 to 0.5664459114724939\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.3635694086551666\n",
      "Validation loss decreased from 0.5664459114724939 to 0.5654320554299788\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.3820762038230896\n",
      "Validation loss decreased from 0.5654320554299788 to 0.5650060881267894\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.4163016080856323\n",
      "Validation loss decreased from 0.5650060881267894 to 0.563693726604635\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.39417415857315063\n",
      "Validation loss decreased from 0.563693726604635 to 0.5629787932742726\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.3760891258716583\n",
      "Validation loss decreased from 0.5629787932742726 to 0.562182141975923\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.381791889667511\n",
      "Validation loss decreased from 0.562182141975923 to 0.5620500499551947\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.4013563394546509\n",
      "Validation loss decreased from 0.5620500499551947 to 0.5601090246980841\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.4119608700275421\n",
      "Validation loss decreased from 0.5601090246980841 to 0.5600601922382008\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.33828380703926086\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.41514867544174194\n",
      "Validation loss decreased from 0.5600601922382008 to 0.5593775266950781\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.38251468539237976\n",
      "Validation loss decreased from 0.5593775266950781 to 0.5592751638455824\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.39891695976257324\n",
      "Validation loss decreased from 0.5592751638455824 to 0.5578927126797762\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.35148701071739197\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.347685843706131\n",
      "Validation loss decreased from 0.5578927126797762 to 0.5575300021605059\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.36493903398513794\n",
      "Validation loss decreased from 0.5575300021605059 to 0.5565933097492565\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.3614647090435028\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.34920358657836914\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.3426738679409027\n",
      "Validation loss decreased from 0.5565933097492565 to 0.5556046366691589\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.35593095421791077\n",
      "Validation loss decreased from 0.5556046366691589 to 0.5550739900632338\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.3677992522716522\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.3435685634613037\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.3879851996898651\n",
      "Validation loss decreased from 0.5550739900632338 to 0.5542254502123053\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.3336781859397888\n",
      "Validation loss decreased from 0.5542254502123053 to 0.553704559803009\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.3377061188220978\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.3310103714466095\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.33206403255462646\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.324702650308609\n",
      "Validation loss decreased from 0.553704559803009 to 0.5531422658400102\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.32304877042770386\n",
      "Validation loss decreased from 0.5531422658400102 to 0.5512769276445563\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.3357829749584198\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.31318607926368713\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.2998368740081787\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.2956866919994354\n",
      "Validation loss decreased from 0.5512769276445563 to 0.5504365861415863\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.3236527144908905\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.2904312312602997\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.3163599371910095\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.28309476375579834\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.28069138526916504\n",
      "Validation loss decreased from 0.5504365861415863 to 0.5490871071815491\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.3502962589263916\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.2906181812286377\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.3027254641056061\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.2902335822582245\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.2736794650554657\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.2786961495876312\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.27947211265563965\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.26166272163391113\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.2923843562602997\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.279936283826828\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.2674017548561096\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.2624164819717407\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.2716635763645172\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.28617531061172485\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.25045281648635864\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.25597652792930603\n",
      "Validation loss decreased from 0.5490871071815491 to 0.5489742810075934\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.29168280959129333\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.2685602903366089\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.29134827852249146\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.25725793838500977\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.24530227482318878\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.2525861859321594\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.2641849219799042\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.26506543159484863\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.2676837742328644\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.2517034709453583\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.2637747526168823\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.22634592652320862\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.24870221316814423\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.25044482946395874\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.2121848613023758\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.23820021748542786\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.2423296719789505\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.24833299219608307\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.23657304048538208\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.24375972151756287\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.2639390826225281\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.19981881976127625\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.24218934774398804\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.24320316314697266\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.23281918466091156\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.23158575594425201\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.22624549269676208\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.20558765530586243\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.2068847417831421\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.18747827410697937\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.19797420501708984\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.20220348238945007\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.20522065460681915\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.20720639824867249\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.2071128934621811\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.22491967678070068\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.19869793951511383\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.21642397344112396\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.1707039177417755\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.18210504949092865\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.1925148367881775\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.17756499350070953\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.1992884874343872\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.16722345352172852\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.1746784746646881\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.20834821462631226\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.17980191111564636\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.15910865366458893\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.15019665658473969\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.17464113235473633\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  372\n",
      "AUC on test data  0.798538650273666\n",
      "model 23 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6948786377906799\n",
      "Validation loss decreased from inf to 0.6931389407678084\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6999465823173523\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7007358074188232\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.7176359295845032\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7179418206214905\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.706668496131897\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6991391181945801\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6816644668579102\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.697342038154602\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7140235304832458\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6939283013343811\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6972301602363586\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6881706714630127\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6889545321464539\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6909183859825134\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6732155680656433\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6917062401771545\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.7139156460762024\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7184901237487793\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6816123723983765\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6918575763702393\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.700371265411377\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6882699728012085\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6995301842689514\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6971177458763123\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7066606283187866\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6931676864624023\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.685379147529602\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.7051552534103394\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6975439786911011\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.688186764717102\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6964970231056213\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6946348547935486\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6841363310813904\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6904390454292297\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6752273440361023\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6984591484069824\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.701920211315155\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.673754096031189\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6959307789802551\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.7050248980522156\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6965092420578003\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.69150310754776\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.692795991897583\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7019603848457336\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6939275860786438\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.699827253818512\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6993460655212402\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.7015531063079834\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6948032975196838\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.7059873938560486\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5037881851761977\n",
      "model 24 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6952627301216125\n",
      "Validation loss decreased from inf to 0.6917289712212302\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6966285109519958\n",
      "Validation loss decreased from 0.6917289712212302 to 0.691708965735002\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7007374167442322\n",
      "Validation loss decreased from 0.691708965735002 to 0.6916922655972567\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6914328336715698\n",
      "Validation loss decreased from 0.6916922655972567 to 0.6916821002960205\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6963410973548889\n",
      "Validation loss decreased from 0.6916821002960205 to 0.6916772560639814\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.701704740524292\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6978312730789185\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6954212188720703\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.693510115146637\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7014009356498718\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6917120814323425\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.701084554195404\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6902046799659729\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.691620409488678\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6911730170249939\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6962251663208008\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6974408626556396\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6910607814788818\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7010330557823181\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6962447762489319\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6981208324432373\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6935985684394836\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.7015177011489868\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6902185082435608\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6921548843383789\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6994665265083313\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6882792711257935\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.69584059715271\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.7009217143058777\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6971509456634521\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6928614377975464\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6925358176231384\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6933426260948181\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7010594606399536\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.69795823097229\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6944381594657898\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6886623501777649\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6932092905044556\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6913022398948669\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6939169764518738\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6966321468353271\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6838345527648926\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6996966004371643\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6893374919891357\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6909894943237305\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6929431557655334\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.691037118434906\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6933152079582214\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6890056729316711\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.694335401058197\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6963277459144592\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6945092678070068\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6943093538284302\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.7002752423286438\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6938927173614502\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  5\n",
      "AUC on test data  0.4853999838226968\n",
      "model 25 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6935849189758301\n",
      "Validation loss decreased from inf to 0.6929286501624368\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6861878037452698\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6911845803260803\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6919659972190857\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6892228722572327\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6978801488876343\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6957913041114807\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6922984719276428\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6876683235168457\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6822106838226318\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6858676671981812\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6928447484970093\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6838350892066956\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6860541105270386\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6866394281387329\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6886131167411804\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6881541013717651\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6860013604164124\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6908427476882935\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6955358982086182\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6826767325401306\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6932141780853271\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6954589486122131\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6900587677955627\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6918020248413086\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6860560178756714\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6904659867286682\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.687881350517273\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6906929612159729\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6971391439437866\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6961327195167542\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6923130750656128\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6919008493423462\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6912558078765869\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6904618740081787\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6916810274124146\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6948196887969971\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6889635920524597\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6895039677619934\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6923256516456604\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6912045478820801\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.691515326499939\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.694461464881897\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6900776624679565\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6934207081794739\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6876916289329529\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6922383904457092\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6934804320335388\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6911359429359436\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6956864595413208\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6881251931190491\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.522261766741262\n",
      "model 26 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.692825436592102\n",
      "Validation loss decreased from inf to 0.6958475763147528\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6914856433868408\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.691667914390564\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6887264847755432\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6899032592773438\n",
      "Validation loss decreased from 0.6958475763147528 to 0.6957189820029519\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6890761852264404\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6890990734100342\n",
      "Validation loss decreased from 0.6957189820029519 to 0.6957172968170859\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6890690922737122\n",
      "Validation loss decreased from 0.6957172968170859 to 0.6950118054043163\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6873507499694824\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6919199824333191\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6893618702888489\n",
      "Validation loss decreased from 0.6950118054043163 to 0.6948243921453302\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6893571615219116\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6896235346794128\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6896684765815735\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6874392628669739\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.69041508436203\n",
      "Validation loss decreased from 0.6948243921453302 to 0.6940985267812555\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6886383891105652\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6855742931365967\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6878265738487244\n",
      "Validation loss decreased from 0.6940985267812555 to 0.6936354203657671\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6827696561813354\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6857512593269348\n",
      "Validation loss decreased from 0.6936354203657671 to 0.6933460181409662\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.684347927570343\n",
      "Validation loss decreased from 0.6933460181409662 to 0.6929392489519987\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6832658052444458\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6807292699813843\n",
      "Validation loss decreased from 0.6929392489519987 to 0.6920212398875843\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6834047436714172\n",
      "Validation loss decreased from 0.6920212398875843 to 0.6916172179308805\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.68072909116745\n",
      "Validation loss decreased from 0.6916172179308805 to 0.6910232522270896\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6782653331756592\n",
      "Validation loss decreased from 0.6910232522270896 to 0.690278562632474\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6755505204200745\n",
      "Validation loss decreased from 0.690278562632474 to 0.6889137354764071\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6771817803382874\n",
      "Validation loss decreased from 0.6889137354764071 to 0.6882429664785211\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6675329208374023\n",
      "Validation loss decreased from 0.6882429664785211 to 0.686760663986206\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6680143475532532\n",
      "Validation loss decreased from 0.686760663986206 to 0.6847312558781017\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6606680154800415\n",
      "Validation loss decreased from 0.6847312558781017 to 0.682655854658647\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6498888731002808\n",
      "Validation loss decreased from 0.682655854658647 to 0.6791233745488253\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6490085124969482\n",
      "Validation loss decreased from 0.6791233745488253 to 0.6762711622498252\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6340862512588501\n",
      "Validation loss decreased from 0.6762711622498252 to 0.6708707755262201\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6178845763206482\n",
      "Validation loss decreased from 0.6708707755262201 to 0.6621060154654763\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6065259575843811\n",
      "Validation loss decreased from 0.6621060154654763 to 0.6511990969831293\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.5825859308242798\n",
      "Validation loss decreased from 0.6511990969831293 to 0.6381862705404108\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.553310751914978\n",
      "Validation loss decreased from 0.6381862705404108 to 0.6248334321108732\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.5505465269088745\n",
      "Validation loss decreased from 0.6248334321108732 to 0.6111324266953901\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.5220910310745239\n",
      "Validation loss decreased from 0.6111324266953901 to 0.5963850996711038\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.46807757019996643\n",
      "Validation loss decreased from 0.5963850996711038 to 0.5826807130466808\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.46057960391044617\n",
      "Validation loss decreased from 0.5826807130466808 to 0.5705494230443781\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.4031202793121338\n",
      "Validation loss decreased from 0.5705494230443781 to 0.5621762438253923\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.38597220182418823\n",
      "Validation loss decreased from 0.5621762438253923 to 0.5551844401793047\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.37518465518951416\n",
      "Validation loss decreased from 0.5551844401793047 to 0.5510171841491353\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.3121519386768341\n",
      "Validation loss decreased from 0.5510171841491353 to 0.5507460209456357\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.29334601759910583\n",
      "Validation loss decreased from 0.5507460209456357 to 0.544675119898536\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.2707809805870056\n",
      "Validation loss decreased from 0.544675119898536 to 0.5427726046605543\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.2513943910598755\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.245991051197052\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.2259635031223297\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.19411039352416992\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.17811356484889984\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.15583761036396027\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.14869076013565063\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.1347101628780365\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.11345312744379044\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.11766351014375687\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.10562973469495773\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.0816228911280632\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.09296829253435135\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.07428490370512009\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.09083476662635803\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.08149559795856476\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.06537224352359772\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.06103411689400673\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.08223261684179306\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06784814596176147\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.05118212103843689\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.07687381654977798\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.056613121181726456\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.06168599799275398\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.05324059724807739\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.05440559238195419\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05111096054315567\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.061353858560323715\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.04904262721538544\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.04463944584131241\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.07210748642683029\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.05149391293525696\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.06269568204879761\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.04941629618406296\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.05148988217115402\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.062680184841156\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.055672939866781235\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.050945211201906204\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.055335886776447296\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.06148644536733627\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.044287651777267456\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.0576082244515419\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.04859420657157898\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.04938778653740883\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.05650635063648224\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.06504884362220764\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.059622909873723984\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.04903916269540787\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.04333154484629631\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.06270547211170197\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  49\n",
      "AUC on test data  0.8213845974098339\n",
      "model 27 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6903011202812195\n",
      "Validation loss decreased from inf to 0.6943268125707452\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6941644549369812\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.686071515083313\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6816139817237854\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6887488961219788\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.7017712593078613\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6689257621765137\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7113978266716003\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.707656741142273\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6996603012084961\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6865959763526917\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.7003610134124756\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6933857202529907\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6869974136352539\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6977667808532715\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.7003870010375977\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6911811828613281\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6961260437965393\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6927123069763184\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6999247670173645\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6874364018440247\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.692290186882019\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.690599262714386\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6968276500701904\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6937023401260376\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6907532215118408\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7129378318786621\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6982313394546509\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6927626729011536\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6838423609733582\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6909758448600769\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6870339512825012\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6974381804466248\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7050739526748657\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.7002651691436768\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6944363117218018\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6882546544075012\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6867092847824097\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7024319767951965\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.684341311454773\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6905873417854309\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6844367980957031\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6905578374862671\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6896305084228516\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6895976066589355\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6970962882041931\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6922852396965027\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.7058899402618408\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6936222314834595\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6923920512199402\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6783813834190369\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5052351550774264\n",
      "model 28 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6839026808738708\n",
      "Validation loss decreased from inf to 0.701314693147486\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6881141066551208\n",
      "Validation loss decreased from 0.701314693147486 to 0.7010996341705322\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6846349835395813\n",
      "Validation loss decreased from 0.7010996341705322 to 0.7008831771937284\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6874939203262329\n",
      "Validation loss decreased from 0.7008831771937284 to 0.7006993998180736\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6981247663497925\n",
      "Validation loss decreased from 0.7006993998180736 to 0.7005295861851085\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6929610371589661\n",
      "Validation loss decreased from 0.7005295861851085 to 0.7003643946214155\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6881734132766724\n",
      "Validation loss decreased from 0.7003643946214155 to 0.7002008990807966\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6900835037231445\n",
      "Validation loss decreased from 0.7002008990807966 to 0.7000288963317871\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6918852925300598\n",
      "Validation loss decreased from 0.7000288963317871 to 0.6998567147688433\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6916237473487854\n",
      "Validation loss decreased from 0.6998567147688433 to 0.6997135389934886\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6900742053985596\n",
      "Validation loss decreased from 0.6997135389934886 to 0.699591029774059\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6908345818519592\n",
      "Validation loss decreased from 0.699591029774059 to 0.699458734555678\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6925109028816223\n",
      "Validation loss decreased from 0.699458734555678 to 0.699337059801275\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6892065405845642\n",
      "Validation loss decreased from 0.699337059801275 to 0.6992184844884005\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6830127835273743\n",
      "Validation loss decreased from 0.6992184844884005 to 0.6990913044322621\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6915037631988525\n",
      "Validation loss decreased from 0.6990913044322621 to 0.6989718946543607\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.688900351524353\n",
      "Validation loss decreased from 0.6989718946543607 to 0.6988579359921542\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6886834502220154\n",
      "Validation loss decreased from 0.6988579359921542 to 0.6987481333992698\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6935645937919617\n",
      "Validation loss decreased from 0.6987481333992698 to 0.698646529154344\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.690076470375061\n",
      "Validation loss decreased from 0.698646529154344 to 0.6985464312813499\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6940939426422119\n",
      "Validation loss decreased from 0.6985464312813499 to 0.6984508037567139\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6872692704200745\n",
      "Validation loss decreased from 0.6984508037567139 to 0.6983569806272333\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6921615600585938\n",
      "Validation loss decreased from 0.6983569806272333 to 0.6982667175206271\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6869193911552429\n",
      "Validation loss decreased from 0.6982667175206271 to 0.6981791908090765\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6899353265762329\n",
      "Validation loss decreased from 0.6981791908090765 to 0.6981016289104115\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6875817179679871\n",
      "Validation loss decreased from 0.6981016289104115 to 0.698015651919625\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6920788288116455\n",
      "Validation loss decreased from 0.698015651919625 to 0.6979389786720276\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6810905337333679\n",
      "Validation loss decreased from 0.6979389786720276 to 0.6978695609352805\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6928125023841858\n",
      "Validation loss decreased from 0.6978695609352805 to 0.6978007392449812\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.69659823179245\n",
      "Validation loss decreased from 0.6978007392449812 to 0.6977307525548068\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6883631944656372\n",
      "Validation loss decreased from 0.6977307525548068 to 0.6976572166789662\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6901614665985107\n",
      "Validation loss decreased from 0.6976572166789662 to 0.6975919062441046\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6921441555023193\n",
      "Validation loss decreased from 0.6975919062441046 to 0.6975381049242887\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6991308331489563\n",
      "Validation loss decreased from 0.6975381049242887 to 0.6974823691628196\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6823665499687195\n",
      "Validation loss decreased from 0.6974823691628196 to 0.6974262270060453\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6941328644752502\n",
      "Validation loss decreased from 0.6974262270060453 to 0.6973809383132241\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6908940076828003\n",
      "Validation loss decreased from 0.6973809383132241 to 0.6973463025960055\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6951937079429626\n",
      "Validation loss decreased from 0.6973463025960055 to 0.6972971612756903\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6849907636642456\n",
      "Validation loss decreased from 0.6972971612756903 to 0.6972477652809836\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6902320384979248\n",
      "Validation loss decreased from 0.6972477652809836 to 0.6971894990314137\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6917513608932495\n",
      "Validation loss decreased from 0.6971894990314137 to 0.6971498836170543\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6850971579551697\n",
      "Validation loss decreased from 0.6971498836170543 to 0.6971145272254944\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6909281015396118\n",
      "Validation loss decreased from 0.6971145272254944 to 0.6970780925317244\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6881456971168518\n",
      "Validation loss decreased from 0.6970780925317244 to 0.697037322954698\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6872597336769104\n",
      "Validation loss decreased from 0.697037322954698 to 0.6969812674955889\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6900838017463684\n",
      "Validation loss decreased from 0.6969812674955889 to 0.6969466209411621\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6864561438560486\n",
      "Validation loss decreased from 0.6969466209411621 to 0.6969234238971364\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6889901757240295\n",
      "Validation loss decreased from 0.6969234238971364 to 0.6968988830393011\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6921635270118713\n",
      "Validation loss decreased from 0.6968988830393011 to 0.6968609257177873\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6895047426223755\n",
      "Validation loss decreased from 0.6968609257177873 to 0.6968364553018049\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6986472606658936\n",
      "Validation loss decreased from 0.6968364553018049 to 0.6968082352118059\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6874471306800842\n",
      "Validation loss decreased from 0.6968082352118059 to 0.6967856667258523\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6912347674369812\n",
      "Validation loss decreased from 0.6967856667258523 to 0.6967778856104071\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6883565187454224\n",
      "Validation loss decreased from 0.6967778856104071 to 0.6967707655646584\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6839801669120789\n",
      "Validation loss decreased from 0.6967707655646584 to 0.6967595653100447\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6957757472991943\n",
      "Validation loss decreased from 0.6967595653100447 to 0.6967442252419211\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6962776780128479\n",
      "Validation loss decreased from 0.6967442252419211 to 0.6967280181971464\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6875845789909363\n",
      "Validation loss decreased from 0.6967280181971464 to 0.6967078935016285\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6965978741645813\n",
      "Validation loss decreased from 0.6967078935016285 to 0.696677413853732\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6938902139663696\n",
      "Validation loss decreased from 0.696677413853732 to 0.6966590881347656\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6899872422218323\n",
      "Validation loss decreased from 0.6966590881347656 to 0.6966376196254384\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6895896792411804\n",
      "Validation loss decreased from 0.6966376196254384 to 0.6966148777441545\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6925594806671143\n",
      "Validation loss decreased from 0.6966148777441545 to 0.6965927481651306\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6963234543800354\n",
      "Validation loss decreased from 0.6965927481651306 to 0.696567177772522\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6916415691375732\n",
      "Validation loss decreased from 0.696567177772522 to 0.6965436176820234\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6895080804824829\n",
      "Validation loss decreased from 0.6965436176820234 to 0.696523433381861\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6895578503608704\n",
      "Validation loss decreased from 0.696523433381861 to 0.6965116966854442\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6912456154823303\n",
      "Validation loss decreased from 0.6965116966854442 to 0.6964958797801625\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6866962909698486\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.694848358631134\n",
      "Validation loss decreased from 0.6964958797801625 to 0.6964853514324535\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6896927356719971\n",
      "Validation loss decreased from 0.6964853514324535 to 0.6964752728288824\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6889549493789673\n",
      "Validation loss decreased from 0.6964752728288824 to 0.6964683749459006\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6854685544967651\n",
      "Validation loss decreased from 0.6964683749459006 to 0.6964539235288446\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.69163578748703\n",
      "Validation loss decreased from 0.6964539235288446 to 0.6964373913678256\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6919737458229065\n",
      "Validation loss decreased from 0.6964373913678256 to 0.6964177976955067\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6941647529602051\n",
      "Validation loss decreased from 0.6964177976955067 to 0.6964039043946699\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6889463663101196\n",
      "Validation loss decreased from 0.6964039043946699 to 0.6963953104886141\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6961638927459717\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6827163696289062\n",
      "Validation loss decreased from 0.6963953104886141 to 0.6963849826292559\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6894803643226624\n",
      "Validation loss decreased from 0.6963849826292559 to 0.6963794502344999\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6917548179626465\n",
      "Validation loss decreased from 0.6963794502344999 to 0.6963721513748169\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6879701018333435\n",
      "Validation loss decreased from 0.6963721513748169 to 0.6963616392829202\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6795059442520142\n",
      "Validation loss decreased from 0.6963616392829202 to 0.696345101703297\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6911892890930176\n",
      "Validation loss decreased from 0.696345101703297 to 0.6963273124261335\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6846967935562134\n",
      "Validation loss decreased from 0.6963273124261335 to 0.6963073936375704\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6861090660095215\n",
      "Validation loss decreased from 0.6963073936375704 to 0.696289290081371\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6822428107261658\n",
      "Validation loss decreased from 0.696289290081371 to 0.696274768222462\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6990776062011719\n",
      "Validation loss decreased from 0.696274768222462 to 0.6962601000612433\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.690819501876831\n",
      "Validation loss decreased from 0.6962601000612433 to 0.6962443644350226\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6862758994102478\n",
      "Validation loss decreased from 0.6962443644350226 to 0.6962261958555742\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6903766989707947\n",
      "Validation loss decreased from 0.6962261958555742 to 0.6962004737420515\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6960591077804565\n",
      "Validation loss decreased from 0.6962004737420515 to 0.6961870952086016\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6889052391052246\n",
      "Validation loss decreased from 0.6961870952086016 to 0.6961752501401034\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6930935382843018\n",
      "Validation loss decreased from 0.6961752501401034 to 0.6961696473034945\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6911871433258057\n",
      "Validation loss decreased from 0.6961696473034945 to 0.696160143071955\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6902249455451965\n",
      "Validation loss decreased from 0.696160143071955 to 0.6961516792123968\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6835758090019226\n",
      "Validation loss decreased from 0.6961516792123968 to 0.69614731723612\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6919559836387634\n",
      "Validation loss decreased from 0.69614731723612 to 0.6961374120278792\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6884046792984009\n",
      "Validation loss decreased from 0.6961374120278792 to 0.6961355751210992\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6916983723640442\n",
      "Validation loss decreased from 0.6961355751210992 to 0.6961232315410267\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6830986738204956\n",
      "Validation loss decreased from 0.6961232315410267 to 0.6961211941458962\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6964926719665527\n",
      "Validation loss decreased from 0.6961211941458962 to 0.6961094845424999\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6946081519126892\n",
      "Validation loss decreased from 0.6961094845424999 to 0.6960987990552728\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6890257596969604\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6879580616950989\n",
      "Validation loss decreased from 0.6960987990552728 to 0.6960866071961143\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6894897818565369\n",
      "Validation loss decreased from 0.6960866071961143 to 0.6960777911272916\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6905947923660278\n",
      "Validation loss decreased from 0.6960777911272916 to 0.6960664174773477\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6921294331550598\n",
      "Validation loss decreased from 0.6960664174773477 to 0.6960565556179393\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6890933513641357\n",
      "Validation loss decreased from 0.6960565556179393 to 0.6960428844798695\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6923729181289673\n",
      "Validation loss decreased from 0.6960428844798695 to 0.696037769317627\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6887485384941101\n",
      "Validation loss decreased from 0.696037769317627 to 0.6960300748998468\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6839844584465027\n",
      "Validation loss decreased from 0.6960300748998468 to 0.6960208903659474\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6900823712348938\n",
      "Validation loss decreased from 0.6960208903659474 to 0.6960084492510016\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6863951683044434\n",
      "Validation loss decreased from 0.6960084492510016 to 0.6959964416243813\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6869781017303467\n",
      "Validation loss decreased from 0.6959964416243813 to 0.6959913535551592\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6937387585639954\n",
      "Validation loss decreased from 0.6959913535551592 to 0.6959834478118203\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6929246187210083\n",
      "Validation loss decreased from 0.6959834478118203 to 0.6959816163236444\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6873753666877747\n",
      "Validation loss decreased from 0.6959816163236444 to 0.695971900766546\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6891179084777832\n",
      "Validation loss decreased from 0.695971900766546 to 0.6959677338600159\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6911736130714417\n",
      "Validation loss decreased from 0.6959677338600159 to 0.6959666501392018\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6879143118858337\n",
      "Validation loss decreased from 0.6959666501392018 to 0.6959602616050027\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6822969317436218\n",
      "Validation loss decreased from 0.6959602616050027 to 0.6959433393044905\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6807816028594971\n",
      "Validation loss decreased from 0.6959433393044905 to 0.6959311745383523\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6841288208961487\n",
      "Validation loss decreased from 0.6959311745383523 to 0.6959113316102461\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6999555826187134\n",
      "Validation loss decreased from 0.6959113316102461 to 0.6959066716107455\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6969162821769714\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6884970664978027\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6956090927124023\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6873022317886353\n",
      "Validation loss decreased from 0.6959066716107455 to 0.6959000609137795\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6923299431800842\n",
      "Validation loss decreased from 0.6959000609137795 to 0.6958888985893943\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.7017174363136292\n",
      "Validation loss decreased from 0.6958888985893943 to 0.6958840922875837\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6850168108940125\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6821421384811401\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6948403120040894\n",
      "Validation loss decreased from 0.6958840922875837 to 0.6958730925213207\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6909788846969604\n",
      "Validation loss decreased from 0.6958730925213207 to 0.6958640163595026\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6912826895713806\n",
      "Validation loss decreased from 0.6958640163595026 to 0.6958618272434581\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6923348903656006\n",
      "Validation loss decreased from 0.6958618272434581 to 0.6958589445460927\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6852667331695557\n",
      "Validation loss decreased from 0.6958589445460927 to 0.6958494294773448\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6856279373168945\n",
      "Validation loss decreased from 0.6958494294773448 to 0.6958384134552695\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6905673146247864\n",
      "Validation loss decreased from 0.6958384134552695 to 0.6958331411535089\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6947293877601624\n",
      "Validation loss decreased from 0.6958331411535089 to 0.6958282481540333\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6845565438270569\n",
      "Validation loss decreased from 0.6958282481540333 to 0.6958166794343428\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6909016370773315\n",
      "Validation loss decreased from 0.6958166794343428 to 0.6958057392727245\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6927230358123779\n",
      "Validation loss decreased from 0.6958057392727245 to 0.6957957744598389\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.684370219707489\n",
      "Validation loss decreased from 0.6957957744598389 to 0.6957901607860218\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6904411911964417\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.687468409538269\n",
      "Validation loss decreased from 0.6957901607860218 to 0.6957892287861217\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.690006673336029\n",
      "Validation loss decreased from 0.6957892287861217 to 0.6957868771119551\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6954002976417542\n",
      "Validation loss decreased from 0.6957868771119551 to 0.6957760832526467\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.689331591129303\n",
      "Validation loss decreased from 0.6957760832526467 to 0.6957582181150263\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6852585673332214\n",
      "Validation loss decreased from 0.6957582181150263 to 0.695751509883187\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6931779980659485\n",
      "Validation loss decreased from 0.695751509883187 to 0.6957449967210944\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.7067849636077881\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6875362992286682\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.690639078617096\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6871881484985352\n",
      "Validation loss decreased from 0.6957449967210944 to 0.6957406293262135\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6891531944274902\n",
      "Validation loss decreased from 0.6957406293262135 to 0.695723912932656\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6923468112945557\n",
      "Validation loss decreased from 0.695723912932656 to 0.6957184834913774\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6964267492294312\n",
      "Validation loss decreased from 0.6957184834913774 to 0.6957161480730231\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6917692422866821\n",
      "Validation loss decreased from 0.6957161480730231 to 0.6957136230035261\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6919082999229431\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6853718161582947\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.68562912940979\n",
      "Validation loss decreased from 0.6957136230035261 to 0.695699009028348\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6897850036621094\n",
      "Validation loss decreased from 0.695699009028348 to 0.6956887787038629\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6935130953788757\n",
      "Validation loss decreased from 0.6956887787038629 to 0.6956876245411959\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6935333013534546\n",
      "Validation loss decreased from 0.6956876245411959 to 0.6956863890994679\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.691403329372406\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6898497343063354\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6834672689437866\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6892576813697815\n",
      "Validation loss decreased from 0.6956863890994679 to 0.6956822276115417\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6898922920227051\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6959646344184875\n",
      "Validation loss decreased from 0.6956822276115417 to 0.6956759907982566\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6864877343177795\n",
      "Validation loss decreased from 0.6956759907982566 to 0.6956750533797524\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6863480806350708\n",
      "Validation loss decreased from 0.6956750533797524 to 0.6956696022640575\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6915807723999023\n",
      "Validation loss decreased from 0.6956696022640575 to 0.6956628181717612\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6843433380126953\n",
      "Validation loss decreased from 0.6956628181717612 to 0.6956529454751448\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6926657557487488\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6857761740684509\n",
      "Validation loss decreased from 0.6956529454751448 to 0.6956457008015026\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6950226426124573\n",
      "Validation loss decreased from 0.6956457008015026 to 0.6956375295465643\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.687214195728302\n",
      "Validation loss decreased from 0.6956375295465643 to 0.695633124221455\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6889249682426453\n",
      "Validation loss decreased from 0.695633124221455 to 0.6956270987337286\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6869836449623108\n",
      "Validation loss decreased from 0.6956270987337286 to 0.6956162561069835\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6876418590545654\n",
      "Validation loss decreased from 0.6956162561069835 to 0.6956060257824984\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.695145308971405\n",
      "Validation loss decreased from 0.6956060257824984 to 0.6956012411551042\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6853083372116089\n",
      "Validation loss decreased from 0.6956012411551042 to 0.6955942619930614\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6918273568153381\n",
      "Validation loss decreased from 0.6955942619930614 to 0.6955868330868807\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6826438307762146\n",
      "Validation loss decreased from 0.6955868330868807 to 0.6955812465060841\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6934826374053955\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.689609706401825\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6851553916931152\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.691024899482727\n",
      "Validation loss decreased from 0.6955812465060841 to 0.6955771446228027\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6937168836593628\n",
      "Validation loss decreased from 0.6955771446228027 to 0.6955690600655295\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6941030621528625\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6903507113456726\n",
      "Validation loss decreased from 0.6955690600655295 to 0.695565174926411\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6909778714179993\n",
      "Validation loss decreased from 0.695565174926411 to 0.6955635656010021\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6853559017181396\n",
      "Validation loss decreased from 0.6955635656010021 to 0.6955572691830721\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6908234357833862\n",
      "Validation loss decreased from 0.6955572691830721 to 0.6955551288344644\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6896282434463501\n",
      "Validation loss decreased from 0.6955551288344644 to 0.6955471418120645\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6895206570625305\n",
      "Validation loss decreased from 0.6955471418120645 to 0.6955379301851446\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6902192831039429\n",
      "Validation loss decreased from 0.6955379301851446 to 0.6955316120927985\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6884106397628784\n",
      "Validation loss decreased from 0.6955316120927985 to 0.6955244920470498\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6954978704452515\n",
      "Validation loss decreased from 0.6955244920470498 to 0.6955184773965315\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6858696341514587\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6905626058578491\n",
      "Validation loss decreased from 0.6955184773965315 to 0.6955153779550032\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6973370909690857\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6968035101890564\n",
      "Validation loss decreased from 0.6955153779550032 to 0.6955130533738569\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6878120303153992\n",
      "Validation loss decreased from 0.6955130533738569 to 0.6955032890493219\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6914331316947937\n",
      "Validation loss decreased from 0.6955032890493219 to 0.6954979842359369\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.694717526435852\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6813462972640991\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6845898628234863\n",
      "Validation loss decreased from 0.6954979842359369 to 0.6954928528178822\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6907261610031128\n",
      "Validation loss decreased from 0.6954928528178822 to 0.6954881223765287\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6868407726287842\n",
      "Validation loss decreased from 0.6954881223765287 to 0.6954875480044972\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6864483952522278\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6859114170074463\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6895331740379333\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.684605598449707\n",
      "Validation loss decreased from 0.6954875480044972 to 0.6954805850982666\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6900550723075867\n",
      "Validation loss decreased from 0.6954805850982666 to 0.6954725005409934\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6795836091041565\n",
      "Validation loss decreased from 0.6954725005409934 to 0.6954617391933094\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6891679167747498\n",
      "Validation loss decreased from 0.6954617391933094 to 0.6954507827758789\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6893676519393921\n",
      "Validation loss decreased from 0.6954507827758789 to 0.6954506744037975\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6920595765113831\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6848333477973938\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6880403757095337\n",
      "Validation loss decreased from 0.6954506744037975 to 0.6954441991719332\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6943442821502686\n",
      "Validation loss decreased from 0.6954441991719332 to 0.6954391165213152\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6899200081825256\n",
      "Validation loss decreased from 0.6954391165213152 to 0.6954352964054454\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6893939971923828\n",
      "Validation loss decreased from 0.6954352964054454 to 0.6954331452196295\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6879910826683044\n",
      "Validation loss decreased from 0.6954331452196295 to 0.6954299915920604\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6963151097297668\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6986295580863953\n",
      "Validation loss decreased from 0.6954299915920604 to 0.6954298398711465\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6877442002296448\n",
      "Validation loss decreased from 0.6954298398711465 to 0.6954246271740306\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.682610034942627\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6933455467224121\n",
      "Validation loss decreased from 0.6954246271740306 to 0.6954133077101274\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.685279905796051\n",
      "Validation loss decreased from 0.6954133077101274 to 0.695401435548609\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6934198141098022\n",
      "Validation loss decreased from 0.695401435548609 to 0.6953995823860168\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6877777576446533\n",
      "Validation loss decreased from 0.6953995823860168 to 0.6953918608752164\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.684688150882721\n",
      "Validation loss decreased from 0.6953918608752164 to 0.6953854018991644\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6949095129966736\n",
      "Validation loss decreased from 0.6953854018991644 to 0.6953794251788746\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6922702789306641\n",
      "Validation loss decreased from 0.6953794251788746 to 0.6953739415515553\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6852051615715027\n",
      "Validation loss decreased from 0.6953739415515553 to 0.695367775180123\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6935998797416687\n",
      "Validation loss decreased from 0.695367775180123 to 0.6953670490871776\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6881586909294128\n",
      "Validation loss decreased from 0.6953670490871776 to 0.6953598044135354\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6823586821556091\n",
      "Validation loss decreased from 0.6953598044135354 to 0.695356244390661\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6809993386268616\n",
      "Validation loss decreased from 0.695356244390661 to 0.695349395275116\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6891708374023438\n",
      "Validation loss decreased from 0.695349395275116 to 0.6953458894382823\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6893821954727173\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6926552653312683\n",
      "Validation loss decreased from 0.6953458894382823 to 0.6953427954153582\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6886386871337891\n",
      "Validation loss decreased from 0.6953427954153582 to 0.6953277425332502\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6896810531616211\n",
      "Validation loss decreased from 0.6953277425332502 to 0.6953135078603571\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6876218318939209\n",
      "Validation loss decreased from 0.6953135078603571 to 0.6952990022572604\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6914949417114258\n",
      "Validation loss decreased from 0.6952990022572604 to 0.6952964934435758\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6926084756851196\n",
      "Validation loss decreased from 0.6952964934435758 to 0.6952936486764387\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6934230923652649\n",
      "Validation loss decreased from 0.6952936486764387 to 0.6952910694209012\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6887397170066833\n",
      "Validation loss decreased from 0.6952910694209012 to 0.6952902566302906\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6902167201042175\n",
      "Validation loss decreased from 0.6952902566302906 to 0.6952888640490446\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6912521123886108\n",
      "Validation loss decreased from 0.6952888640490446 to 0.6952801455150951\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6826187968254089\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6895061135292053\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6909938454627991\n",
      "Validation loss decreased from 0.6952801455150951 to 0.6952766505154696\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6898601651191711\n",
      "Validation loss decreased from 0.6952766505154696 to 0.6952650655399669\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6912998557090759\n",
      "Validation loss decreased from 0.6952650655399669 to 0.6952606873078779\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6817598342895508\n",
      "Validation loss decreased from 0.6952606873078779 to 0.6952533938667991\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6956264972686768\n",
      "Validation loss decreased from 0.6952533938667991 to 0.6952429088679227\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6916620135307312\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6901622414588928\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6886079907417297\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.687437117099762\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6903531551361084\n",
      "Validation loss decreased from 0.6952429088679227 to 0.6952360109849409\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6914572715759277\n",
      "Validation loss decreased from 0.6952360109849409 to 0.6952254934744402\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6859322190284729\n",
      "Validation loss decreased from 0.6952254934744402 to 0.695215257731351\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6932163834571838\n",
      "Validation loss decreased from 0.695215257731351 to 0.6952072327787225\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.697950005531311\n",
      "Validation loss decreased from 0.6952072327787225 to 0.6951966502449729\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6911713480949402\n",
      "Validation loss decreased from 0.6951966502449729 to 0.6951872381297025\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.690141499042511\n",
      "Validation loss decreased from 0.6951872381297025 to 0.6951856558973138\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6873461008071899\n",
      "Validation loss decreased from 0.6951856558973138 to 0.695175745270469\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6902671456336975\n",
      "Validation loss decreased from 0.695175745270469 to 0.6951637268066406\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6854464411735535\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6924700736999512\n",
      "Validation loss decreased from 0.6951637268066406 to 0.6951588012955405\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6898332834243774\n",
      "Validation loss decreased from 0.6951588012955405 to 0.695154374296015\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.690575122833252\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6834340691566467\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6859517693519592\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6846917867660522\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6902586221694946\n",
      "Validation loss decreased from 0.695154374296015 to 0.6951528191566467\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6892458200454712\n",
      "Validation loss decreased from 0.6951528191566467 to 0.6951441439715299\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6875157952308655\n",
      "Validation loss decreased from 0.6951441439715299 to 0.6951250271363691\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6877851486206055\n",
      "Validation loss decreased from 0.6951250271363691 to 0.6951129924167286\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6881498694419861\n",
      "Validation loss decreased from 0.6951129924167286 to 0.6951065009290521\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6914494633674622\n",
      "Validation loss decreased from 0.6951065009290521 to 0.6950985301624645\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6906591057777405\n",
      "Validation loss decreased from 0.6950985301624645 to 0.6950899037447843\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6892715096473694\n",
      "Validation loss decreased from 0.6950899037447843 to 0.6950810389085249\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6930422782897949\n",
      "Validation loss decreased from 0.6950810389085249 to 0.6950742277232084\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6858177781105042\n",
      "Validation loss decreased from 0.6950742277232084 to 0.695060832933946\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6842366456985474\n",
      "Validation loss decreased from 0.695060832933946 to 0.6950473839586432\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6915074586868286\n",
      "Validation loss decreased from 0.6950473839586432 to 0.6950370831923052\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6832548975944519\n",
      "Validation loss decreased from 0.6950370831923052 to 0.6950261917981234\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6882289052009583\n",
      "Validation loss decreased from 0.6950261917981234 to 0.6950230219147422\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6907235980033875\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6892455220222473\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6911773085594177\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6849702000617981\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6910232901573181\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.689655065536499\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6868808269500732\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6827969551086426\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6923795938491821\n",
      "Validation loss decreased from 0.6950230219147422 to 0.695020551031286\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6923825740814209\n",
      "Validation loss decreased from 0.695020551031286 to 0.695010244846344\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6887618899345398\n",
      "Validation loss decreased from 0.695010244846344 to 0.694997950033708\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6869808435440063\n",
      "Validation loss decreased from 0.694997950033708 to 0.6949900876392018\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6918264627456665\n",
      "Validation loss decreased from 0.6949900876392018 to 0.6949788711287759\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.680270254611969\n",
      "Validation loss decreased from 0.6949788711287759 to 0.694971350106326\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6846166253089905\n",
      "Validation loss decreased from 0.694971350106326 to 0.6949656334790316\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.683925449848175\n",
      "Validation loss decreased from 0.6949656334790316 to 0.6949550455266779\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6871650218963623\n",
      "Validation loss decreased from 0.6949550455266779 to 0.6949491067366167\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6926476359367371\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6857700347900391\n",
      "Validation loss decreased from 0.6949491067366167 to 0.6949470855972983\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6896135210990906\n",
      "Validation loss decreased from 0.6949470855972983 to 0.694939830086448\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6924570202827454\n",
      "Validation loss decreased from 0.694939830086448 to 0.6949343356219205\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6934596300125122\n",
      "Validation loss decreased from 0.6949343356219205 to 0.6949293071573431\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6949254274368286\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6837388277053833\n",
      "Validation loss decreased from 0.6949293071573431 to 0.6949274377389387\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6871275305747986\n",
      "Validation loss decreased from 0.6949274377389387 to 0.6949179009957747\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6915528178215027\n",
      "Validation loss decreased from 0.6949179009957747 to 0.6949110085313971\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6868322491645813\n",
      "Validation loss decreased from 0.6949110085313971 to 0.6949020678346808\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6888490319252014\n",
      "Validation loss decreased from 0.6949020678346808 to 0.694900160486048\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6849142909049988\n",
      "Validation loss decreased from 0.694900160486048 to 0.6948937231844122\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6875293850898743\n",
      "Validation loss decreased from 0.6948937231844122 to 0.6948890252546831\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6885485649108887\n",
      "Validation loss decreased from 0.6948890252546831 to 0.6948852376504377\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.682845413684845\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6861022710800171\n",
      "Validation loss decreased from 0.6948852376504377 to 0.6948849558830261\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6895129680633545\n",
      "Validation loss decreased from 0.6948849558830261 to 0.6948759664188732\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6859539747238159\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6857196688652039\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6865876913070679\n",
      "Validation loss decreased from 0.6948759664188732 to 0.6948710246519609\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.692630410194397\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6835651993751526\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6902262568473816\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.690861165523529\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6916708946228027\n",
      "Validation loss decreased from 0.6948710246519609 to 0.6948668523268267\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6913886070251465\n",
      "Validation loss decreased from 0.6948668523268267 to 0.6948605125600641\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6913357377052307\n",
      "Validation loss decreased from 0.6948605125600641 to 0.6948552077466791\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.684697687625885\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6942577958106995\n",
      "Validation loss decreased from 0.6948552077466791 to 0.6948476487940008\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6857761740684509\n",
      "Validation loss decreased from 0.6948476487940008 to 0.6948467493057251\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6839556694030762\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6896572113037109\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6953070759773254\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6839295625686646\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6852624416351318\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6922627091407776\n",
      "Validation loss decreased from 0.6948467493057251 to 0.694845129143108\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6850569844245911\n",
      "Validation loss decreased from 0.694845129143108 to 0.6948425553061746\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6860578656196594\n",
      "Validation loss decreased from 0.6948425553061746 to 0.694831826470115\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6875755190849304\n",
      "Validation loss decreased from 0.694831826470115 to 0.6948293014006182\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6817088723182678\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6902432441711426\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6856056451797485\n",
      "Validation loss decreased from 0.6948293014006182 to 0.6948289654471658\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6915696263313293\n",
      "Validation loss decreased from 0.6948289654471658 to 0.6948266625404358\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6849834322929382\n",
      "Validation loss decreased from 0.6948266625404358 to 0.694821601564234\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6805078387260437\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6854398250579834\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6890460848808289\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6925439238548279\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6876611113548279\n",
      "Validation loss decreased from 0.694821601564234 to 0.6948075673796914\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6838736534118652\n",
      "Validation loss decreased from 0.6948075673796914 to 0.6947992444038391\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6882937550544739\n",
      "Validation loss decreased from 0.6947992444038391 to 0.6947889165444807\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6883041262626648\n",
      "Validation loss decreased from 0.6947889165444807 to 0.694784706289118\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6944506764411926\n",
      "Validation loss decreased from 0.694784706289118 to 0.6947844787077471\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6894733905792236\n",
      "Validation loss decreased from 0.6947844787077471 to 0.6947819969870828\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6923537850379944\n",
      "Validation loss decreased from 0.6947819969870828 to 0.6947759714993563\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6867246031761169\n",
      "Validation loss decreased from 0.6947759714993563 to 0.6947696317325939\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6905256509780884\n",
      "Validation loss decreased from 0.6947696317325939 to 0.6947625983845104\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6886257529258728\n",
      "Validation loss decreased from 0.6947625983845104 to 0.6947539665482261\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6879470348358154\n",
      "Validation loss decreased from 0.6947539665482261 to 0.6947392171079462\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6896330714225769\n",
      "Validation loss decreased from 0.6947392171079462 to 0.6947304172949358\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6895497441291809\n",
      "Validation loss decreased from 0.6947304172949358 to 0.694725676016374\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6894127130508423\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6843387484550476\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6876286268234253\n",
      "Validation loss decreased from 0.694725676016374 to 0.6947237740863453\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6901028156280518\n",
      "Validation loss decreased from 0.6947237740863453 to 0.6947202357378873\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.691466748714447\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6844771504402161\n",
      "Validation loss decreased from 0.6947202357378873 to 0.6947173747149381\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6872438192367554\n",
      "Validation loss decreased from 0.6947173747149381 to 0.6947145895524458\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6878581047058105\n",
      "Validation loss decreased from 0.6947145895524458 to 0.6947074315764687\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6826924085617065\n",
      "Validation loss decreased from 0.6947074315764687 to 0.694703914902427\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6900994777679443\n",
      "Validation loss decreased from 0.694703914902427 to 0.6947035030885176\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6878767013549805\n",
      "Validation loss decreased from 0.6947035030885176 to 0.694698691368103\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6854252815246582\n",
      "Validation loss decreased from 0.694698691368103 to 0.6946920210664923\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6906939148902893\n",
      "Validation loss decreased from 0.6946920210664923 to 0.6946880329738964\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.68417888879776\n",
      "Validation loss decreased from 0.6946880329738964 to 0.6946826685558666\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6839137673377991\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6889861226081848\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6851587891578674\n",
      "Validation loss decreased from 0.6946826685558666 to 0.6946822188117288\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6923505663871765\n",
      "Validation loss decreased from 0.6946822188117288 to 0.6946796178817749\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6889934539794922\n",
      "Validation loss decreased from 0.6946796178817749 to 0.6946743347428062\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.688971757888794\n",
      "Validation loss decreased from 0.6946743347428062 to 0.6946672417900779\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6873464584350586\n",
      "Validation loss decreased from 0.6946672417900779 to 0.6946592818606984\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6862863898277283\n",
      "Validation loss decreased from 0.6946592818606984 to 0.6946591789072211\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6861362457275391\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6886662244796753\n",
      "Validation loss decreased from 0.6946591789072211 to 0.6946559602564032\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6857231855392456\n",
      "Validation loss decreased from 0.6946559602564032 to 0.6946528608148749\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6879100799560547\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6890539526939392\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6895586252212524\n",
      "Validation loss decreased from 0.6946528608148749 to 0.6946513273499229\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6916948556900024\n",
      "Validation loss decreased from 0.6946513273499229 to 0.6946397423744202\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6921287178993225\n",
      "Validation loss decreased from 0.6946397423744202 to 0.6946289918639443\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6848196983337402\n",
      "Validation loss decreased from 0.6946289918639443 to 0.6946276859803633\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6906946897506714\n",
      "Validation loss decreased from 0.6946276859803633 to 0.694624429399317\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6840457916259766\n",
      "Validation loss decreased from 0.694624429399317 to 0.6946189457719977\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6877614259719849\n",
      "Validation loss decreased from 0.6946189457719977 to 0.6946151364933361\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.693230390548706\n",
      "Validation loss decreased from 0.6946151364933361 to 0.6946124055168845\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6869373321533203\n",
      "Validation loss decreased from 0.6946124055168845 to 0.6946069923314181\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6890703439712524\n",
      "Validation loss decreased from 0.6946069923314181 to 0.6945932670073076\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6804656982421875\n",
      "Validation loss decreased from 0.6945932670073076 to 0.6945813298225403\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6893854141235352\n",
      "Validation loss decreased from 0.6945813298225403 to 0.6945681842890653\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6832081079483032\n",
      "Validation loss decreased from 0.6945681842890653 to 0.6945628523826599\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.69390469789505\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6880694031715393\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6884405612945557\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6958408951759338\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6870377659797668\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6830582022666931\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6868062019348145\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6912896633148193\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6889973878860474\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6886072158813477\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6895248293876648\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6898772716522217\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6830090880393982\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.685350239276886\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6880877614021301\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6901008486747742\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.690514862537384\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6859856843948364\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6860335469245911\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6857369542121887\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6818751096725464\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6836625337600708\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6853612065315247\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6860104203224182\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6905284523963928\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6921667456626892\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6839107275009155\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.692230224609375\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.68768310546875\n",
      "Validation loss decreased from 0.6945628523826599 to 0.6945571791041981\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6902810335159302\n",
      "Validation loss decreased from 0.6945571791041981 to 0.6945480270819231\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6907134652137756\n",
      "Validation loss decreased from 0.6945480270819231 to 0.6945420232686129\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6891025900840759\n",
      "Validation loss decreased from 0.6945420232686129 to 0.6945237950845198\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6878001093864441\n",
      "Validation loss decreased from 0.6945237950845198 to 0.6945175636898387\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6873053908348083\n",
      "Validation loss decreased from 0.6945175636898387 to 0.6945129903880033\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6861027479171753\n",
      "Validation loss decreased from 0.6945129903880033 to 0.6945036595517938\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6921959519386292\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6815440058708191\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6855233907699585\n",
      "Validation loss decreased from 0.6945036595517938 to 0.6944977478547529\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6948991417884827\n",
      "Validation loss decreased from 0.6944977478547529 to 0.6944971789013256\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6862488389015198\n",
      "Validation loss decreased from 0.6944971789013256 to 0.6944941282272339\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6884218454360962\n",
      "Validation loss decreased from 0.6944941282272339 to 0.6944872574372725\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6858668327331543\n",
      "Validation loss decreased from 0.6944872574372725 to 0.6944783980196173\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6871375441551208\n",
      "Validation loss decreased from 0.6944783980196173 to 0.694471846927296\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6917475461959839\n",
      "Validation loss decreased from 0.694471846927296 to 0.6944627545096658\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6864050030708313\n",
      "Validation loss decreased from 0.6944627545096658 to 0.6944536837664518\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6921443939208984\n",
      "Validation loss decreased from 0.6944536837664518 to 0.6944462386044589\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6856136322021484\n",
      "Validation loss decreased from 0.6944462386044589 to 0.6944422721862793\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6836259961128235\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.684158980846405\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6879466772079468\n",
      "Validation loss decreased from 0.6944422721862793 to 0.694437482140281\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6914786696434021\n",
      "Validation loss decreased from 0.694437482140281 to 0.6944329576058821\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6913521885871887\n",
      "Validation loss decreased from 0.6944329576058821 to 0.6944323236292059\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6892145872116089\n",
      "Validation loss decreased from 0.6944323236292059 to 0.6944274306297302\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6822097301483154\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6840863227844238\n",
      "Validation loss decreased from 0.6944274306297302 to 0.6944269483739679\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6886284947395325\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6869894862174988\n",
      "Validation loss decreased from 0.6944269483739679 to 0.6944170973517678\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6839144825935364\n",
      "Validation loss decreased from 0.6944170973517678 to 0.6944079236550764\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6891933083534241\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6852595806121826\n",
      "Validation loss decreased from 0.6944079236550764 to 0.694406043399464\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.689909815788269\n",
      "Validation loss decreased from 0.694406043399464 to 0.6944018819115378\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6864440441131592\n",
      "Validation loss decreased from 0.6944018819115378 to 0.694397357377139\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6849275231361389\n",
      "Validation loss decreased from 0.694397357377139 to 0.6943961544470354\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6851667761802673\n",
      "Validation loss decreased from 0.6943961544470354 to 0.6943898309360851\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6893125772476196\n",
      "Validation loss decreased from 0.6943898309360851 to 0.6943856911225752\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6849315166473389\n",
      "Validation loss decreased from 0.6943856911225752 to 0.6943777799606323\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6860812306404114\n",
      "Validation loss decreased from 0.6943777799606323 to 0.694370920007879\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6822760105133057\n",
      "Validation loss decreased from 0.694370920007879 to 0.6943671974268827\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6878138780593872\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6817202568054199\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6896517872810364\n",
      "Validation loss decreased from 0.6943671974268827 to 0.6943624886599454\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6879373788833618\n",
      "Validation loss decreased from 0.6943624886599454 to 0.6943624236366965\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6858431100845337\n",
      "Validation loss decreased from 0.6943624236366965 to 0.6943616108460859\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.685441792011261\n",
      "Validation loss decreased from 0.6943616108460859 to 0.6943589394742792\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6885537505149841\n",
      "Validation loss decreased from 0.6943589394742792 to 0.6943508169867776\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6862659454345703\n",
      "Validation loss decreased from 0.6943508169867776 to 0.6943418275226246\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6838794946670532\n",
      "Validation loss decreased from 0.6943418275226246 to 0.6943340138955549\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6920406222343445\n",
      "Validation loss decreased from 0.6943340138955549 to 0.6943288499658758\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6825352311134338\n",
      "Validation loss decreased from 0.6943288499658758 to 0.6943231658502058\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6872676014900208\n",
      "Validation loss decreased from 0.6943231658502058 to 0.6943163980137218\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6925026178359985\n",
      "Validation loss decreased from 0.6943163980137218 to 0.6943126754327253\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6834672689437866\n",
      "Validation loss decreased from 0.6943126754327253 to 0.6943087848750028\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6858071088790894\n",
      "Validation loss decreased from 0.6943087848750028 to 0.6943049918521534\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6857136487960815\n",
      "Validation loss decreased from 0.6943049918521534 to 0.6943039406429637\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6851021647453308\n",
      "Validation loss decreased from 0.6943039406429637 to 0.6943005431782115\n",
      "no early stopping\n",
      "AUC on test data  0.5562835342015153\n",
      "model 29 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6970311999320984\n",
      "Validation loss decreased from inf to 0.6951491724361073\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.7061189413070679\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6964386701583862\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6765499114990234\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7054610252380371\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6756315231323242\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.685966432094574\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6917969584465027\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.7086191177368164\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6887352466583252\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.7035253047943115\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.7059683799743652\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.7000864744186401\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.7012943625450134\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6834183931350708\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6976446509361267\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.710665762424469\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.7057626843452454\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6970648765563965\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6915705800056458\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.7102874517440796\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6961206793785095\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6992906332015991\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6888856291770935\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.694227933883667\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6862478256225586\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7080339193344116\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.7093654274940491\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.7042863965034485\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6969323754310608\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.7083953022956848\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6828088760375977\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6884875297546387\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6882127523422241\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6814832091331482\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6976646780967712\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6940114498138428\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.692929744720459\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7009913325309753\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6922357082366943\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.7061498761177063\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.7092699408531189\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.7190757989883423\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.7093849778175354\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6857467889785767\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.696183979511261\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6868138909339905\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6891615986824036\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.7011713981628418\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6982845067977905\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.7097629904747009\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.4341583757987544\n",
      "model 30 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6918937563896179\n",
      "Validation loss decreased from inf to 0.6950395053083246\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6918928027153015\n",
      "Validation loss decreased from 0.6950395053083246 to 0.6950394890525124\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6918917894363403\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6918907761573792\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.691889762878418\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6918888092041016\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6918877959251404\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6918867826461792\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.691885769367218\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6918847560882568\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6918837428092957\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6918827295303345\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6918818354606628\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6918807625770569\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6918798089027405\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6918787360191345\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6918777823448181\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6918768286705017\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6918758153915405\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6918748021125793\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6918737888336182\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6918727159500122\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6918717622756958\n",
      "Validation loss decreased from 0.6950394890525124 to 0.6950394836339083\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6918706893920898\n",
      "Validation loss decreased from 0.6950394836339083 to 0.6950394511222839\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6918697953224182\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6918687224388123\n",
      "Validation loss decreased from 0.6950394511222839 to 0.6950394131920554\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6918677687644958\n",
      "Validation loss decreased from 0.6950394131920554 to 0.695039386099035\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6918666958808899\n",
      "Validation loss decreased from 0.695039386099035 to 0.6950393644246188\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6918657422065735\n",
      "Validation loss decreased from 0.6950393644246188 to 0.6950393264943903\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6918646693229675\n",
      "Validation loss decreased from 0.6950393264943903 to 0.69503929940137\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6918637752532959\n",
      "Validation loss decreased from 0.69503929940137 to 0.6950392777269537\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6918628215789795\n",
      "Validation loss decreased from 0.6950392777269537 to 0.6950392343781211\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6918617486953735\n",
      "Validation loss decreased from 0.6950392343781211 to 0.6950391910292886\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6918607950210571\n",
      "Validation loss decreased from 0.6950391910292886 to 0.6950391585176642\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.691859781742096\n",
      "Validation loss decreased from 0.6950391585176642 to 0.6950391205874357\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6918588876724243\n",
      "Validation loss decreased from 0.6950391205874357 to 0.6950391043316234\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6918578743934631\n",
      "Validation loss decreased from 0.6950391043316234 to 0.6950390609827909\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6918569207191467\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6918558478355408\n",
      "Validation loss decreased from 0.6950390609827909 to 0.6950390230525624\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6918548941612244\n",
      "Validation loss decreased from 0.6950390230525624 to 0.6950390067967501\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6918538212776184\n",
      "Validation loss decreased from 0.6950390067967501 to 0.6950389688665216\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6918529272079468\n",
      "Validation loss decreased from 0.6950389688665216 to 0.6950389417735013\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6918519735336304\n",
      "Validation loss decreased from 0.6950389417735013 to 0.6950389038432728\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.691851019859314\n",
      "Validation loss decreased from 0.6950389038432728 to 0.6950388930060647\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.691849946975708\n",
      "Validation loss decreased from 0.6950388930060647 to 0.6950388713316484\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6918490529060364\n",
      "Validation loss decreased from 0.6950388713316484 to 0.6950388550758362\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6918480396270752\n",
      "Validation loss decreased from 0.6950388550758362 to 0.6950388279828158\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.691847026348114\n",
      "Validation loss decreased from 0.6950388279828158 to 0.6950388225642118\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6918460726737976\n",
      "Validation loss decreased from 0.6950388225642118 to 0.6950388008897955\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6918450593948364\n",
      "Validation loss decreased from 0.6950388008897955 to 0.6950387575409629\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6918440461158752\n",
      "Validation loss decreased from 0.6950387575409629 to 0.6950387250293385\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6918431520462036\n",
      "Validation loss decreased from 0.6950387250293385 to 0.6950386979363181\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6918421983718872\n",
      "Validation loss decreased from 0.6950386979363181 to 0.6950386654246937\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6918411254882812\n",
      "Validation loss decreased from 0.6950386654246937 to 0.6950386491688815\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6918401718139648\n",
      "Validation loss decreased from 0.6950386491688815 to 0.695038605820049\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6918392777442932\n",
      "Validation loss decreased from 0.695038605820049 to 0.6950385733084246\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.691838264465332\n",
      "Validation loss decreased from 0.6950385733084246 to 0.6950385407968\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6918373107910156\n",
      "Validation loss decreased from 0.6950385407968 to 0.6950385191223838\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6918362975120544\n",
      "Validation loss decreased from 0.6950385191223838 to 0.6950384703549471\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6918352842330933\n",
      "Validation loss decreased from 0.6950384703549471 to 0.6950384107503024\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6918344497680664\n",
      "Validation loss decreased from 0.6950384107503024 to 0.6950383890758861\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6918333768844604\n",
      "Validation loss decreased from 0.6950383890758861 to 0.6950383403084495\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.691832423210144\n",
      "Validation loss decreased from 0.6950383403084495 to 0.6950382969596169\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6918314099311829\n",
      "Validation loss decreased from 0.6950382969596169 to 0.6950382752852007\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6918305158615112\n",
      "Validation loss decreased from 0.6950382752852007 to 0.6950382102619518\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.69182950258255\n",
      "Validation loss decreased from 0.6950382102619518 to 0.6950381885875355\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6918285489082336\n",
      "Validation loss decreased from 0.6950381885875355 to 0.6950381289828907\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6918275356292725\n",
      "Validation loss decreased from 0.6950381289828907 to 0.69503807479685\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.691826581954956\n",
      "Validation loss decreased from 0.69503807479685 to 0.6950380206108093\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6918256282806396\n",
      "Validation loss decreased from 0.6950380206108093 to 0.6950379718433727\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6918246150016785\n",
      "Validation loss decreased from 0.6950379718433727 to 0.6950379284945402\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6918236613273621\n",
      "Validation loss decreased from 0.6950379284945402 to 0.6950378580526873\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6918227076530457\n",
      "Validation loss decreased from 0.6950378580526873 to 0.6950378092852506\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6918216943740845\n",
      "Validation loss decreased from 0.6950378092852506 to 0.695037760517814\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6918208003044128\n",
      "Validation loss decreased from 0.695037760517814 to 0.6950376954945651\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6918198466300964\n",
      "Validation loss decreased from 0.6950376954945651 to 0.6950376467271284\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6918188333511353\n",
      "Validation loss decreased from 0.6950376467271284 to 0.6950375762852755\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6918178200721741\n",
      "Validation loss decreased from 0.6950375762852755 to 0.6950375600294634\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6918169260025024\n",
      "Validation loss decreased from 0.6950375600294634 to 0.6950374787504022\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.691815972328186\n",
      "Validation loss decreased from 0.6950374787504022 to 0.6950374299829657\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6918150186538696\n",
      "Validation loss decreased from 0.6950374299829657 to 0.695037381215529\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6918139457702637\n",
      "Validation loss decreased from 0.695037381215529 to 0.6950373107736761\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.691813051700592\n",
      "Validation loss decreased from 0.6950373107736761 to 0.6950372620062395\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6918120980262756\n",
      "Validation loss decreased from 0.6950372620062395 to 0.6950371698899702\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6918111443519592\n",
      "Validation loss decreased from 0.6950371698899702 to 0.6950371265411377\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6918101906776428\n",
      "Validation loss decreased from 0.6950371265411377 to 0.6950370615178888\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6918092966079712\n",
      "Validation loss decreased from 0.6950370615178888 to 0.6950369910760359\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6918082237243652\n",
      "Validation loss decreased from 0.6950369910760359 to 0.6950369368899952\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6918072700500488\n",
      "Validation loss decreased from 0.6950369368899952 to 0.6950368447737261\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6918063163757324\n",
      "Validation loss decreased from 0.6950368447737261 to 0.6950367960062894\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6918054223060608\n",
      "Validation loss decreased from 0.6950367960062894 to 0.6950367038900201\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6918044686317444\n",
      "Validation loss decreased from 0.6950367038900201 to 0.6950366442853754\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.691803514957428\n",
      "Validation loss decreased from 0.6950366442853754 to 0.6950365792621266\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6918025016784668\n",
      "Validation loss decreased from 0.6950365792621266 to 0.6950364925644614\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6918016672134399\n",
      "Validation loss decreased from 0.6950364925644614 to 0.6950364275412126\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6918007135391235\n",
      "Validation loss decreased from 0.6950364275412126 to 0.6950363408435475\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6917997002601624\n",
      "Validation loss decreased from 0.6950363408435475 to 0.6950362649830905\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6917988061904907\n",
      "Validation loss decreased from 0.6950362649830905 to 0.6950361674482172\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6917977929115295\n",
      "Validation loss decreased from 0.6950361674482172 to 0.6950361078435724\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6917968988418579\n",
      "Validation loss decreased from 0.6950361078435724 to 0.695035994052887\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6917958855628967\n",
      "Validation loss decreased from 0.695035994052887 to 0.6950359290296381\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6917951107025146\n",
      "Validation loss decreased from 0.6950359290296381 to 0.695035842331973\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6917940378189087\n",
      "Validation loss decreased from 0.695035842331973 to 0.695035761052912\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6917931437492371\n",
      "Validation loss decreased from 0.695035761052912 to 0.6950356526808306\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6917921304702759\n",
      "Validation loss decreased from 0.6950356526808306 to 0.6950355822389777\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6917911767959595\n",
      "Validation loss decreased from 0.6950355822389777 to 0.6950354901227084\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6917903423309326\n",
      "Validation loss decreased from 0.6950354901227084 to 0.6950353980064392\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6917893290519714\n",
      "Validation loss decreased from 0.6950353980064392 to 0.69503530589017\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.691788375377655\n",
      "Validation loss decreased from 0.69503530589017 to 0.695035224611109\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6917874813079834\n",
      "Validation loss decreased from 0.695035224611109 to 0.695035154169256\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.691786527633667\n",
      "Validation loss decreased from 0.695035154169256 to 0.6950350620529868\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6917855739593506\n",
      "Validation loss decreased from 0.6950350620529868 to 0.6950349916111339\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6917846202850342\n",
      "Validation loss decreased from 0.6950349916111339 to 0.6950348940762606\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6917837262153625\n",
      "Validation loss decreased from 0.6950348940762606 to 0.6950348073785956\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6917827725410461\n",
      "Validation loss decreased from 0.6950348073785956 to 0.6950347315181385\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6917818188667297\n",
      "Validation loss decreased from 0.6950347315181385 to 0.6950346339832653\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6917809844017029\n",
      "Validation loss decreased from 0.6950346339832653 to 0.695034536448392\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6917799711227417\n",
      "Validation loss decreased from 0.695034536448392 to 0.6950344389135187\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6917791366577148\n",
      "Validation loss decreased from 0.6950344389135187 to 0.6950343576344576\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6917782425880432\n",
      "Validation loss decreased from 0.6950343576344576 to 0.6950342492623762\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6917772889137268\n",
      "Validation loss decreased from 0.6950342492623762 to 0.6950341679833152\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6917763352394104\n",
      "Validation loss decreased from 0.6950341679833152 to 0.6950340867042542\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.691775381565094\n",
      "Validation loss decreased from 0.6950340867042542 to 0.6950339566577565\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6917746067047119\n",
      "Validation loss decreased from 0.6950339566577565 to 0.6950338699600913\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6917736530303955\n",
      "Validation loss decreased from 0.6950338699600913 to 0.695033767006614\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6917727589607239\n",
      "Validation loss decreased from 0.695033767006614 to 0.6950336586345326\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6917718052864075\n",
      "Validation loss decreased from 0.6950336586345326 to 0.6950335610996593\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6917708516120911\n",
      "Validation loss decreased from 0.6950335610996593 to 0.695033458146182\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6917700171470642\n",
      "Validation loss decreased from 0.695033458146182 to 0.6950333551927046\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6917691230773926\n",
      "Validation loss decreased from 0.6950333551927046 to 0.6950332414020192\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6917681694030762\n",
      "Validation loss decreased from 0.6950332414020192 to 0.69503314928575\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6917672753334045\n",
      "Validation loss decreased from 0.69503314928575 to 0.6950330300764604\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6917663216590881\n",
      "Validation loss decreased from 0.6950330300764604 to 0.6950329162857749\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6917654275894165\n",
      "Validation loss decreased from 0.6950329162857749 to 0.6950328024950895\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6917645931243896\n",
      "Validation loss decreased from 0.6950328024950895 to 0.695032694123008\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.691763699054718\n",
      "Validation loss decreased from 0.695032694123008 to 0.6950325911695306\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6917626857757568\n",
      "Validation loss decreased from 0.6950325911695306 to 0.6950324719602411\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6917619109153748\n",
      "Validation loss decreased from 0.6950324719602411 to 0.6950323473323475\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6917609572410583\n",
      "Validation loss decreased from 0.6950323473323475 to 0.6950322172858499\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6917600035667419\n",
      "Validation loss decreased from 0.6950322172858499 to 0.6950321089137684\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6917591094970703\n",
      "Validation loss decreased from 0.6950321089137684 to 0.6950319788672707\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6917582154273987\n",
      "Validation loss decreased from 0.6950319788672707 to 0.6950318813323975\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.691757321357727\n",
      "Validation loss decreased from 0.6950318813323975 to 0.6950317458672957\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6917564272880554\n",
      "Validation loss decreased from 0.6950317458672957 to 0.6950316266580061\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6917555332183838\n",
      "Validation loss decreased from 0.6950316266580061 to 0.6950315074487166\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6917545795440674\n",
      "Validation loss decreased from 0.6950315074487166 to 0.695031388239427\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6917537450790405\n",
      "Validation loss decreased from 0.695031388239427 to 0.6950312365185131\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6917527914047241\n",
      "Validation loss decreased from 0.6950312365185131 to 0.6950311118906195\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.691752016544342\n",
      "Validation loss decreased from 0.6950311118906195 to 0.6950310035185381\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6917510628700256\n",
      "Validation loss decreased from 0.6950310035185381 to 0.6950308734720404\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6917501091957092\n",
      "Validation loss decreased from 0.6950308734720404 to 0.6950307325883345\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6917491555213928\n",
      "Validation loss decreased from 0.6950307325883345 to 0.695030618797649\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6917483806610107\n",
      "Validation loss decreased from 0.695030618797649 to 0.6950304887511514\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6917474269866943\n",
      "Validation loss decreased from 0.6950304887511514 to 0.6950303478674456\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6917465925216675\n",
      "Validation loss decreased from 0.6950303478674456 to 0.6950302124023438\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6917456984519958\n",
      "Validation loss decreased from 0.6950302124023438 to 0.6950300877744501\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6917447447776794\n",
      "Validation loss decreased from 0.6950300877744501 to 0.6950299523093484\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6917439103126526\n",
      "Validation loss decreased from 0.6950299523093484 to 0.6950298168442466\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6917429566383362\n",
      "Validation loss decreased from 0.6950298168442466 to 0.6950296813791449\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6917420625686646\n",
      "Validation loss decreased from 0.6950296813791449 to 0.6950295459140431\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6917411684989929\n",
      "Validation loss decreased from 0.6950295459140431 to 0.6950294104489413\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6917403340339661\n",
      "Validation loss decreased from 0.6950294104489413 to 0.6950292858210477\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6917393803596497\n",
      "Validation loss decreased from 0.6950292858210477 to 0.6950291286815297\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.691738486289978\n",
      "Validation loss decreased from 0.6950291286815297 to 0.695029004053636\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6917375922203064\n",
      "Validation loss decreased from 0.695029004053636 to 0.6950288577513262\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6917367577552795\n",
      "Validation loss decreased from 0.6950288577513262 to 0.6950287277048285\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6917358040809631\n",
      "Validation loss decreased from 0.6950287277048285 to 0.6950286030769348\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6917349100112915\n",
      "Validation loss decreased from 0.6950286030769348 to 0.6950284405188127\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6917340755462646\n",
      "Validation loss decreased from 0.6950284405188127 to 0.6950282942165028\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6917331218719482\n",
      "Validation loss decreased from 0.6950282942165028 to 0.695028153332797\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6917322874069214\n",
      "Validation loss decreased from 0.695028153332797 to 0.6950280287049033\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6917313933372498\n",
      "Validation loss decreased from 0.6950280287049033 to 0.6950278824025934\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6917304396629333\n",
      "Validation loss decreased from 0.6950278824025934 to 0.6950277198444713\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6917295455932617\n",
      "Validation loss decreased from 0.6950277198444713 to 0.6950275843793695\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6917287111282349\n",
      "Validation loss decreased from 0.6950275843793695 to 0.6950274272398516\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.691727876663208\n",
      "Validation loss decreased from 0.6950274272398516 to 0.6950272917747498\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6917269825935364\n",
      "Validation loss decreased from 0.6950272917747498 to 0.6950271346352317\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6917260885238647\n",
      "Validation loss decreased from 0.6950271346352317 to 0.6950269883329218\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6917251944541931\n",
      "Validation loss decreased from 0.6950269883329218 to 0.6950268311934038\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6917243003845215\n",
      "Validation loss decreased from 0.6950268311934038 to 0.6950266848910939\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6917234063148499\n",
      "Validation loss decreased from 0.6950266848910939 to 0.6950265331701799\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6917224526405334\n",
      "Validation loss decreased from 0.6950265331701799 to 0.6950263760306619\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6917216181755066\n",
      "Validation loss decreased from 0.6950263760306619 to 0.6950262188911438\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.691720724105835\n",
      "Validation loss decreased from 0.6950262188911438 to 0.6950260725888339\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6917198896408081\n",
      "Validation loss decreased from 0.6950260725888339 to 0.6950259046121077\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6917189359664917\n",
      "Validation loss decreased from 0.6950259046121077 to 0.6950257583097978\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6917181015014648\n",
      "Validation loss decreased from 0.6950257583097978 to 0.6950255849144675\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6917172074317932\n",
      "Validation loss decreased from 0.6950255849144675 to 0.6950254331935536\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6917163133621216\n",
      "Validation loss decreased from 0.6950254331935536 to 0.6950252760540355\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.69171541929245\n",
      "Validation loss decreased from 0.6950252760540355 to 0.6950251243331216\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6917145252227783\n",
      "Validation loss decreased from 0.6950251243331216 to 0.6950249509377913\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6917136907577515\n",
      "Validation loss decreased from 0.6950249509377913 to 0.6950247937982733\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6917127966880798\n",
      "Validation loss decreased from 0.6950247937982733 to 0.6950246312401511\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.691711962223053\n",
      "Validation loss decreased from 0.6950246312401511 to 0.6950244795192372\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6917110085487366\n",
      "Validation loss decreased from 0.6950244795192372 to 0.6950243007053029\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6917101144790649\n",
      "Validation loss decreased from 0.6950243007053029 to 0.6950241435657848\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6917092800140381\n",
      "Validation loss decreased from 0.6950241435657848 to 0.6950239593332465\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6917084455490112\n",
      "Validation loss decreased from 0.6950239593332465 to 0.6950237859379161\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6917075514793396\n",
      "Validation loss decreased from 0.6950237859379161 to 0.6950236179611899\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6917065978050232\n",
      "Validation loss decreased from 0.6950236179611899 to 0.6950234499844637\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6917057633399963\n",
      "Validation loss decreased from 0.6950234499844637 to 0.6950232982635498\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6917048692703247\n",
      "Validation loss decreased from 0.6950232982635498 to 0.6950231194496155\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6917040944099426\n",
      "Validation loss decreased from 0.6950231194496155 to 0.6950229514728893\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6917031407356262\n",
      "Validation loss decreased from 0.6950229514728893 to 0.695022767240351\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6917022466659546\n",
      "Validation loss decreased from 0.695022767240351 to 0.695022620938041\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6917014122009277\n",
      "Validation loss decreased from 0.695022620938041 to 0.6950224258682944\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6917004585266113\n",
      "Validation loss decreased from 0.6950224258682944 to 0.6950222524729642\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6916996240615845\n",
      "Validation loss decreased from 0.6950222524729642 to 0.6950220736590299\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6916987299919128\n",
      "Validation loss decreased from 0.6950220736590299 to 0.6950218894264915\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6916978359222412\n",
      "Validation loss decreased from 0.6950218894264915 to 0.6950217214497653\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6916970014572144\n",
      "Validation loss decreased from 0.6950217214497653 to 0.6950215372172269\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6916961073875427\n",
      "Validation loss decreased from 0.6950215372172269 to 0.6950213692405007\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6916951537132263\n",
      "Validation loss decreased from 0.6950213692405007 to 0.6950211904265664\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6916943788528442\n",
      "Validation loss decreased from 0.6950211904265664 to 0.6950210116126321\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6916934847831726\n",
      "Validation loss decreased from 0.6950210116126321 to 0.6950208327986978\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6916926503181458\n",
      "Validation loss decreased from 0.6950208327986978 to 0.6950206594033674\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6916916966438293\n",
      "Validation loss decreased from 0.6950206594033674 to 0.6950204914266412\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6916908025741577\n",
      "Validation loss decreased from 0.6950204914266412 to 0.6950203071941029\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6916900277137756\n",
      "Validation loss decreased from 0.6950203071941029 to 0.6950201229615645\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.691689133644104\n",
      "Validation loss decreased from 0.6950201229615645 to 0.6950199387290261\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6916881799697876\n",
      "Validation loss decreased from 0.6950199387290261 to 0.6950197761709039\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6916874051094055\n",
      "Validation loss decreased from 0.6950197761709039 to 0.6950195973569696\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6916865110397339\n",
      "Validation loss decreased from 0.6950195973569696 to 0.6950194022872231\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6916856169700623\n",
      "Validation loss decreased from 0.6950194022872231 to 0.6950192288918928\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6916847825050354\n",
      "Validation loss decreased from 0.6950192288918928 to 0.6950190338221464\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.691683828830719\n",
      "Validation loss decreased from 0.6950190338221464 to 0.6950188333337958\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6916829943656921\n",
      "Validation loss decreased from 0.6950188333337958 to 0.6950186545198614\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6916821002960205\n",
      "Validation loss decreased from 0.6950186545198614 to 0.6950184594501149\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6916812062263489\n",
      "Validation loss decreased from 0.6950184594501149 to 0.6950182643803683\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6916802525520325\n",
      "Validation loss decreased from 0.6950182643803683 to 0.69501808014783\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6916793584823608\n",
      "Validation loss decreased from 0.69501808014783 to 0.6950178634036671\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.691678524017334\n",
      "Validation loss decreased from 0.6950178634036671 to 0.6950176683339205\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6916775703430176\n",
      "Validation loss decreased from 0.6950176683339205 to 0.69501746784557\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.691676676273346\n",
      "Validation loss decreased from 0.69501746784557 to 0.6950172619386152\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6916758418083191\n",
      "Validation loss decreased from 0.6950172619386152 to 0.695017093961889\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6916748881340027\n",
      "Validation loss decreased from 0.695017093961889 to 0.6950168772177263\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.691673994064331\n",
      "Validation loss decreased from 0.6950168772177263 to 0.6950166713107716\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6916730999946594\n",
      "Validation loss decreased from 0.6950166713107716 to 0.6950164816596291\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6916722059249878\n",
      "Validation loss decreased from 0.6950164816596291 to 0.6950162757526744\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6916712522506714\n",
      "Validation loss decreased from 0.6950162757526744 to 0.695016086101532\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6916704177856445\n",
      "Validation loss decreased from 0.695016086101532 to 0.6950158693573691\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6916695237159729\n",
      "Validation loss decreased from 0.6950158693573691 to 0.6950156688690186\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6916685700416565\n",
      "Validation loss decreased from 0.6950156688690186 to 0.695015468380668\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6916677355766296\n",
      "Validation loss decreased from 0.695015468380668 to 0.6950152624737133\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.691666841506958\n",
      "Validation loss decreased from 0.6950152624737133 to 0.6950150511481545\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6916660070419312\n",
      "Validation loss decreased from 0.6950150511481545 to 0.695014856078408\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6916651129722595\n",
      "Validation loss decreased from 0.695014856078408 to 0.6950146610086615\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6916641592979431\n",
      "Validation loss decreased from 0.6950146610086615 to 0.6950144280086864\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6916633248329163\n",
      "Validation loss decreased from 0.6950144280086864 to 0.6950142275203358\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6916624307632446\n",
      "Validation loss decreased from 0.6950142275203358 to 0.6950140324505892\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6916614770889282\n",
      "Validation loss decreased from 0.6950140324505892 to 0.6950138157064264\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6916607022285461\n",
      "Validation loss decreased from 0.6950138157064264 to 0.6950136097994718\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6916597485542297\n",
      "Validation loss decreased from 0.6950136097994718 to 0.6950134093111212\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6916588544845581\n",
      "Validation loss decreased from 0.6950134093111212 to 0.6950131979855624\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6916579604148865\n",
      "Validation loss decreased from 0.6950131979855624 to 0.6950129920786078\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6916570663452148\n",
      "Validation loss decreased from 0.6950129920786078 to 0.695012780753049\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.691656231880188\n",
      "Validation loss decreased from 0.695012780753049 to 0.6950125694274902\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6916553378105164\n",
      "Validation loss decreased from 0.6950125694274902 to 0.6950123418461193\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6916543841362\n",
      "Validation loss decreased from 0.6950123418461193 to 0.6950121359391646\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6916535496711731\n",
      "Validation loss decreased from 0.6950121359391646 to 0.6950119191950018\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6916526556015015\n",
      "Validation loss decreased from 0.6950119191950018 to 0.695011707869443\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6916518211364746\n",
      "Validation loss decreased from 0.695011707869443 to 0.6950114911252802\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.691650927066803\n",
      "Validation loss decreased from 0.6950114911252802 to 0.6950112906369296\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6916499733924866\n",
      "Validation loss decreased from 0.6950112906369296 to 0.6950110738927667\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6916491389274597\n",
      "Validation loss decreased from 0.6950110738927667 to 0.6950108842416243\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6916482448577881\n",
      "Validation loss decreased from 0.6950108842416243 to 0.6950106512416493\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6916472911834717\n",
      "Validation loss decreased from 0.6950106512416493 to 0.6950104453346946\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6916464567184448\n",
      "Validation loss decreased from 0.6950104453346946 to 0.6950102285905317\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6916455626487732\n",
      "Validation loss decreased from 0.6950102285905317 to 0.6950100335207853\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6916446685791016\n",
      "Validation loss decreased from 0.6950100335207853 to 0.6950098059394143\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6916437745094299\n",
      "Validation loss decreased from 0.6950098059394143 to 0.6950096217068759\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6916428804397583\n",
      "Validation loss decreased from 0.6950096217068759 to 0.695009399544109\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6916420459747314\n",
      "Validation loss decreased from 0.695009399544109 to 0.6950092098929666\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6916411519050598\n",
      "Validation loss decreased from 0.6950092098929666 to 0.6950089877301996\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.691640317440033\n",
      "Validation loss decreased from 0.6950089877301996 to 0.695008781823245\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6916393637657166\n",
      "Validation loss decreased from 0.695008781823245 to 0.695008559660478\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6916384696960449\n",
      "Validation loss decreased from 0.695008559660478 to 0.6950083429163153\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6916376352310181\n",
      "Validation loss decreased from 0.6950083429163153 to 0.6950081315907565\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6916366815567017\n",
      "Validation loss decreased from 0.6950081315907565 to 0.6950079256838019\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6916358470916748\n",
      "Validation loss decreased from 0.6950079256838019 to 0.6950077035210349\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6916348934173584\n",
      "Validation loss decreased from 0.6950077035210349 to 0.6950074867768721\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6916340589523315\n",
      "Validation loss decreased from 0.6950074867768721 to 0.6950072754513134\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6916332840919495\n",
      "Validation loss decreased from 0.6950072754513134 to 0.6950070749629628\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6916323304176331\n",
      "Validation loss decreased from 0.6950070749629628 to 0.6950068528001959\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6916313767433167\n",
      "Validation loss decreased from 0.6950068528001959 to 0.6950066143816168\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6916306018829346\n",
      "Validation loss decreased from 0.6950066143816168 to 0.695006397637454\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6916296482086182\n",
      "Validation loss decreased from 0.695006397637454 to 0.6950061917304993\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6916288733482361\n",
      "Validation loss decreased from 0.6950061917304993 to 0.6950059695677324\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6916279196739197\n",
      "Validation loss decreased from 0.6950059695677324 to 0.6950057474049655\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6916270852088928\n",
      "Validation loss decreased from 0.6950057474049655 to 0.6950055252421986\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6916261911392212\n",
      "Validation loss decreased from 0.6950055252421986 to 0.6950053139166399\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6916252970695496\n",
      "Validation loss decreased from 0.6950053139166399 to 0.6950050917538729\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6916244029998779\n",
      "Validation loss decreased from 0.6950050917538729 to 0.6950048858469183\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6916235089302063\n",
      "Validation loss decreased from 0.6950048858469183 to 0.6950046474283392\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6916226744651794\n",
      "Validation loss decreased from 0.6950046474283392 to 0.6950044198469683\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6916217803955078\n",
      "Validation loss decreased from 0.6950044198469683 to 0.6950041922655973\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.691620945930481\n",
      "Validation loss decreased from 0.6950041922655973 to 0.6950039701028303\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6916199922561646\n",
      "Validation loss decreased from 0.6950039701028303 to 0.6950037371028553\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6916191577911377\n",
      "Validation loss decreased from 0.6950037371028553 to 0.6950035149400885\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6916182637214661\n",
      "Validation loss decreased from 0.6950035149400885 to 0.6950033036145297\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6916174292564392\n",
      "Validation loss decreased from 0.6950033036145297 to 0.6950030814517628\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6916165351867676\n",
      "Validation loss decreased from 0.6950030814517628 to 0.6950028430331837\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6916157007217407\n",
      "Validation loss decreased from 0.6950028430331837 to 0.6950026154518127\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6916148066520691\n",
      "Validation loss decreased from 0.6950026154518127 to 0.6950023987076499\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6916139125823975\n",
      "Validation loss decreased from 0.6950023987076499 to 0.695002176544883\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6916130781173706\n",
      "Validation loss decreased from 0.695002176544883 to 0.6950019489635121\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.691612184047699\n",
      "Validation loss decreased from 0.6950019489635121 to 0.695001715963537\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6916112899780273\n",
      "Validation loss decreased from 0.695001715963537 to 0.6950014992193743\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6916104555130005\n",
      "Validation loss decreased from 0.6950014992193743 to 0.6950012662193992\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6916095614433289\n",
      "Validation loss decreased from 0.6950012662193992 to 0.6950010332194242\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.691608726978302\n",
      "Validation loss decreased from 0.6950010332194242 to 0.6950008327310736\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6916078329086304\n",
      "Validation loss decreased from 0.6950008327310736 to 0.6950005888938904\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6916069388389587\n",
      "Validation loss decreased from 0.6950005888938904 to 0.6950003613125194\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6916061043739319\n",
      "Validation loss decreased from 0.6950003613125194 to 0.6950001499869607\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6916052103042603\n",
      "Validation loss decreased from 0.6950001499869607 to 0.6949999224055897\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6916043758392334\n",
      "Validation loss decreased from 0.6949999224055897 to 0.6949997002428229\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6916034817695618\n",
      "Validation loss decreased from 0.6949997002428229 to 0.6949994726614519\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6916025876998901\n",
      "Validation loss decreased from 0.6949994726614519 to 0.6949992559172891\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6916017532348633\n",
      "Validation loss decreased from 0.6949992559172891 to 0.69499901749871\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6916008591651917\n",
      "Validation loss decreased from 0.69499901749871 to 0.6949987736615267\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6916000247001648\n",
      "Validation loss decreased from 0.6949987736615267 to 0.6949985731731761\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6915991306304932\n",
      "Validation loss decreased from 0.6949985731731761 to 0.694998334754597\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6915981769561768\n",
      "Validation loss decreased from 0.694998334754597 to 0.6949981071732261\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6915974020957947\n",
      "Validation loss decreased from 0.6949981071732261 to 0.6949978904290632\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6915964484214783\n",
      "Validation loss decreased from 0.6949978904290632 to 0.6949976682662964\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6915956139564514\n",
      "Validation loss decreased from 0.6949976682662964 to 0.694997413591905\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6915947198867798\n",
      "Validation loss decreased from 0.694997413591905 to 0.6949971914291382\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6915938854217529\n",
      "Validation loss decreased from 0.6949971914291382 to 0.6949969638477672\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6915930509567261\n",
      "Validation loss decreased from 0.6949969638477672 to 0.6949967362663962\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6915921568870544\n",
      "Validation loss decreased from 0.6949967362663962 to 0.694996481592005\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6915913224220276\n",
      "Validation loss decreased from 0.694996481592005 to 0.694996254010634\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.691590428352356\n",
      "Validation loss decreased from 0.694996254010634 to 0.6949960426850752\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6915894746780396\n",
      "Validation loss decreased from 0.6949960426850752 to 0.6949958096851002\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6915886998176575\n",
      "Validation loss decreased from 0.6949958096851002 to 0.694995560429313\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6915878057479858\n",
      "Validation loss decreased from 0.694995560429313 to 0.6949953436851501\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6915869116783142\n",
      "Validation loss decreased from 0.6949953436851501 to 0.6949951161037792\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6915860176086426\n",
      "Validation loss decreased from 0.6949951161037792 to 0.6949948722665961\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.691585123538971\n",
      "Validation loss decreased from 0.6949948722665961 to 0.6949946230108087\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6915842890739441\n",
      "Validation loss decreased from 0.6949946230108087 to 0.6949943954294379\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6915834546089172\n",
      "Validation loss decreased from 0.6949943954294379 to 0.694994184103879\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6915826201438904\n",
      "Validation loss decreased from 0.694994184103879 to 0.6949939402666959\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6915817260742188\n",
      "Validation loss decreased from 0.6949939402666959 to 0.6949936910109087\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6915808320045471\n",
      "Validation loss decreased from 0.6949936910109087 to 0.6949934525923296\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6915799975395203\n",
      "Validation loss decreased from 0.6949934525923296 to 0.6949932304295626\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6915790438652039\n",
      "Validation loss decreased from 0.6949932304295626 to 0.6949929811737754\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.691578209400177\n",
      "Validation loss decreased from 0.6949929811737754 to 0.6949927427551963\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6915773153305054\n",
      "Validation loss decreased from 0.6949927427551963 to 0.6949925097552213\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6915765404701233\n",
      "Validation loss decreased from 0.6949925097552213 to 0.6949922713366422\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6915755867958069\n",
      "Validation loss decreased from 0.6949922713366422 to 0.6949920383366671\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6915746927261353\n",
      "Validation loss decreased from 0.6949920383366671 to 0.6949918215925043\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6915738582611084\n",
      "Validation loss decreased from 0.6949918215925043 to 0.6949915831739252\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6915730237960815\n",
      "Validation loss decreased from 0.6949915831739252 to 0.6949913447553461\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6915720701217651\n",
      "Validation loss decreased from 0.6949913447553461 to 0.694991106336767\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6915712952613831\n",
      "Validation loss decreased from 0.694991106336767 to 0.6949908679181879\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6915703415870667\n",
      "Validation loss decreased from 0.6949908679181879 to 0.6949906511740251\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6915695667266846\n",
      "Validation loss decreased from 0.6949906511740251 to 0.6949904019182379\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6915686130523682\n",
      "Validation loss decreased from 0.6949904019182379 to 0.6949901634996588\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6915677189826965\n",
      "Validation loss decreased from 0.6949901634996588 to 0.6949899304996837\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6915668845176697\n",
      "Validation loss decreased from 0.6949899304996837 to 0.6949896920811046\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6915660500526428\n",
      "Validation loss decreased from 0.6949896920811046 to 0.6949894644997336\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.691565215587616\n",
      "Validation loss decreased from 0.6949894644997336 to 0.6949892044067383\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6915643215179443\n",
      "Validation loss decreased from 0.6949892044067383 to 0.6949889876625754\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6915634870529175\n",
      "Validation loss decreased from 0.6949889876625754 to 0.6949887438253923\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6915625929832458\n",
      "Validation loss decreased from 0.6949887438253923 to 0.6949885108254172\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.691561758518219\n",
      "Validation loss decreased from 0.6949885108254172 to 0.6949882940812544\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6915608644485474\n",
      "Validation loss decreased from 0.6949882940812544 to 0.6949880448254672\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6915600299835205\n",
      "Validation loss decreased from 0.6949880448254672 to 0.6949878226627003\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6915591359138489\n",
      "Validation loss decreased from 0.6949878226627003 to 0.694987567988309\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.691558301448822\n",
      "Validation loss decreased from 0.694987567988309 to 0.6949873512441461\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6915574669837952\n",
      "Validation loss decreased from 0.6949873512441461 to 0.6949871290813793\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6915565729141235\n",
      "Validation loss decreased from 0.6949871290813793 to 0.6949868852441962\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6915556788444519\n",
      "Validation loss decreased from 0.6949868852441962 to 0.6949866630814292\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.691554844379425\n",
      "Validation loss decreased from 0.6949866630814292 to 0.6949864192442461\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6915540099143982\n",
      "Validation loss decreased from 0.6949864192442461 to 0.694986186244271\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6915531158447266\n",
      "Validation loss decreased from 0.694986186244271 to 0.6949859369884838\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6915522813796997\n",
      "Validation loss decreased from 0.6949859369884838 to 0.6949857039885088\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6915513873100281\n",
      "Validation loss decreased from 0.6949857039885088 to 0.6949854655699297\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6915505528450012\n",
      "Validation loss decreased from 0.6949854655699297 to 0.6949852217327465\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6915497183799744\n",
      "Validation loss decreased from 0.6949852217327465 to 0.6949849833141674\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6915488839149475\n",
      "Validation loss decreased from 0.6949849833141674 to 0.6949847340583801\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6915479898452759\n",
      "Validation loss decreased from 0.6949847340583801 to 0.6949845010584051\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.691547155380249\n",
      "Validation loss decreased from 0.6949845010584051 to 0.6949842463840138\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6915463209152222\n",
      "Validation loss decreased from 0.6949842463840138 to 0.6949840242212469\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6915454864501953\n",
      "Validation loss decreased from 0.6949840242212469 to 0.6949837641282515\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6915445923805237\n",
      "Validation loss decreased from 0.6949837641282515 to 0.6949835311282765\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.691543698310852\n",
      "Validation loss decreased from 0.6949835311282765 to 0.6949832872910933\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6915429830551147\n",
      "Validation loss decreased from 0.6949832872910933 to 0.694983032616702\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6915420889854431\n",
      "Validation loss decreased from 0.694983032616702 to 0.6949828104539351\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6915411949157715\n",
      "Validation loss decreased from 0.6949828104539351 to 0.6949825611981478\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6915403604507446\n",
      "Validation loss decreased from 0.6949825611981478 to 0.6949823119423606\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6915395855903625\n",
      "Validation loss decreased from 0.6949823119423606 to 0.6949820789423856\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6915386915206909\n",
      "Validation loss decreased from 0.6949820789423856 to 0.6949818242679943\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6915378570556641\n",
      "Validation loss decreased from 0.6949818242679943 to 0.6949815966866233\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6915370225906372\n",
      "Validation loss decreased from 0.6949815966866233 to 0.6949813474308361\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6915361285209656\n",
      "Validation loss decreased from 0.6949813474308361 to 0.6949810927564447\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6915352940559387\n",
      "Validation loss decreased from 0.6949810927564447 to 0.6949808489192616\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6915344595909119\n",
      "Validation loss decreased from 0.6949808489192616 to 0.6949806159192865\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.691533625125885\n",
      "Validation loss decreased from 0.6949806159192865 to 0.6949803612448953\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6915327310562134\n",
      "Validation loss decreased from 0.6949803612448953 to 0.694980117407712\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6915319561958313\n",
      "Validation loss decreased from 0.694980117407712 to 0.6949798789891329\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6915310621261597\n",
      "Validation loss decreased from 0.6949798789891329 to 0.6949796243147417\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6915302276611328\n",
      "Validation loss decreased from 0.6949796243147417 to 0.6949793642217462\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.691529393196106\n",
      "Validation loss decreased from 0.6949793642217462 to 0.6949791203845631\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6915286183357239\n",
      "Validation loss decreased from 0.6949791203845631 to 0.6949788711287759\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6915276646614075\n",
      "Validation loss decreased from 0.6949788711287759 to 0.6949786218729886\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6915268301963806\n",
      "Validation loss decreased from 0.6949786218729886 to 0.6949783671985973\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6915259957313538\n",
      "Validation loss decreased from 0.6949783671985973 to 0.6949781287800182\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6915251016616821\n",
      "Validation loss decreased from 0.6949781287800182 to 0.6949778578498147\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6915243268013\n",
      "Validation loss decreased from 0.6949778578498147 to 0.6949775869196112\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6915234327316284\n",
      "Validation loss decreased from 0.6949775869196112 to 0.6949773376638239\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6915225982666016\n",
      "Validation loss decreased from 0.6949773376638239 to 0.6949770992452448\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6915217638015747\n",
      "Validation loss decreased from 0.6949770992452448 to 0.6949768391522494\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6915209889411926\n",
      "Validation loss decreased from 0.6949768391522494 to 0.69497657364065\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6915200352668762\n",
      "Validation loss decreased from 0.69497657364065 to 0.6949763298034668\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6915192008018494\n",
      "Validation loss decreased from 0.6949763298034668 to 0.6949760588732633\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6915184259414673\n",
      "Validation loss decreased from 0.6949760588732633 to 0.6949758258732882\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6915174722671509\n",
      "Validation loss decreased from 0.6949758258732882 to 0.6949755657802928\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6915166974067688\n",
      "Validation loss decreased from 0.6949755657802928 to 0.6949753111059015\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6915158629417419\n",
      "Validation loss decreased from 0.6949753111059015 to 0.694975034757094\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6915150880813599\n",
      "Validation loss decreased from 0.694975034757094 to 0.6949747855013068\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6915141344070435\n",
      "Validation loss decreased from 0.6949747855013068 to 0.6949745308269154\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6915133595466614\n",
      "Validation loss decreased from 0.6949745308269154 to 0.6949742815711282\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6915125250816345\n",
      "Validation loss decreased from 0.6949742815711282 to 0.6949740106409247\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6915117502212524\n",
      "Validation loss decreased from 0.6949740106409247 to 0.6949737234549089\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6915109157562256\n",
      "Validation loss decreased from 0.6949737234549089 to 0.6949734362688932\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6915099620819092\n",
      "Validation loss decreased from 0.6949734362688932 to 0.6949731761758978\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6915092468261719\n",
      "Validation loss decreased from 0.6949731761758978 to 0.6949729106642983\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6915083527565002\n",
      "Validation loss decreased from 0.6949729106642983 to 0.6949726288968866\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6915075778961182\n",
      "Validation loss decreased from 0.6949726288968866 to 0.6949723579666831\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6915068030357361\n",
      "Validation loss decreased from 0.6949723579666831 to 0.6949720978736877\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6915059685707092\n",
      "Validation loss decreased from 0.6949720978736877 to 0.694971810687672\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6915050745010376\n",
      "Validation loss decreased from 0.694971810687672 to 0.6949715505946766\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6915042400360107\n",
      "Validation loss decreased from 0.6949715505946766 to 0.6949712796644731\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6915034055709839\n",
      "Validation loss decreased from 0.6949712796644731 to 0.6949710249900818\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6915026307106018\n",
      "Validation loss decreased from 0.6949710249900818 to 0.694970737804066\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6915017366409302\n",
      "Validation loss decreased from 0.694970737804066 to 0.6949704668738625\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6915009617805481\n",
      "Validation loss decreased from 0.6949704668738625 to 0.6949702013622631\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6915000677108765\n",
      "Validation loss decreased from 0.6949702013622631 to 0.6949699141762473\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6914992928504944\n",
      "Validation loss decreased from 0.6949699141762473 to 0.6949696324088357\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6914984583854675\n",
      "Validation loss decreased from 0.6949696324088357 to 0.6949693668972362\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6914976239204407\n",
      "Validation loss decreased from 0.6949693668972362 to 0.6949690905484286\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6914968490600586\n",
      "Validation loss decreased from 0.6949690905484286 to 0.694968814199621\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6914960145950317\n",
      "Validation loss decreased from 0.694968814199621 to 0.6949685107577931\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6914951801300049\n",
      "Validation loss decreased from 0.6949685107577931 to 0.6949682398275896\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.691494345664978\n",
      "Validation loss decreased from 0.6949682398275896 to 0.6949679580601779\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6914935111999512\n",
      "Validation loss decreased from 0.6949679580601779 to 0.6949676817113702\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6914927363395691\n",
      "Validation loss decreased from 0.6949676817113702 to 0.6949673945253546\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6914918422698975\n",
      "Validation loss decreased from 0.6949673945253546 to 0.6949671019207347\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6914910078048706\n",
      "Validation loss decreased from 0.6949671019207347 to 0.6949668309905312\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6914902329444885\n",
      "Validation loss decreased from 0.6949668309905312 to 0.6949665438045155\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6914893984794617\n",
      "Validation loss decreased from 0.6949665438045155 to 0.6949662620371039\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6914885640144348\n",
      "Validation loss decreased from 0.6949662620371039 to 0.6949659748510881\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6914877891540527\n",
      "Validation loss decreased from 0.6949659748510881 to 0.6949656822464683\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6914868950843811\n",
      "Validation loss decreased from 0.6949656822464683 to 0.6949654167348688\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.691486120223999\n",
      "Validation loss decreased from 0.6949654167348688 to 0.6949650970372286\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6914852261543274\n",
      "Validation loss decreased from 0.6949650970372286 to 0.6949647935954008\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6914844512939453\n",
      "Validation loss decreased from 0.6949647935954008 to 0.6949645280838013\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6914836168289185\n",
      "Validation loss decreased from 0.6949645280838013 to 0.6949642246419733\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6914828419685364\n",
      "Validation loss decreased from 0.6949642246419733 to 0.6949639537117698\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6914819478988647\n",
      "Validation loss decreased from 0.6949639537117698 to 0.6949636448513378\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6914811730384827\n",
      "Validation loss decreased from 0.6949636448513378 to 0.6949633847583424\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6914803385734558\n",
      "Validation loss decreased from 0.6949633847583424 to 0.694963043386286\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6914794445037842\n",
      "Validation loss decreased from 0.694963043386286 to 0.6949627670374784\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6914786696434021\n",
      "Validation loss decreased from 0.6949627670374784 to 0.6949624690142545\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6914778351783752\n",
      "Validation loss decreased from 0.6949624690142545 to 0.6949621872468428\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6914770603179932\n",
      "Validation loss decreased from 0.6949621872468428 to 0.6949618675492026\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6914761662483215\n",
      "Validation loss decreased from 0.6949618675492026 to 0.6949616020376032\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6914753317832947\n",
      "Validation loss decreased from 0.6949616020376032 to 0.6949612877585671\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6914744973182678\n",
      "Validation loss decreased from 0.6949612877585671 to 0.6949610114097595\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6914737224578857\n",
      "Validation loss decreased from 0.6949610114097595 to 0.6949606917121194\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6914728879928589\n",
      "Validation loss decreased from 0.6949606917121194 to 0.6949603936888955\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6914721131324768\n",
      "Validation loss decreased from 0.6949603936888955 to 0.6949601173400879\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6914711594581604\n",
      "Validation loss decreased from 0.6949601173400879 to 0.6949598409912803\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6914703845977783\n",
      "Validation loss decreased from 0.6949598409912803 to 0.694959510456432\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6914695501327515\n",
      "Validation loss decreased from 0.694959510456432 to 0.6949592124332081\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6914687752723694\n",
      "Validation loss decreased from 0.6949592124332081 to 0.6949589306657965\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6914678812026978\n",
      "Validation loss decreased from 0.6949589306657965 to 0.6949586434797808\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6914671063423157\n",
      "Validation loss decreased from 0.6949586434797808 to 0.6949583454565569\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.691466212272644\n",
      "Validation loss decreased from 0.6949583454565569 to 0.6949580745263533\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.691465437412262\n",
      "Validation loss decreased from 0.6949580745263533 to 0.6949577710845254\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6914646029472351\n",
      "Validation loss decreased from 0.6949577710845254 to 0.6949574622240934\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.691463828086853\n",
      "Validation loss decreased from 0.6949574622240934 to 0.6949571858752858\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6914629340171814\n",
      "Validation loss decreased from 0.6949571858752858 to 0.6949569041078741\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6914621591567993\n",
      "Validation loss decreased from 0.6949569041078741 to 0.694956595247442\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6914613246917725\n",
      "Validation loss decreased from 0.694956595247442 to 0.694956280968406\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6914604902267456\n",
      "Validation loss decreased from 0.694956280968406 to 0.6949560046195984\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6914596557617188\n",
      "Validation loss decreased from 0.6949560046195984 to 0.6949557282707908\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6914588809013367\n",
      "Validation loss decreased from 0.6949557282707908 to 0.694955435666171\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6914580464363098\n",
      "Validation loss decreased from 0.694955435666171 to 0.6949551376429471\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.691457211971283\n",
      "Validation loss decreased from 0.6949551376429471 to 0.6949548558755354\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6914563775062561\n",
      "Validation loss decreased from 0.6949548558755354 to 0.6949545361778953\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6914554834365845\n",
      "Validation loss decreased from 0.6949545361778953 to 0.6949542598290877\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6914547085762024\n",
      "Validation loss decreased from 0.6949542598290877 to 0.6949539672244679\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6914539933204651\n",
      "Validation loss decreased from 0.6949539672244679 to 0.694953674619848\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6914530992507935\n",
      "Validation loss decreased from 0.694953674619848 to 0.6949533549222079\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6914523243904114\n",
      "Validation loss decreased from 0.6949533549222079 to 0.6949530623175881\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6914514899253845\n",
      "Validation loss decreased from 0.6949530623175881 to 0.6949527859687805\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6914507150650024\n",
      "Validation loss decreased from 0.6949527859687805 to 0.6949524771083485\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6914498805999756\n",
      "Validation loss decreased from 0.6949524771083485 to 0.6949521899223328\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6914491057395935\n",
      "Validation loss decreased from 0.6949521899223328 to 0.6949518864805048\n",
      "no early stopping\n",
      "AUC on test data  0.52939326125446\n",
      "model 31 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6854870319366455\n",
      "Validation loss decreased from inf to 0.6972357468171553\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6925758123397827\n",
      "Validation loss decreased from 0.6972357468171553 to 0.694252994927493\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6937486529350281\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6919752955436707\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6899235248565674\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6909953355789185\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.688199520111084\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6928329467773438\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6895068883895874\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6887543201446533\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6900836825370789\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6930311918258667\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6898285746574402\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.691719651222229\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6916804909706116\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6878027319908142\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6908527612686157\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6901571750640869\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6905941963195801\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6894303560256958\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6888229846954346\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6887326240539551\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6887272000312805\n",
      "Validation loss decreased from 0.694252994927493 to 0.6942221359773115\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6873477101325989\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.689858078956604\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.688560962677002\n",
      "Validation loss decreased from 0.6942221359773115 to 0.6940848989920183\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6859462857246399\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6883897185325623\n",
      "Validation loss decreased from 0.6940848989920183 to 0.693794922395186\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6874350309371948\n",
      "Validation loss decreased from 0.693794922395186 to 0.6934664195234125\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6882456541061401\n",
      "Validation loss decreased from 0.6934664195234125 to 0.6933396783742037\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6878460049629211\n",
      "Validation loss decreased from 0.6933396783742037 to 0.6930209181525491\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6856644153594971\n",
      "Validation loss decreased from 0.6930209181525491 to 0.692892930724404\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.687638521194458\n",
      "Validation loss decreased from 0.692892930724404 to 0.6927730224349282\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.684597909450531\n",
      "Validation loss decreased from 0.6927730224349282 to 0.6926030245694247\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6830492615699768\n",
      "Validation loss decreased from 0.6926030245694247 to 0.6922926198352467\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6812216639518738\n",
      "Validation loss decreased from 0.6922926198352467 to 0.691714042967016\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6825554966926575\n",
      "Validation loss decreased from 0.691714042967016 to 0.6915999380024996\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6848539710044861\n",
      "Validation loss decreased from 0.6915999380024996 to 0.6909275542606007\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6806710958480835\n",
      "Validation loss decreased from 0.6909275542606007 to 0.6902011199430986\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6799337863922119\n",
      "Validation loss decreased from 0.6902011199430986 to 0.6898845542560924\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6815239787101746\n",
      "Validation loss decreased from 0.6898845542560924 to 0.6885604479096152\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6738379597663879\n",
      "Validation loss decreased from 0.6885604479096152 to 0.6882100430401888\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6726465821266174\n",
      "Validation loss decreased from 0.6882100430401888 to 0.68554856560447\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6724641919136047\n",
      "Validation loss decreased from 0.68554856560447 to 0.6853770396926187\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6717426776885986\n",
      "Validation loss decreased from 0.6853770396926187 to 0.683544245633212\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.665892481803894\n",
      "Validation loss decreased from 0.683544245633212 to 0.6818973476236517\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6515917778015137\n",
      "Validation loss decreased from 0.6818973476236517 to 0.6793458461761475\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6574789881706238\n",
      "Validation loss decreased from 0.6793458461761475 to 0.6762413328344171\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.660588264465332\n",
      "Validation loss decreased from 0.6762413328344171 to 0.6714850989255038\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6440381407737732\n",
      "Validation loss decreased from 0.6714850989255038 to 0.6685069799423218\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6119783520698547\n",
      "Validation loss decreased from 0.6685069799423218 to 0.6613255739212036\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6133182048797607\n",
      "Validation loss decreased from 0.6613255739212036 to 0.6527623588388617\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6270394325256348\n",
      "Validation loss decreased from 0.6527623588388617 to 0.6400130391120911\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.578995943069458\n",
      "Validation loss decreased from 0.6400130391120911 to 0.6316654086112976\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.5544093251228333\n",
      "Validation loss decreased from 0.6316654086112976 to 0.6195091821930625\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.5356242656707764\n",
      "Validation loss decreased from 0.6195091821930625 to 0.6091419404203241\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.5260177254676819\n",
      "Validation loss decreased from 0.6091419404203241 to 0.5965829491615295\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.5098247528076172\n",
      "Validation loss decreased from 0.5965829491615295 to 0.5851890390569513\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.5022929906845093\n",
      "Validation loss decreased from 0.5851890390569513 to 0.5756188576871698\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.4740338921546936\n",
      "Validation loss decreased from 0.5756188576871698 to 0.5695101103999398\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.4012584984302521\n",
      "Validation loss decreased from 0.5695101103999398 to 0.5622586147351698\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.47593796253204346\n",
      "Validation loss decreased from 0.5622586147351698 to 0.556532697244124\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.3766113519668579\n",
      "Validation loss decreased from 0.556532697244124 to 0.5519735460931604\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.3860507011413574\n",
      "Validation loss decreased from 0.5519735460931604 to 0.5480485477230765\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.3872831165790558\n",
      "Validation loss decreased from 0.5480485477230765 to 0.5442699112675407\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.3980303704738617\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.3429778814315796\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.376615047454834\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.34831616282463074\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.26903578639030457\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.28923261165618896\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.2712264358997345\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.25232595205307007\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.26670193672180176\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.22896502912044525\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.2442445456981659\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.226755291223526\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.23466849327087402\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.18066301941871643\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.18658387660980225\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.17329837381839752\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.1523146778345108\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.13148567080497742\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.1676940768957138\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.12807148694992065\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.15072207152843475\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.12480676174163818\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.14817550778388977\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.13713857531547546\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.13356971740722656\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.10229789465665817\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.11134616285562515\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.12798714637756348\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.09229050576686859\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.11205156147480011\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.12753866612911224\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.09312265366315842\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.11980228871107101\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.09826885908842087\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.10673005878925323\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.10567603260278702\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.09498116374015808\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.08355159312486649\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.10905682295560837\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.09325089305639267\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.0886160209774971\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.08237279206514359\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.0884140357375145\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.09296683222055435\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.07716654241085052\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.10778522491455078\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.05690388008952141\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.06235238537192345\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.09593138098716736\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.07417340576648712\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  65\n",
      "AUC on test data  0.8113366946174516\n",
      "model 32 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6930314302444458\n",
      "Validation loss decreased from inf to 0.695326106114821\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6917763352394104\n",
      "Validation loss decreased from 0.695326106114821 to 0.6952624971216376\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7011495232582092\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6896973252296448\n",
      "Validation loss decreased from 0.6952624971216376 to 0.6950467228889465\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6890989542007446\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6908630728721619\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6901814937591553\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6932117342948914\n",
      "Validation loss decreased from 0.6950467228889465 to 0.6941492774269797\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6874874830245972\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6860693097114563\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6911157965660095\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.689261257648468\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6912579536437988\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6879030466079712\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6844720840454102\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6895240545272827\n",
      "Validation loss decreased from 0.6941492774269797 to 0.6936396089467135\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6859796047210693\n",
      "Validation loss decreased from 0.6936396089467135 to 0.6935891509056091\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6842002272605896\n",
      "Validation loss decreased from 0.6935891509056091 to 0.6934551705013622\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6836264133453369\n",
      "Validation loss decreased from 0.6934551705013622 to 0.6926894187927246\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6855495572090149\n",
      "Validation loss decreased from 0.6926894187927246 to 0.6925344304604963\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6804414391517639\n",
      "Validation loss decreased from 0.6925344304604963 to 0.6913085742430254\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6801586747169495\n",
      "Validation loss decreased from 0.6913085742430254 to 0.690826025876132\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6789213418960571\n",
      "Validation loss decreased from 0.690826025876132 to 0.6901417699727145\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.679335355758667\n",
      "Validation loss decreased from 0.6901417699727145 to 0.6896821043708108\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6757134795188904\n",
      "Validation loss decreased from 0.6896821043708108 to 0.6885638507929716\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6736791729927063\n",
      "Validation loss decreased from 0.6885638507929716 to 0.6870937130667947\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6707698702812195\n",
      "Validation loss decreased from 0.6870937130667947 to 0.68622103062543\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6748968362808228\n",
      "Validation loss decreased from 0.68622103062543 to 0.6852159229191866\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6700689196586609\n",
      "Validation loss decreased from 0.6852159229191866 to 0.6808645291761919\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6651284694671631\n",
      "Validation loss decreased from 0.6808645291761919 to 0.6789388331499967\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6481680274009705\n",
      "Validation loss decreased from 0.6789388331499967 to 0.6744207414713773\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6467803120613098\n",
      "Validation loss decreased from 0.6744207414713773 to 0.6728489128026095\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6315670609474182\n",
      "Validation loss decreased from 0.6728489128026095 to 0.6655393405394121\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6334453225135803\n",
      "Validation loss decreased from 0.6655393405394121 to 0.6550875956361945\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6170265078544617\n",
      "Validation loss decreased from 0.6550875956361945 to 0.6452613093636252\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.605011522769928\n",
      "Validation loss decreased from 0.6452613093636252 to 0.6315111951394514\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.5565026998519897\n",
      "Validation loss decreased from 0.6315111951394514 to 0.6169284419579939\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.5719127655029297\n",
      "Validation loss decreased from 0.6169284419579939 to 0.6021931279789318\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.5329760909080505\n",
      "Validation loss decreased from 0.6021931279789318 to 0.5870006680488586\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.5356763005256653\n",
      "Validation loss decreased from 0.5870006680488586 to 0.5727835460142656\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.4729342460632324\n",
      "Validation loss decreased from 0.5727835460142656 to 0.5596167716113004\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.4611439108848572\n",
      "Validation loss decreased from 0.5596167716113004 to 0.546773146499287\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.4404297471046448\n",
      "Validation loss decreased from 0.546773146499287 to 0.5360637252981012\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.41452375054359436\n",
      "Validation loss decreased from 0.5360637252981012 to 0.5248775482177734\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.33138564229011536\n",
      "Validation loss decreased from 0.5248775482177734 to 0.5156859972260215\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.3407069742679596\n",
      "Validation loss decreased from 0.5156859972260215 to 0.512252842838114\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.30857792496681213\n",
      "Validation loss decreased from 0.512252842838114 to 0.5084093294360421\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.31325504183769226\n",
      "Validation loss decreased from 0.5084093294360421 to 0.5080149932341143\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.24940802156925201\n",
      "Validation loss decreased from 0.5080149932341143 to 0.5037842961874875\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.2741501033306122\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.19975879788398743\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.2358497828245163\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.20858336985111237\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.20056968927383423\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.17830154299736023\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.17425677180290222\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.1454484462738037\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.15183934569358826\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.1360144019126892\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.13836859166622162\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.13014978170394897\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.11918510496616364\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.11076962202787399\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.11705928295850754\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.10864915698766708\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.09949493408203125\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.12301945686340332\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.09403195977210999\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.08695066720247269\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.0697171539068222\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.08634038269519806\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.09228090941905975\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.10036694258451462\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.06969879567623138\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.06500452011823654\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05846633389592171\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.0655294805765152\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.0763855054974556\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.08365128934383392\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.07045512646436691\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.061314791440963745\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.0802788957953453\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.07014156877994537\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.09928205609321594\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.059805601835250854\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.06138525530695915\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.05953530967235565\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.06243308261036873\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.07617200911045074\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.05638334900140762\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.06646203994750977\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.07662895321846008\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.06564219295978546\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.05166718363761902\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.08778155595064163\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.07230103760957718\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.07355179637670517\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.0570681169629097\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.0727703794836998\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  49\n",
      "AUC on test data  0.8375708880440742\n",
      "model 33 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7054610848426819\n",
      "Validation loss decreased from inf to 0.693109008398923\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6873352527618408\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7014184594154358\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6908829212188721\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6967244744300842\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6902123689651489\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7023785710334778\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6918052434921265\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6968085169792175\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6927258968353271\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6901402473449707\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6885882616043091\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6962215900421143\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6968896389007568\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6900776028633118\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6962941288948059\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6949994564056396\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6999118328094482\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6950841546058655\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.686671793460846\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6906256675720215\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.7060664296150208\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6962900757789612\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6913695931434631\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6937057375907898\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6933816075325012\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6914242506027222\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6988356709480286\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6894998550415039\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6879882216453552\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6917533278465271\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6879310607910156\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6898787617683411\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6974248886108398\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6841017007827759\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6850074529647827\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6906425356864929\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6951647400856018\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6905553936958313\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6966065764427185\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6875616312026978\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6992971897125244\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6921181082725525\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6795735955238342\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7007468342781067\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6919686794281006\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6894626617431641\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.697859525680542\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6835811138153076\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6909081935882568\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6907265782356262\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.528746169124718\n",
      "model 34 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6937705874443054\n",
      "Validation loss decreased from inf to 0.6966619329019026\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6937701106071472\n",
      "Validation loss decreased from 0.6966619329019026 to 0.6966568665070967\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6937696933746338\n",
      "Validation loss decreased from 0.6966568665070967 to 0.6966516809030012\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6937692165374756\n",
      "Validation loss decreased from 0.6966516809030012 to 0.696646511554718\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6937687397003174\n",
      "Validation loss decreased from 0.696646511554718 to 0.6966413259506226\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6937682628631592\n",
      "Validation loss decreased from 0.6966413259506226 to 0.6966362162069841\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6937679052352905\n",
      "Validation loss decreased from 0.6966362162069841 to 0.6966311118819497\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6937674283981323\n",
      "Validation loss decreased from 0.6966311118819497 to 0.6966260021383112\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6937669515609741\n",
      "Validation loss decreased from 0.6966260021383112 to 0.696620914069089\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6937665343284607\n",
      "Validation loss decreased from 0.696620914069089 to 0.6966158585114912\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6937659978866577\n",
      "Validation loss decreased from 0.6966158585114912 to 0.6966108083724976\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6937656402587891\n",
      "Validation loss decreased from 0.6966108083724976 to 0.6966058178381487\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6937652230262756\n",
      "Validation loss decreased from 0.6966058178381487 to 0.6966008164665916\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6937647461891174\n",
      "Validation loss decreased from 0.6966008164665916 to 0.6965958259322427\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.693764328956604\n",
      "Validation loss decreased from 0.6965958259322427 to 0.6965908624909141\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6937638521194458\n",
      "Validation loss decreased from 0.6965908624909141 to 0.6965859153053977\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6937634944915771\n",
      "Validation loss decreased from 0.6965859153053977 to 0.6965809735384855\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.693763017654419\n",
      "Validation loss decreased from 0.6965809735384855 to 0.6965760534459894\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6937626004219055\n",
      "Validation loss decreased from 0.6965760534459894 to 0.6965711441907015\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6937621235847473\n",
      "Validation loss decreased from 0.6965711441907015 to 0.6965662782842462\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6937617063522339\n",
      "Validation loss decreased from 0.6965662782842462 to 0.696561417796395\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6937613487243652\n",
      "Validation loss decreased from 0.696561417796395 to 0.6965565789829601\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6937608122825623\n",
      "Validation loss decreased from 0.6965565789829601 to 0.696551729332317\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6937604546546936\n",
      "Validation loss decreased from 0.696551729332317 to 0.6965469338677146\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6937599778175354\n",
      "Validation loss decreased from 0.6965469338677146 to 0.6965421329845082\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.693759560585022\n",
      "Validation loss decreased from 0.6965421329845082 to 0.6965373375199058\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6937592029571533\n",
      "Validation loss decreased from 0.6965373375199058 to 0.6965325962413441\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6937587261199951\n",
      "Validation loss decreased from 0.6965325962413441 to 0.6965278441255743\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6937583088874817\n",
      "Validation loss decreased from 0.6965278441255743 to 0.6965231245214288\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6937578916549683\n",
      "Validation loss decreased from 0.6965231245214288 to 0.6965184157544916\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6937574744224548\n",
      "Validation loss decreased from 0.6965184157544916 to 0.696513750336387\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6937570571899414\n",
      "Validation loss decreased from 0.696513750336387 to 0.6965090740810741\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.693756639957428\n",
      "Validation loss decreased from 0.6965090740810741 to 0.6965044195001776\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6937562227249146\n",
      "Validation loss decreased from 0.6965044195001776 to 0.6964997757564891\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6937558650970459\n",
      "Validation loss decreased from 0.6964997757564891 to 0.6964951699430292\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6937554478645325\n",
      "Validation loss decreased from 0.6964951699430292 to 0.6964905641295693\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.693755030632019\n",
      "Validation loss decreased from 0.6964905641295693 to 0.6964859637347135\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6937546133995056\n",
      "Validation loss decreased from 0.6964859637347135 to 0.6964814121072943\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6937541961669922\n",
      "Validation loss decreased from 0.6964814121072943 to 0.696476860479875\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6937538385391235\n",
      "Validation loss decreased from 0.696476860479875 to 0.6964723196896639\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6937533617019653\n",
      "Validation loss decreased from 0.6964723196896639 to 0.6964678222482855\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6937529444694519\n",
      "Validation loss decreased from 0.6964678222482855 to 0.6964633356441151\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.693752646446228\n",
      "Validation loss decreased from 0.6964633356441151 to 0.6964588327841326\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6937522292137146\n",
      "Validation loss decreased from 0.6964588327841326 to 0.6964543786915866\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6937517523765564\n",
      "Validation loss decreased from 0.6964543786915866 to 0.6964499462734569\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6937513947486877\n",
      "Validation loss decreased from 0.6964499462734569 to 0.6964455301111395\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6937509775161743\n",
      "Validation loss decreased from 0.6964455301111395 to 0.6964411302046343\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6937506198883057\n",
      "Validation loss decreased from 0.6964411302046343 to 0.6964367140423168\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6937502026557922\n",
      "Validation loss decreased from 0.6964367140423168 to 0.6964323737404563\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6937498450279236\n",
      "Validation loss decreased from 0.6964323737404563 to 0.6964279955083673\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6937494277954102\n",
      "Validation loss decreased from 0.6964279955083673 to 0.696423655206507\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6937490105628967\n",
      "Validation loss decreased from 0.696423655206507 to 0.6964193311604586\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6937486529350281\n",
      "Validation loss decreased from 0.6964193311604586 to 0.6964150396260348\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6937482357025146\n",
      "Validation loss decreased from 0.6964150396260348 to 0.6964107318357988\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6937478184700012\n",
      "Validation loss decreased from 0.6964107318357988 to 0.6964064511385831\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6937474608421326\n",
      "Validation loss decreased from 0.6964064511385831 to 0.6964021704413674\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6937471032142639\n",
      "Validation loss decreased from 0.6964021704413674 to 0.6963979222557761\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6937467455863953\n",
      "Validation loss decreased from 0.6963979222557761 to 0.6963936794887889\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6937463283538818\n",
      "Validation loss decreased from 0.6963936794887889 to 0.696389452977614\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6937459111213684\n",
      "Validation loss decreased from 0.696389452977614 to 0.6963852589780634\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6937456130981445\n",
      "Validation loss decreased from 0.6963852589780634 to 0.6963810703971169\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6937451958656311\n",
      "Validation loss decreased from 0.6963810703971169 to 0.6963768980719827\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6937448382377625\n",
      "Validation loss decreased from 0.6963768980719827 to 0.6963727582584728\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6937444806098938\n",
      "Validation loss decreased from 0.6963727582584728 to 0.696368623863567\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6937440633773804\n",
      "Validation loss decreased from 0.696368623863567 to 0.6963645165616815\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6937436461448669\n",
      "Validation loss decreased from 0.6963645165616815 to 0.6963604200970043\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6937433481216431\n",
      "Validation loss decreased from 0.6963604200970043 to 0.6963563127951189\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6937429904937744\n",
      "Validation loss decreased from 0.6963563127951189 to 0.696352248842066\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.693742573261261\n",
      "Validation loss decreased from 0.696352248842066 to 0.6963482119820334\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6937422156333923\n",
      "Validation loss decreased from 0.6963482119820334 to 0.696344180540605\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6937418580055237\n",
      "Validation loss decreased from 0.696344180540605 to 0.6963401599363848\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6937414407730103\n",
      "Validation loss decreased from 0.6963401599363848 to 0.6963361501693726\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6937411427497864\n",
      "Validation loss decreased from 0.6963361501693726 to 0.6963321349837563\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6937408447265625\n",
      "Validation loss decreased from 0.6963321349837563 to 0.6963281739841808\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6937404274940491\n",
      "Validation loss decreased from 0.6963281739841808 to 0.6963242129846052\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6937400698661804\n",
      "Validation loss decreased from 0.6963242129846052 to 0.696320273659446\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6937397122383118\n",
      "Validation loss decreased from 0.696320273659446 to 0.6963163126598705\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6937393546104431\n",
      "Validation loss decreased from 0.6963163126598705 to 0.6963123895905234\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6937389969825745\n",
      "Validation loss decreased from 0.6963123895905234 to 0.6963084881955927\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6937386393547058\n",
      "Validation loss decreased from 0.6963084881955927 to 0.6963045759634539\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6937382221221924\n",
      "Validation loss decreased from 0.6963045759634539 to 0.6963006799871271\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6937379240989685\n",
      "Validation loss decreased from 0.6963006799871271 to 0.6962968002666127\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6937375068664551\n",
      "Validation loss decreased from 0.6962968002666127 to 0.6962929313833063\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6937372088432312\n",
      "Validation loss decreased from 0.6962929313833063 to 0.6962890841744163\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6937368512153625\n",
      "Validation loss decreased from 0.6962890841744163 to 0.6962852586399425\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6937364935874939\n",
      "Validation loss decreased from 0.6962852586399425 to 0.696281449361281\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6937361359596252\n",
      "Validation loss decreased from 0.696281449361281 to 0.6962776346640154\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6937357783317566\n",
      "Validation loss decreased from 0.6962776346640154 to 0.696273841641166\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6937354207038879\n",
      "Validation loss decreased from 0.696273841641166 to 0.696270075711337\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6937351226806641\n",
      "Validation loss decreased from 0.696270075711337 to 0.6962662935256958\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6937347054481506\n",
      "Validation loss decreased from 0.6962662935256958 to 0.6962625438516791\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.693734347820282\n",
      "Validation loss decreased from 0.6962625438516791 to 0.6962587833404541\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6937340497970581\n",
      "Validation loss decreased from 0.6962587833404541 to 0.6962550282478333\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6937336325645447\n",
      "Validation loss decreased from 0.6962550282478333 to 0.6962513110854409\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.693733274936676\n",
      "Validation loss decreased from 0.6962513110854409 to 0.6962475939230486\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6937329769134521\n",
      "Validation loss decreased from 0.6962475939230486 to 0.6962439038536765\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6937325596809387\n",
      "Validation loss decreased from 0.6962439038536765 to 0.6962402083657004\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6937322616577148\n",
      "Validation loss decreased from 0.6962402083657004 to 0.6962365291335366\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6937319040298462\n",
      "Validation loss decreased from 0.6962365291335366 to 0.6962328607385809\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6937315464019775\n",
      "Validation loss decreased from 0.6962328607385809 to 0.6962292302738536\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6937311887741089\n",
      "Validation loss decreased from 0.6962292302738536 to 0.6962255727161061\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6937308311462402\n",
      "Validation loss decreased from 0.6962255727161061 to 0.696221958507191\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6937304735183716\n",
      "Validation loss decreased from 0.696221958507191 to 0.696218344298276\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6937301158905029\n",
      "Validation loss decreased from 0.696218344298276 to 0.696214724670757\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6937297582626343\n",
      "Validation loss decreased from 0.696214724670757 to 0.6962111429734663\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6937294602394104\n",
      "Validation loss decreased from 0.6962111429734663 to 0.6962075721133839\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.693729043006897\n",
      "Validation loss decreased from 0.6962075721133839 to 0.6962040391835299\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6937287449836731\n",
      "Validation loss decreased from 0.6962040391835299 to 0.696200506253676\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6937283873558044\n",
      "Validation loss decreased from 0.696200506253676 to 0.696196973323822\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6937280297279358\n",
      "Validation loss decreased from 0.696196973323822 to 0.6961934783241965\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6937276721000671\n",
      "Validation loss decreased from 0.6961934783241965 to 0.696189977905967\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6937273144721985\n",
      "Validation loss decreased from 0.696189977905967 to 0.6961865045807578\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6937270760536194\n",
      "Validation loss decreased from 0.6961865045807578 to 0.6961830475113608\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.693726658821106\n",
      "Validation loss decreased from 0.6961830475113608 to 0.696179601279172\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6937262415885925\n",
      "Validation loss decreased from 0.696179601279172 to 0.6961761658841913\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6937260031700134\n",
      "Validation loss decreased from 0.6961761658841913 to 0.6961727467450228\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6937255859375\n",
      "Validation loss decreased from 0.6961727467450228 to 0.6961693221872504\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6937252283096313\n",
      "Validation loss decreased from 0.6961693221872504 to 0.6961659409783103\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6937249302864075\n",
      "Validation loss decreased from 0.6961659409783103 to 0.6961625435135581\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6937245726585388\n",
      "Validation loss decreased from 0.6961625435135581 to 0.6961591623046182\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6937242746353149\n",
      "Validation loss decreased from 0.6961591623046182 to 0.6961558081886985\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6937239170074463\n",
      "Validation loss decreased from 0.6961558081886985 to 0.6961524540727789\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6937235593795776\n",
      "Validation loss decreased from 0.6961524540727789 to 0.6961490891196511\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.693723201751709\n",
      "Validation loss decreased from 0.6961490891196511 to 0.6961457891897722\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6937229037284851\n",
      "Validation loss decreased from 0.6961457891897722 to 0.6961424675854769\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6937224864959717\n",
      "Validation loss decreased from 0.6961424675854769 to 0.696139162236994\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6937222480773926\n",
      "Validation loss decreased from 0.696139162236994 to 0.6961358677257191\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6937218308448792\n",
      "Validation loss decreased from 0.6961358677257191 to 0.6961325732144442\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6937215328216553\n",
      "Validation loss decreased from 0.6961325732144442 to 0.6961293003775857\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6937211751937866\n",
      "Validation loss decreased from 0.6961293003775857 to 0.6961260492151434\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6937208771705627\n",
      "Validation loss decreased from 0.6961260492151434 to 0.6961227872154929\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6937205195426941\n",
      "Validation loss decreased from 0.6961227872154929 to 0.6961195414716547\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6937201023101807\n",
      "Validation loss decreased from 0.6961195414716547 to 0.6961163174022328\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6937198638916016\n",
      "Validation loss decreased from 0.6961163174022328 to 0.6961131258444353\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6937195658683777\n",
      "Validation loss decreased from 0.6961131258444353 to 0.6961099288680337\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6937191486358643\n",
      "Validation loss decreased from 0.6961099288680337 to 0.6961067373102362\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6937189102172852\n",
      "Validation loss decreased from 0.6961067373102362 to 0.6961035891012712\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6937184929847717\n",
      "Validation loss decreased from 0.6961035891012712 to 0.6961004137992859\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6937182545661926\n",
      "Validation loss decreased from 0.6961004137992859 to 0.6960972981019453\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6937178373336792\n",
      "Validation loss decreased from 0.6960972981019453 to 0.6960941878232089\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6937175393104553\n",
      "Validation loss decreased from 0.6960941878232089 to 0.6960910938002847\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6937172412872314\n",
      "Validation loss decreased from 0.6960910938002847 to 0.6960879889401522\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6937168836593628\n",
      "Validation loss decreased from 0.6960879889401522 to 0.696084894917228\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6937165856361389\n",
      "Validation loss decreased from 0.696084894917228 to 0.6960818225687201\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6937162280082703\n",
      "Validation loss decreased from 0.6960818225687201 to 0.696078744801608\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6937159299850464\n",
      "Validation loss decreased from 0.696078744801608 to 0.6960756941275164\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6937156319618225\n",
      "Validation loss decreased from 0.6960756941275164 to 0.6960726597092368\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6937152743339539\n",
      "Validation loss decreased from 0.6960726597092368 to 0.6960696361281655\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6937148571014404\n",
      "Validation loss decreased from 0.6960696361281655 to 0.6960666125470941\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6937146186828613\n",
      "Validation loss decreased from 0.6960666125470941 to 0.6960636160590432\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6937142014503479\n",
      "Validation loss decreased from 0.6960636160590432 to 0.69606060331518\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6937139630317688\n",
      "Validation loss decreased from 0.69606060331518 to 0.6960576230829413\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6937136054039001\n",
      "Validation loss decreased from 0.6960576230829413 to 0.6960546591065147\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.693713366985321\n",
      "Validation loss decreased from 0.6960546591065147 to 0.696051689711484\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6937130093574524\n",
      "Validation loss decreased from 0.696051689711484 to 0.6960487203164534\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.693712592124939\n",
      "Validation loss decreased from 0.6960487203164534 to 0.6960457725958391\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6937123537063599\n",
      "Validation loss decreased from 0.6960457725958391 to 0.6960428302938287\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6937119364738464\n",
      "Validation loss decreased from 0.6960428302938287 to 0.6960398879918185\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6937116980552673\n",
      "Validation loss decreased from 0.6960398879918185 to 0.6960369836200367\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6937112808227539\n",
      "Validation loss decreased from 0.6960369836200367 to 0.6960340684110468\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.69371098279953\n",
      "Validation loss decreased from 0.6960340684110468 to 0.6960311857136813\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6937106847763062\n",
      "Validation loss decreased from 0.6960311857136813 to 0.6960282867605035\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6937103271484375\n",
      "Validation loss decreased from 0.6960282867605035 to 0.696025398644534\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6937099695205688\n",
      "Validation loss decreased from 0.696025398644534 to 0.6960225376215848\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.693709671497345\n",
      "Validation loss decreased from 0.6960225376215848 to 0.6960196928544478\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6937093734741211\n",
      "Validation loss decreased from 0.6960196928544478 to 0.6960168535059149\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6937090158462524\n",
      "Validation loss decreased from 0.6960168535059149 to 0.6960140087387778\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6937087178230286\n",
      "Validation loss decreased from 0.6960140087387778 to 0.6960112019018694\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6937083005905151\n",
      "Validation loss decreased from 0.6960112019018694 to 0.6960083896463568\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.693708062171936\n",
      "Validation loss decreased from 0.6960083896463568 to 0.6960055828094482\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6937077045440674\n",
      "Validation loss decreased from 0.6960055828094482 to 0.6960028084841642\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6937074065208435\n",
      "Validation loss decreased from 0.6960028084841642 to 0.69600003415888\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6937070488929749\n",
      "Validation loss decreased from 0.69600003415888 to 0.695997259833596\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6937066912651062\n",
      "Validation loss decreased from 0.695997259833596 to 0.6959945126013323\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6937063932418823\n",
      "Validation loss decreased from 0.6959945126013323 to 0.6959917762062766\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6937060356140137\n",
      "Validation loss decreased from 0.6959917762062766 to 0.6959890452298251\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6937057971954346\n",
      "Validation loss decreased from 0.6959890452298251 to 0.6959863196719777\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6937053799629211\n",
      "Validation loss decreased from 0.6959863196719777 to 0.6959836103699424\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6937050223350525\n",
      "Validation loss decreased from 0.6959836103699424 to 0.6959808956493031\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6937047243118286\n",
      "Validation loss decreased from 0.6959808956493031 to 0.6959782026030801\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.69370436668396\n",
      "Validation loss decreased from 0.6959782026030801 to 0.6959755203940652\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6937040686607361\n",
      "Validation loss decreased from 0.6959755203940652 to 0.6959728490222584\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6937037110328674\n",
      "Validation loss decreased from 0.6959728490222584 to 0.695970210162076\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6937033534049988\n",
      "Validation loss decreased from 0.695970210162076 to 0.6959675387902693\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6937029957771301\n",
      "Validation loss decreased from 0.6959675387902693 to 0.6959649270231073\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6937026381492615\n",
      "Validation loss decreased from 0.6959649270231073 to 0.6959622935815291\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6937022805213928\n",
      "Validation loss decreased from 0.6959622935815291 to 0.6959596655585549\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6937020421028137\n",
      "Validation loss decreased from 0.6959596655585549 to 0.6959570700472052\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6937016248703003\n",
      "Validation loss decreased from 0.6959570700472052 to 0.6959544582800432\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6937013268470764\n",
      "Validation loss decreased from 0.6959544582800432 to 0.6959518410942771\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6937009692192078\n",
      "Validation loss decreased from 0.6959518410942771 to 0.6959492510015314\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6937006115913391\n",
      "Validation loss decreased from 0.6959492510015314 to 0.6959466609087858\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6937003135681152\n",
      "Validation loss decreased from 0.6959466609087858 to 0.6959440816532482\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6936999559402466\n",
      "Validation loss decreased from 0.6959440816532482 to 0.6959414969791066\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6936995983123779\n",
      "Validation loss decreased from 0.6959414969791066 to 0.695938912304965\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6936993598937988\n",
      "Validation loss decreased from 0.695938912304965 to 0.6959363493052396\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6936989426612854\n",
      "Validation loss decreased from 0.6959363493052396 to 0.6959337917241183\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6936986446380615\n",
      "Validation loss decreased from 0.6959337917241183 to 0.6959312449802052\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6936982870101929\n",
      "Validation loss decreased from 0.6959312449802052 to 0.6959287144921043\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6936978697776794\n",
      "Validation loss decreased from 0.6959287144921043 to 0.6959261948412115\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6936976313591003\n",
      "Validation loss decreased from 0.6959261948412115 to 0.6959236643531106\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6936972141265869\n",
      "Validation loss decreased from 0.6959236643531106 to 0.6959211392836138\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6936969757080078\n",
      "Validation loss decreased from 0.6959211392836138 to 0.6959186629815535\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6936965584754944\n",
      "Validation loss decreased from 0.6959186629815535 to 0.6959161379120566\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.693696141242981\n",
      "Validation loss decreased from 0.6959161379120566 to 0.695913623679768\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6936959028244019\n",
      "Validation loss decreased from 0.695913623679768 to 0.6959111419591036\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6936954855918884\n",
      "Validation loss decreased from 0.6959111419591036 to 0.6959086710756476\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6936951875686646\n",
      "Validation loss decreased from 0.6959086710756476 to 0.6959062110293995\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6936948299407959\n",
      "Validation loss decreased from 0.6959062110293995 to 0.6959037347273394\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.693694531917572\n",
      "Validation loss decreased from 0.6959037347273394 to 0.6959012800996954\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6936941146850586\n",
      "Validation loss decreased from 0.6959012800996954 to 0.6958988308906555\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6936938166618347\n",
      "Validation loss decreased from 0.6958988308906555 to 0.695896408774636\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6936934590339661\n",
      "Validation loss decreased from 0.695896408774636 to 0.6958939812400124\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.693693220615387\n",
      "Validation loss decreased from 0.6958939812400124 to 0.6958915537053888\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6936929225921631\n",
      "Validation loss decreased from 0.6958915537053888 to 0.6958891424265775\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6936925053596497\n",
      "Validation loss decreased from 0.6958891424265775 to 0.6958867419849742\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6936922669410706\n",
      "Validation loss decreased from 0.6958867419849742 to 0.6958843577991832\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6936918497085571\n",
      "Validation loss decreased from 0.6958843577991832 to 0.695881951938976\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.693691611289978\n",
      "Validation loss decreased from 0.695881951938976 to 0.6958796002648093\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6936912536621094\n",
      "Validation loss decreased from 0.6958796002648093 to 0.6958772269162264\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6936908960342407\n",
      "Validation loss decreased from 0.6958772269162264 to 0.6958748698234558\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6936905980110168\n",
      "Validation loss decreased from 0.6958748698234558 to 0.6958725289864973\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6936902403831482\n",
      "Validation loss decreased from 0.6958725289864973 to 0.6958701773123308\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6936900019645691\n",
      "Validation loss decreased from 0.6958701773123308 to 0.6958678364753723\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6936895847320557\n",
      "Validation loss decreased from 0.6958678364753723 to 0.6958655173128302\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6936893463134766\n",
      "Validation loss decreased from 0.6958655173128302 to 0.6958631818944757\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6936889290809631\n",
      "Validation loss decreased from 0.6958631818944757 to 0.6958608789877458\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6936886310577393\n",
      "Validation loss decreased from 0.6958608789877458 to 0.6958585760810159\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6936882734298706\n",
      "Validation loss decreased from 0.6958585760810159 to 0.69585627859289\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6936879754066467\n",
      "Validation loss decreased from 0.69585627859289 to 0.695853981104764\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6936876177787781\n",
      "Validation loss decreased from 0.695853981104764 to 0.6958517052910544\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6936873197555542\n",
      "Validation loss decreased from 0.6958517052910544 to 0.6958494186401367\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6936869025230408\n",
      "Validation loss decreased from 0.6958494186401367 to 0.695847137407823\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6936866641044617\n",
      "Validation loss decreased from 0.695847137407823 to 0.6958448670127175\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6936862468719482\n",
      "Validation loss decreased from 0.6958448670127175 to 0.6958426074548201\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6936859488487244\n",
      "Validation loss decreased from 0.6958426074548201 to 0.6958403316411105\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6936855912208557\n",
      "Validation loss decreased from 0.6958403316411105 to 0.6958380775018171\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6936852335929871\n",
      "Validation loss decreased from 0.6958380775018171 to 0.6958358287811279\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.693684995174408\n",
      "Validation loss decreased from 0.6958358287811279 to 0.6958335908976468\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6936845779418945\n",
      "Validation loss decreased from 0.6958335908976468 to 0.6958313421769575\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6936842203140259\n",
      "Validation loss decreased from 0.6958313421769575 to 0.6958291205492887\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.693683922290802\n",
      "Validation loss decreased from 0.6958291205492887 to 0.695826915177432\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6936835646629333\n",
      "Validation loss decreased from 0.695826915177432 to 0.695824688131159\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6936832070350647\n",
      "Validation loss decreased from 0.695824688131159 to 0.6958224665034901\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6936829090118408\n",
      "Validation loss decreased from 0.6958224665034901 to 0.6958202502944253\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6936825513839722\n",
      "Validation loss decreased from 0.6958202502944253 to 0.6958180449225686\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6936821341514587\n",
      "Validation loss decreased from 0.6958180449225686 to 0.69581585038792\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6936818361282349\n",
      "Validation loss decreased from 0.69581585038792 to 0.6958136721090837\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.693681538105011\n",
      "Validation loss decreased from 0.6958136721090837 to 0.6958114938302473\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6936811804771423\n",
      "Validation loss decreased from 0.6958114938302473 to 0.6958093263886191\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6936808824539185\n",
      "Validation loss decreased from 0.6958093263886191 to 0.6958071697841991\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.693680465221405\n",
      "Validation loss decreased from 0.6958071697841991 to 0.6958049860867587\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6936801075935364\n",
      "Validation loss decreased from 0.6958049860867587 to 0.6958028240637346\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6936798095703125\n",
      "Validation loss decreased from 0.6958028240637346 to 0.6958006837151267\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6936794519424438\n",
      "Validation loss decreased from 0.6958006837151267 to 0.6957985271107067\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.69367915391922\n",
      "Validation loss decreased from 0.6957985271107067 to 0.695796403017911\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6936787366867065\n",
      "Validation loss decreased from 0.695796403017911 to 0.6957942680879072\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6936784386634827\n",
      "Validation loss decreased from 0.6957942680879072 to 0.6957921277392994\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.693678081035614\n",
      "Validation loss decreased from 0.6957921277392994 to 0.6957900307395242\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6936777234077454\n",
      "Validation loss decreased from 0.6957900307395242 to 0.6957879391583529\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6936774253845215\n",
      "Validation loss decreased from 0.6957879391583529 to 0.6957858421585776\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6936770677566528\n",
      "Validation loss decreased from 0.6957858421585776 to 0.6957837668332186\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6936767101287842\n",
      "Validation loss decreased from 0.6957837668332186 to 0.6957816915078596\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6936764121055603\n",
      "Validation loss decreased from 0.6957816915078596 to 0.6957796324383129\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6936759948730469\n",
      "Validation loss decreased from 0.6957796324383129 to 0.6957775516943498\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6936757564544678\n",
      "Validation loss decreased from 0.6957775516943498 to 0.695775492624803\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6936753392219543\n",
      "Validation loss decreased from 0.695775492624803 to 0.6957734281366522\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6936749815940857\n",
      "Validation loss decreased from 0.6957734281366522 to 0.6957713799043135\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.693674623966217\n",
      "Validation loss decreased from 0.6957713799043135 to 0.6957693316719749\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6936742663383484\n",
      "Validation loss decreased from 0.6957693316719749 to 0.6957672888582404\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6936739087104797\n",
      "Validation loss decreased from 0.6957672888582404 to 0.695765262300318\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6936736106872559\n",
      "Validation loss decreased from 0.695765262300318 to 0.6957632411609996\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6936732530593872\n",
      "Validation loss decreased from 0.6957632411609996 to 0.6957612416960977\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6936728358268738\n",
      "Validation loss decreased from 0.6957612416960977 to 0.6957592097195712\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6936725378036499\n",
      "Validation loss decreased from 0.6957592097195712 to 0.6957572265104814\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6936721801757812\n",
      "Validation loss decreased from 0.6957572265104814 to 0.6957552216269753\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6936717629432678\n",
      "Validation loss decreased from 0.6957552216269753 to 0.6957532384178855\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.693671464920044\n",
      "Validation loss decreased from 0.6957532384178855 to 0.6957512606273998\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6936711072921753\n",
      "Validation loss decreased from 0.6957512606273998 to 0.6957492665811018\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6936708092689514\n",
      "Validation loss decreased from 0.6957492665811018 to 0.6957472887906161\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6936704516410828\n",
      "Validation loss decreased from 0.6957472887906161 to 0.6957453435117548\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6936700344085693\n",
      "Validation loss decreased from 0.6957453435117548 to 0.695743365721269\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6936696171760559\n",
      "Validation loss decreased from 0.695743365721269 to 0.6957413987679915\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6936693787574768\n",
      "Validation loss decreased from 0.6957413987679915 to 0.6957394534891302\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6936690211296082\n",
      "Validation loss decreased from 0.6957394534891302 to 0.6957375353032892\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6936687231063843\n",
      "Validation loss decreased from 0.6957375353032892 to 0.6957356062802401\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6936683058738708\n",
      "Validation loss decreased from 0.6957356062802401 to 0.6957336935130033\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6936678886413574\n",
      "Validation loss decreased from 0.6957336935130033 to 0.6957318024201826\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6936675906181335\n",
      "Validation loss decreased from 0.6957318024201826 to 0.6957298896529458\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6936672925949097\n",
      "Validation loss decreased from 0.6957298896529458 to 0.6957279985601251\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6936668753623962\n",
      "Validation loss decreased from 0.6957279985601251 to 0.6957261020487006\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6936665773391724\n",
      "Validation loss decreased from 0.6957261020487006 to 0.6957241947000677\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6936661601066589\n",
      "Validation loss decreased from 0.6957241947000677 to 0.6957223036072471\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6936658024787903\n",
      "Validation loss decreased from 0.6957223036072471 to 0.6957204450260509\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6936655044555664\n",
      "Validation loss decreased from 0.6957204450260509 to 0.6957185647704385\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6936651468276978\n",
      "Validation loss decreased from 0.6957185647704385 to 0.6957167007706382\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6936647295951843\n",
      "Validation loss decreased from 0.6957167007706382 to 0.6957148313522339\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6936644315719604\n",
      "Validation loss decreased from 0.6957148313522339 to 0.6957129673524336\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.693664014339447\n",
      "Validation loss decreased from 0.6957129673524336 to 0.6957111250270497\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6936636567115784\n",
      "Validation loss decreased from 0.6957111250270497 to 0.6957092664458535\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6936634182929993\n",
      "Validation loss decreased from 0.6957092664458535 to 0.6957074349576776\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6936629414558411\n",
      "Validation loss decreased from 0.6957074349576776 to 0.6957055872136896\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.693662703037262\n",
      "Validation loss decreased from 0.6957055872136896 to 0.6957037557255138\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6936622858047485\n",
      "Validation loss decreased from 0.6957037557255138 to 0.6957019350745461\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6936618685722351\n",
      "Validation loss decreased from 0.6957019350745461 to 0.6957001306793906\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6936615705490112\n",
      "Validation loss decreased from 0.6957001306793906 to 0.6956982991912148\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6936611533164978\n",
      "Validation loss decreased from 0.6956982991912148 to 0.6956965110518716\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6936607956886292\n",
      "Validation loss decreased from 0.6956965110518716 to 0.6956947120753202\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6936603784561157\n",
      "Validation loss decreased from 0.6956947120753202 to 0.6956929185173728\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6936600804328918\n",
      "Validation loss decreased from 0.6956929185173728 to 0.6956911412152377\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6936597228050232\n",
      "Validation loss decreased from 0.6956911412152377 to 0.6956893639131025\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6936593651771545\n",
      "Validation loss decreased from 0.6956893639131025 to 0.6956875974481757\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6936590075492859\n",
      "Validation loss decreased from 0.6956875974481757 to 0.6956858201460405\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6936586499214172\n",
      "Validation loss decreased from 0.6956858201460405 to 0.6956840753555298\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6936582922935486\n",
      "Validation loss decreased from 0.6956840753555298 to 0.695682325146415\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6936579346656799\n",
      "Validation loss decreased from 0.695682325146415 to 0.6956805803559043\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6936575174331665\n",
      "Validation loss decreased from 0.6956805803559043 to 0.6956788464026018\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6936572194099426\n",
      "Validation loss decreased from 0.6956788464026018 to 0.6956771124492992\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6936568021774292\n",
      "Validation loss decreased from 0.6956771124492992 to 0.6956753676587885\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6936565041542053\n",
      "Validation loss decreased from 0.6956753676587885 to 0.6956736607985063\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6936561465263367\n",
      "Validation loss decreased from 0.6956736607985063 to 0.6956719322638079\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6936557292938232\n",
      "Validation loss decreased from 0.6956719322638079 to 0.6956702145663175\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6936553716659546\n",
      "Validation loss decreased from 0.6956702145663175 to 0.6956685077060353\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6936550736427307\n",
      "Validation loss decreased from 0.6956685077060353 to 0.695666795427149\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6936546564102173\n",
      "Validation loss decreased from 0.695666795427149 to 0.6956650831482627\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6936542987823486\n",
      "Validation loss decreased from 0.6956650831482627 to 0.6956633925437927\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6936540007591248\n",
      "Validation loss decreased from 0.6956633925437927 to 0.6956616856835105\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6936536431312561\n",
      "Validation loss decreased from 0.6956616856835105 to 0.6956600004976446\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6936532855033875\n",
      "Validation loss decreased from 0.6956600004976446 to 0.6956583261489868\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6936529874801636\n",
      "Validation loss decreased from 0.6956583261489868 to 0.6956566355445168\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6936525106430054\n",
      "Validation loss decreased from 0.6956566355445168 to 0.6956549503586509\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6936521530151367\n",
      "Validation loss decreased from 0.6956549503586509 to 0.695653270591389\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6936518549919128\n",
      "Validation loss decreased from 0.695653270591389 to 0.6956516341729597\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6936514377593994\n",
      "Validation loss decreased from 0.6956516341729597 to 0.6956499706615101\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6936510801315308\n",
      "Validation loss decreased from 0.6956499706615101 to 0.6956483342430808\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6936507821083069\n",
      "Validation loss decreased from 0.6956483342430808 to 0.6956467086618597\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6936504244804382\n",
      "Validation loss decreased from 0.6956467086618597 to 0.6956450776620344\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6936501264572144\n",
      "Validation loss decreased from 0.6956450776620344 to 0.6956434683366255\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6936497092247009\n",
      "Validation loss decreased from 0.6956434683366255 to 0.6956418481740084\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6936492919921875\n",
      "Validation loss decreased from 0.6956418481740084 to 0.6956402334299955\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6936490535736084\n",
      "Validation loss decreased from 0.6956402334299955 to 0.6956386403603987\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.693648636341095\n",
      "Validation loss decreased from 0.6956386403603987 to 0.6956370256163857\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6936482787132263\n",
      "Validation loss decreased from 0.6956370256163857 to 0.6956354488026012\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6936479210853577\n",
      "Validation loss decreased from 0.6956354488026012 to 0.6956338394771923\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.693647563457489\n",
      "Validation loss decreased from 0.6956338394771923 to 0.6956322518261996\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6936472058296204\n",
      "Validation loss decreased from 0.6956322518261996 to 0.6956306966868314\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6936469078063965\n",
      "Validation loss decreased from 0.6956306966868314 to 0.6956291415474631\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6936464905738831\n",
      "Validation loss decreased from 0.6956291415474631 to 0.6956275755708868\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6936461329460144\n",
      "Validation loss decreased from 0.6956275755708868 to 0.6956260204315186\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6936458349227905\n",
      "Validation loss decreased from 0.6956260204315186 to 0.6956244707107544\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6936454176902771\n",
      "Validation loss decreased from 0.6956244707107544 to 0.6956229101527821\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6936451196670532\n",
      "Validation loss decreased from 0.6956229101527821 to 0.6956213875250383\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6936447620391846\n",
      "Validation loss decreased from 0.6956213875250383 to 0.6956198432228782\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6936444044113159\n",
      "Validation loss decreased from 0.6956198432228782 to 0.6956183151765303\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.693644106388092\n",
      "Validation loss decreased from 0.6956183151765303 to 0.6956167817115784\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6936436891555786\n",
      "Validation loss decreased from 0.6956167817115784 to 0.6956152482466265\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6936432719230652\n",
      "Validation loss decreased from 0.6956152482466265 to 0.695613747293299\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6936430335044861\n",
      "Validation loss decreased from 0.695613747293299 to 0.6956122246655551\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6936426162719727\n",
      "Validation loss decreased from 0.6956122246655551 to 0.6956107020378113\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6936421990394592\n",
      "Validation loss decreased from 0.6956107020378113 to 0.6956091794100675\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6936417818069458\n",
      "Validation loss decreased from 0.6956091794100675 to 0.6956076622009277\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6936415433883667\n",
      "Validation loss decreased from 0.6956076622009277 to 0.695606144991788\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6936410665512085\n",
      "Validation loss decreased from 0.695606144991788 to 0.6956046332012523\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6936407089233398\n",
      "Validation loss decreased from 0.6956046332012523 to 0.6956031159921126\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.693640410900116\n",
      "Validation loss decreased from 0.6956031159921126 to 0.6956016258759932\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6936399936676025\n",
      "Validation loss decreased from 0.6956016258759932 to 0.6956001195040616\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6936396360397339\n",
      "Validation loss decreased from 0.6956001195040616 to 0.6955986510623585\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6936392188072205\n",
      "Validation loss decreased from 0.6955986510623585 to 0.6955971392718229\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6936388611793518\n",
      "Validation loss decreased from 0.6955971392718229 to 0.6955956762487238\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6936384439468384\n",
      "Validation loss decreased from 0.6955956762487238 to 0.6955941861326044\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.693638026714325\n",
      "Validation loss decreased from 0.6955941861326044 to 0.6955927339467135\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6936376690864563\n",
      "Validation loss decreased from 0.6955927339467135 to 0.6955912492491982\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6936373114585876\n",
      "Validation loss decreased from 0.6955912492491982 to 0.6955898404121399\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.693636953830719\n",
      "Validation loss decreased from 0.6955898404121399 to 0.6955883719704368\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6936365962028503\n",
      "Validation loss decreased from 0.6955883719704368 to 0.69558692520315\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6936361789703369\n",
      "Validation loss decreased from 0.69558692520315 to 0.6955854892730713\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6936357617378235\n",
      "Validation loss decreased from 0.6955854892730713 to 0.6955840695988048\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6936354041099548\n",
      "Validation loss decreased from 0.6955840695988048 to 0.6955826174129139\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6936349868774414\n",
      "Validation loss decreased from 0.6955826174129139 to 0.6955811923200433\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.693634569644928\n",
      "Validation loss decreased from 0.6955811923200433 to 0.6955797618085687\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6936341524124146\n",
      "Validation loss decreased from 0.6955797618085687 to 0.6955783529715105\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6936338543891907\n",
      "Validation loss decreased from 0.6955783529715105 to 0.6955769116228278\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6936333775520325\n",
      "Validation loss decreased from 0.6955769116228278 to 0.6955754973671653\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6936330199241638\n",
      "Validation loss decreased from 0.6955754973671653 to 0.6955740560184825\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6936326622962952\n",
      "Validation loss decreased from 0.6955740560184825 to 0.6955726580186323\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6936322450637817\n",
      "Validation loss decreased from 0.6955726580186323 to 0.6955712329257618\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6936318874359131\n",
      "Validation loss decreased from 0.6955712329257618 to 0.6955698566003279\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6936314702033997\n",
      "Validation loss decreased from 0.6955698566003279 to 0.6955684531818737\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.693631112575531\n",
      "Validation loss decreased from 0.6955684531818737 to 0.6955670389262113\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6936306357383728\n",
      "Validation loss decreased from 0.6955670389262113 to 0.695565635507757\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6936302185058594\n",
      "Validation loss decreased from 0.695565635507757 to 0.695564248345115\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.693629801273346\n",
      "Validation loss decreased from 0.695564248345115 to 0.6955628557638689\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6936294436454773\n",
      "Validation loss decreased from 0.6955628557638689 to 0.6955614902756431\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6936289668083191\n",
      "Validation loss decreased from 0.6955614902756431 to 0.6955600814385847\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6936285495758057\n",
      "Validation loss decreased from 0.6955600814385847 to 0.6955586888573386\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.693628191947937\n",
      "Validation loss decreased from 0.6955586888573386 to 0.6955572908574884\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6936277747154236\n",
      "Validation loss decreased from 0.6955572908574884 to 0.6955559253692627\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6936273574829102\n",
      "Validation loss decreased from 0.6955559253692627 to 0.6955545273694125\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6936269402503967\n",
      "Validation loss decreased from 0.6955545273694125 to 0.6955531564625826\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6936264634132385\n",
      "Validation loss decreased from 0.6955531564625826 to 0.6955517638813365\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6936260461807251\n",
      "Validation loss decreased from 0.6955517638813365 to 0.6955503929745067\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6936256885528564\n",
      "Validation loss decreased from 0.6955503929745067 to 0.695549027486281\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6936252117156982\n",
      "Validation loss decreased from 0.695549027486281 to 0.6955476403236389\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6936247944831848\n",
      "Validation loss decreased from 0.6955476403236389 to 0.6955463019284335\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6936243772506714\n",
      "Validation loss decreased from 0.6955463019284335 to 0.6955449256029996\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6936240196228027\n",
      "Validation loss decreased from 0.6955449256029996 to 0.6955435655333779\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6936236023902893\n",
      "Validation loss decreased from 0.6955435655333779 to 0.6955422163009644\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6936231851577759\n",
      "Validation loss decreased from 0.6955422163009644 to 0.6955408508127386\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6936227083206177\n",
      "Validation loss decreased from 0.6955408508127386 to 0.6955395178361372\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.693622350692749\n",
      "Validation loss decreased from 0.6955395178361372 to 0.6955381523479115\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6936218738555908\n",
      "Validation loss decreased from 0.6955381523479115 to 0.6955368302085183\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6936214566230774\n",
      "Validation loss decreased from 0.6955368302085183 to 0.6955354918133129\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.693621039390564\n",
      "Validation loss decreased from 0.6955354918133129 to 0.6955341642553156\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6936206817626953\n",
      "Validation loss decreased from 0.6955341642553156 to 0.6955328529531305\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6936202645301819\n",
      "Validation loss decreased from 0.6955328529531305 to 0.6955315416509454\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6936197876930237\n",
      "Validation loss decreased from 0.6955315416509454 to 0.6955302411859686\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.693619430065155\n",
      "Validation loss decreased from 0.6955302411859686 to 0.6955289298837836\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6936189532279968\n",
      "Validation loss decreased from 0.6955289298837836 to 0.6955276402560148\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6936185956001282\n",
      "Validation loss decreased from 0.6955276402560148 to 0.6955263343724337\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.69361811876297\n",
      "Validation loss decreased from 0.6955263343724337 to 0.6955250664190813\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6936177015304565\n",
      "Validation loss decreased from 0.6955250664190813 to 0.6955237713727084\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6936172842979431\n",
      "Validation loss decreased from 0.6955237713727084 to 0.6955224980007518\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6936169266700745\n",
      "Validation loss decreased from 0.6955224980007518 to 0.6955212246287953\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.693616509437561\n",
      "Validation loss decreased from 0.6955212246287953 to 0.6955199675126509\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6936160326004028\n",
      "Validation loss decreased from 0.6955199675126509 to 0.6955186941406943\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6936156153678894\n",
      "Validation loss decreased from 0.6955186941406943 to 0.6955174261873419\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6936151385307312\n",
      "Validation loss decreased from 0.6955174261873419 to 0.6955161799084056\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6936147809028625\n",
      "Validation loss decreased from 0.6955161799084056 to 0.6955149119550531\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6936143636703491\n",
      "Validation loss decreased from 0.6955149119550531 to 0.6955136710947211\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6936139464378357\n",
      "Validation loss decreased from 0.6955136710947211 to 0.6955124193971808\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.693613588809967\n",
      "Validation loss decreased from 0.6955124193971808 to 0.6955111731182445\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6936131119728088\n",
      "Validation loss decreased from 0.6955111731182445 to 0.6955099430951205\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6936127543449402\n",
      "Validation loss decreased from 0.6955099430951205 to 0.6955087076533925\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.693612277507782\n",
      "Validation loss decreased from 0.6955087076533925 to 0.6955074776302684\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6936118006706238\n",
      "Validation loss decreased from 0.6955074776302684 to 0.6955062421885404\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6936114430427551\n",
      "Validation loss decreased from 0.6955062421885404 to 0.6955050338398326\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6936110258102417\n",
      "Validation loss decreased from 0.6955050338398326 to 0.6955038200725209\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6936106085777283\n",
      "Validation loss decreased from 0.6955038200725209 to 0.6955026117238131\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6936101913452148\n",
      "Validation loss decreased from 0.6955026117238131 to 0.6955014087937095\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6936097741127014\n",
      "Validation loss decreased from 0.6955014087937095 to 0.6955002058636058\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6936092972755432\n",
      "Validation loss decreased from 0.6955002058636058 to 0.6954989975148981\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6936088800430298\n",
      "Validation loss decreased from 0.6954989975148981 to 0.6954978000033986\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6936084628105164\n",
      "Validation loss decreased from 0.6954978000033986 to 0.6954966350035234\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6936079859733582\n",
      "Validation loss decreased from 0.6954966350035234 to 0.6954954158176075\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6936076283454895\n",
      "Validation loss decreased from 0.6954954158176075 to 0.695494223724712\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6936072111129761\n",
      "Validation loss decreased from 0.695494223724712 to 0.6954930316318165\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6936067342758179\n",
      "Validation loss decreased from 0.6954930316318165 to 0.695491839538921\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6936063170433044\n",
      "Validation loss decreased from 0.695491839538921 to 0.6954906582832336\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6936059594154358\n",
      "Validation loss decreased from 0.6954906582832336 to 0.695489460771734\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6936055421829224\n",
      "Validation loss decreased from 0.695489460771734 to 0.6954882740974426\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6936051249504089\n",
      "Validation loss decreased from 0.6954882740974426 to 0.6954871145161715\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6936046481132507\n",
      "Validation loss decreased from 0.6954871145161715 to 0.6954859386790883\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6936042308807373\n",
      "Validation loss decreased from 0.6954859386790883 to 0.695484762842005\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6936038732528687\n",
      "Validation loss decreased from 0.695484762842005 to 0.6954835707491095\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6936033964157104\n",
      "Validation loss decreased from 0.6954835707491095 to 0.6954824220050465\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.693602979183197\n",
      "Validation loss decreased from 0.6954824220050465 to 0.6954812407493591\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6936025023460388\n",
      "Validation loss decreased from 0.6954812407493591 to 0.6954800865866921\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6936022043228149\n",
      "Validation loss decreased from 0.6954800865866921 to 0.6954789161682129\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6936017274856567\n",
      "Validation loss decreased from 0.6954789161682129 to 0.6954777565869418\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6936012506484985\n",
      "Validation loss decreased from 0.6954777565869418 to 0.6954766349358992\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6936008334159851\n",
      "Validation loss decreased from 0.6954766349358992 to 0.6954754753546282\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6936004161834717\n",
      "Validation loss decreased from 0.6954754753546282 to 0.6954743211919611\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6935998797416687\n",
      "Validation loss decreased from 0.6954743211919611 to 0.6954731670292941\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6935995221138\n",
      "Validation loss decreased from 0.6954731670292941 to 0.6954720345410433\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6935991048812866\n",
      "Validation loss decreased from 0.6954720345410433 to 0.6954709128900007\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6935986876487732\n",
      "Validation loss decreased from 0.6954709128900007 to 0.6954697533087297\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6935983300209045\n",
      "Validation loss decreased from 0.6954697533087297 to 0.6954686370762911\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6935978531837463\n",
      "Validation loss decreased from 0.6954686370762911 to 0.6954674991694364\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6935974359512329\n",
      "Validation loss decreased from 0.6954674991694364 to 0.6954663937742059\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6935969591140747\n",
      "Validation loss decreased from 0.6954663937742059 to 0.6954652667045593\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6935965418815613\n",
      "Validation loss decreased from 0.6954652667045593 to 0.6954641450535167\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6935961842536926\n",
      "Validation loss decreased from 0.6954641450535167 to 0.6954630396582864\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6935956478118896\n",
      "Validation loss decreased from 0.6954630396582864 to 0.69546193968166\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6935952305793762\n",
      "Validation loss decreased from 0.69546193968166 to 0.6954608180306174\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6935948133468628\n",
      "Validation loss decreased from 0.6954608180306174 to 0.6954597234725952\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6935943365097046\n",
      "Validation loss decreased from 0.6954597234725952 to 0.6954586397517811\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6935938596725464\n",
      "Validation loss decreased from 0.6954586397517811 to 0.6954575181007385\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6935935020446777\n",
      "Validation loss decreased from 0.6954575181007385 to 0.6954564235427163\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6935930252075195\n",
      "Validation loss decreased from 0.6954564235427163 to 0.6954553506591103\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6935925483703613\n",
      "Validation loss decreased from 0.6954553506591103 to 0.6954542669382963\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6935921311378479\n",
      "Validation loss decreased from 0.6954542669382963 to 0.6954531832174822\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6935917139053345\n",
      "Validation loss decreased from 0.6954531832174822 to 0.6954521103338762\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.693591296672821\n",
      "Validation loss decreased from 0.6954521103338762 to 0.6954510320316661\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6935908198356628\n",
      "Validation loss decreased from 0.6954510320316661 to 0.6954499754038724\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6935904026031494\n",
      "Validation loss decreased from 0.6954499754038724 to 0.6954489079388705\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6935898661613464\n",
      "Validation loss decreased from 0.6954489079388705 to 0.6954478296366605\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.693589448928833\n",
      "Validation loss decreased from 0.6954478296366605 to 0.6954467621716586\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.69358891248703\n",
      "Validation loss decreased from 0.6954467621716586 to 0.6954457001252607\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6935885548591614\n",
      "Validation loss decreased from 0.6954457001252607 to 0.6954446760090914\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6935880780220032\n",
      "Validation loss decreased from 0.6954446760090914 to 0.6954436139626936\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.693587601184845\n",
      "Validation loss decreased from 0.6954436139626936 to 0.695442568172108\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6935871839523315\n",
      "Validation loss decreased from 0.695442568172108 to 0.6954415332187306\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6935866475105286\n",
      "Validation loss decreased from 0.6954415332187306 to 0.6954404820095409\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6935862302780151\n",
      "Validation loss decreased from 0.6954404820095409 to 0.6954394687305797\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6935858130455017\n",
      "Validation loss decreased from 0.6954394687305797 to 0.6954384283585981\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6935853362083435\n",
      "Validation loss decreased from 0.6954384283585981 to 0.6954373879866167\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6935848593711853\n",
      "Validation loss decreased from 0.6954373879866167 to 0.6954363747076555\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6935843825340271\n",
      "Validation loss decreased from 0.6954363747076555 to 0.695435339754278\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6935839653015137\n",
      "Validation loss decreased from 0.695435339754278 to 0.6954343156381086\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6935834884643555\n",
      "Validation loss decreased from 0.6954343156381086 to 0.6954332969405435\n",
      "no early stopping\n",
      "AUC on test data  0.5104972723269253\n",
      "model 35 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6936028599739075\n",
      "Validation loss decreased from inf to 0.7037971344861117\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6935916543006897\n",
      "Validation loss decreased from 0.7037971344861117 to 0.7037678523497148\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6935800909996033\n",
      "Validation loss decreased from 0.7037678523497148 to 0.703737735748291\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6935685873031616\n",
      "Validation loss decreased from 0.703737735748291 to 0.7037076516584917\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6935572028160095\n",
      "Validation loss decreased from 0.7037076516584917 to 0.7036776921965859\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6935458183288574\n",
      "Validation loss decreased from 0.7036776921965859 to 0.7036478573625738\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6935344934463501\n",
      "Validation loss decreased from 0.7036478573625738 to 0.7036181471564553\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6935233473777771\n",
      "Validation loss decreased from 0.7036181471564553 to 0.7035885940898549\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6935122609138489\n",
      "Validation loss decreased from 0.7035885940898549 to 0.703559160232544\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6935011744499207\n",
      "Validation loss decreased from 0.703559160232544 to 0.7035298347473145\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6934901475906372\n",
      "Validation loss decreased from 0.7035298347473145 to 0.7035006826574152\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6934792995452881\n",
      "Validation loss decreased from 0.7035006826574152 to 0.7034716768698259\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6934685111045837\n",
      "Validation loss decreased from 0.7034716768698259 to 0.7034428444775668\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6934579014778137\n",
      "Validation loss decreased from 0.7034428444775668 to 0.7034141312945973\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6934471726417542\n",
      "Validation loss decreased from 0.7034141312945973 to 0.7033855806697499\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6934367418289185\n",
      "Validation loss decreased from 0.7033855806697499 to 0.7033571438355879\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.693426251411438\n",
      "Validation loss decreased from 0.7033571438355879 to 0.7033288858153603\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6934158802032471\n",
      "Validation loss decreased from 0.7033288858153603 to 0.7033007849346508\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6934055089950562\n",
      "Validation loss decreased from 0.7033007849346508 to 0.7032728249376471\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6933952569961548\n",
      "Validation loss decreased from 0.7032728249376471 to 0.7032449678941206\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6933849453926086\n",
      "Validation loss decreased from 0.7032449678941206 to 0.7032172354784879\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.693374752998352\n",
      "Validation loss decreased from 0.7032172354784879 to 0.7031896602023732\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6933647394180298\n",
      "Validation loss decreased from 0.7031896602023732 to 0.703162128275091\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6933546662330627\n",
      "Validation loss decreased from 0.703162128275091 to 0.7031347372315147\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6933447122573853\n",
      "Validation loss decreased from 0.7031347372315147 to 0.7031074545600198\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6933348774909973\n",
      "Validation loss decreased from 0.7031074545600198 to 0.7030802802606062\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6933250427246094\n",
      "Validation loss decreased from 0.7030802802606062 to 0.7030532305890863\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.693315327167511\n",
      "Validation loss decreased from 0.7030532305890863 to 0.7030262730338357\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6933055520057678\n",
      "Validation loss decreased from 0.7030262730338357 to 0.7029994671994989\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6932960152626038\n",
      "Validation loss decreased from 0.7029994671994989 to 0.7029727859930559\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6932864189147949\n",
      "Validation loss decreased from 0.7029727859930559 to 0.7029462131586942\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6932769417762756\n",
      "Validation loss decreased from 0.7029462131586942 to 0.7029197324406017\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6932674646377563\n",
      "Validation loss decreased from 0.7029197324406017 to 0.702893381769007\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6932580471038818\n",
      "Validation loss decreased from 0.702893381769007 to 0.702867101539265\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6932486891746521\n",
      "Validation loss decreased from 0.702867101539265 to 0.7028409296816046\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6932394504547119\n",
      "Validation loss decreased from 0.7028409296816046 to 0.7028148770332336\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6932300925254822\n",
      "Validation loss decreased from 0.7028148770332336 to 0.7027888568964872\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.693220853805542\n",
      "Validation loss decreased from 0.7027888568964872 to 0.702762939713218\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6932116746902466\n",
      "Validation loss decreased from 0.702762939713218 to 0.702737190506675\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6932024359703064\n",
      "Validation loss decreased from 0.702737190506675 to 0.7027114900675687\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6931934356689453\n",
      "Validation loss decreased from 0.7027114900675687 to 0.7026859250935641\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6931843161582947\n",
      "Validation loss decreased from 0.7026859250935641 to 0.7026604305614125\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6931752562522888\n",
      "Validation loss decreased from 0.7026604305614125 to 0.7026350552385504\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6931663155555725\n",
      "Validation loss decreased from 0.7026350552385504 to 0.7026097774505615\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6931573748588562\n",
      "Validation loss decreased from 0.7026097774505615 to 0.7025845863602378\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6931484937667847\n",
      "Validation loss decreased from 0.7025845863602378 to 0.7025594928047874\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6931396126747131\n",
      "Validation loss decreased from 0.7025594928047874 to 0.7025345238772306\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6931309103965759\n",
      "Validation loss decreased from 0.7025345238772306 to 0.7025096633217551\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6931222081184387\n",
      "Validation loss decreased from 0.7025096633217551 to 0.7024849165569652\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6931135058403015\n",
      "Validation loss decreased from 0.7024849165569652 to 0.7024603052572771\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6931049227714539\n",
      "Validation loss decreased from 0.7024603052572771 to 0.7024358240040866\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6930963397026062\n",
      "Validation loss decreased from 0.7024358240040866 to 0.7024114240299572\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6930878162384033\n",
      "Validation loss decreased from 0.7024114240299572 to 0.7023871161720969\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6930792927742004\n",
      "Validation loss decreased from 0.7023871161720969 to 0.7023628679188815\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6930708885192871\n",
      "Validation loss decreased from 0.7023628679188815 to 0.7023387226191434\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.693062424659729\n",
      "Validation loss decreased from 0.7023387226191434 to 0.7023146965286948\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6930540800094604\n",
      "Validation loss decreased from 0.7023146965286948 to 0.7022907571359114\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6930457949638367\n",
      "Validation loss decreased from 0.7022907571359114 to 0.7022669098593972\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6930376291275024\n",
      "Validation loss decreased from 0.7022669098593972 to 0.7022431546991522\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6930294632911682\n",
      "Validation loss decreased from 0.7022431546991522 to 0.7022194808179681\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.693021297454834\n",
      "Validation loss decreased from 0.7022194808179681 to 0.7021958827972412\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6930132508277893\n",
      "Validation loss decreased from 0.7021958827972412 to 0.7021723768927834\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6930051445960999\n",
      "Validation loss decreased from 0.7021723768927834 to 0.7021489360115745\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6929969787597656\n",
      "Validation loss decreased from 0.7021489360115745 to 0.7021255926652388\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6929886937141418\n",
      "Validation loss decreased from 0.7021255926652388 to 0.7021023468537764\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6929804086685181\n",
      "Validation loss decreased from 0.7021023468537764 to 0.7020791172981262\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6929721832275391\n",
      "Validation loss decreased from 0.7020791172981262 to 0.7020560340447859\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6929641366004944\n",
      "Validation loss decreased from 0.7020560340447859 to 0.702032977884466\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6929559707641602\n",
      "Validation loss decreased from 0.702032977884466 to 0.7020100192590193\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6929478645324707\n",
      "Validation loss decreased from 0.7020100192590193 to 0.701987169005654\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6929398775100708\n",
      "Validation loss decreased from 0.701987169005654 to 0.701964405449954\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6929318904876709\n",
      "Validation loss decreased from 0.701964405449954 to 0.7019417123361067\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6929238438606262\n",
      "Validation loss decreased from 0.7019417123361067 to 0.7019191221757368\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6929159164428711\n",
      "Validation loss decreased from 0.7019191221757368 to 0.7018966024572199\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6929080486297607\n",
      "Validation loss decreased from 0.7018966024572199 to 0.7018741315061395\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6929001212120056\n",
      "Validation loss decreased from 0.7018741315061395 to 0.7018517797643488\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.69289231300354\n",
      "Validation loss decreased from 0.7018517797643488 to 0.7018295093016191\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6928845047950745\n",
      "Validation loss decreased from 0.7018295093016191 to 0.7018073688853871\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6928768157958984\n",
      "Validation loss decreased from 0.7018073688853871 to 0.7017853260040283\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6928690671920776\n",
      "Validation loss decreased from 0.7017853260040283 to 0.7017633860761469\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6928614377975464\n",
      "Validation loss decreased from 0.7017633860761469 to 0.7017415545203469\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6928538084030151\n",
      "Validation loss decreased from 0.7017415545203469 to 0.7017197554761713\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6928463578224182\n",
      "Validation loss decreased from 0.7017197554761713 to 0.7016980485482649\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6928388476371765\n",
      "Validation loss decreased from 0.7016980485482649 to 0.7016764120622114\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.69283127784729\n",
      "Validation loss decreased from 0.7016764120622114 to 0.7016548026691783\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6928238272666931\n",
      "Validation loss decreased from 0.7016548026691783 to 0.70163325288079\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6928164958953857\n",
      "Validation loss decreased from 0.70163325288079 to 0.7016118168830872\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6928091049194336\n",
      "Validation loss decreased from 0.7016118168830872 to 0.7015904133970087\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.692801833152771\n",
      "Validation loss decreased from 0.7015904133970087 to 0.7015691020271995\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6927946209907532\n",
      "Validation loss decreased from 0.7015691020271995 to 0.7015478936108676\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6927873492240906\n",
      "Validation loss decreased from 0.7015478936108676 to 0.7015267664735968\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6927801966667175\n",
      "Validation loss decreased from 0.7015267664735968 to 0.7015057043595747\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6927731037139893\n",
      "Validation loss decreased from 0.7015057043595747 to 0.7014847181060098\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.692766010761261\n",
      "Validation loss decreased from 0.7014847181060098 to 0.701463829387318\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6927589178085327\n",
      "Validation loss decreased from 0.701463829387318 to 0.701443000273271\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6927518844604492\n",
      "Validation loss decreased from 0.701443000273271 to 0.7014222957871177\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6927450299263\n",
      "Validation loss decreased from 0.7014222957871177 to 0.7014016996730458\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6927381157875061\n",
      "Validation loss decreased from 0.7014016996730458 to 0.701381195675243\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6927312016487122\n",
      "Validation loss decreased from 0.701381195675243 to 0.7013607837937095\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6927244067192078\n",
      "Validation loss decreased from 0.7013607837937095 to 0.7013404369354248\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6927176117897034\n",
      "Validation loss decreased from 0.7013404369354248 to 0.7013201551003889\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6927108764648438\n",
      "Validation loss decreased from 0.7013201551003889 to 0.7013000087304548\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6927043199539185\n",
      "Validation loss decreased from 0.7013000087304548 to 0.701279878616333\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6926977634429932\n",
      "Validation loss decreased from 0.701279878616333 to 0.7012598514556885\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6926910877227783\n",
      "Validation loss decreased from 0.7012598514556885 to 0.7012399489229376\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6926845908164978\n",
      "Validation loss decreased from 0.7012399489229376 to 0.7012201168320396\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6926780939102173\n",
      "Validation loss decreased from 0.7012201168320396 to 0.701200398531827\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6926716566085815\n",
      "Validation loss decreased from 0.701200398531827 to 0.7011807723478838\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6926652193069458\n",
      "Validation loss decreased from 0.7011807723478838 to 0.7011611840941689\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6926589608192444\n",
      "Validation loss decreased from 0.7011611840941689 to 0.7011416825381193\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6926526427268982\n",
      "Validation loss decreased from 0.7011416825381193 to 0.7011223814704202\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6926464438438416\n",
      "Validation loss decreased from 0.7011223814704202 to 0.7011031291701577\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6926403045654297\n",
      "Validation loss decreased from 0.7011031291701577 to 0.7010839635675604\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6926340460777283\n",
      "Validation loss decreased from 0.7010839635675604 to 0.7010648467323997\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6926279067993164\n",
      "Validation loss decreased from 0.7010648467323997 to 0.7010458003390919\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6926218271255493\n",
      "Validation loss decreased from 0.7010458003390919 to 0.7010268514806574\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6926156878471375\n",
      "Validation loss decreased from 0.7010268514806574 to 0.7010079784826799\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6926096677780151\n",
      "Validation loss decreased from 0.7010079784826799 to 0.7009891759265553\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6926036477088928\n",
      "Validation loss decreased from 0.7009891759265553 to 0.7009704221378673\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6925976872444153\n",
      "Validation loss decreased from 0.7009704221378673 to 0.7009517821398649\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6925918459892273\n",
      "Validation loss decreased from 0.7009517821398649 to 0.7009332342581316\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6925858855247498\n",
      "Validation loss decreased from 0.7009332342581316 to 0.7009147297252308\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6925801038742065\n",
      "Validation loss decreased from 0.7009147297252308 to 0.7008962793783708\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6925742030143738\n",
      "Validation loss decreased from 0.7008962793783708 to 0.7008779157291759\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6925684213638306\n",
      "Validation loss decreased from 0.7008779157291759 to 0.7008595791730013\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6925625801086426\n",
      "Validation loss decreased from 0.7008595791730013 to 0.7008412642912432\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6925567984580994\n",
      "Validation loss decreased from 0.7008412642912432 to 0.7008230090141296\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6925510764122009\n",
      "Validation loss decreased from 0.7008230090141296 to 0.700804824178869\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6925452947616577\n",
      "Validation loss decreased from 0.700804824178869 to 0.7007867206226696\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6925395727157593\n",
      "Validation loss decreased from 0.7007867206226696 to 0.7007686712525107\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6925338506698608\n",
      "Validation loss decreased from 0.7007686712525107 to 0.7007506869056008\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.692528247833252\n",
      "Validation loss decreased from 0.7007506869056008 to 0.7007328271865845\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6925225853919983\n",
      "Validation loss decreased from 0.7007328271865845 to 0.7007150053977966\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6925168037414551\n",
      "Validation loss decreased from 0.7007150053977966 to 0.700697275725278\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6925110220909119\n",
      "Validation loss decreased from 0.700697275725278 to 0.7006796164946123\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.692505419254303\n",
      "Validation loss decreased from 0.7006796164946123 to 0.7006620602174238\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6924998164176941\n",
      "Validation loss decreased from 0.7006620602174238 to 0.7006445635448803\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6924941539764404\n",
      "Validation loss decreased from 0.7006445635448803 to 0.7006271318955855\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6924886703491211\n",
      "Validation loss decreased from 0.7006271318955855 to 0.7006098302927884\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6924831867218018\n",
      "Validation loss decreased from 0.7006098302927884 to 0.7005926099690524\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6924777626991272\n",
      "Validation loss decreased from 0.7005926099690524 to 0.7005754655057733\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6924723386764526\n",
      "Validation loss decreased from 0.7005754655057733 to 0.7005583860657432\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6924670338630676\n",
      "Validation loss decreased from 0.7005583860657432 to 0.7005414258350026\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6924617886543274\n",
      "Validation loss decreased from 0.7005414258350026 to 0.7005245306275107\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6924564242362976\n",
      "Validation loss decreased from 0.7005245306275107 to 0.7005076841874556\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6924512386322021\n",
      "Validation loss decreased from 0.7005076841874556 to 0.7004909352822737\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6924459934234619\n",
      "Validation loss decreased from 0.7004909352822737 to 0.7004742568189447\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6924407482147217\n",
      "Validation loss decreased from 0.7004742568189447 to 0.7004576108672402\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6924357414245605\n",
      "Validation loss decreased from 0.7004576108672402 to 0.7004410245201804\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.692430853843689\n",
      "Validation loss decreased from 0.7004410245201804 to 0.7004245519638062\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6924260258674622\n",
      "Validation loss decreased from 0.7004245519638062 to 0.7004081281748685\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6924210786819458\n",
      "Validation loss decreased from 0.7004081281748685 to 0.7003917965022001\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6924163699150085\n",
      "Validation loss decreased from 0.7003917965022001 to 0.7003755244341764\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6924116015434265\n",
      "Validation loss decreased from 0.7003755244341764 to 0.7003593119707975\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6924070715904236\n",
      "Validation loss decreased from 0.7003593119707975 to 0.7003431645306674\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6924024820327759\n",
      "Validation loss decreased from 0.7003431645306674 to 0.7003270983695984\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.692397952079773\n",
      "Validation loss decreased from 0.7003270983695984 to 0.7003110484643416\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6923933625221252\n",
      "Validation loss decreased from 0.7003110484643416 to 0.700295009396293\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6923888921737671\n",
      "Validation loss decreased from 0.700295009396293 to 0.7002790570259094\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6923844218254089\n",
      "Validation loss decreased from 0.7002790570259094 to 0.7002631534229625\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6923799514770508\n",
      "Validation loss decreased from 0.7002631534229625 to 0.7002473148432645\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6923754811286926\n",
      "Validation loss decreased from 0.7002473148432645 to 0.7002314816821705\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6923710107803345\n",
      "Validation loss decreased from 0.7002314816821705 to 0.7002157189629294\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6923665404319763\n",
      "Validation loss decreased from 0.7002157189629294 to 0.700200005011125\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6923620700836182\n",
      "Validation loss decreased from 0.700200005011125 to 0.7001842639663003\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6923576593399048\n",
      "Validation loss decreased from 0.7001842639663003 to 0.7001686475493691\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6923533082008362\n",
      "Validation loss decreased from 0.7001686475493691 to 0.7001530473882501\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6923489570617676\n",
      "Validation loss decreased from 0.7001530473882501 to 0.7001374905759638\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6923445463180542\n",
      "Validation loss decreased from 0.7001374905759638 to 0.7001219879497181\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6923402547836304\n",
      "Validation loss decreased from 0.7001219879497181 to 0.7001065611839294\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6923360228538513\n",
      "Validation loss decreased from 0.7001065611839294 to 0.7000912102785978\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6923319697380066\n",
      "Validation loss decreased from 0.7000912102785978 to 0.7000759406523271\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6923279166221619\n",
      "Validation loss decreased from 0.7000759406523271 to 0.7000607252120972\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6923239231109619\n",
      "Validation loss decreased from 0.7000607252120972 to 0.7000455314462836\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6923199892044067\n",
      "Validation loss decreased from 0.7000455314462836 to 0.700030348517678\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.692315936088562\n",
      "Validation loss decreased from 0.700030348517678 to 0.7000152739611539\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6923120021820068\n",
      "Validation loss decreased from 0.7000152739611539 to 0.7000002481720664\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6923081278800964\n",
      "Validation loss decreased from 0.7000002481720664 to 0.699985309080644\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6923041343688965\n",
      "Validation loss decreased from 0.699985309080644 to 0.6999704295938666\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6923002600669861\n",
      "Validation loss decreased from 0.6999704295938666 to 0.6999556259675459\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6922965049743652\n",
      "Validation loss decreased from 0.6999556259675459 to 0.6999408819458701\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6922926306724548\n",
      "Validation loss decreased from 0.6999408819458701 to 0.6999262029474432\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.692288875579834\n",
      "Validation loss decreased from 0.6999262029474432 to 0.6999115943908691\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.692284882068634\n",
      "Validation loss decreased from 0.6999115943908691 to 0.6998970020901073\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6922812461853027\n",
      "Validation loss decreased from 0.6998970020901073 to 0.6998824964870106\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6922774910926819\n",
      "Validation loss decreased from 0.6998824964870106 to 0.6998681046745994\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.692273736000061\n",
      "Validation loss decreased from 0.6998681046745994 to 0.6998537616296248\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6922699809074402\n",
      "Validation loss decreased from 0.6998537616296248 to 0.699839483607899\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6922662854194641\n",
      "Validation loss decreased from 0.699839483607899 to 0.699825259772214\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6922626495361328\n",
      "Validation loss decreased from 0.699825259772214 to 0.6998110684481534\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6922590136528015\n",
      "Validation loss decreased from 0.6998110684481534 to 0.6997969800775702\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6922553181648254\n",
      "Validation loss decreased from 0.6997969800775702 to 0.6997829838232561\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6922517418861389\n",
      "Validation loss decreased from 0.6997829838232561 to 0.6997690363363787\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6922481656074524\n",
      "Validation loss decreased from 0.6997690363363787 to 0.6997551051053134\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6922445297241211\n",
      "Validation loss decreased from 0.6997551051053134 to 0.6997412768277255\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6922410130500793\n",
      "Validation loss decreased from 0.6997412768277255 to 0.6997275081547824\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6922374367713928\n",
      "Validation loss decreased from 0.6997275081547824 to 0.6997137774120678\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6922339797019958\n",
      "Validation loss decreased from 0.6997137774120678 to 0.6997001442042264\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6922305226325989\n",
      "Validation loss decreased from 0.6997001442042264 to 0.6996865380894054\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6922270655632019\n",
      "Validation loss decreased from 0.6996865380894054 to 0.6996730078350414\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6922236680984497\n",
      "Validation loss decreased from 0.6996730078350414 to 0.6996595155109059\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6922203898429871\n",
      "Validation loss decreased from 0.6996595155109059 to 0.699646077372811\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.692217230796814\n",
      "Validation loss decreased from 0.699646077372811 to 0.6996327205137773\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6922140717506409\n",
      "Validation loss decreased from 0.6996327205137773 to 0.6996193961663679\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6922109723091125\n",
      "Validation loss decreased from 0.6996193961663679 to 0.6996061368422075\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6922078728675842\n",
      "Validation loss decreased from 0.6996061368422075 to 0.699592953378504\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6922047734260559\n",
      "Validation loss decreased from 0.699592953378504 to 0.6995798403566534\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6922018527984619\n",
      "Validation loss decreased from 0.6995798403566534 to 0.6995667761022394\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6921987533569336\n",
      "Validation loss decreased from 0.6995667761022394 to 0.6995537877082825\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6921958327293396\n",
      "Validation loss decreased from 0.6995537877082825 to 0.6995408643375743\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.692192792892456\n",
      "Validation loss decreased from 0.6995408643375743 to 0.6995279843156988\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6921898126602173\n",
      "Validation loss decreased from 0.6995279843156988 to 0.6995151476426558\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.692186713218689\n",
      "Validation loss decreased from 0.6995151476426558 to 0.6995022838765924\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6921837329864502\n",
      "Validation loss decreased from 0.6995022838765924 to 0.6994895176454023\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6921805739402771\n",
      "Validation loss decreased from 0.6994895176454023 to 0.6994768001816489\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6921776533126831\n",
      "Validation loss decreased from 0.6994768001816489 to 0.6994640881364996\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6921745538711548\n",
      "Validation loss decreased from 0.6994640881364996 to 0.699451441114599\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6921715140342712\n",
      "Validation loss decreased from 0.699451441114599 to 0.699438832022927\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.692168653011322\n",
      "Validation loss decreased from 0.699438832022927 to 0.6994262662800875\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6921656727790833\n",
      "Validation loss decreased from 0.6994262662800875 to 0.6994137113744562\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6921626925468445\n",
      "Validation loss decreased from 0.6994137113744562 to 0.6994012269106779\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6921597719192505\n",
      "Validation loss decreased from 0.6994012269106779 to 0.6993887803771279\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6921568512916565\n",
      "Validation loss decreased from 0.6993887803771279 to 0.6993763934482228\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6921539306640625\n",
      "Validation loss decreased from 0.6993763934482228 to 0.6993641257286072\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6921511292457581\n",
      "Validation loss decreased from 0.6993641257286072 to 0.6993518471717834\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6921482682228088\n",
      "Validation loss decreased from 0.6993518471717834 to 0.6993396336382086\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6921453475952148\n",
      "Validation loss decreased from 0.6993396336382086 to 0.6993274201046337\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6921425461769104\n",
      "Validation loss decreased from 0.6993274201046337 to 0.6993152770129117\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.692139744758606\n",
      "Validation loss decreased from 0.6993152770129117 to 0.6993032152002508\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6921370625495911\n",
      "Validation loss decreased from 0.6993032152002508 to 0.699291164224798\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6921341419219971\n",
      "Validation loss decreased from 0.699291164224798 to 0.6992791620167819\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6921311616897583\n",
      "Validation loss decreased from 0.6992791620167819 to 0.699267181483182\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6921283006668091\n",
      "Validation loss decreased from 0.699267181483182 to 0.6992552713914351\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6921254396438599\n",
      "Validation loss decreased from 0.6992552713914351 to 0.69924335046248\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6921225190162659\n",
      "Validation loss decreased from 0.69924335046248 to 0.6992314837195657\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6921196579933167\n",
      "Validation loss decreased from 0.6992314837195657 to 0.6992196928371083\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6921168565750122\n",
      "Validation loss decreased from 0.6992196928371083 to 0.6992079290476713\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6921140551567078\n",
      "Validation loss decreased from 0.6992079290476713 to 0.6991962627931074\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6921111941337585\n",
      "Validation loss decreased from 0.6991962627931074 to 0.6991846290501681\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6921084523200989\n",
      "Validation loss decreased from 0.6991846290501681 to 0.6991730711676858\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.692105770111084\n",
      "Validation loss decreased from 0.6991730711676858 to 0.6991615132852034\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6921029686927795\n",
      "Validation loss decreased from 0.6991615132852034 to 0.6991500150073658\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6921003460884094\n",
      "Validation loss decreased from 0.6991500150073658 to 0.6991385600783608\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6920976638793945\n",
      "Validation loss decreased from 0.6991385600783608 to 0.6991271268237721\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6920950412750244\n",
      "Validation loss decreased from 0.6991271268237721 to 0.6991157152435996\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6920924782752991\n",
      "Validation loss decreased from 0.6991157152435996 to 0.6991043849424883\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6920900344848633\n",
      "Validation loss decreased from 0.6991043849424883 to 0.6990930438041687\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.692087709903717\n",
      "Validation loss decreased from 0.6990930438041687 to 0.6990817568518899\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6920852661132812\n",
      "Validation loss decreased from 0.6990817568518899 to 0.6990704698996111\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6920828223228455\n",
      "Validation loss decreased from 0.6990704698996111 to 0.6990592262961648\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6920804381370544\n",
      "Validation loss decreased from 0.6990592262961648 to 0.6990480043671348\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6920780539512634\n",
      "Validation loss decreased from 0.6990480043671348 to 0.6990368474613536\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6920756101608276\n",
      "Validation loss decreased from 0.6990368474613536 to 0.6990256905555725\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6920732259750366\n",
      "Validation loss decreased from 0.6990256905555725 to 0.6990145499056036\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6920709609985352\n",
      "Validation loss decreased from 0.6990145499056036 to 0.6990035176277161\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6920685172080994\n",
      "Validation loss decreased from 0.6990035176277161 to 0.6989924690940164\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6920661926269531\n",
      "Validation loss decreased from 0.6989924690940164 to 0.6989814855835654\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6920638680458069\n",
      "Validation loss decreased from 0.6989814855835654 to 0.6989705237475309\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6920616030693054\n",
      "Validation loss decreased from 0.6989705237475309 to 0.6989596323533491\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6920591592788696\n",
      "Validation loss decreased from 0.6989596323533491 to 0.6989487734707919\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6920568943023682\n",
      "Validation loss decreased from 0.6989487734707919 to 0.698937947099859\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6920546293258667\n",
      "Validation loss decreased from 0.698937947099859 to 0.698927180333571\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.69205242395401\n",
      "Validation loss decreased from 0.698927180333571 to 0.6989164677533236\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6920501589775085\n",
      "Validation loss decreased from 0.6989164677533236 to 0.6989057822660967\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6920479536056519\n",
      "Validation loss decreased from 0.6989057822660967 to 0.6988951455463063\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6920456290245056\n",
      "Validation loss decreased from 0.6988951455463063 to 0.6988845467567444\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6920433640480042\n",
      "Validation loss decreased from 0.6988845467567444 to 0.6988740184090354\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6920412182807922\n",
      "Validation loss decreased from 0.6988740184090354 to 0.6988635117357428\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6920390129089355\n",
      "Validation loss decreased from 0.6988635117357428 to 0.6988530267368663\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6920368671417236\n",
      "Validation loss decreased from 0.6988530267368663 to 0.6988426013426348\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6920346617698669\n",
      "Validation loss decreased from 0.6988426013426348 to 0.6988322084600275\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.692032516002655\n",
      "Validation loss decreased from 0.6988322084600275 to 0.6988218535076488\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6920303702354431\n",
      "Validation loss decreased from 0.6988218535076488 to 0.6988115202296864\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6920282244682312\n",
      "Validation loss decreased from 0.6988115202296864 to 0.6988012086261403\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6920261383056641\n",
      "Validation loss decreased from 0.6988012086261403 to 0.6987909566272389\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6920239925384521\n",
      "Validation loss decreased from 0.6987909566272389 to 0.6987806937911294\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6920218467712402\n",
      "Validation loss decreased from 0.6987806937911294 to 0.6987704743038524\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6920196413993835\n",
      "Validation loss decreased from 0.6987704743038524 to 0.6987602710723877\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6920174956321716\n",
      "Validation loss decreased from 0.6987602710723877 to 0.6987501057711515\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6920153498649597\n",
      "Validation loss decreased from 0.6987501057711515 to 0.6987399784001437\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6920132637023926\n",
      "Validation loss decreased from 0.6987399784001437 to 0.6987298943779685\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6920111775398254\n",
      "Validation loss decreased from 0.6987298943779685 to 0.6987198482860218\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6920090317726135\n",
      "Validation loss decreased from 0.6987198482860218 to 0.6987098509615118\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6920069456100464\n",
      "Validation loss decreased from 0.6987098509615118 to 0.6986998861486261\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.692004919052124\n",
      "Validation loss decreased from 0.6986998861486261 to 0.6986899755217812\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6920029520988464\n",
      "Validation loss decreased from 0.6986899755217812 to 0.6986800865693525\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6920008659362793\n",
      "Validation loss decreased from 0.6986800865693525 to 0.6986702355471525\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6919988989830017\n",
      "Validation loss decreased from 0.6986702355471525 to 0.6986604224551808\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6919968724250793\n",
      "Validation loss decreased from 0.6986604224551808 to 0.6986506418748335\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.691994845867157\n",
      "Validation loss decreased from 0.6986506418748335 to 0.6986408721316945\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6919928193092346\n",
      "Validation loss decreased from 0.6986408721316945 to 0.6986310698769309\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6919909119606018\n",
      "Validation loss decreased from 0.6986310698769309 to 0.6986213326454163\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6919888854026794\n",
      "Validation loss decreased from 0.6986213326454163 to 0.6986116062511097\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6919869184494019\n",
      "Validation loss decreased from 0.6986116062511097 to 0.6986019340428439\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6919849514961243\n",
      "Validation loss decreased from 0.6986019340428439 to 0.6985923268578269\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6919829249382019\n",
      "Validation loss decreased from 0.6985923268578269 to 0.6985827684402466\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6919810175895691\n",
      "Validation loss decreased from 0.6985827684402466 to 0.6985732533714988\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.691978931427002\n",
      "Validation loss decreased from 0.6985732533714988 to 0.6985637599771674\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6919769048690796\n",
      "Validation loss decreased from 0.6985637599771674 to 0.698554277420044\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6919749975204468\n",
      "Validation loss decreased from 0.698554277420044 to 0.698544827374545\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6919729709625244\n",
      "Validation loss decreased from 0.698544827374545 to 0.6985353935848583\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.691970944404602\n",
      "Validation loss decreased from 0.6985353935848583 to 0.6985259977254\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.691969096660614\n",
      "Validation loss decreased from 0.6985259977254 to 0.6985166452147744\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6919670701026917\n",
      "Validation loss decreased from 0.6985166452147744 to 0.6985072981227528\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6919651627540588\n",
      "Validation loss decreased from 0.6985072981227528 to 0.6984979781237516\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6919631958007812\n",
      "Validation loss decreased from 0.6984979781237516 to 0.6984887068921869\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6919613480567932\n",
      "Validation loss decreased from 0.6984887068921869 to 0.6984794302420183\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6919593214988708\n",
      "Validation loss decreased from 0.6984794302420183 to 0.6984702131964944\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6919575333595276\n",
      "Validation loss decreased from 0.6984702131964944 to 0.6984609853137623\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.69195556640625\n",
      "Validation loss decreased from 0.6984609853137623 to 0.6984517791054465\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6919536590576172\n",
      "Validation loss decreased from 0.6984517791054465 to 0.698442589152943\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6919516921043396\n",
      "Validation loss decreased from 0.698442589152943 to 0.6984334317120638\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6919496655464172\n",
      "Validation loss decreased from 0.6984334317120638 to 0.6984242959456011\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.691947877407074\n",
      "Validation loss decreased from 0.6984242959456011 to 0.6984151764349504\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6919459104537964\n",
      "Validation loss decreased from 0.6984151764349504 to 0.6984060894359242\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6919440031051636\n",
      "Validation loss decreased from 0.6984060894359242 to 0.6983970403671265\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6919422149658203\n",
      "Validation loss decreased from 0.6983970403671265 to 0.6983880183913491\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.691940188407898\n",
      "Validation loss decreased from 0.6983880183913491 to 0.6983790018341758\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6919382810592651\n",
      "Validation loss decreased from 0.6983790018341758 to 0.698370017788627\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6919361352920532\n",
      "Validation loss decreased from 0.698370017788627 to 0.6983610554174944\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6919341683387756\n",
      "Validation loss decreased from 0.6983610554174944 to 0.6983521309765902\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6919320225715637\n",
      "Validation loss decreased from 0.6983521309765902 to 0.6983432173728943\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6919299364089966\n",
      "Validation loss decreased from 0.6983432173728943 to 0.6983343308622186\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6919278502464294\n",
      "Validation loss decreased from 0.6983343308622186 to 0.6983255039561879\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6919258832931519\n",
      "Validation loss decreased from 0.6983255039561879 to 0.6983166878873651\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6919237375259399\n",
      "Validation loss decreased from 0.6983166878873651 to 0.6983079205859791\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6919216513633728\n",
      "Validation loss decreased from 0.6983079205859791 to 0.6982991587031971\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6919196248054504\n",
      "Validation loss decreased from 0.6982991587031971 to 0.6982904455878518\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6919175386428833\n",
      "Validation loss decreased from 0.6982904455878518 to 0.6982817920771512\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6919156312942505\n",
      "Validation loss decreased from 0.6982817920771512 to 0.6982731819152832\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6919135451316833\n",
      "Validation loss decreased from 0.6982731819152832 to 0.6982645717534152\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.691911518573761\n",
      "Validation loss decreased from 0.6982645717534152 to 0.6982560428706083\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6919095516204834\n",
      "Validation loss decreased from 0.6982560428706083 to 0.6982474814761769\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6919075846672058\n",
      "Validation loss decreased from 0.6982474814761769 to 0.6982389959422025\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6919056177139282\n",
      "Validation loss decreased from 0.6982389959422025 to 0.6982305483384565\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6919037699699402\n",
      "Validation loss decreased from 0.6982305483384565 to 0.6982221386649392\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6919018030166626\n",
      "Validation loss decreased from 0.6982221386649392 to 0.6982137560844421\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6918999552726746\n",
      "Validation loss decreased from 0.6982137560844421 to 0.6982054005969655\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6918981075286865\n",
      "Validation loss decreased from 0.6982054005969655 to 0.6981970505280928\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6918961405754089\n",
      "Validation loss decreased from 0.6981970505280928 to 0.6981887221336365\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6918942928314209\n",
      "Validation loss decreased from 0.6981887221336365 to 0.6981804154135964\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6918923854827881\n",
      "Validation loss decreased from 0.6981804154135964 to 0.6981721737168052\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6918906569480896\n",
      "Validation loss decreased from 0.6981721737168052 to 0.6981639753688466\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6918888092041016\n",
      "Validation loss decreased from 0.6981639753688466 to 0.6981558149511163\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6918869614601135\n",
      "Validation loss decreased from 0.6981558149511163 to 0.6981476707891985\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6918851733207703\n",
      "Validation loss decreased from 0.6981476707891985 to 0.6981395428830927\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6918832659721375\n",
      "Validation loss decreased from 0.6981395428830927 to 0.6981314258141951\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.691881537437439\n",
      "Validation loss decreased from 0.6981314258141951 to 0.6981233304197138\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6918798089027405\n",
      "Validation loss decreased from 0.6981233304197138 to 0.6981152837926691\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.691878080368042\n",
      "Validation loss decreased from 0.6981152837926691 to 0.6981072209098123\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6918763518333435\n",
      "Validation loss decreased from 0.6981072209098123 to 0.6980991959571838\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6918745040893555\n",
      "Validation loss decreased from 0.6980991959571838 to 0.6980912035161798\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.691872775554657\n",
      "Validation loss decreased from 0.6980912035161798 to 0.6980832327495922\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6918710470199585\n",
      "Validation loss decreased from 0.6980832327495922 to 0.6980752674016085\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6918693780899048\n",
      "Validation loss decreased from 0.6980752674016085 to 0.6980673454024575\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6918676495552063\n",
      "Validation loss decreased from 0.6980673454024575 to 0.6980593963102861\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6918659806251526\n",
      "Validation loss decreased from 0.6980593963102861 to 0.6980515176599676\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6918641328811646\n",
      "Validation loss decreased from 0.6980515176599676 to 0.6980436715212736\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6918625235557556\n",
      "Validation loss decreased from 0.6980436715212736 to 0.698035863312808\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6918607950210571\n",
      "Validation loss decreased from 0.698035863312808 to 0.6980280930345709\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6918591856956482\n",
      "Validation loss decreased from 0.6980280930345709 to 0.6980203986167908\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6918575763702393\n",
      "Validation loss decreased from 0.6980203986167908 to 0.698012731292031\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6918559670448303\n",
      "Validation loss decreased from 0.698012731292031 to 0.6980050802230835\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6918542385101318\n",
      "Validation loss decreased from 0.6980050802230835 to 0.6979974399913441\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6918526887893677\n",
      "Validation loss decreased from 0.6979974399913441 to 0.6979898485270414\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6918510794639587\n",
      "Validation loss decreased from 0.6979898485270414 to 0.697982289574363\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.691849410533905\n",
      "Validation loss decreased from 0.697982289574363 to 0.6979747089472684\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6918478608131409\n",
      "Validation loss decreased from 0.6979747089472684 to 0.6979671825062145\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6918463110923767\n",
      "Validation loss decreased from 0.6979671825062145 to 0.6979596669023688\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6918445825576782\n",
      "Validation loss decreased from 0.6979596669023688 to 0.6979521621357311\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6918430924415588\n",
      "Validation loss decreased from 0.6979521621357311 to 0.6979446952993219\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6918414831161499\n",
      "Validation loss decreased from 0.6979446952993219 to 0.6979373097419739\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6918399333953857\n",
      "Validation loss decreased from 0.6979373097419739 to 0.6979299566962502\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6918384432792664\n",
      "Validation loss decreased from 0.6979299566962502 to 0.6979226632551714\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.691836953163147\n",
      "Validation loss decreased from 0.6979226632551714 to 0.6979153914885088\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6918355226516724\n",
      "Validation loss decreased from 0.6979153914885088 to 0.6979081359776583\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.691834032535553\n",
      "Validation loss decreased from 0.6979081359776583 to 0.6979009238156405\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6918325424194336\n",
      "Validation loss decreased from 0.6979009238156405 to 0.6978936899792064\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.691831111907959\n",
      "Validation loss decreased from 0.6978936899792064 to 0.6978864886543967\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6918297410011292\n",
      "Validation loss decreased from 0.6978864886543967 to 0.6978793090040033\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6918284296989441\n",
      "Validation loss decreased from 0.6978793090040033 to 0.6978721835396506\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6918269395828247\n",
      "Validation loss decreased from 0.6978721835396506 to 0.6978650797497142\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6918256282806396\n",
      "Validation loss decreased from 0.6978650797497142 to 0.6978579651225697\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.691824197769165\n",
      "Validation loss decreased from 0.6978579651225697 to 0.6978508667512373\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6918229460716248\n",
      "Validation loss decreased from 0.6978508667512373 to 0.6978437846357172\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6918215751647949\n",
      "Validation loss decreased from 0.6978437846357172 to 0.6978367350318215\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6918202638626099\n",
      "Validation loss decreased from 0.6978367350318215 to 0.697829707102342\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6918189525604248\n",
      "Validation loss decreased from 0.697829707102342 to 0.6978226900100708\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6918177008628845\n",
      "Validation loss decreased from 0.6978226900100708 to 0.6978156891736117\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6918163895606995\n",
      "Validation loss decreased from 0.6978156891736117 to 0.6978087045929648\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6918150782585144\n",
      "Validation loss decreased from 0.6978087045929648 to 0.6978017471053384\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6918138265609741\n",
      "Validation loss decreased from 0.6978017471053384 to 0.6977948167107322\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6918125748634338\n",
      "Validation loss decreased from 0.6977948167107322 to 0.697787962176583\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6918112635612488\n",
      "Validation loss decreased from 0.697787962176583 to 0.6977810697122053\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6918100118637085\n",
      "Validation loss decreased from 0.6977810697122053 to 0.6977742205966603\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6918088793754578\n",
      "Validation loss decreased from 0.6977742205966603 to 0.6977673985741355\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6918075084686279\n",
      "Validation loss decreased from 0.6977673985741355 to 0.697760592807423\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6918063163757324\n",
      "Validation loss decreased from 0.697760592807423 to 0.697753830389543\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6918052434921265\n",
      "Validation loss decreased from 0.697753830389543 to 0.6977470842274752\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.691804051399231\n",
      "Validation loss decreased from 0.6977470842274752 to 0.6977403705770319\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6918028593063354\n",
      "Validation loss decreased from 0.6977403705770319 to 0.6977337111126293\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6918016672134399\n",
      "Validation loss decreased from 0.6977337111126293 to 0.6977270624854348\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.691800594329834\n",
      "Validation loss decreased from 0.6977270624854348 to 0.6977204409512606\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6917993426322937\n",
      "Validation loss decreased from 0.6977204409512606 to 0.6977138248356906\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.691798210144043\n",
      "Validation loss decreased from 0.6977138248356906 to 0.697707246650349\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6917970180511475\n",
      "Validation loss decreased from 0.697707246650349 to 0.6977006793022156\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6917959451675415\n",
      "Validation loss decreased from 0.6977006793022156 to 0.6976941444657065\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6917948126792908\n",
      "Validation loss decreased from 0.6976941444657065 to 0.6976876313036139\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6917937397956848\n",
      "Validation loss decreased from 0.6976876313036139 to 0.6976811289787292\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6917926669120789\n",
      "Validation loss decreased from 0.6976811289787292 to 0.6976746645840731\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6917915940284729\n",
      "Validation loss decreased from 0.6976746645840731 to 0.6976682272824374\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6917905807495117\n",
      "Validation loss decreased from 0.6976682272824374 to 0.6976617953994058\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6917896270751953\n",
      "Validation loss decreased from 0.6976617953994058 to 0.6976553906093944\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6917885541915894\n",
      "Validation loss decreased from 0.6976553906093944 to 0.6976490237496116\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6917875409126282\n",
      "Validation loss decreased from 0.6976490237496116 to 0.6976426677270369\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.691786527633667\n",
      "Validation loss decreased from 0.6976426677270369 to 0.6976363442160867\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6917855143547058\n",
      "Validation loss decreased from 0.6976363442160867 to 0.6976299936121161\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6917843818664551\n",
      "Validation loss decreased from 0.6976299936121161 to 0.6976236375895414\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6917833089828491\n",
      "Validation loss decreased from 0.6976236375895414 to 0.6976173194971952\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6917821168899536\n",
      "Validation loss decreased from 0.6976173194971952 to 0.6976109688932245\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6917810440063477\n",
      "Validation loss decreased from 0.6976109688932245 to 0.6976046616380865\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6917799711227417\n",
      "Validation loss decreased from 0.6976046616380865 to 0.6975983923131769\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.691778838634491\n",
      "Validation loss decreased from 0.6975983923131769 to 0.6975921284068715\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.691777765750885\n",
      "Validation loss decreased from 0.6975921284068715 to 0.6975858915935863\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6917766332626343\n",
      "Validation loss decreased from 0.6975858915935863 to 0.6975796656175093\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6917755603790283\n",
      "Validation loss decreased from 0.6975796656175093 to 0.6975734450600364\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6917744874954224\n",
      "Validation loss decreased from 0.6975734450600364 to 0.6975672515955839\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6917733550071716\n",
      "Validation loss decreased from 0.6975672515955839 to 0.6975610635497353\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6917723417282104\n",
      "Validation loss decreased from 0.6975610635497353 to 0.6975549188527194\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6917712688446045\n",
      "Validation loss decreased from 0.6975549188527194 to 0.6975487470626831\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6917701959609985\n",
      "Validation loss decreased from 0.6975487470626831 to 0.6975426186214794\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6917691230773926\n",
      "Validation loss decreased from 0.6975426186214794 to 0.6975364901802756\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6917679905891418\n",
      "Validation loss decreased from 0.6975364901802756 to 0.6975303509018638\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6917668581008911\n",
      "Validation loss decreased from 0.6975303509018638 to 0.6975242387164723\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6917657256126404\n",
      "Validation loss decreased from 0.6975242387164723 to 0.6975181861357256\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6917645931243896\n",
      "Validation loss decreased from 0.6975181861357256 to 0.6975121064619585\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6917634606361389\n",
      "Validation loss decreased from 0.6975121064619585 to 0.6975060972300443\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6917622685432434\n",
      "Validation loss decreased from 0.6975060972300443 to 0.6975000934167341\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6917611360549927\n",
      "Validation loss decreased from 0.6975000934167341 to 0.6974940950220282\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6917600631713867\n",
      "Validation loss decreased from 0.6974940950220282 to 0.6974881345575507\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6917589902877808\n",
      "Validation loss decreased from 0.6974881345575507 to 0.6974822066046975\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.69175785779953\n",
      "Validation loss decreased from 0.6974822066046975 to 0.6974762786518444\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6917567849159241\n",
      "Validation loss decreased from 0.6974762786518444 to 0.6974703506989912\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6917557120323181\n",
      "Validation loss decreased from 0.6974703506989912 to 0.6974644444205544\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6917546391487122\n",
      "Validation loss decreased from 0.6974644444205544 to 0.6974585706537421\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6917535662651062\n",
      "Validation loss decreased from 0.6974585706537421 to 0.69745272397995\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6917524337768555\n",
      "Validation loss decreased from 0.69745272397995 to 0.6974468718875538\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6917513012886047\n",
      "Validation loss decreased from 0.6974468718875538 to 0.6974410523067821\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6917501091957092\n",
      "Validation loss decreased from 0.6974410523067821 to 0.6974352544004266\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6917490363121033\n",
      "Validation loss decreased from 0.6974352544004266 to 0.6974295106801119\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6917479038238525\n",
      "Validation loss decreased from 0.6974295106801119 to 0.6974237832156095\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6917467713356018\n",
      "Validation loss decreased from 0.6974237832156095 to 0.6974180449138988\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6917456984519958\n",
      "Validation loss decreased from 0.6974180449138988 to 0.6974123445424166\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6917445659637451\n",
      "Validation loss decreased from 0.6974123445424166 to 0.6974066658453508\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6917434334754944\n",
      "Validation loss decreased from 0.6974066658453508 to 0.6974009817296808\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6917423605918884\n",
      "Validation loss decreased from 0.6974009817296808 to 0.6973953788930719\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6917412877082825\n",
      "Validation loss decreased from 0.6973953788930719 to 0.697389770637859\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6917402148246765\n",
      "Validation loss decreased from 0.697389770637859 to 0.6973841678012501\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6917391419410706\n",
      "Validation loss decreased from 0.6973841678012501 to 0.6973785541274331\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.691737949848175\n",
      "Validation loss decreased from 0.6973785541274331 to 0.6973729512908242\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6917367577552795\n",
      "Validation loss decreased from 0.6973729512908242 to 0.6973673267797991\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.691735565662384\n",
      "Validation loss decreased from 0.6973673267797991 to 0.6973616968501698\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6917344927787781\n",
      "Validation loss decreased from 0.6973616968501698 to 0.6973561211065813\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6917334198951721\n",
      "Validation loss decreased from 0.6973561211065813 to 0.6973505345257845\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6917324066162109\n",
      "Validation loss decreased from 0.6973505345257845 to 0.6973449967124246\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6917312145233154\n",
      "Validation loss decreased from 0.6973449967124246 to 0.6973394588990645\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6917300820350647\n",
      "Validation loss decreased from 0.6973394588990645 to 0.6973339373415167\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.691728949546814\n",
      "Validation loss decreased from 0.6973339373415167 to 0.6973284049467607\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6917277574539185\n",
      "Validation loss decreased from 0.6973284049467607 to 0.697322899645025\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6917266249656677\n",
      "Validation loss decreased from 0.697322899645025 to 0.6973173780874773\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.691725492477417\n",
      "Validation loss decreased from 0.6973173780874773 to 0.6973118836229498\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6917243599891663\n",
      "Validation loss decreased from 0.6973118836229498 to 0.6973064108328386\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6917232275009155\n",
      "Validation loss decreased from 0.6973064108328386 to 0.6973009488799355\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6917219758033752\n",
      "Validation loss decreased from 0.6973009488799355 to 0.6972955086014487\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6917208433151245\n",
      "Validation loss decreased from 0.6972955086014487 to 0.697290073741566\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6917197108268738\n",
      "Validation loss decreased from 0.697290073741566 to 0.6972846497188915\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6917185187339783\n",
      "Validation loss decreased from 0.6972846497188915 to 0.6972792256962169\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6917173266410828\n",
      "Validation loss decreased from 0.6972792256962169 to 0.697273850440979\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.691716194152832\n",
      "Validation loss decreased from 0.697273850440979 to 0.6972684589299288\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6917150616645813\n",
      "Validation loss decreased from 0.6972684589299288 to 0.6972630782560869\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6917137503623962\n",
      "Validation loss decreased from 0.6972630782560869 to 0.6972577300938693\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6917126178741455\n",
      "Validation loss decreased from 0.6972577300938693 to 0.6972523927688599\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6917114853858948\n",
      "Validation loss decreased from 0.6972523927688599 to 0.6972470662810586\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6917102932929993\n",
      "Validation loss decreased from 0.6972470662810586 to 0.6972417777234857\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6917091608047485\n",
      "Validation loss decreased from 0.6972417777234857 to 0.6972365000031211\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.691707968711853\n",
      "Validation loss decreased from 0.6972365000031211 to 0.6972312385385687\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6917067170143127\n",
      "Validation loss decreased from 0.6972312385385687 to 0.6972259879112244\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.691705584526062\n",
      "Validation loss decreased from 0.6972259879112244 to 0.69722073728388\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6917043328285217\n",
      "Validation loss decreased from 0.69722073728388 to 0.6972155137495561\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6917030811309814\n",
      "Validation loss decreased from 0.6972155137495561 to 0.697210284796628\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6917018890380859\n",
      "Validation loss decreased from 0.697210284796628 to 0.6972050829367205\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6917006969451904\n",
      "Validation loss decreased from 0.6972050829367205 to 0.6971998756582086\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6916995644569397\n",
      "Validation loss decreased from 0.6971998756582086 to 0.6971947225657377\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.691698431968689\n",
      "Validation loss decreased from 0.6971947225657377 to 0.6971895857290789\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.691697359085083\n",
      "Validation loss decreased from 0.6971895857290789 to 0.6971844597296282\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6916961669921875\n",
      "Validation loss decreased from 0.6971844597296282 to 0.6971793608231978\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6916950941085815\n",
      "Validation loss decreased from 0.6971793608231978 to 0.6971742564981634\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6916939616203308\n",
      "Validation loss decreased from 0.6971742564981634 to 0.6971691792661493\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6916928887367249\n",
      "Validation loss decreased from 0.6971691792661493 to 0.6971641345457598\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6916918158531189\n",
      "Validation loss decreased from 0.6971641345457598 to 0.6971590898253701\n",
      "no early stopping\n",
      "AUC on test data  0.49412674018352254\n",
      "model 36 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6954646110534668\n",
      "Validation loss decreased from inf to 0.7055380236018788\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6939754486083984\n",
      "Validation loss decreased from 0.7055380236018788 to 0.7005273266272112\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6935480833053589\n",
      "Validation loss decreased from 0.7005273266272112 to 0.6979463750665839\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6934775710105896\n",
      "Validation loss decreased from 0.6979463750665839 to 0.6966784596443176\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6934400796890259\n",
      "Validation loss decreased from 0.6966784596443176 to 0.6960264823653481\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6933870315551758\n",
      "Validation loss decreased from 0.6960264823653481 to 0.6956743706356395\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6933229565620422\n",
      "Validation loss decreased from 0.6956743706356395 to 0.6954725330526178\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6932455897331238\n",
      "Validation loss decreased from 0.6954725330526178 to 0.6953450441360474\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6931647658348083\n",
      "Validation loss decreased from 0.6953450441360474 to 0.6952548839829185\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6930809617042542\n",
      "Validation loss decreased from 0.6952548839829185 to 0.6951863169670105\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6929907202720642\n",
      "Validation loss decreased from 0.6951863169670105 to 0.695132396437905\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6928993463516235\n",
      "Validation loss decreased from 0.695132396437905 to 0.6950853575359691\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6928094029426575\n",
      "Validation loss decreased from 0.6950853575359691 to 0.6950417540290139\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6927202343940735\n",
      "Validation loss decreased from 0.6950417540290139 to 0.6950005347078497\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6926311254501343\n",
      "Validation loss decreased from 0.6950005347078497 to 0.6949601335959001\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6925426125526428\n",
      "Validation loss decreased from 0.6949601335959001 to 0.6949194236235186\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6924545764923096\n",
      "Validation loss decreased from 0.6949194236235186 to 0.6948782964186235\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6923670172691345\n",
      "Validation loss decreased from 0.6948782964186235 to 0.6948375701904297\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6922792196273804\n",
      "Validation loss decreased from 0.6948375701904297 to 0.6947966109622609\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6921923756599426\n",
      "Validation loss decreased from 0.6947966109622609 to 0.6947555812922391\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6921065449714661\n",
      "Validation loss decreased from 0.6947555812922391 to 0.694715369831432\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6920227408409119\n",
      "Validation loss decreased from 0.694715369831432 to 0.6946746056730096\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6919388175010681\n",
      "Validation loss decreased from 0.6946746056730096 to 0.6946356350725348\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6918563842773438\n",
      "Validation loss decreased from 0.6946356350725348 to 0.6945965723557905\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6917738914489746\n",
      "Validation loss decreased from 0.6945965723557905 to 0.694557937708768\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6916932463645935\n",
      "Validation loss decreased from 0.694557937708768 to 0.6945203488523309\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6916139721870422\n",
      "Validation loss decreased from 0.6945203488523309 to 0.6944824999028986\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6915351748466492\n",
      "Validation loss decreased from 0.6944824999028986 to 0.694444710558111\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6914564371109009\n",
      "Validation loss decreased from 0.694444710558111 to 0.6944074359807101\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.691379725933075\n",
      "Validation loss decreased from 0.6944074359807101 to 0.6943710229613564\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6913020014762878\n",
      "Validation loss decreased from 0.6943710229613564 to 0.6943355798721313\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.691224217414856\n",
      "Validation loss decreased from 0.6943355798721313 to 0.6943003860386935\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.691146731376648\n",
      "Validation loss decreased from 0.6943003860386935 to 0.6942655498331244\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6910698413848877\n",
      "Validation loss decreased from 0.6942655498331244 to 0.6942304806275801\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6909916400909424\n",
      "Validation loss decreased from 0.6942304806275801 to 0.6941954764452848\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6909151673316956\n",
      "Validation loss decreased from 0.6941954764452848 to 0.69415959444913\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6908360719680786\n",
      "Validation loss decreased from 0.69415959444913 to 0.6941244277087125\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.690758466720581\n",
      "Validation loss decreased from 0.6941244277087125 to 0.6940878900614652\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6906806826591492\n",
      "Validation loss decreased from 0.6940878900614652 to 0.6940508593212474\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6906039714813232\n",
      "Validation loss decreased from 0.6940508593212474 to 0.6940133517438715\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6905261874198914\n",
      "Validation loss decreased from 0.6940133517438715 to 0.693977030840787\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6904468536376953\n",
      "Validation loss decreased from 0.693977030840787 to 0.6939406882632863\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6903690099716187\n",
      "Validation loss decreased from 0.6939406882632863 to 0.6939035166393627\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.690290629863739\n",
      "Validation loss decreased from 0.6939035166393627 to 0.6938665455037897\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6902123093605042\n",
      "Validation loss decreased from 0.6938665455037897 to 0.6938286261125044\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6901341676712036\n",
      "Validation loss decreased from 0.6938286261125044 to 0.693790777163072\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6900564432144165\n",
      "Validation loss decreased from 0.693790777163072 to 0.6937527656555176\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6899769306182861\n",
      "Validation loss decreased from 0.6937527656555176 to 0.6937146241014654\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6898966431617737\n",
      "Validation loss decreased from 0.6937146241014654 to 0.6936763687567278\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6898165345191956\n",
      "Validation loss decreased from 0.6936763687567278 to 0.6936375498771667\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6897375583648682\n",
      "Validation loss decreased from 0.6936375498771667 to 0.6935985359278592\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6896588802337646\n",
      "Validation loss decreased from 0.6935985359278592 to 0.6935595273971558\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6895802617073059\n",
      "Validation loss decreased from 0.6935595273971558 to 0.6935206326571378\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6895010471343994\n",
      "Validation loss decreased from 0.6935206326571378 to 0.6934813423590227\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6894224286079407\n",
      "Validation loss decreased from 0.6934813423590227 to 0.6934414343400435\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6893445253372192\n",
      "Validation loss decreased from 0.6934414343400435 to 0.6934007026932456\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6892656087875366\n",
      "Validation loss decreased from 0.6934007026932456 to 0.693359759720889\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6891862154006958\n",
      "Validation loss decreased from 0.693359759720889 to 0.6933180798183788\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6891064643859863\n",
      "Validation loss decreased from 0.6933180798183788 to 0.6932747309858148\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.68902587890625\n",
      "Validation loss decreased from 0.6932747309858148 to 0.6932305260138079\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6889452934265137\n",
      "Validation loss decreased from 0.6932305260138079 to 0.693185876716267\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6888656616210938\n",
      "Validation loss decreased from 0.693185876716267 to 0.6931410540233959\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6887861490249634\n",
      "Validation loss decreased from 0.6931410540233959 to 0.6930958520282399\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6887033581733704\n",
      "Validation loss decreased from 0.6930958520282399 to 0.6930509643121199\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6886180639266968\n",
      "Validation loss decreased from 0.6930509643121199 to 0.6930064017122443\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6885315775871277\n",
      "Validation loss decreased from 0.6930064017122443 to 0.6929604519497264\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6884443759918213\n",
      "Validation loss decreased from 0.6929604519497264 to 0.6929137164896185\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6883557438850403\n",
      "Validation loss decreased from 0.6929137164896185 to 0.6928660652854226\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6882643103599548\n",
      "Validation loss decreased from 0.6928660652854226 to 0.6928176825696771\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6881706714630127\n",
      "Validation loss decreased from 0.6928176825696771 to 0.6927686550400474\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6880751252174377\n",
      "Validation loss decreased from 0.6927686550400474 to 0.6927193349057977\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6879782676696777\n",
      "Validation loss decreased from 0.6927193349057977 to 0.6926686059344899\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6878782510757446\n",
      "Validation loss decreased from 0.6926686059344899 to 0.6926166361028497\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6877776980400085\n",
      "Validation loss decreased from 0.6926166361028497 to 0.6925640431317416\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6876750588417053\n",
      "Validation loss decreased from 0.6925640431317416 to 0.6925118944861672\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6875709295272827\n",
      "Validation loss decreased from 0.6925118944861672 to 0.6924586892127991\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6874651908874512\n",
      "Validation loss decreased from 0.6924586892127991 to 0.6924047415906732\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6873589158058167\n",
      "Validation loss decreased from 0.6924047415906732 to 0.6923498619686473\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6872515678405762\n",
      "Validation loss decreased from 0.6923498619686473 to 0.6922946193001487\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6871411800384521\n",
      "Validation loss decreased from 0.6922946193001487 to 0.6922373988411643\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6870286464691162\n",
      "Validation loss decreased from 0.6922373988411643 to 0.6921786069869995\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.686914324760437\n",
      "Validation loss decreased from 0.6921786069869995 to 0.6921185796911066\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6867976784706116\n",
      "Validation loss decreased from 0.6921185796911066 to 0.6920577396046032\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6866787075996399\n",
      "Validation loss decreased from 0.6920577396046032 to 0.691996075890281\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6865590214729309\n",
      "Validation loss decreased from 0.691996075890281 to 0.6919325969435952\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6864380240440369\n",
      "Validation loss decreased from 0.6919325969435952 to 0.6918678933923895\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6863143444061279\n",
      "Validation loss decreased from 0.6918678933923895 to 0.6918015642599626\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.686186671257019\n",
      "Validation loss decreased from 0.6918015642599626 to 0.6917328942905773\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6860563158988953\n",
      "Validation loss decreased from 0.6917328942905773 to 0.6916625445539301\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6859212517738342\n",
      "Validation loss decreased from 0.6916625445539301 to 0.6915918371894143\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6857852935791016\n",
      "Validation loss decreased from 0.6915918371894143 to 0.6915199160575867\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6856498122215271\n",
      "Validation loss decreased from 0.6915199160575867 to 0.6914470195770264\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6855102777481079\n",
      "Validation loss decreased from 0.6914470195770264 to 0.6913735162128102\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6853675842285156\n",
      "Validation loss decreased from 0.6913735162128102 to 0.6912986581975763\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6852233409881592\n",
      "Validation loss decreased from 0.6912986581975763 to 0.6912226731126959\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6850776672363281\n",
      "Validation loss decreased from 0.6912226731126959 to 0.6911451166326349\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6849283576011658\n",
      "Validation loss decreased from 0.6911451166326349 to 0.6910655877806924\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6847756505012512\n",
      "Validation loss decreased from 0.6910655877806924 to 0.6909850348125804\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6846222281455994\n",
      "Validation loss decreased from 0.6909850348125804 to 0.6909032734957609\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6844672560691833\n",
      "Validation loss decreased from 0.6909032734957609 to 0.6908200329000299\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6843093633651733\n",
      "Validation loss decreased from 0.6908200329000299 to 0.6907358115369623\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6841505169868469\n",
      "Validation loss decreased from 0.6907358115369623 to 0.6906509020111777\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6839876770973206\n",
      "Validation loss decreased from 0.6906509020111777 to 0.6905636462298307\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6838197112083435\n",
      "Validation loss decreased from 0.6905636462298307 to 0.6904758431694724\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6836469173431396\n",
      "Validation loss decreased from 0.6904758431694724 to 0.6903866150162437\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6834701895713806\n",
      "Validation loss decreased from 0.6903866150162437 to 0.6902944066307761\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6832941770553589\n",
      "Validation loss decreased from 0.6902944066307761 to 0.6901995593851263\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6831203103065491\n",
      "Validation loss decreased from 0.6901995593851263 to 0.6901019757444208\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6829451322555542\n",
      "Validation loss decreased from 0.6901019757444208 to 0.6900017261505127\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6827651858329773\n",
      "Validation loss decreased from 0.6900017261505127 to 0.689897667277943\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6825807690620422\n",
      "Validation loss decreased from 0.689897667277943 to 0.6897916685451161\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6823920607566833\n",
      "Validation loss decreased from 0.6897916685451161 to 0.6896836974404075\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6822006106376648\n",
      "Validation loss decreased from 0.6896836974404075 to 0.6895735751498829\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6820037364959717\n",
      "Validation loss decreased from 0.6895735751498829 to 0.6894614913246848\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6818017959594727\n",
      "Validation loss decreased from 0.6894614913246848 to 0.6893476843833923\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6815928220748901\n",
      "Validation loss decreased from 0.6893476843833923 to 0.6892314607446844\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6813773512840271\n",
      "Validation loss decreased from 0.6892314607446844 to 0.6891127282922919\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6811586618423462\n",
      "Validation loss decreased from 0.6891127282922919 to 0.6889917146075856\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6809335947036743\n",
      "Validation loss decreased from 0.6889917146075856 to 0.6888678073883057\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6807008385658264\n",
      "Validation loss decreased from 0.6888678073883057 to 0.6887412721460516\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6804659962654114\n",
      "Validation loss decreased from 0.6887412721460516 to 0.6886111768809232\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6802241206169128\n",
      "Validation loss decreased from 0.6886111768809232 to 0.6884775920347734\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6799724698066711\n",
      "Validation loss decreased from 0.6884775920347734 to 0.6883398565379056\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6797143816947937\n",
      "Validation loss decreased from 0.6883398565379056 to 0.6881990812041543\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6794527173042297\n",
      "Validation loss decreased from 0.6881990812041543 to 0.6880553202195601\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6791840195655823\n",
      "Validation loss decreased from 0.6880553202195601 to 0.6879097494212064\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6789102554321289\n",
      "Validation loss decreased from 0.6879097494212064 to 0.6877617944370616\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6786320805549622\n",
      "Validation loss decreased from 0.6877617944370616 to 0.6876076297326521\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6783480644226074\n",
      "Validation loss decreased from 0.6876076297326521 to 0.6874487237496809\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6780579090118408\n",
      "Validation loss decreased from 0.6874487237496809 to 0.6872860843485052\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6777623295783997\n",
      "Validation loss decreased from 0.6872860843485052 to 0.6871196302500638\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.677460253238678\n",
      "Validation loss decreased from 0.6871196302500638 to 0.6869511766867205\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6771485209465027\n",
      "Validation loss decreased from 0.6869511766867205 to 0.686780799518932\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6768254041671753\n",
      "Validation loss decreased from 0.686780799518932 to 0.6866058761423285\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6764960289001465\n",
      "Validation loss decreased from 0.6866058761423285 to 0.6864233179525896\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6761566996574402\n",
      "Validation loss decreased from 0.6864233179525896 to 0.6862369775772095\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6758080124855042\n",
      "Validation loss decreased from 0.6862369775772095 to 0.6860469525510614\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6754475235939026\n",
      "Validation loss decreased from 0.6860469525510614 to 0.6858524300835349\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6750703454017639\n",
      "Validation loss decreased from 0.6858524300835349 to 0.6856531663374468\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6746832728385925\n",
      "Validation loss decreased from 0.6856531663374468 to 0.6854495460336859\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6742863655090332\n",
      "Validation loss decreased from 0.6854495460336859 to 0.6852409948002208\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6738827228546143\n",
      "Validation loss decreased from 0.6852409948002208 to 0.68502507426522\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.673468291759491\n",
      "Validation loss decreased from 0.68502507426522 to 0.6848043907772411\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6730369329452515\n",
      "Validation loss decreased from 0.6848043907772411 to 0.6845801039175554\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6725851893424988\n",
      "Validation loss decreased from 0.6845801039175554 to 0.6843487945469943\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6721175312995911\n",
      "Validation loss decreased from 0.6843487945469943 to 0.6841087991541083\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6716319918632507\n",
      "Validation loss decreased from 0.6841087991541083 to 0.6838645772500471\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6711345911026001\n",
      "Validation loss decreased from 0.6838645772500471 to 0.6836139559745789\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6706303954124451\n",
      "Validation loss decreased from 0.6836139559745789 to 0.6833575801415877\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.670108437538147\n",
      "Validation loss decreased from 0.6833575801415877 to 0.6830953305417841\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6695730686187744\n",
      "Validation loss decreased from 0.6830953305417841 to 0.6828233382918618\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6690335273742676\n",
      "Validation loss decreased from 0.6828233382918618 to 0.6825421073219993\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6684844493865967\n",
      "Validation loss decreased from 0.6825421073219993 to 0.6822566227479414\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6679224371910095\n",
      "Validation loss decreased from 0.6822566227479414 to 0.6819614768028259\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.667341947555542\n",
      "Validation loss decreased from 0.6819614768028259 to 0.6816588802771135\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6667504906654358\n",
      "Validation loss decreased from 0.6816588802771135 to 0.6813451051712036\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6661516427993774\n",
      "Validation loss decreased from 0.6813451051712036 to 0.6810233105312694\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6655261516571045\n",
      "Validation loss decreased from 0.6810233105312694 to 0.6806959293105386\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6648773550987244\n",
      "Validation loss decreased from 0.6806959293105386 to 0.6803592172535983\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6642097234725952\n",
      "Validation loss decreased from 0.6803592172535983 to 0.6800142364068464\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6635242700576782\n",
      "Validation loss decreased from 0.6800142364068464 to 0.6796541701663624\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6628290414810181\n",
      "Validation loss decreased from 0.6796541701663624 to 0.6792752255092968\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6621183753013611\n",
      "Validation loss decreased from 0.6792752255092968 to 0.6788886948065325\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6613838076591492\n",
      "Validation loss decreased from 0.6788886948065325 to 0.6784921884536743\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.660627007484436\n",
      "Validation loss decreased from 0.6784921884536743 to 0.6780851700089194\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6598368883132935\n",
      "Validation loss decreased from 0.6780851700089194 to 0.6776681704954668\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6590174436569214\n",
      "Validation loss decreased from 0.6776681704954668 to 0.6772375052625482\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6581665277481079\n",
      "Validation loss decreased from 0.6772375052625482 to 0.6767953742634166\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6572705507278442\n",
      "Validation loss decreased from 0.6767953742634166 to 0.6763456788930026\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6563448309898376\n",
      "Validation loss decreased from 0.6763456788930026 to 0.6758928244764154\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6553704738616943\n",
      "Validation loss decreased from 0.6758928244764154 to 0.6754253669218584\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6543795466423035\n",
      "Validation loss decreased from 0.6754253669218584 to 0.6749396595087919\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6533337831497192\n",
      "Validation loss decreased from 0.6749396595087919 to 0.6744305816563693\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6522831320762634\n",
      "Validation loss decreased from 0.6744305816563693 to 0.6738827607848428\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6512395739555359\n",
      "Validation loss decreased from 0.6738827607848428 to 0.6733193343335931\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6501704454421997\n",
      "Validation loss decreased from 0.6733193343335931 to 0.6727436022324995\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6490648984909058\n",
      "Validation loss decreased from 0.6727436022324995 to 0.6721493276682767\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.647916853427887\n",
      "Validation loss decreased from 0.6721493276682767 to 0.6715442538261414\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6467556357383728\n",
      "Validation loss decreased from 0.6715442538261414 to 0.6709215641021729\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6455570459365845\n",
      "Validation loss decreased from 0.6709215641021729 to 0.670276246287606\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6443271636962891\n",
      "Validation loss decreased from 0.670276246287606 to 0.6696175661954012\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6430588960647583\n",
      "Validation loss decreased from 0.6696175661954012 to 0.6689408638260581\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6417480707168579\n",
      "Validation loss decreased from 0.6689408638260581 to 0.6682436628775164\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6403886079788208\n",
      "Validation loss decreased from 0.6682436628775164 to 0.6675328124653209\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6389782428741455\n",
      "Validation loss decreased from 0.6675328124653209 to 0.666808242147619\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6375389695167542\n",
      "Validation loss decreased from 0.666808242147619 to 0.666057061065327\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6360753178596497\n",
      "Validation loss decreased from 0.666057061065327 to 0.665277443148873\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6345927119255066\n",
      "Validation loss decreased from 0.665277443148873 to 0.6644881746985696\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6330713629722595\n",
      "Validation loss decreased from 0.6644881746985696 to 0.663677762855183\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.631517767906189\n",
      "Validation loss decreased from 0.663677762855183 to 0.6628367088057778\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6299110651016235\n",
      "Validation loss decreased from 0.6628367088057778 to 0.6619654081084512\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6282549500465393\n",
      "Validation loss decreased from 0.6619654081084512 to 0.6610491600903597\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6265674829483032\n",
      "Validation loss decreased from 0.6610491600903597 to 0.6601333022117615\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6248794794082642\n",
      "Validation loss decreased from 0.6601333022117615 to 0.659197368405082\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6231649518013\n",
      "Validation loss decreased from 0.659197368405082 to 0.6582365523685109\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6214114427566528\n",
      "Validation loss decreased from 0.6582365523685109 to 0.657257844101299\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.61962890625\n",
      "Validation loss decreased from 0.657257844101299 to 0.6562511162324385\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.617847740650177\n",
      "Validation loss decreased from 0.6562511162324385 to 0.6552188775756143\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.61598801612854\n",
      "Validation loss decreased from 0.6552188775756143 to 0.6541591557589445\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6140928864479065\n",
      "Validation loss decreased from 0.6541591557589445 to 0.6530663804574446\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6121463775634766\n",
      "Validation loss decreased from 0.6530663804574446 to 0.651946793903004\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6101620197296143\n",
      "Validation loss decreased from 0.651946793903004 to 0.6508132977919145\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6081597805023193\n",
      "Validation loss decreased from 0.6508132977919145 to 0.6496504653583873\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6060960292816162\n",
      "Validation loss decreased from 0.6496504653583873 to 0.6484681313688104\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6039926409721375\n",
      "Validation loss decreased from 0.6484681313688104 to 0.6472487937320363\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6018754243850708\n",
      "Validation loss decreased from 0.6472487937320363 to 0.6459993286566301\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.5997141599655151\n",
      "Validation loss decreased from 0.6459993286566301 to 0.6447211124680259\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.5974937677383423\n",
      "Validation loss decreased from 0.6447211124680259 to 0.6434149579568342\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.5952225923538208\n",
      "Validation loss decreased from 0.6434149579568342 to 0.6420900171453302\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.5929264426231384\n",
      "Validation loss decreased from 0.6420900171453302 to 0.6407331499186429\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.5905599594116211\n",
      "Validation loss decreased from 0.6407331499186429 to 0.63936401497234\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.5881559252738953\n",
      "Validation loss decreased from 0.63936401497234 to 0.6379882747476752\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.5857216119766235\n",
      "Validation loss decreased from 0.6379882747476752 to 0.6365853277119723\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.5832298994064331\n",
      "Validation loss decreased from 0.6365853277119723 to 0.635166509584947\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.5807191133499146\n",
      "Validation loss decreased from 0.635166509584947 to 0.6337363665754144\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.5781861543655396\n",
      "Validation loss decreased from 0.6337363665754144 to 0.632285172289068\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.5755870938301086\n",
      "Validation loss decreased from 0.632285172289068 to 0.6308107972145081\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.5729618072509766\n",
      "Validation loss decreased from 0.6308107972145081 to 0.6293226697228171\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.5703349113464355\n",
      "Validation loss decreased from 0.6293226697228171 to 0.6277942494912581\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.567679226398468\n",
      "Validation loss decreased from 0.6277942494912581 to 0.6262528896331787\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.5650660395622253\n",
      "Validation loss decreased from 0.6262528896331787 to 0.6246714646166022\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.5624685287475586\n",
      "Validation loss decreased from 0.6246714646166022 to 0.623071784322912\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.5598008632659912\n",
      "Validation loss decreased from 0.623071784322912 to 0.621459885077043\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.5570865869522095\n",
      "Validation loss decreased from 0.621459885077043 to 0.6198278232054277\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.5542892217636108\n",
      "Validation loss decreased from 0.6198278232054277 to 0.6182008006355979\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.5514926314353943\n",
      "Validation loss decreased from 0.6182008006355979 to 0.6165469017895785\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.548729658126831\n",
      "Validation loss decreased from 0.6165469017895785 to 0.6148461211811412\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.545850932598114\n",
      "Validation loss decreased from 0.6148461211811412 to 0.6131716858256947\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.5429074764251709\n",
      "Validation loss decreased from 0.6131716858256947 to 0.6114695017988031\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.5399202108383179\n",
      "Validation loss decreased from 0.6114695017988031 to 0.6097620996561918\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.5369619727134705\n",
      "Validation loss decreased from 0.6097620996561918 to 0.608027994632721\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.5339102149009705\n",
      "Validation loss decreased from 0.608027994632721 to 0.606300028887662\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.5308485627174377\n",
      "Validation loss decreased from 0.606300028887662 to 0.6045704809102145\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.5277917981147766\n",
      "Validation loss decreased from 0.6045704809102145 to 0.6028170531446283\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.5246326923370361\n",
      "Validation loss decreased from 0.6028170531446283 to 0.6010606830770319\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.5214946269989014\n",
      "Validation loss decreased from 0.6010606830770319 to 0.5993210727518256\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.5182883739471436\n",
      "Validation loss decreased from 0.5993210727518256 to 0.597585613077337\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.5151330828666687\n",
      "Validation loss decreased from 0.597585613077337 to 0.5958358645439148\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.5118882060050964\n",
      "Validation loss decreased from 0.5958358645439148 to 0.5941006703810259\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.5086232423782349\n",
      "Validation loss decreased from 0.5941006703810259 to 0.5923736908219077\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.5053957104682922\n",
      "Validation loss decreased from 0.5923736908219077 to 0.5906809189102866\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.5021106004714966\n",
      "Validation loss decreased from 0.5906809189102866 to 0.5889983339743181\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.498891144990921\n",
      "Validation loss decreased from 0.5889983339743181 to 0.5873251394792036\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.49569815397262573\n",
      "Validation loss decreased from 0.5873251394792036 to 0.5856976509094238\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.4925307631492615\n",
      "Validation loss decreased from 0.5856976509094238 to 0.5840872905471108\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.48937875032424927\n",
      "Validation loss decreased from 0.5840872905471108 to 0.5825093713673678\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.48619017004966736\n",
      "Validation loss decreased from 0.5825093713673678 to 0.5809323679317128\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.4829958975315094\n",
      "Validation loss decreased from 0.5809323679317128 to 0.5793868194926869\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.47975319623947144\n",
      "Validation loss decreased from 0.5793868194926869 to 0.5778996456753124\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.47646379470825195\n",
      "Validation loss decreased from 0.5778996456753124 to 0.5764075409282338\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.47326526045799255\n",
      "Validation loss decreased from 0.5764075409282338 to 0.5749731443145059\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.47011324763298035\n",
      "Validation loss decreased from 0.5749731443145059 to 0.5735561197454279\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.46690744161605835\n",
      "Validation loss decreased from 0.5735561197454279 to 0.572155161337419\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.46371331810951233\n",
      "Validation loss decreased from 0.572155161337419 to 0.5708042003891685\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.460537314414978\n",
      "Validation loss decreased from 0.5708042003891685 to 0.5694719851016998\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.45730623602867126\n",
      "Validation loss decreased from 0.5694719851016998 to 0.5681632106954401\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.4541037082672119\n",
      "Validation loss decreased from 0.5681632106954401 to 0.5669063844464042\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.4509858191013336\n",
      "Validation loss decreased from 0.5669063844464042 to 0.5657215795733712\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.44784975051879883\n",
      "Validation loss decreased from 0.5657215795733712 to 0.5645540817217394\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.4446590542793274\n",
      "Validation loss decreased from 0.5645540817217394 to 0.5633840669285167\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.4416603446006775\n",
      "Validation loss decreased from 0.5633840669285167 to 0.5622573928399519\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.43864989280700684\n",
      "Validation loss decreased from 0.5622573928399519 to 0.5611683780496771\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.4355710744857788\n",
      "Validation loss decreased from 0.5611683780496771 to 0.5601197535341437\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.4323902726173401\n",
      "Validation loss decreased from 0.5601197535341437 to 0.5590246509421956\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.4292740225791931\n",
      "Validation loss decreased from 0.5590246509421956 to 0.5579755685546182\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.4260818064212799\n",
      "Validation loss decreased from 0.5579755685546182 to 0.5569675673138011\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.42280417680740356\n",
      "Validation loss decreased from 0.5569675673138011 to 0.5560250417752699\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.41972196102142334\n",
      "Validation loss decreased from 0.5560250417752699 to 0.5551305575804277\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.4165846109390259\n",
      "Validation loss decreased from 0.5551305575804277 to 0.5542958974838257\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.4135652780532837\n",
      "Validation loss decreased from 0.5542958974838257 to 0.5534720447930422\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.41041016578674316\n",
      "Validation loss decreased from 0.5534720447930422 to 0.552708392793482\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.40728673338890076\n",
      "Validation loss decreased from 0.552708392793482 to 0.5519287992607463\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.4040862023830414\n",
      "Validation loss decreased from 0.5519287992607463 to 0.5511949089440432\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.4008902907371521\n",
      "Validation loss decreased from 0.5511949089440432 to 0.5504621456969868\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.3976821303367615\n",
      "Validation loss decreased from 0.5504621456969868 to 0.5497679141434756\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.394706130027771\n",
      "Validation loss decreased from 0.5497679141434756 to 0.5490710274739699\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.39153531193733215\n",
      "Validation loss decreased from 0.5490710274739699 to 0.5483749508857727\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.38820648193359375\n",
      "Validation loss decreased from 0.5483749508857727 to 0.5477217950604178\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.38503292202949524\n",
      "Validation loss decreased from 0.5477217950604178 to 0.5472213165326552\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.38214465975761414\n",
      "Validation loss decreased from 0.5472213165326552 to 0.5467062998901714\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.3792250156402588\n",
      "Validation loss decreased from 0.5467062998901714 to 0.5462372411381115\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.37649810314178467\n",
      "Validation loss decreased from 0.5462372411381115 to 0.5457816259427504\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.3737620711326599\n",
      "Validation loss decreased from 0.5457816259427504 to 0.5453508496284485\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.37081053853034973\n",
      "Validation loss decreased from 0.5453508496284485 to 0.5449503876946189\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.36794355511665344\n",
      "Validation loss decreased from 0.5449503876946189 to 0.5445358102971857\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.36501672863960266\n",
      "Validation loss decreased from 0.5445358102971857 to 0.5442097051577135\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.36213022470474243\n",
      "Validation loss decreased from 0.5442097051577135 to 0.5438155586069281\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.35912638902664185\n",
      "Validation loss decreased from 0.5438155586069281 to 0.5434533086690035\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.35596904158592224\n",
      "Validation loss decreased from 0.5434533086690035 to 0.5430898639288816\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.3529166579246521\n",
      "Validation loss decreased from 0.5430898639288816 to 0.5427313528277657\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.3498673141002655\n",
      "Validation loss decreased from 0.5427313528277657 to 0.5423519638451663\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.347108393907547\n",
      "Validation loss decreased from 0.5423519638451663 to 0.5420127267187292\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.3444843888282776\n",
      "Validation loss decreased from 0.5420127267187292 to 0.5416654538024556\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.3416602313518524\n",
      "Validation loss decreased from 0.5416654538024556 to 0.5413257777690887\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.338951975107193\n",
      "Validation loss decreased from 0.5413257777690887 to 0.5410409759391438\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.3361366093158722\n",
      "Validation loss decreased from 0.5410409759391438 to 0.5407650687477805\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.3333851397037506\n",
      "Validation loss decreased from 0.5407650687477805 to 0.5405596088279377\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.3305494785308838\n",
      "Validation loss decreased from 0.5405596088279377 to 0.540369448336688\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.32773450016975403\n",
      "Validation loss decreased from 0.540369448336688 to 0.5401392010125247\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.3250807523727417\n",
      "Validation loss decreased from 0.5401392010125247 to 0.5399643209847537\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.3223892152309418\n",
      "Validation loss decreased from 0.5399643209847537 to 0.5397490100427107\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.31979039311408997\n",
      "Validation loss decreased from 0.5397490100427107 to 0.5396342114968733\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.3169873058795929\n",
      "Validation loss decreased from 0.5396342114968733 to 0.5394327152859081\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.31411677598953247\n",
      "Validation loss decreased from 0.5394327152859081 to 0.5392375805161216\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.3115471303462982\n",
      "Validation loss decreased from 0.5392375805161216 to 0.5392034297639673\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.30881160497665405\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.3059811294078827\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.3032887876033783\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.30048590898513794\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.2976803183555603\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.2947861850261688\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.2921125888824463\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.2895275056362152\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.28669771552085876\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.2838640809059143\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.2809171676635742\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.27811694145202637\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.2753831446170807\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.2726402282714844\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.2697669565677643\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.2670738101005554\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.26428326964378357\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.26149195432662964\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.2587748169898987\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.2561245858669281\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.2533564567565918\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.25037261843681335\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.24752794206142426\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.24506500363349915\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.24237167835235596\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.23974762856960297\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.23717211186885834\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.23466703295707703\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.2322263866662979\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.2296876162290573\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.22722160816192627\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.22458495199680328\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.22207330167293549\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.2195558249950409\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.21707625687122345\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.2148025631904602\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.21228599548339844\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.2100546956062317\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.20760393142700195\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.20532462000846863\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.2030532956123352\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.20068377256393433\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.19829462468624115\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.1957678198814392\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.19354920089244843\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.19139955937862396\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.18909992277622223\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.18686552345752716\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.18471366167068481\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.18244525790214539\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  305\n",
      "AUC on test data  0.7965704117123675\n",
      "model 37 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6909703016281128\n",
      "Validation loss decreased from inf to 0.696974288333546\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6909698247909546\n",
      "Validation loss decreased from 0.696974288333546 to 0.6969670165668834\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6909693479537964\n",
      "Validation loss decreased from 0.6969670165668834 to 0.6969595876607028\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.690968930721283\n",
      "Validation loss decreased from 0.6969595876607028 to 0.6969521858475425\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6909684538841248\n",
      "Validation loss decreased from 0.6969521858475425 to 0.6969448165460066\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6909679174423218\n",
      "Validation loss decreased from 0.6969448165460066 to 0.696937463500283\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6909675002098083\n",
      "Validation loss decreased from 0.696937463500283 to 0.6969301429661837\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6909670233726501\n",
      "Validation loss decreased from 0.6969301429661837 to 0.6969228711995211\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6909664869308472\n",
      "Validation loss decreased from 0.6969228711995211 to 0.6969156482002952\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.690966010093689\n",
      "Validation loss decreased from 0.6969156482002952 to 0.6969084306196733\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6909655332565308\n",
      "Validation loss decreased from 0.6969084306196733 to 0.6969012672250922\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6909651160240173\n",
      "Validation loss decreased from 0.6969012672250922 to 0.6968941309235313\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6909646391868591\n",
      "Validation loss decreased from 0.6968941309235313 to 0.6968870271335948\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6909641623497009\n",
      "Validation loss decreased from 0.6968870271335948 to 0.6968799558552828\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6909637451171875\n",
      "Validation loss decreased from 0.6968799558552828 to 0.6968729170885953\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6909633278846741\n",
      "Validation loss decreased from 0.6968729170885953 to 0.6968659108335321\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6909627914428711\n",
      "Validation loss decreased from 0.6968659108335321 to 0.6968589587645098\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6909624338150024\n",
      "Validation loss decreased from 0.6968589587645098 to 0.696852055462924\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6909619569778442\n",
      "Validation loss decreased from 0.696852055462924 to 0.6968451792543585\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.690961480140686\n",
      "Validation loss decreased from 0.6968451792543585 to 0.6968383301388134\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6909610629081726\n",
      "Validation loss decreased from 0.6968383301388134 to 0.696831535209309\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6909605860710144\n",
      "Validation loss decreased from 0.696831535209309 to 0.6968247782100331\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6909601092338562\n",
      "Validation loss decreased from 0.6968247782100331 to 0.6968180212107572\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6909596920013428\n",
      "Validation loss decreased from 0.6968180212107572 to 0.6968113238161261\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6909591555595398\n",
      "Validation loss decreased from 0.6968113238161261 to 0.6968046697703275\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6909586191177368\n",
      "Validation loss decreased from 0.6968046697703275 to 0.6967980428175493\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6909580826759338\n",
      "Validation loss decreased from 0.6967980428175493 to 0.6967914592136036\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6909576058387756\n",
      "Validation loss decreased from 0.6967914592136036 to 0.6967849135398865\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6909570097923279\n",
      "Validation loss decreased from 0.6967849135398865 to 0.6967783949591897\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6909565329551697\n",
      "Validation loss decreased from 0.6967783949591897 to 0.6967719251459296\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6909559965133667\n",
      "Validation loss decreased from 0.6967719251459296 to 0.6967654932628978\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6909554600715637\n",
      "Validation loss decreased from 0.6967654932628978 to 0.6967590830542825\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6909549236297607\n",
      "Validation loss decreased from 0.6967590830542825 to 0.6967526999386874\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6909543871879578\n",
      "Validation loss decreased from 0.6967526999386874 to 0.696746365590529\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6909538507461548\n",
      "Validation loss decreased from 0.696746365590529 to 0.696740063753995\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6909533739089966\n",
      "Validation loss decreased from 0.696740063753995 to 0.6967337456616488\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6909528374671936\n",
      "Validation loss decreased from 0.6967337456616488 to 0.6967275034297596\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6909523010253906\n",
      "Validation loss decreased from 0.6967275034297596 to 0.6967212774536826\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6909518241882324\n",
      "Validation loss decreased from 0.6967212774536826 to 0.6967150839892301\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6909512877464294\n",
      "Validation loss decreased from 0.6967150839892301 to 0.6967089121991937\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6909507513046265\n",
      "Validation loss decreased from 0.6967089121991937 to 0.696702778339386\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6909503936767578\n",
      "Validation loss decreased from 0.696702778339386 to 0.6966966769912026\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6909497380256653\n",
      "Validation loss decreased from 0.6966966769912026 to 0.6966905973174355\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6909491419792175\n",
      "Validation loss decreased from 0.6966905973174355 to 0.696684560992501\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6909485459327698\n",
      "Validation loss decreased from 0.696684560992501 to 0.6966785734350031\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.690947949886322\n",
      "Validation loss decreased from 0.6966785734350031 to 0.6966726021333174\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.690947413444519\n",
      "Validation loss decreased from 0.6966726021333174 to 0.6966666850176725\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6909467577934265\n",
      "Validation loss decreased from 0.6966666850176725 to 0.6966607949950478\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6909461617469788\n",
      "Validation loss decreased from 0.6966607949950478 to 0.6966549212282355\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.690945565700531\n",
      "Validation loss decreased from 0.6966549212282355 to 0.6966490691358392\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6909449696540833\n",
      "Validation loss decreased from 0.6966490691358392 to 0.6966432658108798\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6909443140029907\n",
      "Validation loss decreased from 0.6966432658108798 to 0.6966374787417325\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6909437775611877\n",
      "Validation loss decreased from 0.6966374787417325 to 0.6966317187656056\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6909433007240295\n",
      "Validation loss decreased from 0.6966317187656056 to 0.6966259967197072\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6909428238868713\n",
      "Validation loss decreased from 0.6966259967197072 to 0.6966202638366006\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6909422874450684\n",
      "Validation loss decreased from 0.6966202638366006 to 0.6966145688837225\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6909417510032654\n",
      "Validation loss decreased from 0.6966145688837225 to 0.6966088901866566\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6909412145614624\n",
      "Validation loss decreased from 0.6966088901866566 to 0.6966032602570273\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6909407377243042\n",
      "Validation loss decreased from 0.6966032602570273 to 0.6965976411646063\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6909402012825012\n",
      "Validation loss decreased from 0.6965976411646063 to 0.6965920491652056\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.690939724445343\n",
      "Validation loss decreased from 0.6965920491652056 to 0.6965865059332415\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6909391283988953\n",
      "Validation loss decreased from 0.6965865059332415 to 0.6965809952129017\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6909385919570923\n",
      "Validation loss decreased from 0.6965809952129017 to 0.6965755170041864\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6909380555152893\n",
      "Validation loss decreased from 0.6965755170041864 to 0.6965700604698875\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6909374594688416\n",
      "Validation loss decreased from 0.6965700604698875 to 0.6965646364472129\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6909368634223938\n",
      "Validation loss decreased from 0.6965646364472129 to 0.696559261191975\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6909363269805908\n",
      "Validation loss decreased from 0.696559261191975 to 0.6965539076111533\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6909357905387878\n",
      "Validation loss decreased from 0.6965539076111533 to 0.6965485702861439\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6909352540969849\n",
      "Validation loss decreased from 0.6965485702861439 to 0.6965432383797385\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6909347176551819\n",
      "Validation loss decreased from 0.6965432383797385 to 0.6965379552407698\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6909341812133789\n",
      "Validation loss decreased from 0.6965379552407698 to 0.6965326937762174\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6909336447715759\n",
      "Validation loss decreased from 0.6965326937762174 to 0.6965274268930609\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6909330487251282\n",
      "Validation loss decreased from 0.6965274268930609 to 0.6965222196145491\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6909325122833252\n",
      "Validation loss decreased from 0.6965222196145491 to 0.6965170285918496\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6909319758415222\n",
      "Validation loss decreased from 0.6965170285918496 to 0.696511832150546\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6909313797950745\n",
      "Validation loss decreased from 0.696511832150546 to 0.6965066519650546\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6909307837486267\n",
      "Validation loss decreased from 0.6965066519650546 to 0.696501531384208\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6909302473068237\n",
      "Validation loss decreased from 0.696501531384208 to 0.6964964487335898\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6909297108650208\n",
      "Validation loss decreased from 0.6964964487335898 to 0.6964913335713473\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6909291744232178\n",
      "Validation loss decreased from 0.6964913335713473 to 0.6964862509207292\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6909286975860596\n",
      "Validation loss decreased from 0.6964862509207292 to 0.6964811791073192\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6909281015396118\n",
      "Validation loss decreased from 0.6964811791073192 to 0.6964761398055337\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6909276247024536\n",
      "Validation loss decreased from 0.6964761398055337 to 0.6964711221781644\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6909272074699402\n",
      "Validation loss decreased from 0.6964711221781644 to 0.6964661262252114\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6909266710281372\n",
      "Validation loss decreased from 0.6964661262252114 to 0.6964611519466747\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6909262537956238\n",
      "Validation loss decreased from 0.6964611519466747 to 0.6964562047611583\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6909258961677551\n",
      "Validation loss decreased from 0.6964562047611583 to 0.6964512738314542\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6909255981445312\n",
      "Validation loss decreased from 0.6964512738314542 to 0.6964463754133745\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6909251809120178\n",
      "Validation loss decreased from 0.6964463754133745 to 0.6964415095069192\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6909247040748596\n",
      "Validation loss decreased from 0.6964415095069192 to 0.6964366652748801\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6909242868423462\n",
      "Validation loss decreased from 0.6964366652748801 to 0.6964318535544656\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6909238696098328\n",
      "Validation loss decreased from 0.6964318535544656 to 0.6964270309968428\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6909234523773193\n",
      "Validation loss decreased from 0.6964270309968428 to 0.6964222572066567\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6909230351448059\n",
      "Validation loss decreased from 0.6964222572066567 to 0.6964174671606584\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6909226179122925\n",
      "Validation loss decreased from 0.6964174671606584 to 0.6964127150448886\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6909221410751343\n",
      "Validation loss decreased from 0.6964127150448886 to 0.6964080008593473\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6909217238426208\n",
      "Validation loss decreased from 0.6964080008593473 to 0.6964032595807855\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6909212470054626\n",
      "Validation loss decreased from 0.6964032595807855 to 0.6963985616510565\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6909207701683044\n",
      "Validation loss decreased from 0.6963985616510565 to 0.6963939016515558\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6909202933311462\n",
      "Validation loss decreased from 0.6963939016515558 to 0.6963892470706593\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6909197568893433\n",
      "Validation loss decreased from 0.6963892470706593 to 0.6963846141641791\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6909193396568298\n",
      "Validation loss decreased from 0.6963846141641791 to 0.696379997513511\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6909189224243164\n",
      "Validation loss decreased from 0.696379997513511 to 0.6963754079558633\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6909184455871582\n",
      "Validation loss decreased from 0.6963754079558633 to 0.6963708346540277\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.69091796875\n",
      "Validation loss decreased from 0.6963708346540277 to 0.6963662992824208\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6909174919128418\n",
      "Validation loss decreased from 0.6963662992824208 to 0.6963617584922097\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6909170150756836\n",
      "Validation loss decreased from 0.6963617584922097 to 0.6963572231206027\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6909166574478149\n",
      "Validation loss decreased from 0.6963572231206027 to 0.6963527256792242\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.690916121006012\n",
      "Validation loss decreased from 0.6963527256792242 to 0.6963482336564497\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6909157037734985\n",
      "Validation loss decreased from 0.6963482336564497 to 0.6963437795639038\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6909151077270508\n",
      "Validation loss decreased from 0.6963437795639038 to 0.6963393092155457\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6909146308898926\n",
      "Validation loss decreased from 0.6963393092155457 to 0.6963348713788119\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6909141540527344\n",
      "Validation loss decreased from 0.6963348713788119 to 0.6963304443792864\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6909136176109314\n",
      "Validation loss decreased from 0.6963304443792864 to 0.6963260282169689\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6909131407737732\n",
      "Validation loss decreased from 0.6963260282169689 to 0.6963216445662759\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6909126043319702\n",
      "Validation loss decreased from 0.6963216445662759 to 0.696317277171395\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6909120678901672\n",
      "Validation loss decreased from 0.696317277171395 to 0.6963129260323264\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6909115314483643\n",
      "Validation loss decreased from 0.6963129260323264 to 0.6963086019862782\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6909109950065613\n",
      "Validation loss decreased from 0.6963086019862782 to 0.6963043050332502\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6909103989601135\n",
      "Validation loss decreased from 0.6963043050332502 to 0.6963000189174305\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6909098625183105\n",
      "Validation loss decreased from 0.6963000189174305 to 0.6962957219644026\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6909093260765076\n",
      "Validation loss decreased from 0.6962957219644026 to 0.6962914846160195\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6909087300300598\n",
      "Validation loss decreased from 0.6962914846160195 to 0.6962872364304282\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6909081935882568\n",
      "Validation loss decreased from 0.6962872364304282 to 0.6962830207564614\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6909076571464539\n",
      "Validation loss decreased from 0.6962830207564614 to 0.6962788105010986\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6909071207046509\n",
      "Validation loss decreased from 0.6962788105010986 to 0.6962746598503806\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6909065842628479\n",
      "Validation loss decreased from 0.6962746598503806 to 0.6962705091996626\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6909060478210449\n",
      "Validation loss decreased from 0.6962705091996626 to 0.6962663748047568\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6909055709838867\n",
      "Validation loss decreased from 0.6962663748047568 to 0.6962622566656633\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6909051537513733\n",
      "Validation loss decreased from 0.6962622566656633 to 0.6962581764567982\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6909046173095703\n",
      "Validation loss decreased from 0.6962581764567982 to 0.6962541070851412\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6909042000770569\n",
      "Validation loss decreased from 0.6962541070851412 to 0.6962500377134844\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6909036636352539\n",
      "Validation loss decreased from 0.6962500377134844 to 0.6962460008534518\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6909032464027405\n",
      "Validation loss decreased from 0.6962460008534518 to 0.6962419965050437\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6909027099609375\n",
      "Validation loss decreased from 0.6962419965050437 to 0.6962379704822194\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6909021735191345\n",
      "Validation loss decreased from 0.6962379704822194 to 0.6962339878082275\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6909016370773315\n",
      "Validation loss decreased from 0.6962339878082275 to 0.6962299888784235\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6909010410308838\n",
      "Validation loss decreased from 0.6962299888784235 to 0.6962260224602439\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.690900444984436\n",
      "Validation loss decreased from 0.6962260224602439 to 0.6962220777164806\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6908999085426331\n",
      "Validation loss decreased from 0.6962220777164806 to 0.6962181221355092\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6908993721008301\n",
      "Validation loss decreased from 0.6962181221355092 to 0.6962142099033702\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6908987760543823\n",
      "Validation loss decreased from 0.6962142099033702 to 0.6962103247642517\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6908981800079346\n",
      "Validation loss decreased from 0.6962103247642517 to 0.6962064179507169\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6908976435661316\n",
      "Validation loss decreased from 0.6962064179507169 to 0.6962025599046187\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6908970475196838\n",
      "Validation loss decreased from 0.6962025599046187 to 0.6961986964399164\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6908964514732361\n",
      "Validation loss decreased from 0.6961986964399164 to 0.6961948709054426\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6908959150314331\n",
      "Validation loss decreased from 0.6961948709054426 to 0.6961910399523649\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6908953785896301\n",
      "Validation loss decreased from 0.6961910399523649 to 0.6961872415109114\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6908948421478271\n",
      "Validation loss decreased from 0.6961872415109114 to 0.6961834701624784\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6908943057060242\n",
      "Validation loss decreased from 0.6961834701624784 to 0.6961796988140453\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6908937096595764\n",
      "Validation loss decreased from 0.6961796988140453 to 0.6961759545586326\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6908930540084839\n",
      "Validation loss decreased from 0.6961759545586326 to 0.6961722265590321\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6908925175666809\n",
      "Validation loss decreased from 0.6961722265590321 to 0.6961685202338479\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6908919811248779\n",
      "Validation loss decreased from 0.6961685202338479 to 0.6961648572574962\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6908913254737854\n",
      "Validation loss decreased from 0.6961648572574962 to 0.6961611834439364\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6908906698226929\n",
      "Validation loss decreased from 0.6961611834439364 to 0.6961575150489807\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6908899545669556\n",
      "Validation loss decreased from 0.6961575150489807 to 0.696153852072629\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6908893585205078\n",
      "Validation loss decreased from 0.696153852072629 to 0.6961502216079019\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6908886432647705\n",
      "Validation loss decreased from 0.6961502216079019 to 0.6961466128175909\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6908879280090332\n",
      "Validation loss decreased from 0.6961466128175909 to 0.6961430257016962\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6908873319625854\n",
      "Validation loss decreased from 0.6961430257016962 to 0.6961394114927812\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6908866763114929\n",
      "Validation loss decreased from 0.6961394114927812 to 0.696135862307115\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6908859610557556\n",
      "Validation loss decreased from 0.696135862307115 to 0.6961322968656366\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6908853054046631\n",
      "Validation loss decreased from 0.6961322968656366 to 0.6961287639357827\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6908846497535706\n",
      "Validation loss decreased from 0.6961287639357827 to 0.6961252364245328\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.690883994102478\n",
      "Validation loss decreased from 0.6961252364245328 to 0.6961216926574707\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6908832788467407\n",
      "Validation loss decreased from 0.6961216926574707 to 0.6961182084950533\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6908826231956482\n",
      "Validation loss decreased from 0.6961182084950533 to 0.6961147351698442\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6908819675445557\n",
      "Validation loss decreased from 0.6961147351698442 to 0.6961112781004473\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6908813118934631\n",
      "Validation loss decreased from 0.6961112781004473 to 0.6961078427054666\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6908806562423706\n",
      "Validation loss decreased from 0.6961078427054666 to 0.6961044289849021\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6908799409866333\n",
      "Validation loss decreased from 0.6961044289849021 to 0.6961009990085255\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6908792853355408\n",
      "Validation loss decreased from 0.6961009990085255 to 0.6960976232181896\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6908786296844482\n",
      "Validation loss decreased from 0.6960976232181896 to 0.6960942474278536\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6908779740333557\n",
      "Validation loss decreased from 0.6960942474278536 to 0.6960908662189137\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6908772587776184\n",
      "Validation loss decreased from 0.6960908662189137 to 0.6960875229402022\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6908766031265259\n",
      "Validation loss decreased from 0.6960875229402022 to 0.6960842067545111\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6908759474754333\n",
      "Validation loss decreased from 0.6960842067545111 to 0.6960808905688199\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6908752918243408\n",
      "Validation loss decreased from 0.6960808905688199 to 0.696077596057545\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6908746361732483\n",
      "Validation loss decreased from 0.696077596057545 to 0.6960743123834784\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.690873920917511\n",
      "Validation loss decreased from 0.6960743123834784 to 0.6960710341280157\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6908732652664185\n",
      "Validation loss decreased from 0.6960710341280157 to 0.6960677721283652\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6908726096153259\n",
      "Validation loss decreased from 0.6960677721283652 to 0.6960645643147555\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6908719539642334\n",
      "Validation loss decreased from 0.6960645643147555 to 0.6960613239895214\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6908712387084961\n",
      "Validation loss decreased from 0.6960613239895214 to 0.6960581215945157\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.690870463848114\n",
      "Validation loss decreased from 0.6960581215945157 to 0.6960549246181141\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.690869927406311\n",
      "Validation loss decreased from 0.6960549246181141 to 0.6960517438975248\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6908692121505737\n",
      "Validation loss decreased from 0.6960517438975248 to 0.6960485902699557\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6908684372901917\n",
      "Validation loss decreased from 0.6960485902699557 to 0.6960454258051786\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6908677220344543\n",
      "Validation loss decreased from 0.6960454258051786 to 0.6960422992706299\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6908668875694275\n",
      "Validation loss decreased from 0.6960422992706299 to 0.6960391889918934\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.690866231918335\n",
      "Validation loss decreased from 0.6960391889918934 to 0.6960360949689691\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6908655166625977\n",
      "Validation loss decreased from 0.6960360949689691 to 0.696033011783253\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6908648610115051\n",
      "Validation loss decreased from 0.696033011783253 to 0.6960299502719532\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6908641457557678\n",
      "Validation loss decreased from 0.6960299502719532 to 0.6960268887606534\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6908634901046753\n",
      "Validation loss decreased from 0.6960268887606534 to 0.6960238489237699\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.690862774848938\n",
      "Validation loss decreased from 0.6960238489237699 to 0.6960208199240945\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6908621191978455\n",
      "Validation loss decreased from 0.6960208199240945 to 0.6960178017616272\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6908613443374634\n",
      "Validation loss decreased from 0.6960178017616272 to 0.696014794436368\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6908606886863708\n",
      "Validation loss decreased from 0.696014794436368 to 0.6960118142041293\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6908600330352783\n",
      "Validation loss decreased from 0.6960118142041293 to 0.6960088285532865\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6908592581748962\n",
      "Validation loss decreased from 0.6960088285532865 to 0.6960058862512762\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6908585429191589\n",
      "Validation loss decreased from 0.6960058862512762 to 0.6960029439492659\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6908578872680664\n",
      "Validation loss decreased from 0.6960029439492659 to 0.6960000179030679\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6908572316169739\n",
      "Validation loss decreased from 0.6960000179030679 to 0.6959971406243064\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6908565163612366\n",
      "Validation loss decreased from 0.6959971406243064 to 0.695994268764149\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.690855860710144\n",
      "Validation loss decreased from 0.695994268764149 to 0.6959913969039917\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6908551454544067\n",
      "Validation loss decreased from 0.6959913969039917 to 0.6959885629740629\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6908544898033142\n",
      "Validation loss decreased from 0.6959885629740629 to 0.6959857236255299\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6908537149429321\n",
      "Validation loss decreased from 0.6959857236255299 to 0.6959829005328092\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6908530592918396\n",
      "Validation loss decreased from 0.6959829005328092 to 0.6959800936959006\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6908524036407471\n",
      "Validation loss decreased from 0.6959800936959006 to 0.6959772814403881\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6908517479896545\n",
      "Validation loss decreased from 0.6959772814403881 to 0.6959745016964999\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6908510327339172\n",
      "Validation loss decreased from 0.6959745016964999 to 0.6959717544642362\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6908502578735352\n",
      "Validation loss decreased from 0.6959717544642362 to 0.6959689638831399\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6908496022224426\n",
      "Validation loss decreased from 0.6959689638831399 to 0.6959661787206476\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6908488869667053\n",
      "Validation loss decreased from 0.6959661787206476 to 0.6959634585814043\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.690848171710968\n",
      "Validation loss decreased from 0.6959634585814043 to 0.695960749279369\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6908475160598755\n",
      "Validation loss decreased from 0.695960749279369 to 0.6959580453959379\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.690846860408783\n",
      "Validation loss decreased from 0.6959580453959379 to 0.6959553306752985\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6908461451530457\n",
      "Validation loss decreased from 0.6959553306752985 to 0.6959526213732633\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6908454298973083\n",
      "Validation loss decreased from 0.6959526213732633 to 0.6959499229084362\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6908447742462158\n",
      "Validation loss decreased from 0.6959499229084362 to 0.6959472406994213\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6908439993858337\n",
      "Validation loss decreased from 0.6959472406994213 to 0.6959445639090105\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6908432841300964\n",
      "Validation loss decreased from 0.6959445639090105 to 0.6959419304674322\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6908425092697144\n",
      "Validation loss decreased from 0.6959419304674322 to 0.6959392807700417\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.690841794013977\n",
      "Validation loss decreased from 0.6959392807700417 to 0.6959366635842756\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6908410787582397\n",
      "Validation loss decreased from 0.6959366635842756 to 0.6959340301426974\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6908403635025024\n",
      "Validation loss decreased from 0.6959340301426974 to 0.6959314454685558\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6908396482467651\n",
      "Validation loss decreased from 0.6959314454685558 to 0.6959288282827898\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6908389925956726\n",
      "Validation loss decreased from 0.6959288282827898 to 0.6959262381900441\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6908382773399353\n",
      "Validation loss decreased from 0.6959262381900441 to 0.6959236372600902\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6908375024795532\n",
      "Validation loss decreased from 0.6959236372600902 to 0.695921085097573\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6908368468284607\n",
      "Validation loss decreased from 0.695921085097573 to 0.6959185220978477\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6908361315727234\n",
      "Validation loss decreased from 0.6959185220978477 to 0.6959159861911427\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6908354163169861\n",
      "Validation loss decreased from 0.6959159861911427 to 0.6959134394472296\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6908347010612488\n",
      "Validation loss decreased from 0.6959134394472296 to 0.6959109197963368\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6908340454101562\n",
      "Validation loss decreased from 0.6959109197963368 to 0.6959084218198602\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6908333897590637\n",
      "Validation loss decreased from 0.6959084218198602 to 0.6959058913317594\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6908327341079712\n",
      "Validation loss decreased from 0.6959058913317594 to 0.6959033879366788\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6908320188522339\n",
      "Validation loss decreased from 0.6959033879366788 to 0.6959008899602023\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6908313632011414\n",
      "Validation loss decreased from 0.6959008899602023 to 0.695898408239538\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6908307075500488\n",
      "Validation loss decreased from 0.695898408239538 to 0.6958959265188738\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6908301115036011\n",
      "Validation loss decreased from 0.6958959265188738 to 0.6958934773098339\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.690829336643219\n",
      "Validation loss decreased from 0.6958934773098339 to 0.6958910443566062\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6908286809921265\n",
      "Validation loss decreased from 0.6958910443566062 to 0.6958886330777948\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6908280849456787\n",
      "Validation loss decreased from 0.6958886330777948 to 0.6958862326361916\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.690827488899231\n",
      "Validation loss decreased from 0.6958862326361916 to 0.6958837942643599\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6908267736434937\n",
      "Validation loss decreased from 0.6958837942643599 to 0.6958814100785689\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6908260583877563\n",
      "Validation loss decreased from 0.6958814100785689 to 0.6958790421485901\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6908254623413086\n",
      "Validation loss decreased from 0.6958790421485901 to 0.695876652544195\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.6908248066902161\n",
      "Validation loss decreased from 0.695876652544195 to 0.6958742737770081\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6908241510391235\n",
      "Validation loss decreased from 0.6958742737770081 to 0.6958719166842374\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6908234357833862\n",
      "Validation loss decreased from 0.6958719166842374 to 0.6958695541728627\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6908227801322937\n",
      "Validation loss decreased from 0.6958695541728627 to 0.6958672079173002\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6908221244812012\n",
      "Validation loss decreased from 0.6958672079173002 to 0.6958648670803417\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6908214092254639\n",
      "Validation loss decreased from 0.6958648670803417 to 0.6958625424991954\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6908206939697266\n",
      "Validation loss decreased from 0.6958625424991954 to 0.6958602450110696\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6908198595046997\n",
      "Validation loss decreased from 0.6958602450110696 to 0.6958579150113192\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6908191442489624\n",
      "Validation loss decreased from 0.6958579150113192 to 0.695855590430173\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6908183693885803\n",
      "Validation loss decreased from 0.695855590430173 to 0.695853287523443\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6908177137374878\n",
      "Validation loss decreased from 0.695853287523443 to 0.6958509846167131\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6908169984817505\n",
      "Validation loss decreased from 0.6958509846167131 to 0.6958486979657953\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6908162236213684\n",
      "Validation loss decreased from 0.6958486979657953 to 0.6958464221520857\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6908154487609863\n",
      "Validation loss decreased from 0.6958464221520857 to 0.6958441788500006\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6908147931098938\n",
      "Validation loss decreased from 0.6958441788500006 to 0.6958419301293113\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6908140182495117\n",
      "Validation loss decreased from 0.6958419301293113 to 0.6958396922458302\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6908133029937744\n",
      "Validation loss decreased from 0.6958396922458302 to 0.6958374381065369\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6908126473426819\n",
      "Validation loss decreased from 0.6958374381065369 to 0.6958352002230558\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6908118724822998\n",
      "Validation loss decreased from 0.6958352002230558 to 0.6958329352465543\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6908111572265625\n",
      "Validation loss decreased from 0.6958329352465543 to 0.6958307136188854\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6908104419708252\n",
      "Validation loss decreased from 0.6958307136188854 to 0.6958284757354043\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6908096671104431\n",
      "Validation loss decreased from 0.6958284757354043 to 0.6958262432705272\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6908089518547058\n",
      "Validation loss decreased from 0.6958262432705272 to 0.6958240108056502\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6908082365989685\n",
      "Validation loss decreased from 0.6958240108056502 to 0.6958217837593772\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6908074021339417\n",
      "Validation loss decreased from 0.6958217837593772 to 0.6958195621317084\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6908067464828491\n",
      "Validation loss decreased from 0.6958195621317084 to 0.6958173675970598\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.690805971622467\n",
      "Validation loss decreased from 0.6958173675970598 to 0.6958151784810153\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.690805196762085\n",
      "Validation loss decreased from 0.6958151784810153 to 0.6958129839463667\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6908044815063477\n",
      "Validation loss decreased from 0.6958129839463667 to 0.6958108056675304\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6908037066459656\n",
      "Validation loss decreased from 0.6958108056675304 to 0.6958086490631104\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6908029913902283\n",
      "Validation loss decreased from 0.6958086490631104 to 0.6958064978772943\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6908022165298462\n",
      "Validation loss decreased from 0.6958064978772943 to 0.6958043087612499\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6908014416694641\n",
      "Validation loss decreased from 0.6958043087612499 to 0.6958021738312461\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6908007264137268\n",
      "Validation loss decreased from 0.6958021738312461 to 0.6958000226454302\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6908000111579895\n",
      "Validation loss decreased from 0.6958000226454302 to 0.6957979256456549\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6907992362976074\n",
      "Validation loss decreased from 0.6957979256456549 to 0.6957958178086714\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6907984614372253\n",
      "Validation loss decreased from 0.6957958178086714 to 0.6957937424833124\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6907976865768433\n",
      "Validation loss decreased from 0.6957937424833124 to 0.6957916834137656\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.690796971321106\n",
      "Validation loss decreased from 0.6957916834137656 to 0.6957896026698026\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6907961964607239\n",
      "Validation loss decreased from 0.6957896026698026 to 0.6957875219258395\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.690795361995697\n",
      "Validation loss decreased from 0.6957875219258395 to 0.6957854628562927\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6907946467399597\n",
      "Validation loss decreased from 0.6957854628562927 to 0.6957833983681418\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6907938718795776\n",
      "Validation loss decreased from 0.6957833983681418 to 0.6957813447171991\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6907930970191956\n",
      "Validation loss decreased from 0.6957813447171991 to 0.6957793181592767\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6907922625541687\n",
      "Validation loss decreased from 0.6957793181592767 to 0.6957772699269381\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6907915472984314\n",
      "Validation loss decreased from 0.6957772699269381 to 0.6957752379504117\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6907908320426941\n",
      "Validation loss decreased from 0.6957752379504117 to 0.6957732005552812\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6907899379730225\n",
      "Validation loss decreased from 0.6957732005552812 to 0.6957711739973589\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6907891631126404\n",
      "Validation loss decreased from 0.6957711739973589 to 0.6957691636952487\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6907882690429688\n",
      "Validation loss decreased from 0.6957691636952487 to 0.6957671317187223\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6907874941825867\n",
      "Validation loss decreased from 0.6957671317187223 to 0.6957651430910284\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.690786600112915\n",
      "Validation loss decreased from 0.6957651430910284 to 0.6957631653005426\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6907857060432434\n",
      "Validation loss decreased from 0.6957631653005426 to 0.6957611712542447\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6907849311828613\n",
      "Validation loss decreased from 0.6957611712542447 to 0.6957591826265509\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6907840371131897\n",
      "Validation loss decreased from 0.6957591826265509 to 0.6957572319290855\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6907832026481628\n",
      "Validation loss decreased from 0.6957572319290855 to 0.6957552595572039\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6907823085784912\n",
      "Validation loss decreased from 0.6957552595572039 to 0.6957532871853221\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6907814741134644\n",
      "Validation loss decreased from 0.6957532871853221 to 0.6957513364878568\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6907806396484375\n",
      "Validation loss decreased from 0.6957513364878568 to 0.6957493857903914\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6907796859741211\n",
      "Validation loss decreased from 0.6957493857903914 to 0.6957474459301342\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.690778911113739\n",
      "Validation loss decreased from 0.6957474459301342 to 0.6957455223256891\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6907779574394226\n",
      "Validation loss decreased from 0.6957455223256891 to 0.6957435770468279\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6907771825790405\n",
      "Validation loss decreased from 0.6957435770468279 to 0.6957416751167991\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6907763481140137\n",
      "Validation loss decreased from 0.6957416751167991 to 0.6957397786053744\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.690775454044342\n",
      "Validation loss decreased from 0.6957397786053744 to 0.6957378712567416\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6907746195793152\n",
      "Validation loss decreased from 0.6957378712567416 to 0.6957359910011292\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6907737255096436\n",
      "Validation loss decreased from 0.6957359910011292 to 0.6957341540943492\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6907728910446167\n",
      "Validation loss decreased from 0.6957341540943492 to 0.6957323280247775\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6907719969749451\n",
      "Validation loss decreased from 0.6957323280247775 to 0.6957304640249773\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6907711625099182\n",
      "Validation loss decreased from 0.6957304640249773 to 0.6957286108623851\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6907702684402466\n",
      "Validation loss decreased from 0.6957286108623851 to 0.6957267739556052\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.690769374370575\n",
      "Validation loss decreased from 0.6957267739556052 to 0.6957249370488253\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6907685995101929\n",
      "Validation loss decreased from 0.6957249370488253 to 0.6957231163978577\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6907676458358765\n",
      "Validation loss decreased from 0.6957231163978577 to 0.6957213120027022\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6907667517662048\n",
      "Validation loss decreased from 0.6957213120027022 to 0.6957194805145264\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6907657980918884\n",
      "Validation loss decreased from 0.6957194805145264 to 0.695717681537975\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6907649636268616\n",
      "Validation loss decreased from 0.695717681537975 to 0.6957158933986317\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6907640695571899\n",
      "Validation loss decreased from 0.6957158933986317 to 0.6957140998406843\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6907631158828735\n",
      "Validation loss decreased from 0.6957140998406843 to 0.6957123062827371\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6907621622085571\n",
      "Validation loss decreased from 0.6957123062827371 to 0.6957105181433938\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6907613277435303\n",
      "Validation loss decreased from 0.6957105181433938 to 0.6957087516784668\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6907604336738586\n",
      "Validation loss decreased from 0.6957087516784668 to 0.695707001469352\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6907594799995422\n",
      "Validation loss decreased from 0.695707001469352 to 0.6957052512602373\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6907585859298706\n",
      "Validation loss decreased from 0.6957052512602373 to 0.6957034902139143\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.690757691860199\n",
      "Validation loss decreased from 0.6957034902139143 to 0.6957017508420077\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6907567977905273\n",
      "Validation loss decreased from 0.6957017508420077 to 0.6957000223073092\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6907559037208557\n",
      "Validation loss decreased from 0.6957000223073092 to 0.6956983262842352\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6907549500465393\n",
      "Validation loss decreased from 0.6956983262842352 to 0.6956965977495367\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6907541155815125\n",
      "Validation loss decreased from 0.6956965977495367 to 0.6956948963078585\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6907532215118408\n",
      "Validation loss decreased from 0.6956948963078585 to 0.6956931731917642\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6907522678375244\n",
      "Validation loss decreased from 0.6956931731917642 to 0.6956914934245023\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6907513737678528\n",
      "Validation loss decreased from 0.6956914934245023 to 0.6956897919828241\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6907504796981812\n",
      "Validation loss decreased from 0.6956897919828241 to 0.6956881230527704\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6907495856285095\n",
      "Validation loss decreased from 0.6956881230527704 to 0.6956864107738842\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6907486319541931\n",
      "Validation loss decreased from 0.6956864107738842 to 0.6956847526810386\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6907477974891663\n",
      "Validation loss decreased from 0.6956847526810386 to 0.695683089169589\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6907469034194946\n",
      "Validation loss decreased from 0.695683089169589 to 0.6956814256581393\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6907459497451782\n",
      "Validation loss decreased from 0.6956814256581393 to 0.6956797675652937\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6907450556755066\n",
      "Validation loss decreased from 0.6956797675652937 to 0.6956781094724481\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6907442212104797\n",
      "Validation loss decreased from 0.6956781094724481 to 0.6956764784726229\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6907433271408081\n",
      "Validation loss decreased from 0.6956764784726229 to 0.695674869147214\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6907424926757812\n",
      "Validation loss decreased from 0.695674869147214 to 0.6956732435659929\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6907415390014648\n",
      "Validation loss decreased from 0.6956732435659929 to 0.6956716234033758\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6907407641410828\n",
      "Validation loss decreased from 0.6956716234033758 to 0.6956700411709872\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6907398104667664\n",
      "Validation loss decreased from 0.6956700411709872 to 0.6956684318455783\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6907390356063843\n",
      "Validation loss decreased from 0.6956684318455783 to 0.6956668496131897\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6907381415367126\n",
      "Validation loss decreased from 0.6956668496131897 to 0.6956652402877808\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6907373666763306\n",
      "Validation loss decreased from 0.6956652402877808 to 0.6956636526367881\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6907364726066589\n",
      "Validation loss decreased from 0.6956636526367881 to 0.6956620866602118\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6907356977462769\n",
      "Validation loss decreased from 0.6956620866602118 to 0.695660493590615\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.69073486328125\n",
      "Validation loss decreased from 0.695660493590615 to 0.6956589113582264\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6907339692115784\n",
      "Validation loss decreased from 0.6956589113582264 to 0.6956573670560663\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6907331347465515\n",
      "Validation loss decreased from 0.6956573670560663 to 0.6956558119166981\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6907323002815247\n",
      "Validation loss decreased from 0.6956558119166981 to 0.6956542730331421\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6907315254211426\n",
      "Validation loss decreased from 0.6956542730331421 to 0.695652728730982\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.690730631351471\n",
      "Validation loss decreased from 0.695652728730982 to 0.695651189847426\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6907297968864441\n",
      "Validation loss decreased from 0.695651189847426 to 0.6956496455452659\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6907291412353516\n",
      "Validation loss decreased from 0.6956496455452659 to 0.6956480958245017\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6907281875610352\n",
      "Validation loss decreased from 0.6956480958245017 to 0.6956465461037376\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6907274127006531\n",
      "Validation loss decreased from 0.6956465461037376 to 0.6956450126387856\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6907265782356262\n",
      "Validation loss decreased from 0.6956450126387856 to 0.6956434791738336\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6907257437705994\n",
      "Validation loss decreased from 0.6956434791738336 to 0.6956419565460898\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6907249689102173\n",
      "Validation loss decreased from 0.6956419565460898 to 0.6956404447555542\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.69072425365448\n",
      "Validation loss decreased from 0.6956404447555542 to 0.6956389058719982\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6907234191894531\n",
      "Validation loss decreased from 0.6956389058719982 to 0.6956374103372748\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6907227039337158\n",
      "Validation loss decreased from 0.6956374103372748 to 0.6956359093839471\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.690721869468689\n",
      "Validation loss decreased from 0.6956359093839471 to 0.6956343975934115\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6907210946083069\n",
      "Validation loss decreased from 0.6956343975934115 to 0.6956329183145002\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.69072026014328\n",
      "Validation loss decreased from 0.6956329183145002 to 0.6956314119425687\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.690719485282898\n",
      "Validation loss decreased from 0.6956314119425687 to 0.6956299326636575\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6907187104225159\n",
      "Validation loss decreased from 0.6956299326636575 to 0.6956284533847462\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6907179355621338\n",
      "Validation loss decreased from 0.6956284533847462 to 0.6956269686872308\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6907171607017517\n",
      "Validation loss decreased from 0.6956269686872308 to 0.6956254894083197\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6907163262367249\n",
      "Validation loss decreased from 0.6956254894083197 to 0.6956239992922003\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6907156109809875\n",
      "Validation loss decreased from 0.6956239992922003 to 0.6956225525249135\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6907147765159607\n",
      "Validation loss decreased from 0.6956225525249135 to 0.6956210786646063\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6907140612602234\n",
      "Validation loss decreased from 0.6956210786646063 to 0.6956196210601113\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6907132267951965\n",
      "Validation loss decreased from 0.6956196210601113 to 0.6956181634556163\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6907125115394592\n",
      "Validation loss decreased from 0.6956181634556163 to 0.6956167166883295\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6907117962837219\n",
      "Validation loss decreased from 0.6956167166883295 to 0.6956152753396467\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6907109618186951\n",
      "Validation loss decreased from 0.6956152753396467 to 0.6956138394095681\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6907102465629578\n",
      "Validation loss decreased from 0.6956138394095681 to 0.6956124305725098\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6907094120979309\n",
      "Validation loss decreased from 0.6956124305725098 to 0.6956110379912637\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6907086968421936\n",
      "Validation loss decreased from 0.6956110379912637 to 0.6956096399914135\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.690707802772522\n",
      "Validation loss decreased from 0.6956096399914135 to 0.6956082690845836\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6907071471214294\n",
      "Validation loss decreased from 0.6956082690845836 to 0.6956068927591498\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6907063722610474\n",
      "Validation loss decreased from 0.6956068927591498 to 0.695605527270924\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6907055377960205\n",
      "Validation loss decreased from 0.695605527270924 to 0.6956041617826982\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6907047629356384\n",
      "Validation loss decreased from 0.6956041617826982 to 0.6956028288060968\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6907039284706116\n",
      "Validation loss decreased from 0.6956028288060968 to 0.695601457899267\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6907031536102295\n",
      "Validation loss decreased from 0.695601457899267 to 0.6956001086668535\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6907023191452026\n",
      "Validation loss decreased from 0.6956001086668535 to 0.6955987540158358\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6907015442848206\n",
      "Validation loss decreased from 0.6955987540158358 to 0.6955973722717979\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6907007098197937\n",
      "Validation loss decreased from 0.6955973722717979 to 0.695595995946364\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6906998753547668\n",
      "Validation loss decreased from 0.695595995946364 to 0.6955946412953463\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.69069904088974\n",
      "Validation loss decreased from 0.6955946412953463 to 0.6955933137373491\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6906982660293579\n",
      "Validation loss decreased from 0.6955933137373491 to 0.6955919536677274\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6906973719596863\n",
      "Validation loss decreased from 0.6955919536677274 to 0.695590615272522\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6906965970993042\n",
      "Validation loss decreased from 0.695590615272522 to 0.6955892714587125\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6906957626342773\n",
      "Validation loss decreased from 0.6955892714587125 to 0.6955879168076948\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6906949877738953\n",
      "Validation loss decreased from 0.6955879168076948 to 0.6955866163427179\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.690694272518158\n",
      "Validation loss decreased from 0.6955866163427179 to 0.6955852671103044\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6906933784484863\n",
      "Validation loss decreased from 0.6955852671103044 to 0.6955839612267234\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.690692663192749\n",
      "Validation loss decreased from 0.6955839612267234 to 0.6955826336687262\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6906918883323669\n",
      "Validation loss decreased from 0.6955826336687262 to 0.6955813440409574\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6906911134719849\n",
      "Validation loss decreased from 0.6955813440409574 to 0.6955800489945845\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6906902194023132\n",
      "Validation loss decreased from 0.6955800489945845 to 0.6955787322737954\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6906895041465759\n",
      "Validation loss decreased from 0.6955787322737954 to 0.6955774372274225\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6906886696815491\n",
      "Validation loss decreased from 0.6955774372274225 to 0.6955761475996538\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.690687894821167\n",
      "Validation loss decreased from 0.6955761475996538 to 0.695574857971885\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6906870603561401\n",
      "Validation loss decreased from 0.695574857971885 to 0.6955735845999285\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6906863451004028\n",
      "Validation loss decreased from 0.6955735845999285 to 0.6955723166465759\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6906855702400208\n",
      "Validation loss decreased from 0.6955723166465759 to 0.6955710541118275\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6906847357749939\n",
      "Validation loss decreased from 0.6955710541118275 to 0.695569786158475\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6906840205192566\n",
      "Validation loss decreased from 0.695569786158475 to 0.6955685073679144\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6906831860542297\n",
      "Validation loss decreased from 0.6955685073679144 to 0.6955672556703741\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6906824111938477\n",
      "Validation loss decreased from 0.6955672556703741 to 0.695566020228646\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6906815767288208\n",
      "Validation loss decreased from 0.695566020228646 to 0.6955647956241261\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6906808018684387\n",
      "Validation loss decreased from 0.6955647956241261 to 0.6955635385079817\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6906799674034119\n",
      "Validation loss decreased from 0.6955635385079817 to 0.6955623193220659\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6906791925430298\n",
      "Validation loss decreased from 0.6955623193220659 to 0.6955610838803378\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6906785368919373\n",
      "Validation loss decreased from 0.6955610838803378 to 0.695559870113026\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6906777024269104\n",
      "Validation loss decreased from 0.695559870113026 to 0.6955586455085061\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6906769275665283\n",
      "Validation loss decreased from 0.6955586455085061 to 0.6955574317411943\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6906760931015015\n",
      "Validation loss decreased from 0.6955574317411943 to 0.6955562017180703\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6906753182411194\n",
      "Validation loss decreased from 0.6955562017180703 to 0.6955550258809869\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6906744837760925\n",
      "Validation loss decreased from 0.6955550258809869 to 0.6955538066950712\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6906737089157104\n",
      "Validation loss decreased from 0.6955538066950712 to 0.6955526091835715\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6906728744506836\n",
      "Validation loss decreased from 0.6955526091835715 to 0.6955514225092801\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6906720399856567\n",
      "Validation loss decreased from 0.6955514225092801 to 0.6955502249977805\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6906712055206299\n",
      "Validation loss decreased from 0.6955502249977805 to 0.6955490383234891\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.690670371055603\n",
      "Validation loss decreased from 0.6955490383234891 to 0.6955478624864058\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6906695365905762\n",
      "Validation loss decreased from 0.6955478624864058 to 0.6955467029051348\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6906687617301941\n",
      "Validation loss decreased from 0.6955467029051348 to 0.6955455379052595\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6906679272651672\n",
      "Validation loss decreased from 0.6955455379052595 to 0.6955443674867804\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6906670331954956\n",
      "Validation loss decreased from 0.6955443674867804 to 0.6955432187427174\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6906661987304688\n",
      "Validation loss decreased from 0.6955432187427174 to 0.69554203748703\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6906654238700867\n",
      "Validation loss decreased from 0.69554203748703 to 0.6955409049987793\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6906645894050598\n",
      "Validation loss decreased from 0.6955409049987793 to 0.6955397562547163\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.690663754940033\n",
      "Validation loss decreased from 0.6955397562547163 to 0.6955386291850697\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6906628608703613\n",
      "Validation loss decreased from 0.6955386291850697 to 0.695537496696819\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6906619668006897\n",
      "Validation loss decreased from 0.695537496696819 to 0.6955363533713601\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6906611323356628\n",
      "Validation loss decreased from 0.6955363533713601 to 0.6955352208831094\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6906602382659912\n",
      "Validation loss decreased from 0.6955352208831094 to 0.6955340992320668\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6906594038009644\n",
      "Validation loss decreased from 0.6955340992320668 to 0.6955330046740446\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6906585097312927\n",
      "Validation loss decreased from 0.6955330046740446 to 0.695531883023002\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6906576156616211\n",
      "Validation loss decreased from 0.695531883023002 to 0.6955307667905634\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6906567215919495\n",
      "Validation loss decreased from 0.6955307667905634 to 0.6955296668139371\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6906558871269226\n",
      "Validation loss decreased from 0.6955296668139371 to 0.6955285722559149\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6906550526618958\n",
      "Validation loss decreased from 0.6955285722559149 to 0.6955274776978926\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6906541585922241\n",
      "Validation loss decreased from 0.6955274776978926 to 0.6955263668840582\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6906532645225525\n",
      "Validation loss decreased from 0.6955263668840582 to 0.6955252940004523\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6906524300575256\n",
      "Validation loss decreased from 0.6955252940004523 to 0.6955242211168463\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6906515955924988\n",
      "Validation loss decreased from 0.6955242211168463 to 0.6955231373960321\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6906508207321167\n",
      "Validation loss decreased from 0.6955231373960321 to 0.6955220590938221\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6906499266624451\n",
      "Validation loss decreased from 0.6955220590938221 to 0.6955210133032366\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6906490921974182\n",
      "Validation loss decreased from 0.6955210133032366 to 0.6955199675126509\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.6906482577323914\n",
      "Validation loss decreased from 0.6955199675126509 to 0.695518900047649\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6906474828720093\n",
      "Validation loss decreased from 0.695518900047649 to 0.6955178488384594\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6906466484069824\n",
      "Validation loss decreased from 0.6955178488384594 to 0.6955168030478738\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6906458735466003\n",
      "Validation loss decreased from 0.6955168030478738 to 0.6955157572572882\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6906450390815735\n",
      "Validation loss decreased from 0.6955157572572882 to 0.6955147060480985\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6906442642211914\n",
      "Validation loss decreased from 0.6955147060480985 to 0.6955136548389088\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6906434297561646\n",
      "Validation loss decreased from 0.6955136548389088 to 0.6955126144669272\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6906426548957825\n",
      "Validation loss decreased from 0.6955126144669272 to 0.6955115578391335\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6906417608261108\n",
      "Validation loss decreased from 0.6955115578391335 to 0.695510512048548\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6906410455703735\n",
      "Validation loss decreased from 0.695510512048548 to 0.6955094770951704\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6906402111053467\n",
      "Validation loss decreased from 0.6955094770951704 to 0.6955084313045848\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6906394362449646\n",
      "Validation loss decreased from 0.6955084313045848 to 0.6955074180256237\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6906386017799377\n",
      "Validation loss decreased from 0.6955074180256237 to 0.6955063884908502\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6906378269195557\n",
      "Validation loss decreased from 0.6955063884908502 to 0.6955053589560769\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6906371712684631\n",
      "Validation loss decreased from 0.6955053589560769 to 0.6955043185840953\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6906362771987915\n",
      "Validation loss decreased from 0.6955043185840953 to 0.695503294467926\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6906355023384094\n",
      "Validation loss decreased from 0.695503294467926 to 0.6955022595145486\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6906346678733826\n",
      "Validation loss decreased from 0.6955022595145486 to 0.6955012624913995\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6906339526176453\n",
      "Validation loss decreased from 0.6955012624913995 to 0.6955002383752302\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6906331181526184\n",
      "Validation loss decreased from 0.6955002383752302 to 0.6954992088404569\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6906323432922363\n",
      "Validation loss decreased from 0.6954992088404569 to 0.6954981901428916\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6906315088272095\n",
      "Validation loss decreased from 0.6954981901428916 to 0.69549714977091\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6906307339668274\n",
      "Validation loss decreased from 0.69549714977091 to 0.695496141910553\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6906299591064453\n",
      "Validation loss decreased from 0.695496141910553 to 0.6954951286315918\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6906291246414185\n",
      "Validation loss decreased from 0.6954951286315918 to 0.6954941153526306\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6906283497810364\n",
      "Validation loss decreased from 0.6954941153526306 to 0.6954931129108776\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6906275749206543\n",
      "Validation loss decreased from 0.6954931129108776 to 0.6954921213063326\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6906267404556274\n",
      "Validation loss decreased from 0.6954921213063326 to 0.6954910809343512\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6906259655952454\n",
      "Validation loss decreased from 0.6954910809343512 to 0.6954901110042225\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6906251311302185\n",
      "Validation loss decreased from 0.6954901110042225 to 0.6954891139810736\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6906242966651917\n",
      "Validation loss decreased from 0.6954891139810736 to 0.6954881115393206\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6906235814094543\n",
      "Validation loss decreased from 0.6954881115393206 to 0.6954871307719838\n",
      "no early stopping\n",
      "AUC on test data  0.5013166527362112\n",
      "model 38 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6940512657165527\n",
      "Validation loss decreased from inf to 0.7096974632956765\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6938439011573792\n",
      "Validation loss decreased from 0.7096974632956765 to 0.709253338250247\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6936388611793518\n",
      "Validation loss decreased from 0.709253338250247 to 0.7088102319023826\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6934435963630676\n",
      "Validation loss decreased from 0.7088102319023826 to 0.7083823139017279\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6932579278945923\n",
      "Validation loss decreased from 0.7083823139017279 to 0.7079698118296537\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6930813789367676\n",
      "Validation loss decreased from 0.7079698118296537 to 0.707572189244357\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6929137110710144\n",
      "Validation loss decreased from 0.707572189244357 to 0.7071897983551025\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6927544474601746\n",
      "Validation loss decreased from 0.7071897983551025 to 0.7068209593946283\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6926031112670898\n",
      "Validation loss decreased from 0.7068209593946283 to 0.7064655043862083\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.692459225654602\n",
      "Validation loss decreased from 0.7064655043862083 to 0.7061222845857794\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6923223733901978\n",
      "Validation loss decreased from 0.7061222845857794 to 0.705790947784077\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6921922564506531\n",
      "Validation loss decreased from 0.705790947784077 to 0.7054710008881309\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6920686960220337\n",
      "Validation loss decreased from 0.7054710008881309 to 0.7051627961072054\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6919515132904053\n",
      "Validation loss decreased from 0.7051627961072054 to 0.704866495999423\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6918410062789917\n",
      "Validation loss decreased from 0.704866495999423 to 0.7045807838439941\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6917359232902527\n",
      "Validation loss decreased from 0.7045807838439941 to 0.7043039744550531\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.69163578748703\n",
      "Validation loss decreased from 0.7043039744550531 to 0.7040362574837424\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6915407180786133\n",
      "Validation loss decreased from 0.7040362574837424 to 0.703777399930087\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.691450297832489\n",
      "Validation loss decreased from 0.703777399930087 to 0.7035271362824873\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6913644671440125\n",
      "Validation loss decreased from 0.7035271362824873 to 0.7032851630991156\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6912840008735657\n",
      "Validation loss decreased from 0.7032851630991156 to 0.7030511606823314\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6912088990211487\n",
      "Validation loss decreased from 0.7030511606823314 to 0.7028246142647483\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6911380290985107\n",
      "Validation loss decreased from 0.7028246142647483 to 0.7026059681719\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.691073477268219\n",
      "Validation loss decreased from 0.7026059681719 to 0.7023945504968817\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6910139322280884\n",
      "Validation loss decreased from 0.7023945504968817 to 0.7021893208677118\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6909594535827637\n",
      "Validation loss decreased from 0.7021893208677118 to 0.7019909240982749\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6909079551696777\n",
      "Validation loss decreased from 0.7019909240982749 to 0.7017984769561074\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6908591985702515\n",
      "Validation loss decreased from 0.7017984769561074 to 0.701612342487682\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6908116936683655\n",
      "Validation loss decreased from 0.701612342487682 to 0.7014324448325417\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6907663941383362\n",
      "Validation loss decreased from 0.7014324448325417 to 0.7012593421069059\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6907234787940979\n",
      "Validation loss decreased from 0.7012593421069059 to 0.7010914791714061\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6906826496124268\n",
      "Validation loss decreased from 0.7010914791714061 to 0.7009288560260426\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6906441450119019\n",
      "Validation loss decreased from 0.7009288560260426 to 0.7007708170197227\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6906074285507202\n",
      "Validation loss decreased from 0.7007708170197227 to 0.7006178877570413\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6905727982521057\n",
      "Validation loss decreased from 0.7006178877570413 to 0.7004695372147993\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6905401349067688\n",
      "Validation loss decreased from 0.7004695372147993 to 0.7003252560442145\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6905090808868408\n",
      "Validation loss decreased from 0.7003252560442145 to 0.7001850659197028\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6904801726341248\n",
      "Validation loss decreased from 0.7001850659197028 to 0.7000485821203752\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6904528737068176\n",
      "Validation loss decreased from 0.7000485821203752 to 0.6999163627624512\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6904271245002747\n",
      "Validation loss decreased from 0.6999163627624512 to 0.6997880989854987\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6904027462005615\n",
      "Validation loss decreased from 0.6997880989854987 to 0.6996639425104315\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6903795599937439\n",
      "Validation loss decreased from 0.6996639425104315 to 0.6995435465465892\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.69035804271698\n",
      "Validation loss decreased from 0.6995435465465892 to 0.6994261199777777\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6903377771377563\n",
      "Validation loss decreased from 0.6994261199777777 to 0.6993115056644786\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6903186440467834\n",
      "Validation loss decreased from 0.6993115056644786 to 0.6992004134438254\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6903017163276672\n",
      "Validation loss decreased from 0.6992004134438254 to 0.6990921497344971\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6902869343757629\n",
      "Validation loss decreased from 0.6990921497344971 to 0.6989870342341337\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6902742981910706\n",
      "Validation loss decreased from 0.6989870342341337 to 0.6988852565938776\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6902630925178528\n",
      "Validation loss decreased from 0.6988852565938776 to 0.6987863833254034\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6902529001235962\n",
      "Validation loss decreased from 0.6987863833254034 to 0.6986901164054871\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6902437806129456\n",
      "Validation loss decreased from 0.6986901164054871 to 0.6985964179039001\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6902352571487427\n",
      "Validation loss decreased from 0.6985964179039001 to 0.69850539077412\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6902276873588562\n",
      "Validation loss decreased from 0.69850539077412 to 0.6984167098999023\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6902203559875488\n",
      "Validation loss decreased from 0.6984167098999023 to 0.6983307979323647\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6902135014533997\n",
      "Validation loss decreased from 0.6983307979323647 to 0.6982471238483082\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6902069449424744\n",
      "Validation loss decreased from 0.6982471238483082 to 0.6981658068570223\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6902004480361938\n",
      "Validation loss decreased from 0.6981658068570223 to 0.6980870257724415\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6901940703392029\n",
      "Validation loss decreased from 0.6980870257724415 to 0.6980106071992354\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6901879906654358\n",
      "Validation loss decreased from 0.6980106071992354 to 0.697936242276972\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6901823282241821\n",
      "Validation loss decreased from 0.697936242276972 to 0.6978637034242804\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6901769042015076\n",
      "Validation loss decreased from 0.6978637034242804 to 0.6977932290597395\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6901717782020569\n",
      "Validation loss decreased from 0.6977932290597395 to 0.6977243965322321\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6901666522026062\n",
      "Validation loss decreased from 0.6977243965322321 to 0.6976574876091697\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6901621222496033\n",
      "Validation loss decreased from 0.6976574876091697 to 0.6975922421975569\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6901577115058899\n",
      "Validation loss decreased from 0.6975922421975569 to 0.6975286061113531\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6901536583900452\n",
      "Validation loss decreased from 0.6975286061113531 to 0.6974663842808116\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6901499032974243\n",
      "Validation loss decreased from 0.6974663842808116 to 0.697405690496618\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6901464462280273\n",
      "Validation loss decreased from 0.697405690496618 to 0.6973466873168945\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6901431083679199\n",
      "Validation loss decreased from 0.6973466873168945 to 0.6972893313928084\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.690139889717102\n",
      "Validation loss decreased from 0.6972893313928084 to 0.6972335739569231\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6901364326477051\n",
      "Validation loss decreased from 0.6972335739569231 to 0.6971794854510914\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6901329755783081\n",
      "Validation loss decreased from 0.6971794854510914 to 0.6971269304102118\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6901297569274902\n",
      "Validation loss decreased from 0.6971269304102118 to 0.6970756812529131\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6901266574859619\n",
      "Validation loss decreased from 0.6970756812529131 to 0.6970258409326727\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6901236176490784\n",
      "Validation loss decreased from 0.6970258409326727 to 0.6969772360541604\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6901208758354187\n",
      "Validation loss decreased from 0.6969772360541604 to 0.6969297853383151\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6901183128356934\n",
      "Validation loss decreased from 0.6969297853383151 to 0.6968833695758473\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6901159286499023\n",
      "Validation loss decreased from 0.6968833695758473 to 0.6968379779295488\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6901135444641113\n",
      "Validation loss decreased from 0.6968379779295488 to 0.6967938379807905\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.690110981464386\n",
      "Validation loss decreased from 0.6967938379807905 to 0.6967508142644708\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.690108597278595\n",
      "Validation loss decreased from 0.6967508142644708 to 0.6967088255015287\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6901064515113831\n",
      "Validation loss decreased from 0.6967088255015287 to 0.6966678120873191\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6901043057441711\n",
      "Validation loss decreased from 0.6966678120873191 to 0.6966277686032382\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6901021599769592\n",
      "Validation loss decreased from 0.6966277686032382 to 0.6965887383981184\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6901001334190369\n",
      "Validation loss decreased from 0.6965887383981184 to 0.6965505914254622\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6900981664657593\n",
      "Validation loss decreased from 0.6965505914254622 to 0.6965133005922491\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6900962591171265\n",
      "Validation loss decreased from 0.6965133005922491 to 0.6964768875728954\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6900943517684937\n",
      "Validation loss decreased from 0.6964768875728954 to 0.6964412114836953\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6900925040245056\n",
      "Validation loss decreased from 0.6964412114836953 to 0.6964063536037098\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6900907754898071\n",
      "Validation loss decreased from 0.6964063536037098 to 0.696372313932939\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6900891661643982\n",
      "Validation loss decreased from 0.696372313932939 to 0.6963390220295299\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6900877356529236\n",
      "Validation loss decreased from 0.6963390220295299 to 0.6963064128702338\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6900862455368042\n",
      "Validation loss decreased from 0.6963064128702338 to 0.6962745785713196\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6900848746299744\n",
      "Validation loss decreased from 0.6962745785713196 to 0.6962434107607062\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6900835633277893\n",
      "Validation loss decreased from 0.6962434107607062 to 0.6962129473686218\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6900823712348938\n",
      "Validation loss decreased from 0.6962129473686218 to 0.6961831775578585\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6900812387466431\n",
      "Validation loss decreased from 0.6961831775578585 to 0.6961540579795837\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6900801062583923\n",
      "Validation loss decreased from 0.6961540579795837 to 0.6961255777965892\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.690078854560852\n",
      "Validation loss decreased from 0.6961255777965892 to 0.6960977695204995\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6900777816772461\n",
      "Validation loss decreased from 0.6960977695204995 to 0.6960705735466697\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6900767087936401\n",
      "Validation loss decreased from 0.6960705735466697 to 0.6960439790378917\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6900756359100342\n",
      "Validation loss decreased from 0.6960439790378917 to 0.6960179697383534\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6900745630264282\n",
      "Validation loss decreased from 0.6960179697383534 to 0.6959925619038668\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6900738477706909\n",
      "Validation loss decreased from 0.6959925619038668 to 0.6959675496274774\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6900731325149536\n",
      "Validation loss decreased from 0.6959675496274774 to 0.695943062955683\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6900723576545715\n",
      "Validation loss decreased from 0.695943062955683 to 0.6959191289815035\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6900715231895447\n",
      "Validation loss decreased from 0.6959191289815035 to 0.6958957477049394\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.690070629119873\n",
      "Validation loss decreased from 0.6958957477049394 to 0.6958729137073864\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6900696158409119\n",
      "Validation loss decreased from 0.6958729137073864 to 0.6958506161516363\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6900686621665955\n",
      "Validation loss decreased from 0.6958506161516363 to 0.6958287845958363\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6900677680969238\n",
      "Validation loss decreased from 0.6958287845958363 to 0.6958073594353416\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6900668144226074\n",
      "Validation loss decreased from 0.6958073594353416 to 0.6957863460887562\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6900660991668701\n",
      "Validation loss decreased from 0.6957863460887562 to 0.6957657553932883\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6900653839111328\n",
      "Validation loss decreased from 0.6957657553932883 to 0.6957455765117299\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.690064549446106\n",
      "Validation loss decreased from 0.6957455765117299 to 0.6957258202812888\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6900637745857239\n",
      "Validation loss decreased from 0.6957258202812888 to 0.6957064650275491\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6900629997253418\n",
      "Validation loss decreased from 0.6957064650275491 to 0.6956874836574901\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6900623440742493\n",
      "Validation loss decreased from 0.6956874836574901 to 0.6956688761711121\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.690061628818512\n",
      "Validation loss decreased from 0.6956688761711121 to 0.6956506154753945\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6900609135627747\n",
      "Validation loss decreased from 0.6956506154753945 to 0.6956326853145253\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6900600790977478\n",
      "Validation loss decreased from 0.6956326853145253 to 0.6956151290373369\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6900594830513\n",
      "Validation loss decreased from 0.6956151290373369 to 0.6955978491089561\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6900588870048523\n",
      "Validation loss decreased from 0.6955978491089561 to 0.6955808563665911\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6900584697723389\n",
      "Validation loss decreased from 0.6955808563665911 to 0.6955641453916376\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6900579929351807\n",
      "Validation loss decreased from 0.6955641453916376 to 0.6955477703701366\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6900573968887329\n",
      "Validation loss decreased from 0.6955477703701366 to 0.6955317963253368\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6900568008422852\n",
      "Validation loss decreased from 0.6955317963253368 to 0.6955161094665527\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6900563836097717\n",
      "Validation loss decreased from 0.6955161094665527 to 0.6955006664449518\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6900560259819031\n",
      "Validation loss decreased from 0.6955006664449518 to 0.6954854672605341\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6900557279586792\n",
      "Validation loss decreased from 0.6954854672605341 to 0.6954705931923606\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6900553107261658\n",
      "Validation loss decreased from 0.6954705931923606 to 0.6954560388218273\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6900549530982971\n",
      "Validation loss decreased from 0.6954560388218273 to 0.6954417608001016\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6900545358657837\n",
      "Validation loss decreased from 0.6954417608001016 to 0.6954278349876404\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6900539994239807\n",
      "Validation loss decreased from 0.6954278349876404 to 0.695414196361195\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.690053403377533\n",
      "Validation loss decreased from 0.695414196361195 to 0.6954007798975165\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6900529861450195\n",
      "Validation loss decreased from 0.6954007798975165 to 0.6953875910152089\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6900525093078613\n",
      "Validation loss decreased from 0.6953875910152089 to 0.6953746730631049\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6900520324707031\n",
      "Validation loss decreased from 0.6953746730631049 to 0.6953620531342246\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6900514960289001\n",
      "Validation loss decreased from 0.6953620531342246 to 0.6953496716239236\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6900510787963867\n",
      "Validation loss decreased from 0.6953496716239236 to 0.6953374689275568\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6900507807731628\n",
      "Validation loss decreased from 0.6953374689275568 to 0.6953254558823325\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6900503635406494\n",
      "Validation loss decreased from 0.6953254558823325 to 0.6953136920928955\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6900498270988464\n",
      "Validation loss decreased from 0.6953136920928955 to 0.6953022046522661\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6900492310523987\n",
      "Validation loss decreased from 0.6953022046522661 to 0.6952909502116117\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6900485157966614\n",
      "Validation loss decreased from 0.6952909502116117 to 0.6952798745848916\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6900476813316345\n",
      "Validation loss decreased from 0.6952798745848916 to 0.6952690807255831\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.6900467276573181\n",
      "Validation loss decreased from 0.6952690807255831 to 0.6952584927732294\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.690045952796936\n",
      "Validation loss decreased from 0.6952584927732294 to 0.6952481269836426\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6900449991226196\n",
      "Validation loss decreased from 0.6952481269836426 to 0.6952379508451982\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6900440454483032\n",
      "Validation loss decreased from 0.6952379508451982 to 0.6952279589392922\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6900432109832764\n",
      "Validation loss decreased from 0.6952279589392922 to 0.6952181295915083\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6900423169136047\n",
      "Validation loss decreased from 0.6952181295915083 to 0.6952084411274303\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6900415420532227\n",
      "Validation loss decreased from 0.6952084411274303 to 0.6951989423144947\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6900407075881958\n",
      "Validation loss decreased from 0.6951989423144947 to 0.6951895572922446\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.690040111541748\n",
      "Validation loss decreased from 0.6951895572922446 to 0.6951803185723044\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6900395154953003\n",
      "Validation loss decreased from 0.6951803185723044 to 0.6951711665500294\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6900388598442078\n",
      "Validation loss decreased from 0.6951711665500294 to 0.695162215016105\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.69003826379776\n",
      "Validation loss decreased from 0.695162215016105 to 0.6951534152030945\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6900376677513123\n",
      "Validation loss decreased from 0.6951534152030945 to 0.695144842971455\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6900368332862854\n",
      "Validation loss decreased from 0.695144842971455 to 0.6951364495537498\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6900361776351929\n",
      "Validation loss decreased from 0.6951364495537498 to 0.6951281807639382\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6900352239608765\n",
      "Validation loss decreased from 0.6951281807639382 to 0.6951200907880609\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6900344491004944\n",
      "Validation loss decreased from 0.6951200907880609 to 0.6951121471144937\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6900335550308228\n",
      "Validation loss decreased from 0.6951121471144937 to 0.695104333487424\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6900327205657959\n",
      "Validation loss decreased from 0.695104333487424 to 0.6950966228138317\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6900317668914795\n",
      "Validation loss decreased from 0.6950966228138317 to 0.6950890801169656\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6900308132171631\n",
      "Validation loss decreased from 0.6950890801169656 to 0.6950817053968256\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6900298595428467\n",
      "Validation loss decreased from 0.6950817053968256 to 0.6950744390487671\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6900287866592407\n",
      "Validation loss decreased from 0.6950744390487671 to 0.6950673081658103\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6900278925895691\n",
      "Validation loss decreased from 0.6950673081658103 to 0.6950602910735391\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6900269389152527\n",
      "Validation loss decreased from 0.6950602910735391 to 0.6950534257021818\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.690025806427002\n",
      "Validation loss decreased from 0.6950534257021818 to 0.6950467824935913\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.690024733543396\n",
      "Validation loss decreased from 0.6950467824935913 to 0.695040225982666\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6900237202644348\n",
      "Validation loss decreased from 0.695040225982666 to 0.6950337507508018\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6900227665901184\n",
      "Validation loss decreased from 0.6950337507508018 to 0.6950274055654352\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6900218725204468\n",
      "Validation loss decreased from 0.6950274055654352 to 0.6950211795893583\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6900208592414856\n",
      "Validation loss decreased from 0.6950211795893583 to 0.695015089078383\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6900198459625244\n",
      "Validation loss decreased from 0.695015089078383 to 0.6950091069394891\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6900185942649841\n",
      "Validation loss decreased from 0.6950091069394891 to 0.6950033415447582\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6900172829627991\n",
      "Validation loss decreased from 0.6950033415447582 to 0.6949976736849005\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.6900158524513245\n",
      "Validation loss decreased from 0.6949976736849005 to 0.6949921412901445\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6900144815444946\n",
      "Validation loss decreased from 0.6949921412901445 to 0.6949866197325967\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6900131702423096\n",
      "Validation loss decreased from 0.6949866197325967 to 0.6949812228029425\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6900118589401245\n",
      "Validation loss decreased from 0.6949812228029425 to 0.6949758529663086\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6900106072425842\n",
      "Validation loss decreased from 0.6949758529663086 to 0.6949706240133806\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6900095343589783\n",
      "Validation loss decreased from 0.6949706240133806 to 0.6949654655023054\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.690008282661438\n",
      "Validation loss decreased from 0.6949654655023054 to 0.6949604045261036\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6900068521499634\n",
      "Validation loss decreased from 0.6949604045261036 to 0.6949554627591913\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.690005362033844\n",
      "Validation loss decreased from 0.6949554627591913 to 0.6949505643411116\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6900039911270142\n",
      "Validation loss decreased from 0.6949505643411116 to 0.6949457688765093\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6900023221969604\n",
      "Validation loss decreased from 0.6949457688765093 to 0.6949410926211964\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6900007128715515\n",
      "Validation loss decreased from 0.6949410926211964 to 0.6949364759705283\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6899991631507874\n",
      "Validation loss decreased from 0.6949364759705283 to 0.6949318647384644\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6899975538253784\n",
      "Validation loss decreased from 0.6949318647384644 to 0.6949272914366289\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6899960041046143\n",
      "Validation loss decreased from 0.6949272914366289 to 0.6949227777394381\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.6899944543838501\n",
      "Validation loss decreased from 0.6949227777394381 to 0.6949183344841003\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6899927854537964\n",
      "Validation loss decreased from 0.6949183344841003 to 0.694913999600844\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.6899909377098083\n",
      "Validation loss decreased from 0.694913999600844 to 0.6949097080664202\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6899890899658203\n",
      "Validation loss decreased from 0.6949097080664202 to 0.6949055411598899\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6899875402450562\n",
      "Validation loss decreased from 0.6949055411598899 to 0.6949013092301108\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6899858713150024\n",
      "Validation loss decreased from 0.6949013092301108 to 0.6948972127654336\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.6899840831756592\n",
      "Validation loss decreased from 0.6948972127654336 to 0.6948931163007562\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6899826526641846\n",
      "Validation loss decreased from 0.6948931163007562 to 0.6948890848593279\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6899808049201965\n",
      "Validation loss decreased from 0.6948890848593279 to 0.6948851238597523\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6899793148040771\n",
      "Validation loss decreased from 0.6948851238597523 to 0.694881179115989\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6899779438972473\n",
      "Validation loss decreased from 0.694881179115989 to 0.6948772289536216\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6899764537811279\n",
      "Validation loss decreased from 0.6948772289536216 to 0.6948733492331072\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.6899750232696533\n",
      "Validation loss decreased from 0.6948733492331072 to 0.6948696103962985\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6899736523628235\n",
      "Validation loss decreased from 0.6948696103962985 to 0.6948658769780939\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.689972460269928\n",
      "Validation loss decreased from 0.6948658769780939 to 0.6948621273040771\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6899713277816772\n",
      "Validation loss decreased from 0.6948621273040771 to 0.6948583451184359\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6899702548980713\n",
      "Validation loss decreased from 0.6948583451184359 to 0.6948546767234802\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6899692416191101\n",
      "Validation loss decreased from 0.6948546767234802 to 0.694851046258753\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6899685859680176\n",
      "Validation loss decreased from 0.694851046258753 to 0.6948474591428583\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6899677515029907\n",
      "Validation loss decreased from 0.6948474591428583 to 0.6948439099571921\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6899670958518982\n",
      "Validation loss decreased from 0.6948439099571921 to 0.6948403770273383\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6899663805961609\n",
      "Validation loss decreased from 0.6948403770273383 to 0.6948368928649209\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6899656653404236\n",
      "Validation loss decreased from 0.6948368928649209 to 0.6948334032838995\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.689965009689331\n",
      "Validation loss decreased from 0.6948334032838995 to 0.694829978726127\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.6899644136428833\n",
      "Validation loss decreased from 0.694829978726127 to 0.6948265704241666\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.689963698387146\n",
      "Validation loss decreased from 0.6948265704241666 to 0.694823216308247\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6899630427360535\n",
      "Validation loss decreased from 0.694823216308247 to 0.6948198947039518\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.6899624466896057\n",
      "Validation loss decreased from 0.6948198947039518 to 0.6948166272856973\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.6899617314338684\n",
      "Validation loss decreased from 0.6948166272856973 to 0.6948134465651079\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6899610757827759\n",
      "Validation loss decreased from 0.6948134465651079 to 0.6948103146119551\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6899604797363281\n",
      "Validation loss decreased from 0.6948103146119551 to 0.6948072531006553\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.6899598240852356\n",
      "Validation loss decreased from 0.6948072531006553 to 0.6948042024265636\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6899591684341431\n",
      "Validation loss decreased from 0.6948042024265636 to 0.6948012059385126\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.689958393573761\n",
      "Validation loss decreased from 0.6948012059385126 to 0.6947982419620861\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6899576783180237\n",
      "Validation loss decreased from 0.6947982419620861 to 0.6947952725670554\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.6899569630622864\n",
      "Validation loss decreased from 0.6947952725670554 to 0.6947923573580655\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6899561882019043\n",
      "Validation loss decreased from 0.6947923573580655 to 0.6947894529862837\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.6899555921554565\n",
      "Validation loss decreased from 0.6947894529862837 to 0.6947865540331061\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.689954936504364\n",
      "Validation loss decreased from 0.6947865540331061 to 0.6947837146845731\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.6899542808532715\n",
      "Validation loss decreased from 0.6947837146845731 to 0.6947808319872076\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6899535655975342\n",
      "Validation loss decreased from 0.6947808319872076 to 0.6947780034758828\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6899528503417969\n",
      "Validation loss decreased from 0.6947780034758828 to 0.6947752291505987\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6899520754814148\n",
      "Validation loss decreased from 0.6947752291505987 to 0.6947724277322943\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6899513006210327\n",
      "Validation loss decreased from 0.6947724277322943 to 0.6947697346860712\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6899504661560059\n",
      "Validation loss decreased from 0.6947697346860712 to 0.6947670849886808\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6899495124816895\n",
      "Validation loss decreased from 0.6947670849886808 to 0.6947644732215188\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.6899484992027283\n",
      "Validation loss decreased from 0.6947644732215188 to 0.6947619102217935\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6899475455284119\n",
      "Validation loss decreased from 0.6947619102217935 to 0.6947593472220681\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6899466514587402\n",
      "Validation loss decreased from 0.6947593472220681 to 0.6947568600827997\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6899456977844238\n",
      "Validation loss decreased from 0.6947568600827997 to 0.6947543133388866\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6899447441101074\n",
      "Validation loss decreased from 0.6947543133388866 to 0.6947518370368264\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6899438500404358\n",
      "Validation loss decreased from 0.6947518370368264 to 0.6947494095022028\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6899428963661194\n",
      "Validation loss decreased from 0.6947494095022028 to 0.6947469873861833\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6899417638778687\n",
      "Validation loss decreased from 0.6947469873861833 to 0.6947447224096819\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6899404525756836\n",
      "Validation loss decreased from 0.6947447224096819 to 0.6947424845262007\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6899393796920776\n",
      "Validation loss decreased from 0.6947424845262007 to 0.69474027373574\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.689938485622406\n",
      "Validation loss decreased from 0.69474027373574 to 0.6947379925034263\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6899376511573792\n",
      "Validation loss decreased from 0.6947379925034263 to 0.69473566792228\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6899368762969971\n",
      "Validation loss decreased from 0.69473566792228 to 0.6947333379225298\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.6899362206459045\n",
      "Validation loss decreased from 0.6947333379225298 to 0.6947311000390486\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6899355053901672\n",
      "Validation loss decreased from 0.6947311000390486 to 0.6947288567369635\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.6899348497390747\n",
      "Validation loss decreased from 0.6947288567369635 to 0.6947266784581271\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6899340748786926\n",
      "Validation loss decreased from 0.6947266784581271 to 0.6947245055978949\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6899333596229553\n",
      "Validation loss decreased from 0.6947245055978949 to 0.6947223706678911\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.6899324059486389\n",
      "Validation loss decreased from 0.6947223706678911 to 0.6947202953425321\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6899314522743225\n",
      "Validation loss decreased from 0.6947202953425321 to 0.694718214598569\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6899305582046509\n",
      "Validation loss decreased from 0.694718214598569 to 0.6947161988778547\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6899296045303345\n",
      "Validation loss decreased from 0.6947161988778547 to 0.6947142319245772\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6899287104606628\n",
      "Validation loss decreased from 0.6947142319245772 to 0.6947123516689647\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.6899276375770569\n",
      "Validation loss decreased from 0.6947123516689647 to 0.6947104172273115\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6899266242980957\n",
      "Validation loss decreased from 0.6947104172273115 to 0.6947084936228666\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6899256706237793\n",
      "Validation loss decreased from 0.6947084936228666 to 0.6947065212509849\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6899248361587524\n",
      "Validation loss decreased from 0.6947065212509849 to 0.6947045868093317\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.689923882484436\n",
      "Validation loss decreased from 0.6947045868093317 to 0.6947026469490745\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6899229288101196\n",
      "Validation loss decreased from 0.6947026469490745 to 0.6947007233446295\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6899220943450928\n",
      "Validation loss decreased from 0.6947007233446295 to 0.6946988159959967\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.6899210214614868\n",
      "Validation loss decreased from 0.6946988159959967 to 0.694696919484572\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6899197101593018\n",
      "Validation loss decreased from 0.694696919484572 to 0.6946951150894165\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6899185180664062\n",
      "Validation loss decreased from 0.6946951150894165 to 0.6946932836012407\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6899171471595764\n",
      "Validation loss decreased from 0.6946932836012407 to 0.6946915333921259\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6899157166481018\n",
      "Validation loss decreased from 0.6946915333921259 to 0.6946898048574274\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6899142861366272\n",
      "Validation loss decreased from 0.6946898048574274 to 0.6946881467645819\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.6899130344390869\n",
      "Validation loss decreased from 0.6946881467645819 to 0.6946864995089445\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6899117231369019\n",
      "Validation loss decreased from 0.6946864995089445 to 0.694684852253307\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.689910352230072\n",
      "Validation loss decreased from 0.694684852253307 to 0.694683237509294\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.6899087429046631\n",
      "Validation loss decreased from 0.694683237509294 to 0.694681628183885\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.689907431602478\n",
      "Validation loss decreased from 0.694681628183885 to 0.694680008021268\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6899060606956482\n",
      "Validation loss decreased from 0.694680008021268 to 0.6946783607656305\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.6899044513702393\n",
      "Validation loss decreased from 0.6946783607656305 to 0.6946768002076582\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6899030208587646\n",
      "Validation loss decreased from 0.6946768002076582 to 0.6946752396496859\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6899015307426453\n",
      "Validation loss decreased from 0.6946752396496859 to 0.6946737278591503\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6898999810218811\n",
      "Validation loss decreased from 0.6946737278591503 to 0.6946722323244269\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6898985505104065\n",
      "Validation loss decreased from 0.6946722323244269 to 0.6946706609292463\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.6898972988128662\n",
      "Validation loss decreased from 0.6946706609292463 to 0.6946690732782538\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6898961067199707\n",
      "Validation loss decreased from 0.6946690732782538 to 0.6946675452319059\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.68989497423172\n",
      "Validation loss decreased from 0.6946675452319059 to 0.694666022604162\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.6898936033248901\n",
      "Validation loss decreased from 0.694666022604162 to 0.6946644674647938\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6898924112319946\n",
      "Validation loss decreased from 0.6946644674647938 to 0.694662950255654\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6898909211158752\n",
      "Validation loss decreased from 0.694662950255654 to 0.6946614330465143\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6898894906044006\n",
      "Validation loss decreased from 0.6946614330465143 to 0.6946599266745828\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.689888060092926\n",
      "Validation loss decreased from 0.6946599266745828 to 0.6946584257212552\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6898865103721619\n",
      "Validation loss decreased from 0.6946584257212552 to 0.6946569193493236\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6898850798606873\n",
      "Validation loss decreased from 0.6946569193493236 to 0.6946554292332042\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6898834705352783\n",
      "Validation loss decreased from 0.6946554292332042 to 0.6946539391170848\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6898819208145142\n",
      "Validation loss decreased from 0.6946539391170848 to 0.6946524706753817\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.68988037109375\n",
      "Validation loss decreased from 0.6946524706753817 to 0.6946510347453031\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6898788213729858\n",
      "Validation loss decreased from 0.6946510347453031 to 0.6946495933966204\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6898772716522217\n",
      "Validation loss decreased from 0.6946495933966204 to 0.6946481574665416\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6898760199546814\n",
      "Validation loss decreased from 0.6946481574665416 to 0.6946466565132141\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6898748874664307\n",
      "Validation loss decreased from 0.6946466565132141 to 0.6946451393040743\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6898738741874695\n",
      "Validation loss decreased from 0.6946451393040743 to 0.694643578746102\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6898729205131531\n",
      "Validation loss decreased from 0.694643578746102 to 0.6946420127695258\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.6898720264434814\n",
      "Validation loss decreased from 0.6946420127695258 to 0.6946404413743452\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6898711919784546\n",
      "Validation loss decreased from 0.6946404413743452 to 0.6946388699791648\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6898703575134277\n",
      "Validation loss decreased from 0.6946388699791648 to 0.6946372877467762\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.6898694038391113\n",
      "Validation loss decreased from 0.6946372877467762 to 0.6946357867934487\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.6898685097694397\n",
      "Validation loss decreased from 0.6946357867934487 to 0.694634264165705\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6898676753044128\n",
      "Validation loss decreased from 0.694634264165705 to 0.6946327686309814\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6898666024208069\n",
      "Validation loss decreased from 0.6946327686309814 to 0.694631343538111\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.6898656487464905\n",
      "Validation loss decreased from 0.694631343538111 to 0.6946299076080322\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6898646950721741\n",
      "Validation loss decreased from 0.6946299076080322 to 0.6946284662593495\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6898638606071472\n",
      "Validation loss decreased from 0.6946284662593495 to 0.6946270520036871\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.689862847328186\n",
      "Validation loss decreased from 0.6946270520036871 to 0.6946256269108165\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6898618936538696\n",
      "Validation loss decreased from 0.6946256269108165 to 0.6946242180737582\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6898610591888428\n",
      "Validation loss decreased from 0.6946242180737582 to 0.694622814655304\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6898600459098816\n",
      "Validation loss decreased from 0.694622814655304 to 0.6946214437484741\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6898590922355652\n",
      "Validation loss decreased from 0.6946214437484741 to 0.6946201053532687\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.6898581385612488\n",
      "Validation loss decreased from 0.6946201053532687 to 0.6946187777952715\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6898570656776428\n",
      "Validation loss decreased from 0.6946187777952715 to 0.6946174935861067\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6898561120033264\n",
      "Validation loss decreased from 0.6946174935861067 to 0.6946162581443787\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6898550391197205\n",
      "Validation loss decreased from 0.6946162581443787 to 0.6946150064468384\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.689854085445404\n",
      "Validation loss decreased from 0.6946150064468384 to 0.6946137872609225\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6898530721664429\n",
      "Validation loss decreased from 0.6946137872609225 to 0.6946125680750067\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6898519992828369\n",
      "Validation loss decreased from 0.6946125680750067 to 0.6946113326332786\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.689850926399231\n",
      "Validation loss decreased from 0.6946113326332786 to 0.6946101026101545\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.689849853515625\n",
      "Validation loss decreased from 0.6946101026101545 to 0.6946088671684265\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.689848780632019\n",
      "Validation loss decreased from 0.6946088671684265 to 0.6946076425639066\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6898476481437683\n",
      "Validation loss decreased from 0.6946076425639066 to 0.6946064829826355\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.689846396446228\n",
      "Validation loss decreased from 0.6946064829826355 to 0.6946052854711359\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.689845085144043\n",
      "Validation loss decreased from 0.6946052854711359 to 0.6946041042154486\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6898438334465027\n",
      "Validation loss decreased from 0.6946041042154486 to 0.6946029554713856\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6898423433303833\n",
      "Validation loss decreased from 0.6946029554713856 to 0.6946018554947593\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6898409128189087\n",
      "Validation loss decreased from 0.6946018554947593 to 0.6946008042855696\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6898394227027893\n",
      "Validation loss decreased from 0.6946008042855696 to 0.6945997747507963\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6898378133773804\n",
      "Validation loss decreased from 0.6945997747507963 to 0.6945987397974188\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.689836323261261\n",
      "Validation loss decreased from 0.6945987397974188 to 0.6945976885882291\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6898349523544312\n",
      "Validation loss decreased from 0.6945976885882291 to 0.6945966861464761\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6898336410522461\n",
      "Validation loss decreased from 0.6945966861464761 to 0.6945955319838091\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6898324489593506\n",
      "Validation loss decreased from 0.6945955319838091 to 0.6945943940769542\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6898311376571655\n",
      "Validation loss decreased from 0.6945943940769542 to 0.6945933157747443\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6898297667503357\n",
      "Validation loss decreased from 0.6945933157747443 to 0.6945922645655546\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6898283958435059\n",
      "Validation loss decreased from 0.6945922645655546 to 0.6945912458679893\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6898269653320312\n",
      "Validation loss decreased from 0.6945912458679893 to 0.6945902813564647\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6898254752159119\n",
      "Validation loss decreased from 0.6945902813564647 to 0.6945893114263361\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6898238062858582\n",
      "Validation loss decreased from 0.6945893114263361 to 0.6945884065194563\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6898221373558044\n",
      "Validation loss decreased from 0.6945884065194563 to 0.6945875287055969\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6898202896118164\n",
      "Validation loss decreased from 0.6945875287055969 to 0.6945867104963823\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6898183822631836\n",
      "Validation loss decreased from 0.6945867104963823 to 0.6945859464732084\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.689816415309906\n",
      "Validation loss decreased from 0.6945859464732084 to 0.6945851445198059\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6898145079612732\n",
      "Validation loss decreased from 0.6945851445198059 to 0.6945843425664034\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6898126602172852\n",
      "Validation loss decreased from 0.6945843425664034 to 0.6945835189385847\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6898110508918762\n",
      "Validation loss decreased from 0.6945835189385847 to 0.6945826248689131\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6898095607757568\n",
      "Validation loss decreased from 0.6945826248689131 to 0.6945817037062212\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6898080110549927\n",
      "Validation loss decreased from 0.6945817037062212 to 0.694580777124925\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6898065209388733\n",
      "Validation loss decreased from 0.694580777124925 to 0.6945798830552534\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.6898047924041748\n",
      "Validation loss decreased from 0.6945798830552534 to 0.694579075683247\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.6898031234741211\n",
      "Validation loss decreased from 0.694579075683247 to 0.6945782899856567\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6898014545440674\n",
      "Validation loss decreased from 0.6945782899856567 to 0.6945774826136503\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6897996664047241\n",
      "Validation loss decreased from 0.6945774826136503 to 0.6945767023346641\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6897979378700256\n",
      "Validation loss decreased from 0.6945767023346641 to 0.6945759003812616\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.6897962093353271\n",
      "Validation loss decreased from 0.6945759003812616 to 0.6945750442418185\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.6897946000099182\n",
      "Validation loss decreased from 0.6945750442418185 to 0.6945741718465631\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6897931098937988\n",
      "Validation loss decreased from 0.6945741718465631 to 0.6945732723582875\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.689791738986969\n",
      "Validation loss decreased from 0.6945732723582875 to 0.6945723457769915\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6897901892662048\n",
      "Validation loss decreased from 0.6945723457769915 to 0.6945715167305686\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6897884607315063\n",
      "Validation loss decreased from 0.6945715167305686 to 0.6945707093585621\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6897867321968079\n",
      "Validation loss decreased from 0.6945707093585621 to 0.6945698965679515\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6897850632667542\n",
      "Validation loss decreased from 0.6945698965679515 to 0.6945691054517572\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6897833347320557\n",
      "Validation loss decreased from 0.6945691054517572 to 0.6945683305913751\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6897816061973572\n",
      "Validation loss decreased from 0.6945683305913751 to 0.6945675611495972\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6897798776626587\n",
      "Validation loss decreased from 0.6945675611495972 to 0.6945667483589866\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6897782683372498\n",
      "Validation loss decreased from 0.6945667483589866 to 0.6945659572427924\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6897767782211304\n",
      "Validation loss decreased from 0.6945659572427924 to 0.6945650956847451\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6897751688957214\n",
      "Validation loss decreased from 0.6945650956847451 to 0.6945641961964694\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6897736191749573\n",
      "Validation loss decreased from 0.6945641961964694 to 0.694563323801214\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6897720694541931\n",
      "Validation loss decreased from 0.694563323801214 to 0.6945624405687506\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6897702813148499\n",
      "Validation loss decreased from 0.6945624405687506 to 0.6945616440339522\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6897685527801514\n",
      "Validation loss decreased from 0.6945616440339522 to 0.6945608204061334\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6897665858268738\n",
      "Validation loss decreased from 0.6945608204061334 to 0.6945600563829596\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6897648572921753\n",
      "Validation loss decreased from 0.6945600563829596 to 0.694559243592349\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6897631287574768\n",
      "Validation loss decreased from 0.694559243592349 to 0.6945583766156976\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.689761221408844\n",
      "Validation loss decreased from 0.6945583766156976 to 0.6945576288483359\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6897591352462769\n",
      "Validation loss decreased from 0.6945576288483359 to 0.69455702196468\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6897567510604858\n",
      "Validation loss decreased from 0.69455702196468 to 0.6945564638484608\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.68975430727005\n",
      "Validation loss decreased from 0.6945564638484608 to 0.6945559436624701\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6897518634796143\n",
      "Validation loss decreased from 0.6945559436624701 to 0.6945553909648549\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.689749538898468\n",
      "Validation loss decreased from 0.6945553909648549 to 0.6945548491044478\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.689747154712677\n",
      "Validation loss decreased from 0.6945548491044478 to 0.6945543343370612\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6897447109222412\n",
      "Validation loss decreased from 0.6945543343370612 to 0.6945538304068826\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6897422671318054\n",
      "Validation loss decreased from 0.6945538304068826 to 0.6945532885464755\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6897398829460144\n",
      "Validation loss decreased from 0.6945532885464755 to 0.694552784616297\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6897375583648682\n",
      "Validation loss decreased from 0.694552784616297 to 0.6945522969419305\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6897352337837219\n",
      "Validation loss decreased from 0.6945522969419305 to 0.6945518255233765\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.68973308801651\n",
      "Validation loss decreased from 0.6945518255233765 to 0.6945513378490101\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6897309422492981\n",
      "Validation loss decreased from 0.6945513378490101 to 0.6945508393374357\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6897289156913757\n",
      "Validation loss decreased from 0.6945508393374357 to 0.6945502920584246\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6897268295288086\n",
      "Validation loss decreased from 0.6945502920584246 to 0.6945497556166216\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6897246837615967\n",
      "Validation loss decreased from 0.6945497556166216 to 0.6945492625236511\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6897225975990295\n",
      "Validation loss decreased from 0.6945492625236511 to 0.6945487694306807\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.6897204518318176\n",
      "Validation loss decreased from 0.6945487694306807 to 0.6945482546632941\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6897184252738953\n",
      "Validation loss decreased from 0.6945482546632941 to 0.6945476857098666\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.6897163987159729\n",
      "Validation loss decreased from 0.6945476857098666 to 0.6945471059192311\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6897144913673401\n",
      "Validation loss decreased from 0.6945471059192311 to 0.6945465044541792\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.6897129416465759\n",
      "Validation loss decreased from 0.6945465044541792 to 0.6945457025007769\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.689711332321167\n",
      "Validation loss decreased from 0.6945457025007769 to 0.6945449384776029\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6897098422050476\n",
      "Validation loss decreased from 0.6945449384776029 to 0.6945441636172208\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6897082328796387\n",
      "Validation loss decreased from 0.6945441636172208 to 0.6945434591986916\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6897063255310059\n",
      "Validation loss decreased from 0.6945434591986916 to 0.6945427439429543\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.689704179763794\n",
      "Validation loss decreased from 0.6945427439429543 to 0.6945421641523187\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6897019743919373\n",
      "Validation loss decreased from 0.6945421641523187 to 0.6945416818965565\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6896995306015015\n",
      "Validation loss decreased from 0.6945416818965565 to 0.6945411129431291\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6896970272064209\n",
      "Validation loss decreased from 0.6945411129431291 to 0.6945405114780773\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.6896946430206299\n",
      "Validation loss decreased from 0.6945405114780773 to 0.6945397799665277\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.6896923184394836\n",
      "Validation loss decreased from 0.6945397799665277 to 0.6945390159433539\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6896900534629822\n",
      "Validation loss decreased from 0.6945390159433539 to 0.6945382519201799\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.6896877884864807\n",
      "Validation loss decreased from 0.6945382519201799 to 0.6945374391295693\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6896857023239136\n",
      "Validation loss decreased from 0.6945374391295693 to 0.6945365396412936\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6896836161613464\n",
      "Validation loss decreased from 0.6945365396412936 to 0.6945356835018505\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6896815896034241\n",
      "Validation loss decreased from 0.6945356835018505 to 0.6945348111065951\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6896794438362122\n",
      "Validation loss decreased from 0.6945348111065951 to 0.6945339766415682\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6896772980690002\n",
      "Validation loss decreased from 0.6945339766415682 to 0.6945331530137495\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6896752715110779\n",
      "Validation loss decreased from 0.6945331530137495 to 0.6945323185487227\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6896731853485107\n",
      "Validation loss decreased from 0.6945323185487227 to 0.6945314732464877\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6896710991859436\n",
      "Validation loss decreased from 0.6945314732464877 to 0.6945306008512323\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6896690130233765\n",
      "Validation loss decreased from 0.6945306008512323 to 0.6945297230373729\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6896668672561646\n",
      "Validation loss decreased from 0.6945297230373729 to 0.6945288939909502\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.689664900302887\n",
      "Validation loss decreased from 0.6945288939909502 to 0.69452810829336\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6896628737449646\n",
      "Validation loss decreased from 0.69452810829336 to 0.6945272846655413\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6896607279777527\n",
      "Validation loss decreased from 0.6945272846655413 to 0.6945265802470121\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6896584630012512\n",
      "Validation loss decreased from 0.6945265802470121 to 0.6945258704098788\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.6896564960479736\n",
      "Validation loss decreased from 0.6945258704098788 to 0.6945251768285577\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6896547675132751\n",
      "Validation loss decreased from 0.6945251768285577 to 0.6945244019681757\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6896530985832214\n",
      "Validation loss decreased from 0.6945244019681757 to 0.6945235891775652\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6896514892578125\n",
      "Validation loss decreased from 0.6945235891775652 to 0.6945226463404569\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6896499991416931\n",
      "Validation loss decreased from 0.6945226463404569 to 0.6945217414335771\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6896485090255737\n",
      "Validation loss decreased from 0.6945217414335771 to 0.6945207985964689\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.6896469593048096\n",
      "Validation loss decreased from 0.6945207985964689 to 0.6945198286663402\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6896455883979797\n",
      "Validation loss decreased from 0.6945198286663402 to 0.6945187774571505\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6896442174911499\n",
      "Validation loss decreased from 0.6945187774571505 to 0.6945177316665649\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6896427869796753\n",
      "Validation loss decreased from 0.6945177316665649 to 0.6945166912945834\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6896412968635559\n",
      "Validation loss decreased from 0.6945166912945834 to 0.6945156725970182\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6896399855613708\n",
      "Validation loss decreased from 0.6945156725970182 to 0.6945145726203918\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6896384954452515\n",
      "Validation loss decreased from 0.6945145726203918 to 0.6945135647600348\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.689637303352356\n",
      "Validation loss decreased from 0.6945135647600348 to 0.694512432271784\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6896360516548157\n",
      "Validation loss decreased from 0.694512432271784 to 0.6945112997835333\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6896348595619202\n",
      "Validation loss decreased from 0.6945112997835333 to 0.6945101456208662\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6896336674690247\n",
      "Validation loss decreased from 0.6945101456208662 to 0.694508969783783\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.6896324753761292\n",
      "Validation loss decreased from 0.694508969783783 to 0.6945077343420549\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.6896315217018127\n",
      "Validation loss decreased from 0.6945077343420549 to 0.6945064447142861\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6896307468414307\n",
      "Validation loss decreased from 0.6945064447142861 to 0.6945050738074563\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6896299719810486\n",
      "Validation loss decreased from 0.6945050738074563 to 0.6945037245750427\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.6896291375160217\n",
      "Validation loss decreased from 0.6945037245750427 to 0.6945023428310048\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.6896283626556396\n",
      "Validation loss decreased from 0.6945023428310048 to 0.6945010098544034\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.689627468585968\n",
      "Validation loss decreased from 0.6945010098544034 to 0.6944996931336143\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6896266937255859\n",
      "Validation loss decreased from 0.6944996931336143 to 0.6944983222267844\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6896259188652039\n",
      "Validation loss decreased from 0.6944983222267844 to 0.6944969729943709\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6896251440048218\n",
      "Validation loss decreased from 0.6944969729943709 to 0.6944956075061451\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6896244287490845\n",
      "Validation loss decreased from 0.6944956075061451 to 0.6944942745295438\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6896236538887024\n",
      "Validation loss decreased from 0.6944942745295438 to 0.6944929307157343\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.6896228790283203\n",
      "Validation loss decreased from 0.6944929307157343 to 0.6944915869019248\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.689622163772583\n",
      "Validation loss decreased from 0.6944915869019248 to 0.6944902864369479\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6896213889122009\n",
      "Validation loss decreased from 0.6944902864369479 to 0.6944889697161588\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6896205544471741\n",
      "Validation loss decreased from 0.6944889697161588 to 0.6944876584139738\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.689619779586792\n",
      "Validation loss decreased from 0.6944876584139738 to 0.6944863471117887\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6896189451217651\n",
      "Validation loss decreased from 0.6944863471117887 to 0.6944850087165833\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6896181702613831\n",
      "Validation loss decreased from 0.6944850087165833 to 0.6944837136702104\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6896174550056458\n",
      "Validation loss decreased from 0.6944837136702104 to 0.6944824186238375\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6896165609359741\n",
      "Validation loss decreased from 0.6944824186238375 to 0.694481145251881\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6896158456802368\n",
      "Validation loss decreased from 0.694481145251881 to 0.6944798827171326\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6896150708198547\n",
      "Validation loss decreased from 0.6944798827171326 to 0.69447861476378\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.6896143555641174\n",
      "Validation loss decreased from 0.69447861476378 to 0.6944774226708845\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6896136403083801\n",
      "Validation loss decreased from 0.6944774226708845 to 0.694476230577989\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.689612865447998\n",
      "Validation loss decreased from 0.694476230577989 to 0.6944750059734691\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.689612090587616\n",
      "Validation loss decreased from 0.6944750059734691 to 0.6944737867875532\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6896112561225891\n",
      "Validation loss decreased from 0.6944737867875532 to 0.6944726272062822\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6896104216575623\n",
      "Validation loss decreased from 0.6944726272062822 to 0.6944714296947826\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6896095871925354\n",
      "Validation loss decreased from 0.6944714296947826 to 0.6944702701135115\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6896088123321533\n",
      "Validation loss decreased from 0.6944702701135115 to 0.6944691376252607\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6896078586578369\n",
      "Validation loss decreased from 0.6944691376252607 to 0.6944680864160712\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6896069049835205\n",
      "Validation loss decreased from 0.6944680864160712 to 0.694466997276653\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6896060109138489\n",
      "Validation loss decreased from 0.694466997276653 to 0.6944659623232755\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6896049976348877\n",
      "Validation loss decreased from 0.6944659623232755 to 0.6944649436257102\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6896039843559265\n",
      "Validation loss decreased from 0.6944649436257102 to 0.6944639140909369\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6896029114723206\n",
      "Validation loss decreased from 0.6944639140909369 to 0.6944628520445391\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6896018981933594\n",
      "Validation loss decreased from 0.6944628520445391 to 0.69446185502139\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6896008849143982\n",
      "Validation loss decreased from 0.69446185502139 to 0.6944608796726573\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6895997524261475\n",
      "Validation loss decreased from 0.6944608796726573 to 0.6944598772309043\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6895987391471863\n",
      "Validation loss decreased from 0.6944598772309043 to 0.6944589127193798\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.6895976662635803\n",
      "Validation loss decreased from 0.6944589127193798 to 0.6944579482078552\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.6895965933799744\n",
      "Validation loss decreased from 0.6944579482078552 to 0.6944569566033103\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6895955204963684\n",
      "Validation loss decreased from 0.6944569566033103 to 0.694456008347598\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.6895944476127625\n",
      "Validation loss decreased from 0.694456008347598 to 0.694455011324449\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6895935535430908\n",
      "Validation loss decreased from 0.694455011324449 to 0.6944539926268838\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6895925402641296\n",
      "Validation loss decreased from 0.6944539926268838 to 0.6944529793479226\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6895915269851685\n",
      "Validation loss decreased from 0.6944529793479226 to 0.6944519823247736\n",
      "no early stopping\n",
      "AUC on test data  0.5934374073175336\n",
      "model 39 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.695713996887207\n",
      "Validation loss decreased from inf to 0.6942762949249961\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6885102391242981\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6961923837661743\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.717847466468811\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6941913366317749\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6887001395225525\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7236281037330627\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6971234679222107\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6763196587562561\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6875084638595581\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6867985129356384\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6852129697799683\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6964774131774902\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6944526433944702\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.7000806331634521\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.694914698600769\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.702031672000885\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6928894519805908\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6911879181861877\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6838293075561523\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6920479536056519\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6888880133628845\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6897626519203186\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.7061959505081177\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6822262406349182\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7065103650093079\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6697624921798706\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6916593909263611\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.7039779424667358\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6955134272575378\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6984134316444397\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.7087075710296631\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.7132645845413208\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.691131055355072\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6855459213256836\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6954466700553894\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6774529218673706\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.703052282333374\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7017272710800171\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.7022543549537659\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.7006809711456299\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6844663023948669\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6880900859832764\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6850972771644592\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6916159987449646\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6858280301094055\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.7019211649894714\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6874510645866394\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.69014573097229\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6983051300048828\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.69146728515625\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5195970054014218\n",
      "model 40 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6969686150550842\n",
      "Validation loss decreased from inf to 0.6955869956450029\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6882214546203613\n",
      "Validation loss decreased from 0.6955869956450029 to 0.6955867789008401\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6934753060340881\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6900316476821899\n",
      "Validation loss decreased from 0.6955867789008401 to 0.6955862478776411\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6897454857826233\n",
      "Validation loss decreased from 0.6955862478776411 to 0.6955858469009399\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6971801519393921\n",
      "Validation loss decreased from 0.6955858469009399 to 0.6955855868079446\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6835897564888\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6980781555175781\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6914184093475342\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6906997561454773\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6927134394645691\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.7017195224761963\n",
      "Validation loss decreased from 0.6955855868079446 to 0.695585082877766\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6967141032218933\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6906757354736328\n",
      "Validation loss decreased from 0.695585082877766 to 0.6955848715522073\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6963738203048706\n",
      "Validation loss decreased from 0.6955848715522073 to 0.6955847306685015\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6967745423316956\n",
      "Validation loss decreased from 0.6955847306685015 to 0.6955839395523071\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6971104741096497\n",
      "Validation loss decreased from 0.6955839395523071 to 0.6955820972269232\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6930617094039917\n",
      "Validation loss decreased from 0.6955820972269232 to 0.6955805637619712\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.691024899482727\n",
      "Validation loss decreased from 0.6955805637619712 to 0.6955796480178833\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6987439393997192\n",
      "Validation loss decreased from 0.6955796480178833 to 0.6955779845064337\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6982330083847046\n",
      "Validation loss decreased from 0.6955779845064337 to 0.6955770470879294\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6860426068305969\n",
      "Validation loss decreased from 0.6955770470879294 to 0.6955761584368619\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.695347011089325\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6913985013961792\n",
      "Validation loss decreased from 0.6955761584368619 to 0.6955760067159479\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6947979927062988\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6976671814918518\n",
      "Validation loss decreased from 0.6955760067159479 to 0.6955758766694502\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6978740692138672\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6972112655639648\n",
      "Validation loss decreased from 0.6955758766694502 to 0.6955751559951089\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.688728392124176\n",
      "Validation loss decreased from 0.6955751559951089 to 0.6955742077393965\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6940231323242188\n",
      "Validation loss decreased from 0.6955742077393965 to 0.6955729885534807\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6943446397781372\n",
      "Validation loss decreased from 0.6955729885534807 to 0.6955718343908136\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6966055631637573\n",
      "Validation loss decreased from 0.6955718343908136 to 0.6955712329257618\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6882814168930054\n",
      "Validation loss decreased from 0.6955712329257618 to 0.6955706152048978\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6939987540245056\n",
      "Validation loss decreased from 0.6955706152048978 to 0.6955695910887285\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.687393069267273\n",
      "Validation loss decreased from 0.6955695910887285 to 0.6955695043910634\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.7032846212387085\n",
      "Validation loss decreased from 0.6955695043910634 to 0.6955685778097673\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6985451579093933\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6940641403198242\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6945368647575378\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.698576033115387\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6906237006187439\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6945249438285828\n",
      "Validation loss decreased from 0.6955685778097673 to 0.6955679817633196\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6841112375259399\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6943901777267456\n",
      "Validation loss decreased from 0.6955679817633196 to 0.6955677704377607\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6964327692985535\n",
      "Validation loss decreased from 0.6955677704377607 to 0.6955673586238514\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.7014050483703613\n",
      "Validation loss decreased from 0.6955673586238514 to 0.6955667463215914\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6904116272926331\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6906370520591736\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6817995309829712\n",
      "Validation loss decreased from 0.6955667463215914 to 0.6955663941123269\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6939263939857483\n",
      "Validation loss decreased from 0.6955663941123269 to 0.6955653699961576\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6962345242500305\n",
      "Validation loss decreased from 0.6955653699961576 to 0.6955642591823231\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6945489048957825\n",
      "Validation loss decreased from 0.6955642591823231 to 0.6955634138800881\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6881795525550842\n",
      "Validation loss decreased from 0.6955634138800881 to 0.6955628178336404\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6803544759750366\n",
      "Validation loss decreased from 0.6955628178336404 to 0.6955620917406949\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.7008700370788574\n",
      "Validation loss decreased from 0.6955620917406949 to 0.69556171243841\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.696593165397644\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6924992799758911\n",
      "Validation loss decreased from 0.69556171243841 to 0.6955607587640936\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6981452703475952\n",
      "Validation loss decreased from 0.6955607587640936 to 0.6955602927641436\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.7027883529663086\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6904770731925964\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6923653483390808\n",
      "Validation loss decreased from 0.6955602927641436 to 0.6955599405548789\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6874160766601562\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6861676573753357\n",
      "Validation loss decreased from 0.6955599405548789 to 0.6955594962293451\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6915979385375977\n",
      "Validation loss decreased from 0.6955594962293451 to 0.6955592252991416\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6864902377128601\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6975113153457642\n",
      "Validation loss decreased from 0.6955592252991416 to 0.6955592090433295\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6905714273452759\n",
      "Validation loss decreased from 0.6955592090433295 to 0.6955586184154857\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6912651062011719\n",
      "Validation loss decreased from 0.6955586184154857 to 0.6955570036714728\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6949875354766846\n",
      "Validation loss decreased from 0.6955570036714728 to 0.695555871183222\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.6952513456344604\n",
      "Validation loss decreased from 0.695555871183222 to 0.6955548145554282\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6936678886413574\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.6978667378425598\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6981363296508789\n",
      "Validation loss decreased from 0.6955548145554282 to 0.6955540505322543\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6835291981697083\n",
      "Validation loss decreased from 0.6955540505322543 to 0.6955539042299445\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.694413959980011\n",
      "Validation loss decreased from 0.6955539042299445 to 0.695553026416085\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6965534090995789\n",
      "Validation loss decreased from 0.695553026416085 to 0.6955523219975558\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6834787726402283\n",
      "Validation loss decreased from 0.6955523219975558 to 0.6955521269278093\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6940256953239441\n",
      "Validation loss decreased from 0.6955521269278093 to 0.6955520781603727\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.688298761844635\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6946275234222412\n",
      "Validation loss decreased from 0.6955520781603727 to 0.695551032369787\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6871734857559204\n",
      "Validation loss decreased from 0.695551032369787 to 0.6955500407652422\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6917070150375366\n",
      "Validation loss decreased from 0.6955500407652422 to 0.6955483935096047\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6969374418258667\n",
      "Validation loss decreased from 0.6955483935096047 to 0.6955479166724465\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6976776719093323\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.6981364488601685\n",
      "Validation loss decreased from 0.6955479166724465 to 0.6955478353933855\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6910578608512878\n",
      "Validation loss decreased from 0.6955478353933855 to 0.6955473314632069\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.692633330821991\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.700162410736084\n",
      "Validation loss decreased from 0.6955473314632069 to 0.6955465566028248\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6949148178100586\n",
      "Validation loss decreased from 0.6955465566028248 to 0.69554603099823\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6915931105613708\n",
      "Validation loss decreased from 0.69554603099823 to 0.6955449743704363\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6905024647712708\n",
      "Validation loss decreased from 0.6955449743704363 to 0.6955443837425925\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6972713470458984\n",
      "Validation loss decreased from 0.6955443837425925 to 0.6955437985333529\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6990247964859009\n",
      "Validation loss decreased from 0.6955437985333529 to 0.6955437931147489\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.6953107714653015\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6936769485473633\n",
      "Validation loss decreased from 0.6955437931147489 to 0.6955436088822105\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6883559226989746\n",
      "Validation loss decreased from 0.6955436088822105 to 0.695542498068376\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6996652483940125\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6965389251708984\n",
      "Validation loss decreased from 0.695542498068376 to 0.695541874928908\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6919981241226196\n",
      "Validation loss decreased from 0.695541874928908 to 0.6955417015335776\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6944150924682617\n",
      "Validation loss decreased from 0.6955417015335776 to 0.6955411596731707\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.687985360622406\n",
      "Validation loss decreased from 0.6955411596731707 to 0.6955410567196932\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6889782547950745\n",
      "Validation loss decreased from 0.6955410567196932 to 0.6955398321151733\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6924548149108887\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6908371448516846\n",
      "Validation loss decreased from 0.6955398321151733 to 0.6955396912314675\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.7005695700645447\n",
      "Validation loss decreased from 0.6955396912314675 to 0.6955392902547662\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6962800621986389\n",
      "Validation loss decreased from 0.6955392902547662 to 0.6955375454642556\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6828210353851318\n",
      "Validation loss decreased from 0.6955375454642556 to 0.6955367922782898\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6963571906089783\n",
      "Validation loss decreased from 0.6955367922782898 to 0.6955361799760298\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.686499297618866\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.688339114189148\n",
      "Validation loss decreased from 0.6955361799760298 to 0.6955360661853444\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6897991895675659\n",
      "Validation loss decreased from 0.6955360661853444 to 0.6955352859063582\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6935985088348389\n",
      "Validation loss decreased from 0.6955352859063582 to 0.6955342563715848\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6972406506538391\n",
      "Validation loss decreased from 0.6955342563715848 to 0.6955340125344016\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6926643252372742\n",
      "Validation loss decreased from 0.6955340125344016 to 0.6955332485112277\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.7037141919136047\n",
      "Validation loss decreased from 0.6955332485112277 to 0.6955323869531805\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6860002279281616\n",
      "Validation loss decreased from 0.6955323869531805 to 0.6955323056741194\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6911270022392273\n",
      "Validation loss decreased from 0.6955323056741194 to 0.6955322785810991\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6881225109100342\n",
      "Validation loss decreased from 0.6955322785810991 to 0.6955318450927734\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6931281089782715\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6878826022148132\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6860212683677673\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6941210031509399\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6970300078392029\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6965997219085693\n",
      "Validation loss decreased from 0.6955318450927734 to 0.6955314007672396\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6881478428840637\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6874856948852539\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6797094941139221\n",
      "Validation loss decreased from 0.6955314007672396 to 0.6955312111160972\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6950496435165405\n",
      "Validation loss decreased from 0.6955312111160972 to 0.695530587976629\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.6852482557296753\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6863763928413391\n",
      "Validation loss decreased from 0.695530587976629 to 0.6955302032557401\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6847746968269348\n",
      "Validation loss decreased from 0.6955302032557401 to 0.6955287944186818\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.703720211982727\n",
      "Validation loss decreased from 0.6955287944186818 to 0.6955268003723838\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6839948892593384\n",
      "Validation loss decreased from 0.6955268003723838 to 0.6955258087678389\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6831888556480408\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6878296136856079\n",
      "Validation loss decreased from 0.6955258087678389 to 0.6955253861167214\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6877801418304443\n",
      "Validation loss decreased from 0.6955253861167214 to 0.695524356581948\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6915825605392456\n",
      "Validation loss decreased from 0.695524356581948 to 0.6955237009308555\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6887282133102417\n",
      "Validation loss decreased from 0.6955237009308555 to 0.6955230669541792\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6882786154747009\n",
      "Validation loss decreased from 0.6955230669541792 to 0.6955225955356251\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6887022852897644\n",
      "Validation loss decreased from 0.6955225955356251 to 0.695521202954379\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6871657967567444\n",
      "Validation loss decreased from 0.695521202954379 to 0.6955197507684882\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6991482973098755\n",
      "Validation loss decreased from 0.6955197507684882 to 0.6955193714662031\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6850455403327942\n",
      "Validation loss decreased from 0.6955193714662031 to 0.6955193010243502\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6946219801902771\n",
      "Validation loss decreased from 0.6955193010243502 to 0.6955191005359996\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6865348219871521\n",
      "Validation loss decreased from 0.6955191005359996 to 0.6955181468616832\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6873931884765625\n",
      "Validation loss decreased from 0.6955181468616832 to 0.6955171606757424\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.682315468788147\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.698421061038971\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.7023305892944336\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6923089623451233\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6946810483932495\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6898815035820007\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6907817125320435\n",
      "Validation loss decreased from 0.6955171606757424 to 0.6955169981176202\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.6933228373527527\n",
      "Validation loss decreased from 0.6955169981176202 to 0.695516131140969\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.6955245137214661\n",
      "Validation loss decreased from 0.695516131140969 to 0.6955146139318292\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.6906265616416931\n",
      "Validation loss decreased from 0.6955146139318292 to 0.6955138986760919\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.702747106552124\n",
      "Validation loss decreased from 0.6955138986760919 to 0.6955131509087302\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.7007795572280884\n",
      "Validation loss decreased from 0.6955131509087302 to 0.6955126903273843\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6951473355293274\n",
      "Validation loss decreased from 0.6955126903273843 to 0.6955121809786017\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.6839107275009155\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6994612812995911\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.690994918346405\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6898464560508728\n",
      "Validation loss decreased from 0.6955121809786017 to 0.6955119425600226\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6946815252304077\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6952341794967651\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6895976662635803\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6900236010551453\n",
      "Validation loss decreased from 0.6955119425600226 to 0.6955111676996405\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6956064105033875\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.6959184408187866\n",
      "Validation loss decreased from 0.6955111676996405 to 0.695510680025274\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6960384845733643\n",
      "Validation loss decreased from 0.695510680025274 to 0.6955097859556024\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6818842887878418\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6930880546569824\n",
      "Validation loss decreased from 0.6955097859556024 to 0.695509590885856\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6964114308357239\n",
      "Validation loss decreased from 0.695509590885856 to 0.6955090652812611\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6837759613990784\n",
      "Validation loss decreased from 0.6955090652812611 to 0.6955082362348383\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6879810094833374\n",
      "Validation loss decreased from 0.6955082362348383 to 0.695507363839583\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.6988175511360168\n",
      "Validation loss decreased from 0.695507363839583 to 0.6955060687932101\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6928412914276123\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.689557671546936\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6922204494476318\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6885606050491333\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.7019074559211731\n",
      "Validation loss decreased from 0.6955060687932101 to 0.6955057328397577\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6929756999015808\n",
      "Validation loss decreased from 0.6955057328397577 to 0.6955055323514071\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.6877070665359497\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.6905022859573364\n",
      "Validation loss decreased from 0.6955055323514071 to 0.6955054510723461\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6936360597610474\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6948370933532715\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6940459609031677\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.7016154527664185\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.695146918296814\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6924235820770264\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.695331871509552\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.6871229410171509\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6888109445571899\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6828531622886658\n",
      "Validation loss decreased from 0.6955054510723461 to 0.6955042589794506\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6864224076271057\n",
      "Validation loss decreased from 0.6955042589794506 to 0.6955035924911499\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.7019887566566467\n",
      "Validation loss decreased from 0.6955035924911499 to 0.6955017447471619\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6951490640640259\n",
      "Validation loss decreased from 0.6955017447471619 to 0.6955013058402322\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.691953718662262\n",
      "Validation loss decreased from 0.6955013058402322 to 0.6955005038868297\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6970956325531006\n",
      "Validation loss decreased from 0.6955005038868297 to 0.6954999132589861\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6849430203437805\n",
      "Validation loss decreased from 0.6954999132589861 to 0.6954994906078685\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.7061060667037964\n",
      "Validation loss decreased from 0.6954994906078685 to 0.6954990733753551\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.69929438829422\n",
      "Validation loss decreased from 0.6954990733753551 to 0.695497063073245\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6931177377700806\n",
      "Validation loss decreased from 0.695497063073245 to 0.695495914329182\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6934216022491455\n",
      "Validation loss decreased from 0.695495914329182 to 0.6954956650733948\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.6939191222190857\n",
      "Validation loss decreased from 0.6954956650733948 to 0.6954948902130127\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.693875253200531\n",
      "Validation loss decreased from 0.6954948902130127 to 0.6954935734922235\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.690226137638092\n",
      "Validation loss decreased from 0.6954935734922235 to 0.6954933350736444\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.684604287147522\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6869213581085205\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6985803246498108\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6920132637023926\n",
      "Validation loss decreased from 0.6954933350736444 to 0.6954933242364363\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6793507933616638\n",
      "Validation loss decreased from 0.6954933242364363 to 0.69549283656207\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.6939473748207092\n",
      "Validation loss decreased from 0.69549283656207 to 0.695492067120292\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.6898335218429565\n",
      "Validation loss decreased from 0.695492067120292 to 0.6954914873296564\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.6969096064567566\n",
      "Validation loss decreased from 0.6954914873296564 to 0.6954898129809987\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.6981337666511536\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.6909812688827515\n",
      "Validation loss decreased from 0.6954898129809987 to 0.6954892440275713\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.6862442493438721\n",
      "Validation loss decreased from 0.6954892440275713 to 0.6954888484694741\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.6884783506393433\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.7030752897262573\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.6899306774139404\n",
      "Validation loss decreased from 0.6954888484694741 to 0.6954879327253862\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.6904370784759521\n",
      "Validation loss decreased from 0.6954879327253862 to 0.6954878514463251\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.7033904194831848\n",
      "Validation loss decreased from 0.6954878514463251 to 0.6954873312603344\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.7023196220397949\n",
      "Validation loss decreased from 0.6954873312603344 to 0.6954872499812733\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.6850314140319824\n",
      "Validation loss decreased from 0.6954872499812733 to 0.6954863613302057\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.6937741637229919\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.69134521484375\n",
      "Validation loss decreased from 0.6954863613302057 to 0.695485917004672\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.6873921155929565\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.6915061473846436\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.6970597505569458\n",
      "Validation loss decreased from 0.695485917004672 to 0.6954848007722334\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.7012209892272949\n",
      "Validation loss decreased from 0.6954848007722334 to 0.6954843185164712\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.6945871114730835\n",
      "Validation loss decreased from 0.6954843185164712 to 0.695484074679288\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.7000305652618408\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.6955406069755554\n",
      "Validation loss decreased from 0.695484074679288 to 0.6954831860282205\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.69025057554245\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.6821722984313965\n",
      "Validation loss decreased from 0.6954831860282205 to 0.6954825954003767\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.6997827887535095\n",
      "Validation loss decreased from 0.6954825954003767 to 0.6954821023074064\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.6867517828941345\n",
      "Validation loss decreased from 0.6954821023074064 to 0.6954817121679132\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.6920148730278015\n",
      "Validation loss decreased from 0.6954817121679132 to 0.6954815712842074\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.6969213485717773\n",
      "Validation loss decreased from 0.6954815712842074 to 0.6954812570051714\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.6889992356300354\n",
      "Validation loss decreased from 0.6954812570051714 to 0.6954808235168457\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.697980523109436\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.6916341185569763\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.6967401504516602\n",
      "Validation loss decreased from 0.6954808235168457 to 0.6954806338657032\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.6851344704627991\n",
      "Validation loss decreased from 0.6954806338657032 to 0.695479772307656\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.6951702237129211\n",
      "Validation loss decreased from 0.695479772307656 to 0.6954785151915117\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.6931049227714539\n",
      "Validation loss decreased from 0.6954785151915117 to 0.6954780871217902\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.6993938088417053\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.6997016072273254\n",
      "Validation loss decreased from 0.6954780871217902 to 0.6954776644706726\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.6962018013000488\n",
      "Validation loss decreased from 0.6954776644706726 to 0.6954771117730574\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.6918425559997559\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.7023627161979675\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.6913259625434875\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.6877956390380859\n",
      "Validation loss decreased from 0.6954771117730574 to 0.6954769817265597\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.689484179019928\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.6957136392593384\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.7001033425331116\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.6879461407661438\n",
      "Validation loss decreased from 0.6954769817265597 to 0.6954768787730824\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.6976345777511597\n",
      "Validation loss decreased from 0.6954768787730824 to 0.6954759630289945\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.7024779915809631\n",
      "Validation loss decreased from 0.6954759630289945 to 0.6954754753546282\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.6840386986732483\n",
      "Validation loss decreased from 0.6954754753546282 to 0.6954746192151849\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.6925315260887146\n",
      "Validation loss decreased from 0.6954746192151849 to 0.6954732754013755\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.6932749152183533\n",
      "Validation loss decreased from 0.6954732754013755 to 0.6954725222154097\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.6925708651542664\n",
      "Validation loss decreased from 0.6954725222154097 to 0.6954717798666521\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.7049337029457092\n",
      "Validation loss decreased from 0.6954717798666521 to 0.6954709562388334\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.6916818618774414\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.6893711686134338\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.6887531280517578\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.6976456046104431\n",
      "Validation loss decreased from 0.6954709562388334 to 0.6954705660993402\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.6944401860237122\n",
      "Validation loss decreased from 0.6954705660993402 to 0.6954693252390082\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.6917126178741455\n",
      "Validation loss decreased from 0.6954693252390082 to 0.695469319820404\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.695092499256134\n",
      "Validation loss decreased from 0.695469319820404 to 0.695469243959947\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.6970518827438354\n",
      "Validation loss decreased from 0.695469243959947 to 0.6954676400531422\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.6910780072212219\n",
      "Validation loss decreased from 0.6954676400531422 to 0.6954674341461875\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.6910886168479919\n",
      "Validation loss decreased from 0.6954674341461875 to 0.6954672119834207\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.6916281580924988\n",
      "Validation loss decreased from 0.6954672119834207 to 0.695466550913724\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.6937665343284607\n",
      "Validation loss decreased from 0.695466550913724 to 0.6954663937742059\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.7058927416801453\n",
      "Validation loss decreased from 0.6954663937742059 to 0.6954656568440524\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.6855601072311401\n",
      "Validation loss decreased from 0.6954656568440524 to 0.6954645406116139\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.6951500177383423\n",
      "Validation loss decreased from 0.6954645406116139 to 0.6954642913558267\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.690356433391571\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.6851956844329834\n",
      "Validation loss decreased from 0.6954642913558267 to 0.6954641829837452\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.6949141621589661\n",
      "Validation loss decreased from 0.6954641829837452 to 0.6954635056582364\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.699588418006897\n",
      "Validation loss decreased from 0.6954635056582364 to 0.6954633376815103\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.6873905062675476\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.6936339735984802\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.6881259083747864\n",
      "Validation loss decreased from 0.6954633376815103 to 0.6954617554491217\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.6936171054840088\n",
      "Validation loss decreased from 0.6954617554491217 to 0.6954613057049838\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.7004297971725464\n",
      "Validation loss decreased from 0.6954613057049838 to 0.6954607584259727\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.6874357461929321\n",
      "Validation loss decreased from 0.6954607584259727 to 0.6954604874957692\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.6961665749549866\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.696243941783905\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.6964025497436523\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.6934530138969421\n",
      "Validation loss decreased from 0.6954604874957692 to 0.6954589215191928\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.6935686469078064\n",
      "Validation loss decreased from 0.6954589215191928 to 0.6954576535658403\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.6882585287094116\n",
      "Validation loss decreased from 0.6954576535658403 to 0.6954556486823342\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.6978639364242554\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.6896998286247253\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.6982128620147705\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.6916887164115906\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.6991664171218872\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.6885777711868286\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.6970056891441345\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.6903271079063416\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.6937036514282227\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.6980705857276917\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.6871176362037659\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.691938042640686\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.6896282434463501\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.6845163106918335\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.696009635925293\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.7057020664215088\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.6866524815559387\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.6901429295539856\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.693152666091919\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.6846209764480591\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.6895008683204651\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.6937443017959595\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.6932020783424377\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.6931912899017334\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.6980771422386169\n",
      "Validation loss decreased from 0.6954556486823342 to 0.6954543753103777\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.6873754858970642\n",
      "Validation loss decreased from 0.6954543753103777 to 0.6954539255662398\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.690794050693512\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.6933534741401672\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.6912594437599182\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.6997696757316589\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.6851043701171875\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.6947224736213684\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.6982364654541016\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.6929214000701904\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.6912097930908203\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.6942842602729797\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.6969402432441711\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.6865728497505188\n",
      "Validation loss decreased from 0.6954539255662398 to 0.6954529014500704\n",
      "Model trained for 335 epochs out of 500. Training loss is 0.6832622289657593\n",
      "Validation loss decreased from 0.6954529014500704 to 0.6954516497525302\n",
      "Model trained for 336 epochs out of 500. Training loss is 0.6960340142250061\n",
      "Validation loss decreased from 0.6954516497525302 to 0.6954514655199918\n",
      "Model trained for 337 epochs out of 500. Training loss is 0.6880401968955994\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 338 epochs out of 500. Training loss is 0.6884753704071045\n",
      "Validation loss decreased from 0.6954514655199918 to 0.6954514384269714\n",
      "Model trained for 339 epochs out of 500. Training loss is 0.6901196241378784\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 340 epochs out of 500. Training loss is 0.6969549059867859\n",
      "Validation loss decreased from 0.6954514384269714 to 0.6954510482874784\n",
      "Model trained for 341 epochs out of 500. Training loss is 0.6887884140014648\n",
      "Validation loss decreased from 0.6954510482874784 to 0.6954501542178068\n",
      "Model trained for 342 epochs out of 500. Training loss is 0.6907013654708862\n",
      "Validation loss decreased from 0.6954501542178068 to 0.6954496069387957\n",
      "Model trained for 343 epochs out of 500. Training loss is 0.6830275058746338\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 344 epochs out of 500. Training loss is 0.6919164657592773\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 345 epochs out of 500. Training loss is 0.6971946358680725\n",
      "Validation loss decreased from 0.6954496069387957 to 0.6954494172876532\n",
      "Model trained for 346 epochs out of 500. Training loss is 0.6986168622970581\n",
      "Validation loss decreased from 0.6954494172876532 to 0.6954483064738187\n",
      "Model trained for 347 epochs out of 500. Training loss is 0.6939229965209961\n",
      "Validation loss decreased from 0.6954483064738187 to 0.6954478946599093\n",
      "Model trained for 348 epochs out of 500. Training loss is 0.6932675838470459\n",
      "Validation loss decreased from 0.6954478946599093 to 0.6954475587064569\n",
      "Model trained for 349 epochs out of 500. Training loss is 0.6914343237876892\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 350 epochs out of 500. Training loss is 0.6894831657409668\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 351 epochs out of 500. Training loss is 0.6953396797180176\n",
      "Validation loss decreased from 0.6954475587064569 to 0.695446409962394\n",
      "Model trained for 352 epochs out of 500. Training loss is 0.6912736296653748\n",
      "Validation loss decreased from 0.695446409962394 to 0.6954460631717335\n",
      "Model trained for 353 epochs out of 500. Training loss is 0.6845412254333496\n",
      "Validation loss decreased from 0.6954460631717335 to 0.6954453208229758\n",
      "Model trained for 354 epochs out of 500. Training loss is 0.6841467618942261\n",
      "Validation loss decreased from 0.6954453208229758 to 0.6954446868462996\n",
      "Model trained for 355 epochs out of 500. Training loss is 0.6985167264938354\n",
      "Validation loss decreased from 0.6954446868462996 to 0.6954440962184559\n",
      "Model trained for 356 epochs out of 500. Training loss is 0.6953204274177551\n",
      "Validation loss decreased from 0.6954440962184559 to 0.6954436085440896\n",
      "Model trained for 357 epochs out of 500. Training loss is 0.6843145489692688\n",
      "Validation loss decreased from 0.6954436085440896 to 0.6954423731023615\n",
      "Model trained for 358 epochs out of 500. Training loss is 0.6961180567741394\n",
      "Validation loss decreased from 0.6954423731023615 to 0.6954419992186807\n",
      "Model trained for 359 epochs out of 500. Training loss is 0.6897085309028625\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 360 epochs out of 500. Training loss is 0.6897420287132263\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 361 epochs out of 500. Training loss is 0.70066237449646\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 362 epochs out of 500. Training loss is 0.689423143863678\n",
      "Validation loss decreased from 0.6954419992186807 to 0.6954411647536538\n",
      "Model trained for 363 epochs out of 500. Training loss is 0.6981261372566223\n",
      "Validation loss decreased from 0.6954411647536538 to 0.6954404494979165\n",
      "Model trained for 364 epochs out of 500. Training loss is 0.6971962451934814\n",
      "Validation loss decreased from 0.6954404494979165 to 0.6954397721724077\n",
      "Model trained for 365 epochs out of 500. Training loss is 0.6880051493644714\n",
      "Validation loss decreased from 0.6954397721724077 to 0.6954389756376093\n",
      "Model trained for 366 epochs out of 500. Training loss is 0.700130045413971\n",
      "Validation loss decreased from 0.6954389756376093 to 0.6954380978237499\n",
      "Model trained for 367 epochs out of 500. Training loss is 0.7001412510871887\n",
      "Validation loss decreased from 0.6954380978237499 to 0.6954372687773271\n",
      "Model trained for 368 epochs out of 500. Training loss is 0.6887399554252625\n",
      "Validation loss decreased from 0.6954372687773271 to 0.6954371766610579\n",
      "Model trained for 369 epochs out of 500. Training loss is 0.6908829808235168\n",
      "Validation loss decreased from 0.6954371766610579 to 0.6954364343123003\n",
      "Model trained for 370 epochs out of 500. Training loss is 0.6938803195953369\n",
      "Validation loss decreased from 0.6954364343123003 to 0.6954357624053955\n",
      "Model trained for 371 epochs out of 500. Training loss is 0.6924909949302673\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 372 epochs out of 500. Training loss is 0.6953707337379456\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 373 epochs out of 500. Training loss is 0.6878273487091064\n",
      "Validation loss decreased from 0.6954357624053955 to 0.6954353614286943\n",
      "Model trained for 374 epochs out of 500. Training loss is 0.6939199566841125\n",
      "Validation loss decreased from 0.6954353614286943 to 0.6954348195682872\n",
      "Model trained for 375 epochs out of 500. Training loss is 0.6858009696006775\n",
      "Validation loss decreased from 0.6954348195682872 to 0.6954343481497332\n",
      "Model trained for 376 epochs out of 500. Training loss is 0.6940701007843018\n",
      "Validation loss decreased from 0.6954343481497332 to 0.6954336654056202\n",
      "Model trained for 377 epochs out of 500. Training loss is 0.6926351189613342\n",
      "Validation loss decreased from 0.6954336654056202 to 0.6954324678941206\n",
      "Model trained for 378 epochs out of 500. Training loss is 0.6952356696128845\n",
      "Validation loss decreased from 0.6954324678941206 to 0.6954318610104647\n",
      "Model trained for 379 epochs out of 500. Training loss is 0.6859344840049744\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 380 epochs out of 500. Training loss is 0.6947160959243774\n",
      "Validation loss decreased from 0.6954318610104647 to 0.6954316876151345\n",
      "Model trained for 381 epochs out of 500. Training loss is 0.6906006336212158\n",
      "Validation loss decreased from 0.6954316876151345 to 0.6954307556152344\n",
      "Model trained for 382 epochs out of 500. Training loss is 0.6856739521026611\n",
      "Validation loss decreased from 0.6954307556152344 to 0.6954298452897505\n",
      "Model trained for 383 epochs out of 500. Training loss is 0.6953781843185425\n",
      "Validation loss decreased from 0.6954298452897505 to 0.695429574359547\n",
      "Model trained for 384 epochs out of 500. Training loss is 0.6944562196731567\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 385 epochs out of 500. Training loss is 0.6927655339241028\n",
      "Validation loss decreased from 0.695429574359547 to 0.6954288320107893\n",
      "Model trained for 386 epochs out of 500. Training loss is 0.6946262717247009\n",
      "Validation loss decreased from 0.6954288320107893 to 0.6954273960807107\n",
      "Model trained for 387 epochs out of 500. Training loss is 0.6846520900726318\n",
      "Validation loss decreased from 0.6954273960807107 to 0.695427266034213\n",
      "Model trained for 388 epochs out of 500. Training loss is 0.6866592764854431\n",
      "Validation loss decreased from 0.695427266034213 to 0.6954271793365479\n",
      "Model trained for 389 epochs out of 500. Training loss is 0.6931490898132324\n",
      "Validation loss decreased from 0.6954271793365479 to 0.6954267675226385\n",
      "Model trained for 390 epochs out of 500. Training loss is 0.6940011978149414\n",
      "Validation loss decreased from 0.6954267675226385 to 0.6954247843135487\n",
      "Model trained for 391 epochs out of 500. Training loss is 0.6882382035255432\n",
      "Validation loss decreased from 0.6954247843135487 to 0.6954237060113386\n",
      "Model trained for 392 epochs out of 500. Training loss is 0.6988257765769958\n",
      "Validation loss decreased from 0.6954237060113386 to 0.6954222809184681\n",
      "Model trained for 393 epochs out of 500. Training loss is 0.6880084872245789\n",
      "Validation loss decreased from 0.6954222809184681 to 0.6954220370812849\n",
      "Model trained for 394 epochs out of 500. Training loss is 0.6864479780197144\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 395 epochs out of 500. Training loss is 0.6932516098022461\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 396 epochs out of 500. Training loss is 0.6955316662788391\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 397 epochs out of 500. Training loss is 0.6909574866294861\n",
      "Validation loss decreased from 0.6954220370812849 to 0.6954215819185431\n",
      "Model trained for 398 epochs out of 500. Training loss is 0.6922047734260559\n",
      "Validation loss decreased from 0.6954215819185431 to 0.6954205469651655\n",
      "Model trained for 399 epochs out of 500. Training loss is 0.6850352883338928\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 400 epochs out of 500. Training loss is 0.6958103179931641\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 401 epochs out of 500. Training loss is 0.6943536996841431\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 402 epochs out of 500. Training loss is 0.6760331392288208\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 403 epochs out of 500. Training loss is 0.6979471445083618\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 404 epochs out of 500. Training loss is 0.6897649765014648\n",
      "Validation loss decreased from 0.6954205469651655 to 0.6954200213605707\n",
      "Model trained for 405 epochs out of 500. Training loss is 0.679157018661499\n",
      "Validation loss decreased from 0.6954200213605707 to 0.6954196366396818\n",
      "Model trained for 406 epochs out of 500. Training loss is 0.6922899484634399\n",
      "Validation loss decreased from 0.6954196366396818 to 0.6954191652211276\n",
      "Model trained for 407 epochs out of 500. Training loss is 0.688755214214325\n",
      "Validation loss decreased from 0.6954191652211276 to 0.6954189755699851\n",
      "Model trained for 408 epochs out of 500. Training loss is 0.6967987418174744\n",
      "Validation loss decreased from 0.6954189755699851 to 0.6954189268025485\n",
      "Model trained for 409 epochs out of 500. Training loss is 0.7013319730758667\n",
      "Validation loss decreased from 0.6954189268025485 to 0.6954186450351368\n",
      "Model trained for 410 epochs out of 500. Training loss is 0.6943487524986267\n",
      "Validation loss decreased from 0.6954186450351368 to 0.6954175558957186\n",
      "Model trained for 411 epochs out of 500. Training loss is 0.6923976540565491\n",
      "Validation loss decreased from 0.6954175558957186 to 0.6954164613376964\n",
      "Model trained for 412 epochs out of 500. Training loss is 0.6823446750640869\n",
      "Validation loss decreased from 0.6954164613376964 to 0.6954162175005133\n",
      "Model trained for 413 epochs out of 500. Training loss is 0.6935368776321411\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 414 epochs out of 500. Training loss is 0.6945923566818237\n",
      "Validation loss decreased from 0.6954162175005133 to 0.6954153884540905\n",
      "Model trained for 415 epochs out of 500. Training loss is 0.6965915560722351\n",
      "Validation loss decreased from 0.6954153884540905 to 0.6954144131053578\n",
      "Model trained for 416 epochs out of 500. Training loss is 0.6866719722747803\n",
      "Validation loss decreased from 0.6954144131053578 to 0.6954144022681497\n",
      "Model trained for 417 epochs out of 500. Training loss is 0.6960161328315735\n",
      "Validation loss decreased from 0.6954144022681497 to 0.6954142884774641\n",
      "Model trained for 418 epochs out of 500. Training loss is 0.695734977722168\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 419 epochs out of 500. Training loss is 0.7000192999839783\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 420 epochs out of 500. Training loss is 0.6842701435089111\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 421 epochs out of 500. Training loss is 0.7018680572509766\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 422 epochs out of 500. Training loss is 0.6798759698867798\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 423 epochs out of 500. Training loss is 0.6852372884750366\n",
      "Validation loss decreased from 0.6954142884774641 to 0.6954139308495955\n",
      "Model trained for 424 epochs out of 500. Training loss is 0.6931489706039429\n",
      "Validation loss decreased from 0.6954139308495955 to 0.6954125599427656\n",
      "Model trained for 425 epochs out of 500. Training loss is 0.6948416233062744\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 426 epochs out of 500. Training loss is 0.6796302199363708\n",
      "Validation loss decreased from 0.6954125599427656 to 0.6954121264544401\n",
      "Model trained for 427 epochs out of 500. Training loss is 0.6979095935821533\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 428 epochs out of 500. Training loss is 0.6892971992492676\n",
      "Validation loss decreased from 0.6954121264544401 to 0.6954115249893882\n",
      "Model trained for 429 epochs out of 500. Training loss is 0.6888828277587891\n",
      "Validation loss decreased from 0.6954115249893882 to 0.6954102516174316\n",
      "Model trained for 430 epochs out of 500. Training loss is 0.6941327452659607\n",
      "Validation loss decreased from 0.6954102516174316 to 0.6954093087803234\n",
      "Model trained for 431 epochs out of 500. Training loss is 0.6955376267433167\n",
      "Validation loss decreased from 0.6954093087803234 to 0.6954086802222512\n",
      "Model trained for 432 epochs out of 500. Training loss is 0.6989620923995972\n",
      "Validation loss decreased from 0.6954086802222512 to 0.6954082142223011\n",
      "Model trained for 433 epochs out of 500. Training loss is 0.6922310590744019\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 434 epochs out of 500. Training loss is 0.6922673583030701\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 435 epochs out of 500. Training loss is 0.6819196939468384\n",
      "Validation loss decreased from 0.6954082142223011 to 0.695407433943315\n",
      "Model trained for 436 epochs out of 500. Training loss is 0.69205242395401\n",
      "Validation loss decreased from 0.695407433943315 to 0.6954068704084917\n",
      "Model trained for 437 epochs out of 500. Training loss is 0.6950204372406006\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 438 epochs out of 500. Training loss is 0.6944521069526672\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 439 epochs out of 500. Training loss is 0.6958358287811279\n",
      "Validation loss decreased from 0.6954068704084917 to 0.6954068270596591\n",
      "Model trained for 440 epochs out of 500. Training loss is 0.6978022456169128\n",
      "Validation loss decreased from 0.6954068270596591 to 0.695405125617981\n",
      "Model trained for 441 epochs out of 500. Training loss is 0.6943414211273193\n",
      "Validation loss decreased from 0.695405125617981 to 0.6954043074087664\n",
      "Model trained for 442 epochs out of 500. Training loss is 0.7007308006286621\n",
      "Validation loss decreased from 0.6954043074087664 to 0.6954039335250854\n",
      "Model trained for 443 epochs out of 500. Training loss is 0.6931820511817932\n",
      "Validation loss decreased from 0.6954039335250854 to 0.6954035975716331\n",
      "Model trained for 444 epochs out of 500. Training loss is 0.6814748048782349\n",
      "Validation loss decreased from 0.6954035975716331 to 0.695402589711276\n",
      "Model trained for 445 epochs out of 500. Training loss is 0.6843010187149048\n",
      "Validation loss decreased from 0.695402589711276 to 0.6954024271531538\n",
      "Model trained for 446 epochs out of 500. Training loss is 0.6898921132087708\n",
      "Validation loss decreased from 0.6954024271531538 to 0.6954020207578485\n",
      "Model trained for 447 epochs out of 500. Training loss is 0.6922115087509155\n",
      "Validation loss decreased from 0.6954020207578485 to 0.6954011808742177\n",
      "Model trained for 448 epochs out of 500. Training loss is 0.6969600915908813\n",
      "Validation loss decreased from 0.6954011808742177 to 0.695400899106806\n",
      "Model trained for 449 epochs out of 500. Training loss is 0.6947777271270752\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 450 epochs out of 500. Training loss is 0.6852390170097351\n",
      "Validation loss decreased from 0.695400899106806 to 0.6954008449207653\n",
      "Model trained for 451 epochs out of 500. Training loss is 0.6856210231781006\n",
      "Validation loss decreased from 0.6954008449207653 to 0.6954007961533286\n",
      "Model trained for 452 epochs out of 500. Training loss is 0.6897082328796387\n",
      "Validation loss decreased from 0.6954007961533286 to 0.6954001946882769\n",
      "Model trained for 453 epochs out of 500. Training loss is 0.699449896812439\n",
      "Validation loss decreased from 0.6954001946882769 to 0.6953992139209401\n",
      "Model trained for 454 epochs out of 500. Training loss is 0.691045880317688\n",
      "Validation loss decreased from 0.6953992139209401 to 0.6953986503861167\n",
      "Model trained for 455 epochs out of 500. Training loss is 0.6913465857505798\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 456 epochs out of 500. Training loss is 0.6927133202552795\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 457 epochs out of 500. Training loss is 0.688340425491333\n",
      "Validation loss decreased from 0.6953986503861167 to 0.695398292758248\n",
      "Model trained for 458 epochs out of 500. Training loss is 0.7008256316184998\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 459 epochs out of 500. Training loss is 0.6963440775871277\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 460 epochs out of 500. Training loss is 0.6997531652450562\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 461 epochs out of 500. Training loss is 0.6931288242340088\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 462 epochs out of 500. Training loss is 0.6946547627449036\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 463 epochs out of 500. Training loss is 0.6908276081085205\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 464 epochs out of 500. Training loss is 0.6937702894210815\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 465 epochs out of 500. Training loss is 0.69588303565979\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 466 epochs out of 500. Training loss is 0.6995920538902283\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 467 epochs out of 500. Training loss is 0.6911258697509766\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 468 epochs out of 500. Training loss is 0.6977259516716003\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 469 epochs out of 500. Training loss is 0.694718599319458\n",
      "Validation loss decreased from 0.695398292758248 to 0.6953975449908864\n",
      "Model trained for 470 epochs out of 500. Training loss is 0.6929420232772827\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 471 epochs out of 500. Training loss is 0.6847333908081055\n",
      "Validation loss decreased from 0.6953975449908864 to 0.6953966400840066\n",
      "Model trained for 472 epochs out of 500. Training loss is 0.6892156004905701\n",
      "Validation loss decreased from 0.6953966400840066 to 0.6953963095491583\n",
      "Model trained for 473 epochs out of 500. Training loss is 0.6949297189712524\n",
      "Validation loss decreased from 0.6953963095491583 to 0.6953962499445135\n",
      "Model trained for 474 epochs out of 500. Training loss is 0.6931391358375549\n",
      "Validation loss decreased from 0.6953962499445135 to 0.6953958598050204\n",
      "Model trained for 475 epochs out of 500. Training loss is 0.6941115856170654\n",
      "Validation loss decreased from 0.6953958598050204 to 0.695395594293421\n",
      "Model trained for 476 epochs out of 500. Training loss is 0.696376621723175\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 477 epochs out of 500. Training loss is 0.6822291612625122\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 478 epochs out of 500. Training loss is 0.6877025365829468\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 479 epochs out of 500. Training loss is 0.6936095952987671\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 480 epochs out of 500. Training loss is 0.6906558871269226\n",
      "Validation loss decreased from 0.695395594293421 to 0.6953950957818464\n",
      "Model trained for 481 epochs out of 500. Training loss is 0.6997875571250916\n",
      "Validation loss decreased from 0.6953950957818464 to 0.6953945322470232\n",
      "Model trained for 482 epochs out of 500. Training loss is 0.6826992630958557\n",
      "Validation loss decreased from 0.6953945322470232 to 0.6953941204331138\n",
      "Model trained for 483 epochs out of 500. Training loss is 0.6978829503059387\n",
      "Validation loss decreased from 0.6953941204331138 to 0.6953938007354736\n",
      "Model trained for 484 epochs out of 500. Training loss is 0.6940921545028687\n",
      "Validation loss decreased from 0.6953938007354736 to 0.6953934485262091\n",
      "Model trained for 485 epochs out of 500. Training loss is 0.6860247850418091\n",
      "Validation loss decreased from 0.6953934485262091 to 0.6953916224566373\n",
      "Model trained for 486 epochs out of 500. Training loss is 0.6858565211296082\n",
      "Validation loss decreased from 0.6953916224566373 to 0.6953913948752664\n",
      "Model trained for 487 epochs out of 500. Training loss is 0.6876976490020752\n",
      "Validation loss decreased from 0.6953913948752664 to 0.6953912594101646\n",
      "Model trained for 488 epochs out of 500. Training loss is 0.6936448812484741\n",
      "Validation loss decreased from 0.6953912594101646 to 0.6953903057358481\n",
      "Model trained for 489 epochs out of 500. Training loss is 0.6886583566665649\n",
      "Validation loss decreased from 0.6953903057358481 to 0.6953900239684365\n",
      "Model trained for 490 epochs out of 500. Training loss is 0.6922877430915833\n",
      "Validation loss decreased from 0.6953900239684365 to 0.6953894929452376\n",
      "Model trained for 491 epochs out of 500. Training loss is 0.6929041743278503\n",
      "Validation loss decreased from 0.6953894929452376 to 0.6953881274570118\n",
      "Model trained for 492 epochs out of 500. Training loss is 0.6908776760101318\n",
      "Validation loss decreased from 0.6953881274570118 to 0.6953871087594465\n",
      "Model trained for 493 epochs out of 500. Training loss is 0.6928181648254395\n",
      "Validation loss decreased from 0.6953871087594465 to 0.6953860412944447\n",
      "Model trained for 494 epochs out of 500. Training loss is 0.699368417263031\n",
      "Validation loss decreased from 0.6953860412944447 to 0.6953851526433771\n",
      "Model trained for 495 epochs out of 500. Training loss is 0.681765615940094\n",
      "Validation loss decreased from 0.6953851526433771 to 0.6953837004574862\n",
      "Model trained for 496 epochs out of 500. Training loss is 0.6954370737075806\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 497 epochs out of 500. Training loss is 0.7019990682601929\n",
      "Validation loss decreased from 0.6953837004574862 to 0.6953826925971291\n",
      "Model trained for 498 epochs out of 500. Training loss is 0.6988047361373901\n",
      "Validation loss decreased from 0.6953826925971291 to 0.6953823458064686\n",
      "Model trained for 499 epochs out of 500. Training loss is 0.6883015036582947\n",
      "Validation loss decreased from 0.6953823458064686 to 0.695382150736722\n",
      "Model trained for 500 epochs out of 500. Training loss is 0.6824522614479065\n",
      "Counter for early stopping: 1 out of 50\n",
      "no early stopping\n",
      "AUC on test data  0.48295541355478266\n",
      "model 41 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6992175579071045\n",
      "Validation loss decreased from inf to 0.6938813166184858\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.684568464756012\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6936373710632324\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.692208468914032\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6896461248397827\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.693741500377655\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6837527751922607\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6906388401985168\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.69212406873703\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.683348536491394\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6934167742729187\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6972428560256958\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6928733587265015\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6919231414794922\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6917902231216431\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6871567964553833\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6860338449478149\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6886430978775024\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6887885928153992\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6887980699539185\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6904090642929077\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6913513541221619\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6890633702278137\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6834505200386047\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.68543940782547\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6868628859519958\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6945652961730957\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6924912929534912\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6862426996231079\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6924183964729309\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6906601786613464\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6885860562324524\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6920128464698792\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6923466920852661\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6900917291641235\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6910519599914551\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6900274157524109\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6950430870056152\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6940045952796936\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6856738924980164\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6919984817504883\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6905905604362488\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.690066397190094\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6949337124824524\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6889260411262512\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6867578029632568\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6897349953651428\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6873500943183899\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6861673593521118\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6893475651741028\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6924765706062317\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.507904410112612\n",
      "model 42 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6927201151847839\n",
      "Validation loss decreased from inf to 0.6919367421757091\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6892397999763489\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6902452707290649\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6901600956916809\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6995016932487488\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6882126331329346\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6865326166152954\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6902488470077515\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6912757754325867\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6895843148231506\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.684608519077301\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6970852613449097\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6887900233268738\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6856238842010498\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6794577240943909\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6863909959793091\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6924793720245361\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6927671432495117\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6966743469238281\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6918175220489502\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6936240196228027\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6920595169067383\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6867073774337769\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6910372376441956\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.690158486366272\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6921327114105225\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6907156109809875\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6896061897277832\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6845099329948425\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6963016390800476\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6865581274032593\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6986956596374512\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6862166523933411\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6864668130874634\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6912068724632263\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6878265738487244\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6865423321723938\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6905742883682251\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6851046681404114\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6913372278213501\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6865532994270325\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6942620873451233\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6856346726417542\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6905832886695862\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6870505809783936\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6855326890945435\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6834335923194885\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6896264553070068\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6888445019721985\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.693013072013855\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6892149448394775\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5610019143142171\n",
      "model 43 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6925927996635437\n",
      "Validation loss decreased from inf to 0.6986255808310076\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6913453340530396\n",
      "Validation loss decreased from 0.6986255808310076 to 0.6960450139912692\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6904083490371704\n",
      "Validation loss decreased from 0.6960450139912692 to 0.6958272673866965\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6896824240684509\n",
      "Validation loss decreased from 0.6958272673866965 to 0.6954602219841697\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.688924252986908\n",
      "Validation loss decreased from 0.6954602219841697 to 0.6950603886084123\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6880987882614136\n",
      "Validation loss decreased from 0.6950603886084123 to 0.6947363073175604\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6872102618217468\n",
      "Validation loss decreased from 0.6947363073175604 to 0.6943289745937694\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6861333847045898\n",
      "Validation loss decreased from 0.6943289745937694 to 0.6939469467509877\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6849278211593628\n",
      "Validation loss decreased from 0.6939469467509877 to 0.6935111284255981\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.683631181716919\n",
      "Validation loss decreased from 0.6935111284255981 to 0.6929674473675814\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6821050643920898\n",
      "Validation loss decreased from 0.6929674473675814 to 0.6923593228513544\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6803727746009827\n",
      "Validation loss decreased from 0.6923593228513544 to 0.6916357224637811\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6783748865127563\n",
      "Validation loss decreased from 0.6916357224637811 to 0.6907469630241394\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6759659647941589\n",
      "Validation loss decreased from 0.6907469630241394 to 0.689658750187267\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6731083989143372\n",
      "Validation loss decreased from 0.689658750187267 to 0.6882732835682955\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6695240139961243\n",
      "Validation loss decreased from 0.6882732835682955 to 0.6865675340999257\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6650383472442627\n",
      "Validation loss decreased from 0.6865675340999257 to 0.6845525232228366\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6591794490814209\n",
      "Validation loss decreased from 0.6845525232228366 to 0.6819133541800759\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.651732325553894\n",
      "Validation loss decreased from 0.6819133541800759 to 0.6785115220329978\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.642118513584137\n",
      "Validation loss decreased from 0.6785115220329978 to 0.6740282448855314\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6295215487480164\n",
      "Validation loss decreased from 0.6740282448855314 to 0.6677608977664601\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6136694550514221\n",
      "Validation loss decreased from 0.6677608977664601 to 0.6587502306157892\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.5932939052581787\n",
      "Validation loss decreased from 0.6587502306157892 to 0.6459431377324191\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.5691433548927307\n",
      "Validation loss decreased from 0.6459431377324191 to 0.6307306777347218\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.5418693423271179\n",
      "Validation loss decreased from 0.6307306777347218 to 0.6149296218698675\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.5082537531852722\n",
      "Validation loss decreased from 0.6149296218698675 to 0.5978782827203925\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.4697333872318268\n",
      "Validation loss decreased from 0.5978782827203925 to 0.5808811350302263\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.43054667115211487\n",
      "Validation loss decreased from 0.5808811350302263 to 0.565425230698152\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.39348104596138\n",
      "Validation loss decreased from 0.565425230698152 to 0.552119330926375\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.358144074678421\n",
      "Validation loss decreased from 0.552119330926375 to 0.541001710024747\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.3273671865463257\n",
      "Validation loss decreased from 0.541001710024747 to 0.5344437089833346\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.2955141067504883\n",
      "Validation loss decreased from 0.5344437089833346 to 0.5312032022259452\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.26146137714385986\n",
      "Validation loss decreased from 0.5312032022259452 to 0.5294151902198792\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.22891369462013245\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.19992761313915253\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.17483501136302948\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.15206019580364227\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.13386885821819305\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.1151551604270935\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.10335297882556915\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.09197867661714554\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.08390840888023376\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.07702770829200745\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.07158194482326508\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.06689693033695221\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.06377476453781128\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.06073141470551491\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.05895531177520752\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.05714932829141617\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.05518333613872528\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.05435226112604141\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.0529465451836586\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.0516975037753582\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.0505470409989357\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.049980875104665756\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.04907447099685669\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.04860047996044159\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.04758848622441292\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.04713661968708038\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.046525973826646805\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.04612882807850838\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.045708686113357544\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.045973483473062515\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.045239947736263275\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.045551005750894547\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.04509144276380539\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.04515768215060234\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.04469863325357437\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.04442720115184784\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.044486578553915024\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.044366829097270966\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.044033654034137726\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.04427269101142883\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.04392009600996971\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.044033583253622055\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.044001586735248566\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.04402560368180275\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.04374973103404045\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.04371902719140053\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.043487489223480225\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.043347377330064774\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.04294464364647865\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.043326523154973984\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  33\n",
      "AUC on test data  0.8138082270574383\n",
      "model 44 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.7013509273529053\n",
      "Validation loss decreased from inf to 0.692285727370869\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6874942779541016\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6916694045066833\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6836504936218262\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6987425684928894\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6897442936897278\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6914864778518677\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6983789801597595\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6958165764808655\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.7012059688568115\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6906244158744812\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.69173663854599\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.700706422328949\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6924898028373718\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6941645741462708\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6887261271476746\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.693621039390564\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.694311797618866\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6899732947349548\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6903069615364075\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6882863640785217\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6973387002944946\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6917352676391602\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6925506591796875\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6845964193344116\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.689418613910675\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6840560436248779\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.688367486000061\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6865333914756775\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6899805068969727\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6818079352378845\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6978304982185364\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6937436461448669\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.685470700263977\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6838356256484985\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6861937046051025\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.688202977180481\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6929701566696167\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6882153153419495\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6861844062805176\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6902302503585815\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6805799007415771\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6920836567878723\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6912709474563599\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6851395964622498\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6917658448219299\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6900501847267151\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6919810771942139\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6897681951522827\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6855459213256836\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6916715502738953\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5624938211689\n",
      "model 45 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6980728507041931\n",
      "Validation loss decreased from inf to 0.6926116997545416\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.7054532170295715\n",
      "Validation loss decreased from 0.6926116997545416 to 0.6926039511507208\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.7061970829963684\n",
      "Validation loss decreased from 0.6926039511507208 to 0.6925964572212913\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6923485994338989\n",
      "Validation loss decreased from 0.6925964572212913 to 0.6925893480127508\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.7073469758033752\n",
      "Validation loss decreased from 0.6925893480127508 to 0.6925825855948708\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6952889561653137\n",
      "Validation loss decreased from 0.6925825855948708 to 0.6925759857351129\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7130025029182434\n",
      "Validation loss decreased from 0.6925759857351129 to 0.6925696351311423\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.7096977829933167\n",
      "Validation loss decreased from 0.6925696351311423 to 0.6925634904341265\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6987772583961487\n",
      "Validation loss decreased from 0.6925634904341265 to 0.6925580447370355\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6869325041770935\n",
      "Validation loss decreased from 0.6925580447370355 to 0.692552691156214\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.7059822678565979\n",
      "Validation loss decreased from 0.692552691156214 to 0.692547695203261\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6922450661659241\n",
      "Validation loss decreased from 0.692547695203261 to 0.6925428292968057\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6989604830741882\n",
      "Validation loss decreased from 0.6925428292968057 to 0.6925384889949452\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.7041464447975159\n",
      "Validation loss decreased from 0.6925384889949452 to 0.6925343166698109\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6958291530609131\n",
      "Validation loss decreased from 0.6925343166698109 to 0.6925306699492715\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.7032684683799744\n",
      "Validation loss decreased from 0.6925306699492715 to 0.6925270503217523\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6945114135742188\n",
      "Validation loss decreased from 0.6925270503217523 to 0.6925235065546903\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6946830153465271\n",
      "Validation loss decreased from 0.6925235065546903 to 0.6925203149968927\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.7053598761558533\n",
      "Validation loss decreased from 0.6925203149968927 to 0.6925173185088418\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.7028173804283142\n",
      "Validation loss decreased from 0.6925173185088418 to 0.6925146308812228\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.7073202133178711\n",
      "Validation loss decreased from 0.6925146308812228 to 0.6925125501372598\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6981567740440369\n",
      "Validation loss decreased from 0.6925125501372598 to 0.6925106265328147\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6961477398872375\n",
      "Validation loss decreased from 0.6925106265328147 to 0.6925086975097656\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.7000830173492432\n",
      "Validation loss decreased from 0.6925086975097656 to 0.692507266998291\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.7010420560836792\n",
      "Validation loss decreased from 0.692507266998291 to 0.6925059719519182\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.7061476707458496\n",
      "Validation loss decreased from 0.6925059719519182 to 0.6925048990683123\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.7018929123878479\n",
      "Validation loss decreased from 0.6925048990683123 to 0.6925040537660773\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6950581073760986\n",
      "Validation loss decreased from 0.6925040537660773 to 0.6925035389986905\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6947070956230164\n",
      "Validation loss decreased from 0.6925035389986905 to 0.6925032301382585\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6921934485435486\n",
      "Validation loss decreased from 0.6925032301382585 to 0.6925029646266591\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6946317553520203\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6871169805526733\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.7003880739212036\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.7058801651000977\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.691432535648346\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.7030801773071289\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.7068983316421509\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6923888325691223\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.7017444968223572\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6980013251304626\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6946175694465637\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6969605684280396\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6946941018104553\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.7068711519241333\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.7124024033546448\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6944308280944824\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.7090733647346497\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.700171172618866\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.7027202248573303\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6956005692481995\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6895883083343506\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6954784393310547\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6927447319030762\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6956379413604736\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.7099677920341492\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.7163365483283997\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.6900267004966736\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6999017596244812\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.6922975182533264\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6841699481010437\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.7116150259971619\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6965721845626831\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.7022477388381958\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.693027913570404\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6958926320075989\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.7140088677406311\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.6869829297065735\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6891341209411621\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6838708519935608\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.703278124332428\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6978720426559448\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.7100194096565247\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.700168788433075\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.7062488198280334\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.7021371722221375\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6942774057388306\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6991189122200012\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6919955015182495\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6888896226882935\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6994776129722595\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  30\n",
      "AUC on test data  0.46803185131260844\n",
      "model 46 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6916188597679138\n",
      "Validation loss decreased from inf to 0.6997071016918529\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.695540726184845\n",
      "Validation loss decreased from 0.6997071016918529 to 0.6966676224361766\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6817651391029358\n",
      "Validation loss decreased from 0.6966676224361766 to 0.6962233565070413\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.695557177066803\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6891756653785706\n",
      "Validation loss decreased from 0.6962233565070413 to 0.6957261670719493\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6944521069526672\n",
      "Validation loss decreased from 0.6957261670719493 to 0.6951140436259183\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.7006786465644836\n",
      "Validation loss decreased from 0.6951140436259183 to 0.6949402581561696\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6872237920761108\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6768232583999634\n",
      "Validation loss decreased from 0.6949402581561696 to 0.6942676847631281\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6839313507080078\n",
      "Validation loss decreased from 0.6942676847631281 to 0.6929089535366405\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6803320646286011\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6838988065719604\n",
      "Validation loss decreased from 0.6929089535366405 to 0.6922378756783225\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6846203804016113\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6823151111602783\n",
      "Validation loss decreased from 0.6922378756783225 to 0.6920277963985096\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.687400758266449\n",
      "Validation loss decreased from 0.6920277963985096 to 0.6908190250396729\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.67130047082901\n",
      "Validation loss decreased from 0.6908190250396729 to 0.6899385831572793\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6773292422294617\n",
      "Validation loss decreased from 0.6899385831572793 to 0.6891675374724648\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6735881567001343\n",
      "Validation loss decreased from 0.6891675374724648 to 0.6881538250229575\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.678677499294281\n",
      "Validation loss decreased from 0.6881538250229575 to 0.6861475814472545\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6712334752082825\n",
      "Validation loss decreased from 0.6861475814472545 to 0.6836900602687489\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6670262813568115\n",
      "Validation loss decreased from 0.6836900602687489 to 0.6813925396312367\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6549524664878845\n",
      "Validation loss decreased from 0.6813925396312367 to 0.6788488789038225\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6504743099212646\n",
      "Validation loss decreased from 0.6788488789038225 to 0.6754800189625133\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6393554210662842\n",
      "Validation loss decreased from 0.6754800189625133 to 0.6701788902282715\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6309483051300049\n",
      "Validation loss decreased from 0.6701788902282715 to 0.6616362224925648\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6037003397941589\n",
      "Validation loss decreased from 0.6616362224925648 to 0.6499946117401123\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.5834583640098572\n",
      "Validation loss decreased from 0.6499946117401123 to 0.6363229047168385\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.5726000666618347\n",
      "Validation loss decreased from 0.6363229047168385 to 0.6239124048839916\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.5482729077339172\n",
      "Validation loss decreased from 0.6239124048839916 to 0.6088371493599631\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.5037049651145935\n",
      "Validation loss decreased from 0.6088371493599631 to 0.5940312418070707\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.48247411847114563\n",
      "Validation loss decreased from 0.5940312418070707 to 0.5784518176859076\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.4356723725795746\n",
      "Validation loss decreased from 0.5784518176859076 to 0.5649151449853723\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.42243045568466187\n",
      "Validation loss decreased from 0.5649151449853723 to 0.5564304454760118\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.38377615809440613\n",
      "Validation loss decreased from 0.5564304454760118 to 0.5469473356550391\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.35750362277030945\n",
      "Validation loss decreased from 0.5469473356550391 to 0.5404470454562794\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.3522864282131195\n",
      "Validation loss decreased from 0.5404470454562794 to 0.5358668267726898\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.31489571928977966\n",
      "Validation loss decreased from 0.5358668267726898 to 0.5325969593091444\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.2724217474460602\n",
      "Validation loss decreased from 0.5325969593091444 to 0.5294285335324027\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.255812406539917\n",
      "Validation loss decreased from 0.5294285335324027 to 0.5289447036656466\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.23990029096603394\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.2403474897146225\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.18209266662597656\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.18915197253227234\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.19123484194278717\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.1330789476633072\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.1708371490240097\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.13392892479896545\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.14343339204788208\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.13439737260341644\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.11135408282279968\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.12480092793703079\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.08585603535175323\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.09556844830513\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.10426966100931168\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.0794253945350647\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.09192004799842834\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.07698923349380493\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.06902358680963516\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.08395002782344818\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.05939174443483353\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.08392156660556793\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.09150142967700958\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.0853583887219429\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.05832508206367493\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.06064630672335625\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.081130251288414\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.06045794486999512\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.06864459812641144\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06015603616833687\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.07595731317996979\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.06976504623889923\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.08504199981689453\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.058239467442035675\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.06600788980722427\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.07494223862886429\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.060978252440690994\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.047250330448150635\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.08011314272880554\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.061052463948726654\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.06702464073896408\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.06168530508875847\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.05131980776786804\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.089305579662323\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.06827729940414429\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.05252477526664734\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.07390540093183517\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.0554363988339901\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.05565743148326874\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.06389999389648438\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  39\n",
      "AUC on test data  0.812801639300062\n",
      "model 47 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6932772397994995\n",
      "Validation loss decreased from inf to 0.6957187760959972\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6950235366821289\n",
      "Validation loss decreased from 0.6957187760959972 to 0.6951360377398405\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.690636396408081\n",
      "Validation loss decreased from 0.6951360377398405 to 0.694117399779233\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6931934356689453\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6929800510406494\n",
      "Validation loss decreased from 0.694117399779233 to 0.6940891200845892\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6898534893989563\n",
      "Validation loss decreased from 0.6940891200845892 to 0.6935327378186312\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6882690191268921\n",
      "Validation loss decreased from 0.6935327378186312 to 0.6930730126120828\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6885498762130737\n",
      "Validation loss decreased from 0.6930730126120828 to 0.692773087458177\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6858846545219421\n",
      "Validation loss decreased from 0.692773087458177 to 0.692176033150066\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6872661113739014\n",
      "Validation loss decreased from 0.692176033150066 to 0.6920426487922668\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.68475741147995\n",
      "Validation loss decreased from 0.6920426487922668 to 0.6914585612036965\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6836429834365845\n",
      "Validation loss decreased from 0.6914585612036965 to 0.6903389692306519\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6853134036064148\n",
      "Validation loss decreased from 0.6903389692306519 to 0.6895427649671381\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6809472441673279\n",
      "Validation loss decreased from 0.6895427649671381 to 0.6883723898367449\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6796925663948059\n",
      "Validation loss decreased from 0.6883723898367449 to 0.6873605847358704\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6725258231163025\n",
      "Validation loss decreased from 0.6873605847358704 to 0.6849837411533702\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.671070396900177\n",
      "Validation loss decreased from 0.6849837411533702 to 0.683473527431488\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6659337878227234\n",
      "Validation loss decreased from 0.683473527431488 to 0.6814871376210992\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6552371978759766\n",
      "Validation loss decreased from 0.6814871376210992 to 0.6787016066637906\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6487922668457031\n",
      "Validation loss decreased from 0.6787016066637906 to 0.6742803942073475\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6415590643882751\n",
      "Validation loss decreased from 0.6742803942073475 to 0.6678329760378058\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6303584575653076\n",
      "Validation loss decreased from 0.6678329760378058 to 0.6595799652012911\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6071914434432983\n",
      "Validation loss decreased from 0.6595799652012911 to 0.6478042494166981\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.5915757417678833\n",
      "Validation loss decreased from 0.6478042494166981 to 0.6352385065772317\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.5634962916374207\n",
      "Validation loss decreased from 0.6352385065772317 to 0.6209490082480691\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.5446919798851013\n",
      "Validation loss decreased from 0.6209490082480691 to 0.6062968535856768\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.527352511882782\n",
      "Validation loss decreased from 0.6062968535856768 to 0.5926487337459218\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.4924201965332031\n",
      "Validation loss decreased from 0.5926487337459218 to 0.5791976560245861\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.4467221200466156\n",
      "Validation loss decreased from 0.5791976560245861 to 0.5671249736439098\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.41789183020591736\n",
      "Validation loss decreased from 0.5671249736439098 to 0.5570399246432565\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.3855659067630768\n",
      "Validation loss decreased from 0.5570399246432565 to 0.5497889816761017\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.365149587392807\n",
      "Validation loss decreased from 0.5497889816761017 to 0.5456818206743761\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.33969730138778687\n",
      "Validation loss decreased from 0.5456818206743761 to 0.5435220951383765\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.2881126403808594\n",
      "Validation loss decreased from 0.5435220951383765 to 0.5376571633599021\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.2613970935344696\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.24186259508132935\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.20003165304660797\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.2051987200975418\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.1767575889825821\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.15470534563064575\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.1484944373369217\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.12016791850328445\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.11732078343629837\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.108244389295578\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.08561047911643982\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.09942016005516052\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.08838091790676117\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.07796280831098557\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.07804080098867416\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.09200897812843323\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.07035424560308456\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.0758008286356926\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.061349619179964066\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.0675002858042717\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.06641151010990143\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.05412178859114647\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.06620987504720688\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.07888206094503403\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.06353238970041275\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.056373707950115204\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.05725602060556412\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.057626061141490936\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.05818613991141319\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.04568621888756752\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.05103055760264397\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.07335105538368225\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.06126756966114044\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.060091547667980194\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06492408365011215\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.05736273154616356\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.05549350753426552\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.05155956745147705\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.0623801089823246\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.05217757076025009\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.048538558185100555\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.06591692566871643\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.04967592656612396\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.056035637855529785\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.05203699320554733\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.05446832627058029\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.059300389140844345\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.05113820359110832\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.05307476222515106\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.06192665919661522\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  34\n",
      "AUC on test data  0.8170796372689116\n",
      "model 48 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6923016309738159\n",
      "Validation loss decreased from inf to 0.6951513994823803\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.693238377571106\n",
      "Validation loss decreased from 0.6951513994823803 to 0.695149383761666\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6885798573493958\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6941494345664978\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6913958191871643\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6938143372535706\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6908953785896301\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6892210841178894\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6911731958389282\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6955419182777405\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.691834032535553\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.688869833946228\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.690612256526947\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6914766430854797\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6946264505386353\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.695465087890625\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6942335963249207\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6920889616012573\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6962637901306152\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.693098247051239\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6915087699890137\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6911855936050415\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6931983828544617\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6928785443305969\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6878336668014526\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6918313503265381\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6879703402519226\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6873276829719543\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6892848014831543\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6947556734085083\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6919679045677185\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6910770535469055\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6892488598823547\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6916348934173584\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6902011036872864\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6888771653175354\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6890761852264404\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6894651651382446\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6901214122772217\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6931930780410767\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6868423223495483\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.694379985332489\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.688947856426239\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6908506751060486\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6908093094825745\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6864678859710693\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6943747401237488\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6912586092948914\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6918487548828125\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6879795789718628\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6908186674118042\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6914154887199402\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  2\n",
      "AUC on test data  0.5180107309444848\n",
      "model 49 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6820003390312195\n",
      "Validation loss decreased from inf to 0.6947052099487998\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6899811029434204\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6902545094490051\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6890548467636108\n",
      "Validation loss decreased from 0.6947052099487998 to 0.6944156614216891\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6841360330581665\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6900970935821533\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.683103621006012\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6836084723472595\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6928693652153015\n",
      "Validation loss decreased from 0.6944156614216891 to 0.6937392841685902\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6923537850379944\n",
      "Validation loss decreased from 0.6937392841685902 to 0.6933031298897483\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6896353363990784\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.686690092086792\n",
      "Validation loss decreased from 0.6933031298897483 to 0.6928688341921027\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6843937635421753\n",
      "Validation loss decreased from 0.6928688341921027 to 0.6923741589892994\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.6856613159179688\n",
      "Validation loss decreased from 0.6923741589892994 to 0.6918697953224182\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6817663908004761\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6846674680709839\n",
      "Validation loss decreased from 0.6918697953224182 to 0.6912504922259938\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6865954995155334\n",
      "Validation loss decreased from 0.6912504922259938 to 0.6906420642679388\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6782194375991821\n",
      "Validation loss decreased from 0.6906420642679388 to 0.6902444416826422\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6711145043373108\n",
      "Validation loss decreased from 0.6902444416826422 to 0.6893233060836792\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.671423614025116\n",
      "Validation loss decreased from 0.6893233060836792 to 0.6870680451393127\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.66949462890625\n",
      "Validation loss decreased from 0.6870680451393127 to 0.6860079602761702\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6665708422660828\n",
      "Validation loss decreased from 0.6860079602761702 to 0.6834892684763129\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.662489116191864\n",
      "Validation loss decreased from 0.6834892684763129 to 0.6814015724442222\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.662779688835144\n",
      "Validation loss decreased from 0.6814015724442222 to 0.6773111495104703\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6584530472755432\n",
      "Validation loss decreased from 0.6773111495104703 to 0.6749508001587607\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.651725172996521\n",
      "Validation loss decreased from 0.6749508001587607 to 0.6701054031198675\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6244472861289978\n",
      "Validation loss decreased from 0.6701054031198675 to 0.660981763492931\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6120244264602661\n",
      "Validation loss decreased from 0.660981763492931 to 0.6513493006879633\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.5881438851356506\n",
      "Validation loss decreased from 0.6513493006879633 to 0.6408355723727833\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.5930500030517578\n",
      "Validation loss decreased from 0.6408355723727833 to 0.6274076158350165\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.580216646194458\n",
      "Validation loss decreased from 0.6274076158350165 to 0.6144273281097412\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.5433343052864075\n",
      "Validation loss decreased from 0.6144273281097412 to 0.6023636568676342\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.5255091786384583\n",
      "Validation loss decreased from 0.6023636568676342 to 0.5909662734378468\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.48057469725608826\n",
      "Validation loss decreased from 0.5909662734378468 to 0.5780474218455228\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.4724932909011841\n",
      "Validation loss decreased from 0.5780474218455228 to 0.5680753534490411\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.39583760499954224\n",
      "Validation loss decreased from 0.5680753534490411 to 0.5579420490698381\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.4064622223377228\n",
      "Validation loss decreased from 0.5579420490698381 to 0.5517190532250837\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.3776591122150421\n",
      "Validation loss decreased from 0.5517190532250837 to 0.5481954921375621\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.348147988319397\n",
      "Validation loss decreased from 0.5481954921375621 to 0.541477076031945\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.3379388153553009\n",
      "Validation loss decreased from 0.541477076031945 to 0.5369510515169664\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.34689849615097046\n",
      "Validation loss decreased from 0.5369510515169664 to 0.5315806513482874\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.2850996255874634\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.27842357754707336\n",
      "Validation loss decreased from 0.5315806513482874 to 0.5307254330678419\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.26220637559890747\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.22534453868865967\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.19345727562904358\n",
      "Validation loss decreased from 0.5307254330678419 to 0.5296788351102308\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.21384045481681824\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.14685431122779846\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.17028813064098358\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.14367495477199554\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.16667836904525757\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.11516603827476501\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.1440725475549698\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.1270100474357605\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.13703252375125885\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.1194624975323677\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.10334009677171707\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.08475596457719803\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.0958162248134613\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.10748212784528732\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.1025652140378952\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.09434898942708969\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.08487715572118759\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.08549516648054123\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.07131794840097427\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.09746715426445007\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.09837283194065094\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.07789089530706406\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.06662849336862564\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.07187029719352722\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.061886344105005264\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.08304131031036377\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.056010399013757706\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.10512924194335938\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.06827734410762787\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.05698077753186226\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.07149455696344376\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.06532607227563858\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.07669986039400101\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.05929524451494217\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.04927214980125427\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.06855639815330505\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.0499463826417923\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.06678089499473572\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.07571988552808762\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.060405537486076355\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.05322778597474098\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.056943129748106\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.057214509695768356\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.05800002068281174\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.06642048805952072\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.07932239770889282\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.06381796300411224\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.05176689103245735\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.06217844411730766\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.05071982368826866\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  46\n",
      "AUC on test data  0.8367530354912058\n",
      "model 50 out of 50\n",
      "Model trained for 1 epochs out of 500. Training loss is 0.6938124299049377\n",
      "Validation loss decreased from inf to 0.6918797167864713\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6938028335571289\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.696234941482544\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6888863444328308\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6928911805152893\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6857141852378845\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6941284537315369\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6896031498908997\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6952561736106873\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6899006962776184\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6885803937911987\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6876294612884521\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6909642815589905\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.694491982460022\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6872197389602661\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6866321563720703\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6883469820022583\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.6931242346763611\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6942706108093262\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6950426697731018\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6842398643493652\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6872149705886841\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6837406158447266\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.691248893737793\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6875556707382202\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6834259033203125\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6889739036560059\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6845687031745911\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6867924332618713\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6858401298522949\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6851162910461426\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6840817928314209\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6875277161598206\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6897763013839722\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6878241300582886\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6883103251457214\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6843113303184509\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.688463568687439\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6863898038864136\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.6830623745918274\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6877723336219788\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6882577538490295\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6865643858909607\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6895684003829956\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6942620873451233\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6951236724853516\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6890438199043274\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6896955370903015\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.690876841545105\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6882830858230591\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6823764443397522\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  1\n",
      "AUC on test data  0.5913343578958722\n"
     ]
    }
   ],
   "source": [
    "num_motif_list = [20,30,40,60]\n",
    "num_conv_layers_list = [1]\n",
    "dropprob_list = [0, 0.15, 0.3, 0.45]\n",
    "learning_rate_list = [10**-5,10**-4,10**-3,10**-2]\n",
    "max_num_models = 50\n",
    "maxepochs = 500\n",
    "epochs_for_early_stop = 50\n",
    "best_hyperparameters,results = Calibrate_model(calib_loader,valid_loader, num_motif_list, num_conv_layers_list , dropprob_list,\n",
    "                                               learning_rate_list,model_dir, max_num_models=max_num_models, maxepochs=maxepochs,\n",
    "                                               epochs_for_early_stop=max_num_models,motif_len=motif_len, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test the best model\n",
    "\n",
    "With the model calibrated here I move on to take the best performing one and train and test it. This model is then evaluated using AUC (Error under the ROC curve), which is a method for evaluating model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no early stopping\n"
     ]
    }
   ],
   "source": [
    "numMotif = best_hyperparameters['best_num_motif']\n",
    "convLayers = best_hyperparameters['best_num_conv_layers']\n",
    "drop = best_hyperparameters['best_dropprob']\n",
    "lRate = best_hyperparameters['best_l_rate']\n",
    "\n",
    "\n",
    "model = Network(numMotif , motif_len , convLayers , drop).to(device)\n",
    "best_model,epochs,train_losses,valid_losses = Train_model(model,train_loader,valid_loader,device,model_dir,lRate,save_model=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data  0.8179892382774094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8179892382774094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = Test_model(best_model,test_loader,device)\n",
    "auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Motifs\n",
    "\n",
    "Motif extraction uses the filters (or patches) generated by the model and then translates those back into DNA motifs. The get_motif function related the CNN filters back to the sequences they originated from, getting us DNA instead of numbers and also calculates the IC (Information Content) for each motif. For this calculation, relative entropy or relative IC is calculated giving us a more wholistic view of how much power or how reliable each motif returned by the CNN is. Higher numbers are essentially returning motifs that we can be more confident about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_sequences_test = mitoSeqList\n",
    "\n",
    "weights = best_model.conv[0].weight.detach().cpu().numpy()\n",
    "bias = best_model.conv[0].bias.detach().cpu().numpy()\n",
    "motif_sequences=generate_onehot_data(peak_sequences_test,motif_len,include_dinuc=False)\n",
    "motif_dataset=dataset(motif_sequences)\n",
    "batch_size = 100000\n",
    "motif_loader = DataLoader(dataset=motif_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "out_model = conv_output(weights,bias,device)\n",
    "filter_output = return_filter_outputs(out_model,motif_loader,best_model, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitochondria Targeting Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+------------+-----------------------+-------------+------------+\n",
      "| Filter |        consensus         | annotation |           ic          |     mean    |    std     |\n",
      "+--------+--------------------------+------------+-----------------------+-------------+------------+\n",
      "|   0    | AATAGTCAGAGTTAAATTTCACAC |     .      |  -0.17216390337199416 | 0.028421137 | 0.06406527 |\n",
      "|   1    | TGACGGGCCATACAGGCCTTTGCA |     .      |  0.07501420433914097  |  0.03236068 | 0.07499075 |\n",
      "|   2    | CGGTGTAATTATACATTGAGATCC |     .      |  -0.14120928591085846 | 0.037449602 | 0.08740096 |\n",
      "|   3    | GAAATTGGGTAATAGCCTATAGGT |     .      |  -0.11403296153410342 | 0.041967586 | 0.0921072  |\n",
      "|   4    | GCGATCGGCAAAAATTAACGGTCG |     .      |  -0.13011172747181016 |  0.04569335 | 0.10573264 |\n",
      "|   5    | AACTGAATTTATTAGTTAGACAGA |     .      |  0.36571789029646223  |  0.05199312 | 0.11838116 |\n",
      "|   6    | CTAGCGTTGACATTTTACTCGCGT |     .      |  0.04350945094565423  | 0.054182213 | 0.11265547 |\n",
      "|   7    | GTCCCGCGGACACTCCTACTTTTG |     .      |  0.20937108116528946  | 0.056351807 | 0.12352032 |\n",
      "|   8    | ATAACTTTGCGCGCATCTTCGGAT |     .      |   0.6450516789494287  |  0.06174658 | 0.13691342 |\n",
      "|   9    | ATTCCGCGCTAATCTAACGCGGGC |     .      |   0.6527960488941187  |   0.063924  | 0.13175805 |\n",
      "|   10   | ACATAACTAGATAATGGTGCGGCA |     .      |  -0.17168880905891892 | 0.067578055 | 0.1435045  |\n",
      "|   11   | CTATGCGGCTCCCCGCGCTCTGCC |     .      |  0.04734499332114522  | 0.072731666 | 0.15893719 |\n",
      "|   12   | CCCCACTTAGTCGCCCCTAGTAAG |     .      |  -0.05734696515265508 |  0.07468703 | 0.15104827 |\n",
      "|   13   | TAGAGTGGACAACGGTGCGGTTAC |     .      |  -0.08402057080275288 |  0.07752889 | 0.16129956 |\n",
      "|   14   | AATTCATACCCCCTAAGGGCGGGC |     .      |   0.296082767767633   |  0.08126379 | 0.17357373 |\n",
      "|   15   | GTGCGCCTTACTAAGGGGCGCGCT |     .      |   0.3786550155266703  |  0.08273762 | 0.16284004 |\n",
      "|   16   | GATGTTTTTCCCCTTTATGCTGTT |     .      |   0.6357050296384037  |  0.08642556 | 0.17360827 |\n",
      "|   17   | TTCGAGAGGGACAAGGAGGAGCCA |     .      |   0.7387547257131479  |  0.08951045 | 0.18574144 |\n",
      "|   18   | TACGGGGTCTAAGTATCTAGTGGG |     .      |  0.19620364355470332  | 0.090742156 | 0.17350245 |\n",
      "|   19   | CGAAGCTCTTTATACCCATGAAGG |     .      |  0.07386220080990324  |  0.09319239 | 0.18571208 |\n",
      "|   20   | GTGTTCGCCTTGGTGCTTCTCAAT |     .      |  -0.04119019946830882 | 0.099008575 | 0.20018186 |\n",
      "|   21   | CGTCAGAATAACGGTTAACTTCTC |     .      | -0.016736290407638743 |  0.09929854 | 0.18899818 |\n",
      "|   22   | CACAGCAGTTGTTGCAGCAGCTGA |     .      |   0.8951232523875029  |  0.10365662 | 0.20040822 |\n",
      "|   23   | GCCCTTTTATTTAACGTGTGACGT |     .      |  0.047551738154270995 |  0.10551788 | 0.20853075 |\n",
      "|   24   | AGGGTTCATCAGCTGCAGCATTTG |     .      |  0.03193301644450125  |  0.10537774 | 0.19722225 |\n",
      "|   25   | GCTATCGGGCGGTCCGCAGACCGC |     .      |   0.0052179103869745  |  0.10517651 | 0.20471469 |\n",
      "|   26   | CCCATAGATTTACGGTAATAATCG |     .      |   0.4833444413636995  | 0.105848245 | 0.21180165 |\n",
      "|   27   | CTATACGCGCTCAGGCGGGCTGCA |     .      |   0.245076792576866   |  0.10528263 | 0.1966553  |\n",
      "|   28   | AGAACCTTTGCCCAAACCATCGGT |     .      |  -0.3500065090555169  |  0.10513817 | 0.2041562  |\n",
      "|   29   | CATCTCAAGCAACCATCACCTGTT |     .      |  0.10688156943173116  |  0.10551402 | 0.21023141 |\n",
      "+--------+--------------------------+------------+-----------------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "get_motif(weights,filter_output,peak_sequences_test,'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainDataset = dataset(plastidTrainData)\n",
    "valDataset = dataset(plastidValData)\n",
    "testDataset = dataset(plastidTestData)\n",
    "\n",
    "train_loader = DataLoader(dataset=trainDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "test_loader = DataLoader(dataset=testDataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "calib_loader = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1\n",
      "0.3\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparameters['best_num_motif'])\n",
    "print(best_hyperparameters['best_num_conv_layers'])\n",
    "print(best_hyperparameters['best_dropprob'])\n",
    "print(best_hyperparameters['best_l_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no early stopping\n"
     ]
    }
   ],
   "source": [
    "numMotif = best_hyperparameters['best_num_motif']\n",
    "convLayers = best_hyperparameters['best_num_conv_layers']\n",
    "drop = best_hyperparameters['best_dropprob']\n",
    "lRate = best_hyperparameters['best_l_rate']\n",
    "\n",
    "\n",
    "model = Network(numMotif , motif_len , convLayers , drop).to(device)\n",
    "best_model,epochs,train_losses,valid_losses = Train_model(model,train_loader,valid_loader,device,model_dir,lRate,save_model=False,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data  0.8280485925621534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8280485925621534"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = Test_model(best_model,test_loader,device)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_sequences_test = plastidSeqList\n",
    "\n",
    "weights = best_model.conv[0].weight.detach().cpu().numpy()\n",
    "bias = best_model.conv[0].bias.detach().cpu().numpy()\n",
    "motif_sequences=generate_onehot_data(peak_sequences_test,motif_len,include_dinuc=False)\n",
    "motif_dataset=dataset(motif_sequences)\n",
    "batch_size = 100000\n",
    "motif_loader = DataLoader(dataset=motif_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "out_model = conv_output(weights,bias,device)\n",
    "filter_output = return_filter_outputs(out_model,motif_loader,best_model, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plastid Targeting Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+------------+-----------------------+-------------+-------------+\n",
      "| Filter |        consensus         | annotation |           ic          |     mean    |     std     |\n",
      "+--------+--------------------------+------------+-----------------------+-------------+-------------+\n",
      "|   0    | ACCTAGGGCGGGGGACTTTATATA |     .      | -0.038469054175373274 | 0.031407524 | 0.057097133 |\n",
      "|   1    | CGTTGATGAAGTCGTCTTTGATTT |     .      |   0.3323348482632948  |  0.03281173 |  0.06918165 |\n",
      "|   2    | TATAGAAGATGAAGAGCTTAATGA |     .      |   0.8091525229140204  | 0.037073556 |  0.08031098 |\n",
      "|   3    | CCATTGCTGGAACCGTCAGTGCTT |     .      |  -0.46431822012722634 | 0.041239575 |  0.09011602 |\n",
      "|   4    | TGCTAACTAACGAATTAAAATTAT |     .      |   0.5663795807940841  | 0.046491083 | 0.101999715 |\n",
      "|   5    | GCGAAGATGACCGGCGGAGCGTGG |     .      |   -0.347368446715291  | 0.049736243 |  0.11093548 |\n",
      "|   6    | AATATTAAAATTTACGTGTCCTGT |     .      |  0.20191404281581493  |  0.05190731 |  0.1134072  |\n",
      "|   7    | ATCATCTCCGGTTTCATCTCATTG |     .      |  -0.6151555669742663  | 0.058324147 |  0.12724788 |\n",
      "|   8    | CCGAATTACCGGCGAGCGGGCGTG |     .      | -0.029603071141037107 |   0.061799  |  0.13290279 |\n",
      "|   9    | GGTTGAGTTTGCTGAAGCAGTAAC |     .      |  -0.07956557312044371 |  0.06345359 |  0.13792525 |\n",
      "|   10   | ACAACAGCAGAACTGGTGGAGACA |     .      |   0.2995059692139062  |  0.07256027 |  0.15345478 |\n",
      "|   11   | TAATAAAAAAATAATTTCGCGATC |     .      |  -0.2599826325889488  |  0.07164495 |  0.15229592 |\n",
      "|   12   | TGCCCGCCGCGCAAGTGCAATTCT |     .      |  -0.1684862725697827  |  0.07394212 |  0.15552299 |\n",
      "|   13   | CAAGCAATTTCTTGAAGAAGTATA |     .      |  -0.1797399161932745  |  0.08298347 |  0.17125899 |\n",
      "|   14   | AGTTCTAAAATCGTAATAGGGGCA |     .      |  0.22630470072722192  |  0.08479798 |  0.17520596 |\n",
      "|   15   | TCGGAGCCGTTGGAGATGCTGGTT |     .      |  0.29358844723748245  | 0.083069086 |  0.17106403 |\n",
      "|   16   | TCGGCCGAACTTAACAGTTGTATT |     .      |  0.28314096158778435  |  0.09178694 |  0.18507792 |\n",
      "|   17   | GCAGACTAAAAATGTCGACCCTGG |     .      |   0.8022280273004567  |  0.09462883 |  0.19335045 |\n",
      "|   18   | TCAGTATTATAAAATACGGGCAAT |     .      |  -0.2269349669346294  |  0.08996608 |  0.18290699 |\n",
      "|   19   | CTGACTTTTAGATGCTACGGAGGC |     .      |  0.45997815889924015  |  0.10070097 |  0.19801554 |\n",
      "|   20   | CATAATCATTGCGCGCGGCTGTCG |     .      |   1.0561739793033114  |  0.10405361 |  0.20797515 |\n",
      "|   21   | AGAAGACGGCTGCTCCACTGGTTC |     .      |  -0.2572317230305187  |  0.09842543 |  0.19611529 |\n",
      "|   22   | AGCTACTGCTACCTCTGCATCTCT |     .      |  -0.34122962856825073 |  0.10977754 |  0.2101673  |\n",
      "|   23   | ATTAGTTTATATCGGACAGCCGGC |     .      |  -0.4391333742369083  |  0.11154657 |  0.21951538 |\n",
      "|   24   | TAGTTTTTTATAATAGTGTCACCC |     .      |  -0.07969872460036587 |  0.10027503 |  0.20035085 |\n",
      "|   25   | CATTCGTGCGGGATTGAGGTGCGC |     .      |  -0.40090143634406855 |  0.11111978 |  0.21132421 |\n",
      "|   26   | TTAATTCGGGTTTAAGACTTGATC |     .      |  -0.13964929498474493 | 0.112435564 |  0.22202776 |\n",
      "|   27   | TTAGTGTGACCCGCGTGCGGGCAT |     .      |  -0.5679815425674146  | 0.100327566 |  0.20019493 |\n",
      "|   28   | CCGATATAATATTACAAATCCCCG |     .      |   0.2203192891104533  |  0.11124598 |  0.21214086 |\n",
      "|   29   | ATGTCGGGAATTGAGCGGAAAGTG |     .      |  -0.18006496317589316 |  0.11210801 |  0.22209856 |\n",
      "+--------+--------------------------+------------+-----------------------+-------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "get_motif(weights,filter_output,peak_sequences_test,'results')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Discussion: \n",
    "\n",
    "This model ended up being relatively successful with a decent AUC of ~82% for both mitochondrially targeted and plastid targeted proteins. An AUC value of 0.82 means that rougly 82% of the time the model was able to correctly discern whether or not a protein contained a real motif instead of just being jumbled data, which implies relative success at finding the motif patterns of these proteins. While the information content from the motif_extraction phase is generally fairly low, there are some positive outliers in the ~0.8 or ~1.0 range which also implies a motif pattern within the DNA that is relatively conserved. Testing the veracity of these potential targeting motifs, however, would be beyond the scope of this kind of project. In order to ascertain just how correct this model was able to find targeting motifs I would first need to research and find a suite of known targeting motifs for both mitochondria and plastid targeted genes. With that information I would then need to push these found motifs and the known motifs through MSA (Multiple Sequence Alignment) software, which could score similarity. Another potential avenue for future work on the project would be to run my data through TargetP, a ML based pipeline that extracts DNA targeting motifs and then run outputs through MSA software to compare and score similarity. At this time, however, I am pleased that the model responded well enough to my data, despite not being built for this kind of analysis and I think that with an AUC of 82% I can safely say that the CNN *was* in fact able to find some motif signals in the DNA. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II \n",
    "This part of the project will shift from motif extraction to simple binary classification. The model I'm using for this part of the pipeline is a modified 1D CNN provided to us from Assignment 5. The modification includes the addition of dropout regularization in order to prevent and deal with overfitting issues. This process follows much of the same pattern as other setups for ML based pipelines where data is imported, wrangled into shape, split into Train/Test/Val splits and then run through the model for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>GeneLoc</th>\n",
       "      <th>GeneSeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G01170.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, G, C, A, T, C, A, G, G, A, G, G, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G01290.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, A, T, T, T, C, G, A, C, G, C, T, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G01970.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, G, G, A, A, T, T, T, A, T, A, G, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G02160.2</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, T, C, G, A, C, G, A, A, A, G, G, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT1G02370.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, A, A, T, T, T, C, C, G, T, A, A, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>AT5G67290.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, C, G, G, T, G, A, T, C, T, C, A, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>AT5G67370.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, C, T, C, A, G, G, T, T, A, A, T, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>AT5G67520.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, A, T, G, T, T, G, C, C, G, C, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>AT5G67570.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, A, T, G, C, T, T, C, G, G, T, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>AT5G67630.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, C, G, G, A, A, C, T, A, A, A, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GeneID       GeneLoc  \\\n",
       "1     AT1G01170.1  Mitochondria   \n",
       "2     AT1G01290.1  Mitochondria   \n",
       "3     AT1G01970.1  Mitochondria   \n",
       "4     AT1G02160.2  Mitochondria   \n",
       "5     AT1G02370.1  Mitochondria   \n",
       "...           ...           ...   \n",
       "2491  AT5G67290.1       Plastid   \n",
       "2492  AT5G67370.1       Plastid   \n",
       "2493  AT5G67520.1       Plastid   \n",
       "2494  AT5G67570.1       Plastid   \n",
       "2495  AT5G67630.1       Plastid   \n",
       "\n",
       "                                                GeneSeq  \n",
       "1     (A, T, G, G, C, A, T, C, A, G, G, A, G, G, T, ...  \n",
       "2     (A, T, G, A, T, T, T, C, G, A, C, G, C, T, C, ...  \n",
       "3     (A, T, G, G, G, A, A, T, T, T, A, T, A, G, C, ...  \n",
       "4     (A, T, G, T, C, G, A, C, G, A, A, A, G, G, C, ...  \n",
       "5     (A, T, G, A, A, T, T, T, C, C, G, T, A, A, T, ...  \n",
       "...                                                 ...  \n",
       "2491  (A, T, G, G, C, G, G, T, G, A, T, C, T, C, A, ...  \n",
       "2492  (A, T, G, C, T, C, A, G, G, T, T, A, A, T, C, ...  \n",
       "2493  (A, T, G, G, A, T, G, T, T, G, C, C, G, C, G, ...  \n",
       "2494  (A, T, G, G, A, T, G, C, T, T, C, G, G, T, G, ...  \n",
       "2495  (A, T, G, G, C, G, G, A, A, C, T, A, A, A, G, ...  \n",
       "\n",
       "[3832 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullMatrix = pd.concat([mitoData, plastidData], axis=0)\n",
    "fullMatrix\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubSampling of Data\n",
    "\n",
    "The dataset used in for this analyses was highly imbalanced with only about 35% of the samples being mitochondrially localized and the other 65% being plastid localized. This caused significant issues in overfitting and testing accuracy. Initially, to try to handle this problem I dropped ~1000 Plastid targeted genes at random in order to balance the data set, but this didn't end up helping. So, instead I tried to subsamble the mitochondrially targeted genes by simply randomly selecting 1000 genes that are already represented in the data set and duplicating them. This has affect helped significantly likely for two reasons. Data scarcity is somewhat of an issue here. Where many datasets may contain tens of thousands to millions of data points to calculate and build a model from, my dataset only consisted of roughly ~4000 genes. Adding 1000 'extra' genes is much more helpful than subtracting 1000 from an already small data set. The other way it helps is by giving more 'chances' to learn the smaller data set. This helps reinforce some of the motifs present in that set, which become helpful for discerning the patterns on the validation and test sets, which remain inbalanced.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "superSample = fullMatrix[:1000]\n",
    "fullMatrix = pd.concat((superSample,fullMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>GeneLoc</th>\n",
       "      <th>GeneSeq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G01170.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, G, C, A, T, C, A, G, G, A, G, G, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G01290.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, A, T, T, T, C, G, A, C, G, C, T, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G01970.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, G, G, A, A, T, T, T, A, T, A, G, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G02160.2</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, T, C, G, A, C, G, A, A, A, G, G, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT1G02370.1</td>\n",
       "      <td>Mitochondria</td>\n",
       "      <td>(A, T, G, A, A, T, T, T, C, C, G, T, A, A, T, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>AT5G67290.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, C, G, G, T, G, A, T, C, T, C, A, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>AT5G67370.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, C, T, C, A, G, G, T, T, A, A, T, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>AT5G67520.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, A, T, G, T, T, G, C, C, G, C, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>AT5G67570.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, A, T, G, C, T, T, C, G, G, T, G, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>AT5G67630.1</td>\n",
       "      <td>Plastid</td>\n",
       "      <td>(A, T, G, G, C, G, G, A, A, C, T, A, A, A, G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4832 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GeneID       GeneLoc  \\\n",
       "1     AT1G01170.1  Mitochondria   \n",
       "2     AT1G01290.1  Mitochondria   \n",
       "3     AT1G01970.1  Mitochondria   \n",
       "4     AT1G02160.2  Mitochondria   \n",
       "5     AT1G02370.1  Mitochondria   \n",
       "...           ...           ...   \n",
       "2491  AT5G67290.1       Plastid   \n",
       "2492  AT5G67370.1       Plastid   \n",
       "2493  AT5G67520.1       Plastid   \n",
       "2494  AT5G67570.1       Plastid   \n",
       "2495  AT5G67630.1       Plastid   \n",
       "\n",
       "                                                GeneSeq  \n",
       "1     (A, T, G, G, C, A, T, C, A, G, G, A, G, G, T, ...  \n",
       "2     (A, T, G, A, T, T, T, C, G, A, C, G, C, T, C, ...  \n",
       "3     (A, T, G, G, G, A, A, T, T, T, A, T, A, G, C, ...  \n",
       "4     (A, T, G, T, C, G, A, C, G, A, A, A, G, G, C, ...  \n",
       "5     (A, T, G, A, A, T, T, T, C, C, G, T, A, A, T, ...  \n",
       "...                                                 ...  \n",
       "2491  (A, T, G, G, C, G, G, T, G, A, T, C, T, C, A, ...  \n",
       "2492  (A, T, G, C, T, C, A, G, G, T, T, A, A, T, C, ...  \n",
       "2493  (A, T, G, G, A, T, G, T, T, G, C, C, G, C, G, ...  \n",
       "2494  (A, T, G, G, A, T, G, C, T, T, C, G, G, T, G, ...  \n",
       "2495  (A, T, G, G, C, G, G, A, A, C, T, A, A, A, G, ...  \n",
       "\n",
       "[4832 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullMatrix = pd.DataFrame(fullMatrix, columns= ['GeneID', 'GeneLoc', 'GeneSeq'])\n",
    "fullMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullMatrix = pd.DataFrame(fullMatrix)\n",
    "sizedSeqs = []\n",
    "encodedSeqs = []\n",
    "dataList = fullMatrix['GeneSeq'].values.tolist()\n",
    "for seq in dataList:\n",
    "    sizedSeqs.append(str(seq[-40:]))\n",
    "\n",
    "for seq in sizedSeqs:\n",
    "    aaIndex = 0\n",
    "    baseDict = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "    w = 4\n",
    "    h = len(seq)\n",
    "    OneHotEncoded = [[0 for x in range(w)] for y in range(h)]\n",
    "    for aa in seq:\n",
    "        OneHotEncoded[aaIndex][baseDict[aa]] = 1\n",
    "        aaIndex += 1\n",
    "    OneHotEncoded = np.asarray(OneHotEncoded)\n",
    "    OneHotEncoded = OneHotEncoded.flatten()\n",
    "    OneHotEncoded = OneHotEncoded.tolist()\n",
    "\n",
    "    #print(OneHotEncoded)\n",
    "    encodedSeqs.append(OneHotEncoded.copy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n",
    "\n",
    "Much like before we OneHotEncode the matrix which contains the DNA sequences and then flatten them down into 1 dimensional arrays such that our 1D CNN can read them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedSeqs = np.array(encodedSeqs)\n",
    "encodedSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten each individual GeneSeq\n",
    "#Stride length of 1 = stride length of 4 (Try between 4 and 4) window size of 12 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "Mitochondrially targeted proteins are encoded as 1s whilst plastid are encoded with -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1], [-1]]\n",
      "[[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "encodedLocs = []\n",
    "\n",
    "seqIndex = 0\n",
    "for i in range(len(fullMatrix)):\n",
    "    if (fullMatrix.iloc[seqIndex][1] == 'Mitochondria'):\n",
    "        encodedLocs.append([-1])\n",
    "    else:\n",
    "        encodedLocs.append([1])\n",
    "    seqIndex += 1\n",
    "\n",
    "print(encodedLocs[0:10])\n",
    "print(encodedLocs[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4832, 1)\n",
      "(4832, 160)\n"
     ]
    }
   ],
   "source": [
    "encodedLocs = np.asarray(encodedLocs)\n",
    "\n",
    "print(encodedLocs.shape)\n",
    "print(encodedSeqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3382, 1, 160), (3382, 1), (724, 1, 160), (724, 1), (726, 1, 160), (726, 1))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = encodedSeqs\n",
    "X = X.reshape(X.shape[0], 1, -1)\n",
    "X.shape\n",
    "T = encodedLocs\n",
    "n_samples = X.shape[0]\n",
    "rows = np.arange(n_samples)\n",
    "np.random.shuffle(rows)\n",
    "n_train = int(n_samples * 0.7)\n",
    "Xtrain = X[rows[:n_train], ...]\n",
    "Ttrain = T[rows[:n_train], ...]\n",
    "Xval = X[rows[n_train:(n_train + int((n_samples * 0.15)))], ...]\n",
    "Tval = T[rows[n_train:(n_train + int((n_samples * 0.15)))], ...]\n",
    "Xtest = X[rows[(n_train + int((n_samples * 0.15))):], ...]\n",
    "Ttest = T[rows[(n_train + int((n_samples * 0.15))):], ...]\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xval.shape, Tval.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam: Epoch 5 Loss 0.656\n",
      "adam: Epoch 10 Loss 0.633\n",
      "adam: Epoch 15 Loss 0.594\n",
      "adam: Epoch 20 Loss 0.561\n",
      "adam: Epoch 25 Loss 0.518\n",
      "adam: Epoch 30 Loss 0.482\n",
      "adam: Epoch 35 Loss 0.453\n",
      "adam: Epoch 40 Loss 0.431\n",
      "adam: Epoch 45 Loss 0.422\n",
      "adam: Epoch 50 Loss 0.427\n",
      "adam: Epoch 5 Loss 0.667\n",
      "adam: Epoch 10 Loss 0.639\n",
      "adam: Epoch 15 Loss 0.602\n",
      "adam: Epoch 20 Loss 0.547\n",
      "adam: Epoch 25 Loss 0.501\n",
      "adam: Epoch 30 Loss 0.468\n",
      "adam: Epoch 35 Loss 0.453\n",
      "adam: Epoch 40 Loss 0.436\n",
      "adam: Epoch 45 Loss 0.428\n",
      "adam: Epoch 50 Loss 0.416\n",
      "adam: Epoch 5 Loss 0.669\n",
      "adam: Epoch 10 Loss 0.652\n",
      "adam: Epoch 15 Loss 0.635\n",
      "adam: Epoch 20 Loss 0.605\n",
      "adam: Epoch 25 Loss 0.580\n",
      "adam: Epoch 30 Loss 0.554\n",
      "adam: Epoch 35 Loss 0.534\n",
      "adam: Epoch 40 Loss 0.521\n",
      "adam: Epoch 45 Loss 0.512\n",
      "adam: Epoch 50 Loss 0.498\n",
      "adam: Epoch 5 Loss 0.667\n",
      "adam: Epoch 10 Loss 0.652\n",
      "adam: Epoch 15 Loss 0.643\n",
      "adam: Epoch 20 Loss 0.629\n",
      "adam: Epoch 25 Loss 0.612\n",
      "adam: Epoch 30 Loss 0.604\n",
      "adam: Epoch 35 Loss 0.588\n",
      "adam: Epoch 40 Loss 0.581\n",
      "adam: Epoch 45 Loss 0.576\n",
      "adam: Epoch 50 Loss 0.558\n",
      "adam: Epoch 5 Loss 0.664\n",
      "adam: Epoch 10 Loss 0.641\n",
      "adam: Epoch 15 Loss 0.611\n",
      "adam: Epoch 20 Loss 0.575\n",
      "adam: Epoch 25 Loss 0.548\n",
      "adam: Epoch 30 Loss 0.521\n",
      "adam: Epoch 35 Loss 0.506\n",
      "adam: Epoch 40 Loss 0.495\n",
      "adam: Epoch 45 Loss 0.496\n",
      "adam: Epoch 50 Loss 0.490\n",
      "adam: Epoch 5 Loss 0.653\n",
      "adam: Epoch 10 Loss 0.602\n",
      "adam: Epoch 15 Loss 0.526\n",
      "adam: Epoch 20 Loss 0.446\n",
      "adam: Epoch 25 Loss 0.367\n",
      "adam: Epoch 30 Loss 0.320\n",
      "adam: Epoch 35 Loss 0.292\n",
      "adam: Epoch 40 Loss 0.283\n",
      "adam: Epoch 45 Loss 0.255\n",
      "adam: Epoch 50 Loss 0.241\n",
      "adam: Epoch 5 Loss 0.653\n",
      "adam: Epoch 10 Loss 0.583\n",
      "adam: Epoch 15 Loss 0.491\n",
      "adam: Epoch 20 Loss 0.421\n",
      "adam: Epoch 25 Loss 0.351\n",
      "adam: Epoch 30 Loss 0.324\n",
      "adam: Epoch 35 Loss 0.288\n",
      "adam: Epoch 40 Loss 0.268\n",
      "adam: Epoch 45 Loss 0.263\n",
      "adam: Epoch 50 Loss 0.251\n",
      "adam: Epoch 5 Loss 0.660\n",
      "adam: Epoch 10 Loss 0.628\n",
      "adam: Epoch 15 Loss 0.582\n",
      "adam: Epoch 20 Loss 0.529\n",
      "adam: Epoch 25 Loss 0.476\n",
      "adam: Epoch 30 Loss 0.427\n",
      "adam: Epoch 35 Loss 0.399\n",
      "adam: Epoch 40 Loss 0.366\n",
      "adam: Epoch 45 Loss 0.328\n",
      "adam: Epoch 50 Loss 0.312\n",
      "adam: Epoch 5 Loss 0.665\n",
      "adam: Epoch 10 Loss 0.632\n",
      "adam: Epoch 15 Loss 0.586\n",
      "adam: Epoch 20 Loss 0.550\n",
      "adam: Epoch 25 Loss 0.515\n",
      "adam: Epoch 30 Loss 0.476\n",
      "adam: Epoch 35 Loss 0.460\n",
      "adam: Epoch 40 Loss 0.441\n",
      "adam: Epoch 45 Loss 0.412\n",
      "adam: Epoch 50 Loss 0.378\n",
      "adam: Epoch 5 Loss 0.660\n",
      "adam: Epoch 10 Loss 0.630\n",
      "adam: Epoch 15 Loss 0.572\n",
      "adam: Epoch 20 Loss 0.488\n",
      "adam: Epoch 25 Loss 0.411\n",
      "adam: Epoch 30 Loss 0.361\n",
      "adam: Epoch 35 Loss 0.318\n",
      "adam: Epoch 40 Loss 0.278\n",
      "adam: Epoch 45 Loss 0.274\n",
      "adam: Epoch 50 Loss 0.237\n",
      "adam: Epoch 5 Loss 0.646\n",
      "adam: Epoch 10 Loss 0.523\n",
      "adam: Epoch 15 Loss 0.349\n",
      "adam: Epoch 20 Loss 0.272\n",
      "adam: Epoch 25 Loss 0.208\n",
      "adam: Epoch 30 Loss 0.179\n",
      "adam: Epoch 35 Loss 0.163\n",
      "adam: Epoch 40 Loss 0.168\n",
      "adam: Epoch 45 Loss 0.165\n",
      "adam: Epoch 50 Loss 0.148\n",
      "adam: Epoch 5 Loss 0.642\n",
      "adam: Epoch 10 Loss 0.527\n",
      "adam: Epoch 15 Loss 0.369\n",
      "adam: Epoch 20 Loss 0.243\n",
      "adam: Epoch 25 Loss 0.192\n",
      "adam: Epoch 30 Loss 0.138\n",
      "adam: Epoch 35 Loss 0.142\n",
      "adam: Epoch 40 Loss 0.144\n",
      "adam: Epoch 45 Loss 0.130\n",
      "adam: Epoch 50 Loss 0.147\n",
      "adam: Epoch 5 Loss 0.640\n",
      "adam: Epoch 10 Loss 0.533\n",
      "adam: Epoch 15 Loss 0.407\n",
      "adam: Epoch 20 Loss 0.304\n",
      "adam: Epoch 25 Loss 0.223\n",
      "adam: Epoch 30 Loss 0.189\n",
      "adam: Epoch 35 Loss 0.170\n",
      "adam: Epoch 40 Loss 0.150\n",
      "adam: Epoch 45 Loss 0.153\n",
      "adam: Epoch 50 Loss 0.125\n",
      "adam: Epoch 5 Loss 0.646\n",
      "adam: Epoch 10 Loss 0.591\n",
      "adam: Epoch 15 Loss 0.509\n",
      "adam: Epoch 20 Loss 0.437\n",
      "adam: Epoch 25 Loss 0.391\n",
      "adam: Epoch 30 Loss 0.344\n",
      "adam: Epoch 35 Loss 0.307\n",
      "adam: Epoch 40 Loss 0.277\n",
      "adam: Epoch 45 Loss 0.246\n",
      "adam: Epoch 50 Loss 0.221\n",
      "adam: Epoch 5 Loss 0.652\n",
      "adam: Epoch 10 Loss 0.586\n",
      "adam: Epoch 15 Loss 0.466\n",
      "adam: Epoch 20 Loss 0.310\n",
      "adam: Epoch 25 Loss 0.231\n",
      "adam: Epoch 30 Loss 0.174\n",
      "adam: Epoch 35 Loss 0.154\n",
      "adam: Epoch 40 Loss 0.129\n",
      "adam: Epoch 45 Loss 0.124\n",
      "adam: Epoch 50 Loss 0.117\n",
      "adam: Epoch 5 Loss 0.653\n",
      "adam: Epoch 10 Loss 0.618\n",
      "adam: Epoch 15 Loss 0.571\n",
      "adam: Epoch 20 Loss 0.519\n",
      "adam: Epoch 25 Loss 0.465\n",
      "adam: Epoch 30 Loss 0.435\n",
      "adam: Epoch 35 Loss 0.406\n",
      "adam: Epoch 40 Loss 0.397\n",
      "adam: Epoch 45 Loss 0.379\n",
      "adam: Epoch 50 Loss 0.378\n",
      "adam: Epoch 5 Loss 0.655\n",
      "adam: Epoch 10 Loss 0.629\n",
      "adam: Epoch 15 Loss 0.588\n",
      "adam: Epoch 20 Loss 0.555\n",
      "adam: Epoch 25 Loss 0.517\n",
      "adam: Epoch 30 Loss 0.496\n",
      "adam: Epoch 35 Loss 0.483\n",
      "adam: Epoch 40 Loss 0.478\n",
      "adam: Epoch 45 Loss 0.460\n",
      "adam: Epoch 50 Loss 0.459\n",
      "adam: Epoch 5 Loss 0.663\n",
      "adam: Epoch 10 Loss 0.642\n",
      "adam: Epoch 15 Loss 0.615\n",
      "adam: Epoch 20 Loss 0.584\n",
      "adam: Epoch 25 Loss 0.564\n",
      "adam: Epoch 30 Loss 0.542\n",
      "adam: Epoch 35 Loss 0.519\n",
      "adam: Epoch 40 Loss 0.497\n",
      "adam: Epoch 45 Loss 0.482\n",
      "adam: Epoch 50 Loss 0.478\n",
      "adam: Epoch 5 Loss 0.668\n",
      "adam: Epoch 10 Loss 0.655\n",
      "adam: Epoch 15 Loss 0.639\n",
      "adam: Epoch 20 Loss 0.626\n",
      "adam: Epoch 25 Loss 0.608\n",
      "adam: Epoch 30 Loss 0.590\n",
      "adam: Epoch 35 Loss 0.575\n",
      "adam: Epoch 40 Loss 0.557\n",
      "adam: Epoch 45 Loss 0.547\n",
      "adam: Epoch 50 Loss 0.536\n",
      "adam: Epoch 5 Loss 0.664\n",
      "adam: Epoch 10 Loss 0.641\n",
      "adam: Epoch 15 Loss 0.616\n",
      "adam: Epoch 20 Loss 0.584\n",
      "adam: Epoch 25 Loss 0.546\n",
      "adam: Epoch 30 Loss 0.518\n",
      "adam: Epoch 35 Loss 0.493\n",
      "adam: Epoch 40 Loss 0.481\n",
      "adam: Epoch 45 Loss 0.462\n",
      "adam: Epoch 50 Loss 0.451\n",
      "adam: Epoch 5 Loss 0.648\n",
      "adam: Epoch 10 Loss 0.568\n",
      "adam: Epoch 15 Loss 0.409\n",
      "adam: Epoch 20 Loss 0.260\n",
      "adam: Epoch 25 Loss 0.195\n",
      "adam: Epoch 30 Loss 0.157\n",
      "adam: Epoch 35 Loss 0.121\n",
      "adam: Epoch 40 Loss 0.123\n",
      "adam: Epoch 45 Loss 0.095\n",
      "adam: Epoch 50 Loss 0.110\n",
      "adam: Epoch 5 Loss 0.650\n",
      "adam: Epoch 10 Loss 0.595\n",
      "adam: Epoch 15 Loss 0.468\n",
      "adam: Epoch 20 Loss 0.353\n",
      "adam: Epoch 25 Loss 0.271\n",
      "adam: Epoch 30 Loss 0.220\n",
      "adam: Epoch 35 Loss 0.189\n",
      "adam: Epoch 40 Loss 0.171\n",
      "adam: Epoch 45 Loss 0.137\n",
      "adam: Epoch 50 Loss 0.154\n",
      "adam: Epoch 5 Loss 0.652\n",
      "adam: Epoch 10 Loss 0.597\n",
      "adam: Epoch 15 Loss 0.509\n",
      "adam: Epoch 20 Loss 0.428\n",
      "adam: Epoch 25 Loss 0.370\n",
      "adam: Epoch 30 Loss 0.327\n",
      "adam: Epoch 35 Loss 0.290\n",
      "adam: Epoch 40 Loss 0.258\n",
      "adam: Epoch 45 Loss 0.221\n",
      "adam: Epoch 50 Loss 0.197\n",
      "adam: Epoch 5 Loss 0.662\n",
      "adam: Epoch 10 Loss 0.629\n",
      "adam: Epoch 15 Loss 0.583\n",
      "adam: Epoch 20 Loss 0.523\n",
      "adam: Epoch 25 Loss 0.469\n",
      "adam: Epoch 30 Loss 0.435\n",
      "adam: Epoch 35 Loss 0.397\n",
      "adam: Epoch 40 Loss 0.360\n",
      "adam: Epoch 45 Loss 0.358\n",
      "adam: Epoch 50 Loss 0.335\n",
      "adam: Epoch 5 Loss 0.658\n",
      "adam: Epoch 10 Loss 0.619\n",
      "adam: Epoch 15 Loss 0.544\n",
      "adam: Epoch 20 Loss 0.458\n",
      "adam: Epoch 25 Loss 0.387\n",
      "adam: Epoch 30 Loss 0.333\n",
      "adam: Epoch 35 Loss 0.281\n",
      "adam: Epoch 40 Loss 0.264\n",
      "adam: Epoch 45 Loss 0.238\n",
      "adam: Epoch 50 Loss 0.196\n",
      "adam: Epoch 5 Loss 0.637\n",
      "adam: Epoch 10 Loss 0.487\n",
      "adam: Epoch 15 Loss 0.237\n",
      "adam: Epoch 20 Loss 0.111\n",
      "adam: Epoch 25 Loss 0.057\n",
      "adam: Epoch 30 Loss 0.062\n",
      "adam: Epoch 35 Loss 0.048\n",
      "adam: Epoch 40 Loss 0.027\n",
      "adam: Epoch 45 Loss 0.049\n",
      "adam: Epoch 50 Loss 0.053\n",
      "adam: Epoch 5 Loss 0.632\n",
      "adam: Epoch 10 Loss 0.478\n",
      "adam: Epoch 15 Loss 0.231\n",
      "adam: Epoch 20 Loss 0.134\n",
      "adam: Epoch 25 Loss 0.098\n",
      "adam: Epoch 30 Loss 0.068\n",
      "adam: Epoch 35 Loss 0.061\n",
      "adam: Epoch 40 Loss 0.053\n",
      "adam: Epoch 45 Loss 0.078\n",
      "adam: Epoch 50 Loss 0.054\n",
      "adam: Epoch 5 Loss 0.632\n",
      "adam: Epoch 10 Loss 0.487\n",
      "adam: Epoch 15 Loss 0.310\n",
      "adam: Epoch 20 Loss 0.179\n",
      "adam: Epoch 25 Loss 0.137\n",
      "adam: Epoch 30 Loss 0.101\n",
      "adam: Epoch 35 Loss 0.103\n",
      "adam: Epoch 40 Loss 0.081\n",
      "adam: Epoch 45 Loss 0.063\n",
      "adam: Epoch 50 Loss 0.057\n",
      "adam: Epoch 5 Loss 0.638\n",
      "adam: Epoch 10 Loss 0.555\n",
      "adam: Epoch 15 Loss 0.451\n",
      "adam: Epoch 20 Loss 0.366\n",
      "adam: Epoch 25 Loss 0.300\n",
      "adam: Epoch 30 Loss 0.262\n",
      "adam: Epoch 35 Loss 0.215\n",
      "adam: Epoch 40 Loss 0.174\n",
      "adam: Epoch 45 Loss 0.174\n",
      "adam: Epoch 50 Loss 0.146\n",
      "adam: Epoch 5 Loss 0.649\n",
      "adam: Epoch 10 Loss 0.557\n",
      "adam: Epoch 15 Loss 0.374\n",
      "adam: Epoch 20 Loss 0.205\n",
      "adam: Epoch 25 Loss 0.125\n",
      "adam: Epoch 30 Loss 0.095\n",
      "adam: Epoch 35 Loss 0.065\n",
      "adam: Epoch 40 Loss 0.074\n",
      "adam: Epoch 45 Loss 0.057\n",
      "adam: Epoch 50 Loss 0.062\n",
      "adam: Epoch 5 Loss 0.648\n",
      "adam: Epoch 10 Loss 0.617\n",
      "adam: Epoch 15 Loss 0.557\n",
      "adam: Epoch 20 Loss 0.498\n",
      "adam: Epoch 25 Loss 0.439\n",
      "adam: Epoch 30 Loss 0.401\n",
      "adam: Epoch 35 Loss 0.386\n",
      "adam: Epoch 40 Loss 0.357\n",
      "adam: Epoch 45 Loss 0.365\n",
      "adam: Epoch 50 Loss 0.340\n",
      "adam: Epoch 5 Loss 0.663\n",
      "adam: Epoch 10 Loss 0.637\n",
      "adam: Epoch 15 Loss 0.598\n",
      "adam: Epoch 20 Loss 0.544\n",
      "adam: Epoch 25 Loss 0.493\n",
      "adam: Epoch 30 Loss 0.449\n",
      "adam: Epoch 35 Loss 0.423\n",
      "adam: Epoch 40 Loss 0.402\n",
      "adam: Epoch 45 Loss 0.377\n",
      "adam: Epoch 50 Loss 0.375\n",
      "adam: Epoch 5 Loss 0.661\n",
      "adam: Epoch 10 Loss 0.648\n",
      "adam: Epoch 15 Loss 0.617\n",
      "adam: Epoch 20 Loss 0.574\n",
      "adam: Epoch 25 Loss 0.536\n",
      "adam: Epoch 30 Loss 0.501\n",
      "adam: Epoch 35 Loss 0.489\n",
      "adam: Epoch 40 Loss 0.478\n",
      "adam: Epoch 45 Loss 0.458\n",
      "adam: Epoch 50 Loss 0.436\n",
      "adam: Epoch 5 Loss 0.664\n",
      "adam: Epoch 10 Loss 0.654\n",
      "adam: Epoch 15 Loss 0.638\n",
      "adam: Epoch 20 Loss 0.614\n",
      "adam: Epoch 25 Loss 0.576\n",
      "adam: Epoch 30 Loss 0.540\n",
      "adam: Epoch 35 Loss 0.515\n",
      "adam: Epoch 40 Loss 0.494\n",
      "adam: Epoch 45 Loss 0.460\n",
      "adam: Epoch 50 Loss 0.442\n",
      "adam: Epoch 5 Loss 0.662\n",
      "adam: Epoch 10 Loss 0.636\n",
      "adam: Epoch 15 Loss 0.603\n",
      "adam: Epoch 20 Loss 0.559\n",
      "adam: Epoch 25 Loss 0.527\n",
      "adam: Epoch 30 Loss 0.497\n",
      "adam: Epoch 35 Loss 0.475\n",
      "adam: Epoch 40 Loss 0.448\n",
      "adam: Epoch 45 Loss 0.427\n",
      "adam: Epoch 50 Loss 0.420\n",
      "adam: Epoch 5 Loss 0.648\n",
      "adam: Epoch 10 Loss 0.562\n",
      "adam: Epoch 15 Loss 0.404\n",
      "adam: Epoch 20 Loss 0.295\n",
      "adam: Epoch 25 Loss 0.218\n",
      "adam: Epoch 30 Loss 0.179\n",
      "adam: Epoch 35 Loss 0.165\n",
      "adam: Epoch 40 Loss 0.115\n",
      "adam: Epoch 45 Loss 0.086\n",
      "adam: Epoch 50 Loss 0.108\n",
      "adam: Epoch 5 Loss 0.652\n",
      "adam: Epoch 10 Loss 0.582\n",
      "adam: Epoch 15 Loss 0.443\n",
      "adam: Epoch 20 Loss 0.344\n",
      "adam: Epoch 25 Loss 0.271\n",
      "adam: Epoch 30 Loss 0.220\n",
      "adam: Epoch 35 Loss 0.175\n",
      "adam: Epoch 40 Loss 0.153\n",
      "adam: Epoch 45 Loss 0.129\n",
      "adam: Epoch 50 Loss 0.142\n",
      "adam: Epoch 5 Loss 0.654\n",
      "adam: Epoch 10 Loss 0.603\n",
      "adam: Epoch 15 Loss 0.491\n",
      "adam: Epoch 20 Loss 0.387\n",
      "adam: Epoch 25 Loss 0.331\n",
      "adam: Epoch 30 Loss 0.262\n",
      "adam: Epoch 35 Loss 0.235\n",
      "adam: Epoch 40 Loss 0.191\n",
      "adam: Epoch 45 Loss 0.171\n",
      "adam: Epoch 50 Loss 0.137\n",
      "adam: Epoch 5 Loss 0.660\n",
      "adam: Epoch 10 Loss 0.616\n",
      "adam: Epoch 15 Loss 0.521\n",
      "adam: Epoch 20 Loss 0.445\n",
      "adam: Epoch 25 Loss 0.383\n",
      "adam: Epoch 30 Loss 0.337\n",
      "adam: Epoch 35 Loss 0.309\n",
      "adam: Epoch 40 Loss 0.284\n",
      "adam: Epoch 45 Loss 0.250\n",
      "adam: Epoch 50 Loss 0.239\n",
      "adam: Epoch 5 Loss 0.654\n",
      "adam: Epoch 10 Loss 0.608\n",
      "adam: Epoch 15 Loss 0.516\n",
      "adam: Epoch 20 Loss 0.401\n",
      "adam: Epoch 25 Loss 0.334\n",
      "adam: Epoch 30 Loss 0.259\n",
      "adam: Epoch 35 Loss 0.223\n",
      "adam: Epoch 40 Loss 0.201\n",
      "adam: Epoch 45 Loss 0.169\n",
      "adam: Epoch 50 Loss 0.159\n",
      "adam: Epoch 5 Loss 0.632\n",
      "adam: Epoch 10 Loss 0.411\n",
      "adam: Epoch 15 Loss 0.188\n",
      "adam: Epoch 20 Loss 0.084\n",
      "adam: Epoch 25 Loss 0.069\n",
      "adam: Epoch 30 Loss 0.051\n",
      "adam: Epoch 35 Loss 0.044\n",
      "adam: Epoch 40 Loss 0.039\n",
      "adam: Epoch 45 Loss 0.021\n",
      "adam: Epoch 50 Loss 0.012\n",
      "adam: Epoch 5 Loss 0.640\n",
      "adam: Epoch 10 Loss 0.444\n",
      "adam: Epoch 15 Loss 0.179\n",
      "adam: Epoch 20 Loss 0.094\n",
      "adam: Epoch 25 Loss 0.076\n",
      "adam: Epoch 30 Loss 0.070\n",
      "adam: Epoch 35 Loss 0.062\n",
      "adam: Epoch 40 Loss 0.030\n",
      "adam: Epoch 45 Loss 0.041\n",
      "adam: Epoch 50 Loss 0.040\n",
      "adam: Epoch 5 Loss 0.633\n",
      "adam: Epoch 10 Loss 0.433\n",
      "adam: Epoch 15 Loss 0.240\n",
      "adam: Epoch 20 Loss 0.149\n",
      "adam: Epoch 25 Loss 0.121\n",
      "adam: Epoch 30 Loss 0.090\n",
      "adam: Epoch 35 Loss 0.078\n",
      "adam: Epoch 40 Loss 0.065\n",
      "adam: Epoch 45 Loss 0.053\n",
      "adam: Epoch 50 Loss 0.056\n",
      "adam: Epoch 5 Loss 0.641\n",
      "adam: Epoch 10 Loss 0.509\n",
      "adam: Epoch 15 Loss 0.349\n",
      "adam: Epoch 20 Loss 0.255\n",
      "adam: Epoch 25 Loss 0.183\n",
      "adam: Epoch 30 Loss 0.160\n",
      "adam: Epoch 35 Loss 0.127\n",
      "adam: Epoch 40 Loss 0.121\n",
      "adam: Epoch 45 Loss 0.118\n",
      "adam: Epoch 50 Loss 0.119\n",
      "adam: Epoch 5 Loss 0.646\n",
      "adam: Epoch 10 Loss 0.521\n",
      "adam: Epoch 15 Loss 0.295\n",
      "adam: Epoch 20 Loss 0.143\n",
      "adam: Epoch 25 Loss 0.105\n",
      "adam: Epoch 30 Loss 0.068\n",
      "adam: Epoch 35 Loss 0.081\n",
      "adam: Epoch 40 Loss 0.045\n",
      "adam: Epoch 45 Loss 0.043\n",
      "adam: Epoch 50 Loss 0.055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc_network_structs</th>\n",
       "      <th>conv_network_structs</th>\n",
       "      <th>patches</th>\n",
       "      <th>strides</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.245417</td>\n",
       "      <td>64.876033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.807215</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.130101</td>\n",
       "      <td>62.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>74.807806</td>\n",
       "      <td>59.504132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.928445</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.115908</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.027203</td>\n",
       "      <td>67.217631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>90.567711</td>\n",
       "      <td>66.253444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.156712</td>\n",
       "      <td>67.217631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.406268</td>\n",
       "      <td>65.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.072738</td>\n",
       "      <td>71.349862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.072738</td>\n",
       "      <td>71.074380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.486694</td>\n",
       "      <td>70.523416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.672383</td>\n",
       "      <td>69.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.959787</td>\n",
       "      <td>72.314050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>87.551745</td>\n",
       "      <td>67.630854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.022472</td>\n",
       "      <td>65.564738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.011827</td>\n",
       "      <td>62.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>73.950325</td>\n",
       "      <td>59.366391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.259018</td>\n",
       "      <td>63.774105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.314607</td>\n",
       "      <td>66.942149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.978711</td>\n",
       "      <td>68.595041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.239503</td>\n",
       "      <td>68.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>87.581313</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.879361</td>\n",
       "      <td>67.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.763454</td>\n",
       "      <td>72.589532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.018924</td>\n",
       "      <td>70.661157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.053814</td>\n",
       "      <td>70.798898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.564755</td>\n",
       "      <td>69.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.846836</td>\n",
       "      <td>71.625344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>88.586635</td>\n",
       "      <td>64.600551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>86.221171</td>\n",
       "      <td>63.085399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.100532</td>\n",
       "      <td>62.258953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.662330</td>\n",
       "      <td>64.600551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.761679</td>\n",
       "      <td>65.840220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.220580</td>\n",
       "      <td>69.834711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.298640</td>\n",
       "      <td>68.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.943820</td>\n",
       "      <td>69.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>91.691307</td>\n",
       "      <td>65.013774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.855115</td>\n",
       "      <td>67.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.704317</td>\n",
       "      <td>71.487603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.586044</td>\n",
       "      <td>71.349862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.817268</td>\n",
       "      <td>74.104683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>96.274394</td>\n",
       "      <td>70.110193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.492017</td>\n",
       "      <td>71.625344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fc_network_structs conv_network_structs   patches strides  train_acc  \\\n",
       "0              [5, 5]               [5, 5]  [80, 24]  [3, 3]  85.245417   \n",
       "1              [5, 5]               [5, 5]  [50, 24]  [3, 3]  85.807215   \n",
       "2              [5, 5]               [5, 5]  [10, 24]  [3, 3]  80.130101   \n",
       "3              [5, 5]               [5, 5]  [10, 12]  [3, 3]  74.807806   \n",
       "4              [5, 5]               [5, 5]  [50, 12]  [3, 3]  80.928445   \n",
       "5              [5, 5]             [10, 10]  [80, 24]  [3, 3]  94.115908   \n",
       "6              [5, 5]             [10, 10]  [50, 24]  [3, 3]  94.027203   \n",
       "7              [5, 5]             [10, 10]  [10, 24]  [3, 3]  90.567711   \n",
       "8              [5, 5]             [10, 10]  [10, 12]  [3, 3]  85.156712   \n",
       "9              [5, 5]             [10, 10]  [50, 12]  [3, 3]  93.406268   \n",
       "10             [5, 5]             [20, 20]  [80, 24]  [3, 3]  97.072738   \n",
       "11             [5, 5]             [20, 20]  [50, 24]  [3, 3]  97.072738   \n",
       "12             [5, 5]             [20, 20]  [10, 24]  [3, 3]  97.486694   \n",
       "13             [5, 5]             [20, 20]  [10, 12]  [3, 3]  93.672383   \n",
       "14             [5, 5]             [20, 20]  [50, 12]  [3, 3]  97.959787   \n",
       "15           [10, 10]               [5, 5]  [80, 24]  [3, 3]  87.551745   \n",
       "16           [10, 10]               [5, 5]  [50, 24]  [3, 3]  82.022472   \n",
       "17           [10, 10]               [5, 5]  [10, 24]  [3, 3]  80.011827   \n",
       "18           [10, 10]               [5, 5]  [10, 12]  [3, 3]  73.950325   \n",
       "19           [10, 10]               [5, 5]  [50, 12]  [3, 3]  82.259018   \n",
       "20           [10, 10]             [10, 10]  [80, 24]  [3, 3]  98.314607   \n",
       "21           [10, 10]             [10, 10]  [50, 24]  [3, 3]  95.978711   \n",
       "22           [10, 10]             [10, 10]  [10, 24]  [3, 3]  95.239503   \n",
       "23           [10, 10]             [10, 10]  [10, 12]  [3, 3]  87.581313   \n",
       "24           [10, 10]             [10, 10]  [50, 12]  [3, 3]  93.879361   \n",
       "25           [10, 10]             [20, 20]  [80, 24]  [3, 3]  99.763454   \n",
       "26           [10, 10]             [20, 20]  [50, 24]  [3, 3]  98.018924   \n",
       "27           [10, 10]             [20, 20]  [10, 24]  [3, 3]  99.053814   \n",
       "28           [10, 10]             [20, 20]  [10, 12]  [3, 3]  95.564755   \n",
       "29           [10, 10]             [20, 20]  [50, 12]  [3, 3]  98.846836   \n",
       "30           [20, 20]               [5, 5]  [80, 24]  [3, 3]  88.586635   \n",
       "31           [20, 20]               [5, 5]  [50, 24]  [3, 3]  86.221171   \n",
       "32           [20, 20]               [5, 5]  [10, 24]  [3, 3]  80.100532   \n",
       "33           [20, 20]               [5, 5]  [10, 12]  [3, 3]  80.662330   \n",
       "34           [20, 20]               [5, 5]  [50, 12]  [3, 3]  82.761679   \n",
       "35           [20, 20]             [10, 10]  [80, 24]  [3, 3]  97.220580   \n",
       "36           [20, 20]             [10, 10]  [50, 24]  [3, 3]  95.298640   \n",
       "37           [20, 20]             [10, 10]  [10, 24]  [3, 3]  94.943820   \n",
       "38           [20, 20]             [10, 10]  [10, 12]  [3, 3]  91.691307   \n",
       "39           [20, 20]             [10, 10]  [50, 12]  [3, 3]  94.855115   \n",
       "40           [20, 20]             [20, 20]  [80, 24]  [3, 3]  99.704317   \n",
       "41           [20, 20]             [20, 20]  [50, 24]  [3, 3]  99.586044   \n",
       "42           [20, 20]             [20, 20]  [10, 24]  [3, 3]  98.817268   \n",
       "43           [20, 20]             [20, 20]  [10, 12]  [3, 3]  96.274394   \n",
       "44           [20, 20]             [20, 20]  [50, 12]  [3, 3]  98.492017   \n",
       "\n",
       "     test_acc  \n",
       "0   64.876033  \n",
       "1   64.187328  \n",
       "2   62.809917  \n",
       "3   59.504132  \n",
       "4   64.187328  \n",
       "5   66.666667  \n",
       "6   67.217631  \n",
       "7   66.253444  \n",
       "8   67.217631  \n",
       "9   65.151515  \n",
       "10  71.349862  \n",
       "11  71.074380  \n",
       "12  70.523416  \n",
       "13  69.008264  \n",
       "14  72.314050  \n",
       "15  67.630854  \n",
       "16  65.564738  \n",
       "17  62.121212  \n",
       "18  59.366391  \n",
       "19  63.774105  \n",
       "20  66.942149  \n",
       "21  68.595041  \n",
       "22  68.457300  \n",
       "23  64.187328  \n",
       "24  67.906336  \n",
       "25  72.589532  \n",
       "26  70.661157  \n",
       "27  70.798898  \n",
       "28  69.696970  \n",
       "29  71.625344  \n",
       "30  64.600551  \n",
       "31  63.085399  \n",
       "32  62.258953  \n",
       "33  64.600551  \n",
       "34  65.840220  \n",
       "35  69.834711  \n",
       "36  68.181818  \n",
       "37  69.008264  \n",
       "38  65.013774  \n",
       "39  67.906336  \n",
       "40  71.487603  \n",
       "41  71.349862  \n",
       "42  74.104683  \n",
       "43  70.110193  \n",
       "44  71.625344  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_network_structs = [[5,5], [10,10], [20,20]]\n",
    "#fc_network_structs = [[10,10]]\n",
    "conv_network_structs = [[5,5], [10, 10], [20, 20]]\n",
    "#conv_network_structs = [[10,10]]\n",
    "patches = [[80, 24], [50, 24], [10,24], [10,12], [50,12]]\n",
    "#patches = [[80,24]]\n",
    "strides = [[3,3]]\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "nnList = []\n",
    "cols = ['fc_network_structs', 'conv_network_structs', 'patches', 'strides', 'train_acc', 'test_acc']\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "for fc in fc_network_structs:\n",
    "    for conv in conv_network_structs:\n",
    "        for patch in patches:\n",
    "            for stride in strides:\n",
    "                cnn1d = CNN1D(Xtrain.shape[-1], conv, fc, 2, patch, stride, device=device)\n",
    "                cnn1d.train(Xtrain, Ttrain, batch_size, n_epochs, learning_rate, method='adam')\n",
    "                Classes, _ = cnn1d.use(Xtest)\n",
    "                test_perc_correct = 100 * np.mean(Classes == Ttest)\n",
    "                #print(f'Test accuracy in percent correct: {test_perc_correct:.2f}')\n",
    "                Classes, _ = cnn1d.use(Xtrain)\n",
    "                train_perc_correct = 100 * np.mean(Classes == Ttrain)\n",
    "                nnList.append([fc, conv, patch, stride, train_perc_correct,test_perc_correct])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(nnList, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc_network_structs</th>\n",
       "      <th>conv_network_structs</th>\n",
       "      <th>patches</th>\n",
       "      <th>strides</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>73.950325</td>\n",
       "      <td>59.366391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>74.807806</td>\n",
       "      <td>59.504132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.011827</td>\n",
       "      <td>62.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.100532</td>\n",
       "      <td>62.258953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.130101</td>\n",
       "      <td>62.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>86.221171</td>\n",
       "      <td>63.085399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.259018</td>\n",
       "      <td>63.774105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.807215</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.928445</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>87.581313</td>\n",
       "      <td>64.187328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>88.586635</td>\n",
       "      <td>64.600551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>80.662330</td>\n",
       "      <td>64.600551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.245417</td>\n",
       "      <td>64.876033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>91.691307</td>\n",
       "      <td>65.013774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.406268</td>\n",
       "      <td>65.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.022472</td>\n",
       "      <td>65.564738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>82.761679</td>\n",
       "      <td>65.840220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>90.567711</td>\n",
       "      <td>66.253444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.115908</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.314607</td>\n",
       "      <td>66.942149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>85.156712</td>\n",
       "      <td>67.217631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.027203</td>\n",
       "      <td>67.217631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>87.551745</td>\n",
       "      <td>67.630854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.855115</td>\n",
       "      <td>67.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.879361</td>\n",
       "      <td>67.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.298640</td>\n",
       "      <td>68.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.239503</td>\n",
       "      <td>68.457300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.978711</td>\n",
       "      <td>68.595041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>94.943820</td>\n",
       "      <td>69.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>93.672383</td>\n",
       "      <td>69.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>95.564755</td>\n",
       "      <td>69.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.220580</td>\n",
       "      <td>69.834711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>96.274394</td>\n",
       "      <td>70.110193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.486694</td>\n",
       "      <td>70.523416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.018924</td>\n",
       "      <td>70.661157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.053814</td>\n",
       "      <td>70.798898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.072738</td>\n",
       "      <td>71.074380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.072738</td>\n",
       "      <td>71.349862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.586044</td>\n",
       "      <td>71.349862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.704317</td>\n",
       "      <td>71.487603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.846836</td>\n",
       "      <td>71.625344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.492017</td>\n",
       "      <td>71.625344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[50, 12]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>97.959787</td>\n",
       "      <td>72.314050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[80, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>99.763454</td>\n",
       "      <td>72.589532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[20, 20]</td>\n",
       "      <td>[10, 24]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>98.817268</td>\n",
       "      <td>74.104683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fc_network_structs conv_network_structs   patches strides  train_acc  \\\n",
       "18           [10, 10]               [5, 5]  [10, 12]  [3, 3]  73.950325   \n",
       "3              [5, 5]               [5, 5]  [10, 12]  [3, 3]  74.807806   \n",
       "17           [10, 10]               [5, 5]  [10, 24]  [3, 3]  80.011827   \n",
       "32           [20, 20]               [5, 5]  [10, 24]  [3, 3]  80.100532   \n",
       "2              [5, 5]               [5, 5]  [10, 24]  [3, 3]  80.130101   \n",
       "31           [20, 20]               [5, 5]  [50, 24]  [3, 3]  86.221171   \n",
       "19           [10, 10]               [5, 5]  [50, 12]  [3, 3]  82.259018   \n",
       "1              [5, 5]               [5, 5]  [50, 24]  [3, 3]  85.807215   \n",
       "4              [5, 5]               [5, 5]  [50, 12]  [3, 3]  80.928445   \n",
       "23           [10, 10]             [10, 10]  [10, 12]  [3, 3]  87.581313   \n",
       "30           [20, 20]               [5, 5]  [80, 24]  [3, 3]  88.586635   \n",
       "33           [20, 20]               [5, 5]  [10, 12]  [3, 3]  80.662330   \n",
       "0              [5, 5]               [5, 5]  [80, 24]  [3, 3]  85.245417   \n",
       "38           [20, 20]             [10, 10]  [10, 12]  [3, 3]  91.691307   \n",
       "9              [5, 5]             [10, 10]  [50, 12]  [3, 3]  93.406268   \n",
       "16           [10, 10]               [5, 5]  [50, 24]  [3, 3]  82.022472   \n",
       "34           [20, 20]               [5, 5]  [50, 12]  [3, 3]  82.761679   \n",
       "7              [5, 5]             [10, 10]  [10, 24]  [3, 3]  90.567711   \n",
       "5              [5, 5]             [10, 10]  [80, 24]  [3, 3]  94.115908   \n",
       "20           [10, 10]             [10, 10]  [80, 24]  [3, 3]  98.314607   \n",
       "8              [5, 5]             [10, 10]  [10, 12]  [3, 3]  85.156712   \n",
       "6              [5, 5]             [10, 10]  [50, 24]  [3, 3]  94.027203   \n",
       "15           [10, 10]               [5, 5]  [80, 24]  [3, 3]  87.551745   \n",
       "39           [20, 20]             [10, 10]  [50, 12]  [3, 3]  94.855115   \n",
       "24           [10, 10]             [10, 10]  [50, 12]  [3, 3]  93.879361   \n",
       "36           [20, 20]             [10, 10]  [50, 24]  [3, 3]  95.298640   \n",
       "22           [10, 10]             [10, 10]  [10, 24]  [3, 3]  95.239503   \n",
       "21           [10, 10]             [10, 10]  [50, 24]  [3, 3]  95.978711   \n",
       "37           [20, 20]             [10, 10]  [10, 24]  [3, 3]  94.943820   \n",
       "13             [5, 5]             [20, 20]  [10, 12]  [3, 3]  93.672383   \n",
       "28           [10, 10]             [20, 20]  [10, 12]  [3, 3]  95.564755   \n",
       "35           [20, 20]             [10, 10]  [80, 24]  [3, 3]  97.220580   \n",
       "43           [20, 20]             [20, 20]  [10, 12]  [3, 3]  96.274394   \n",
       "12             [5, 5]             [20, 20]  [10, 24]  [3, 3]  97.486694   \n",
       "26           [10, 10]             [20, 20]  [50, 24]  [3, 3]  98.018924   \n",
       "27           [10, 10]             [20, 20]  [10, 24]  [3, 3]  99.053814   \n",
       "11             [5, 5]             [20, 20]  [50, 24]  [3, 3]  97.072738   \n",
       "10             [5, 5]             [20, 20]  [80, 24]  [3, 3]  97.072738   \n",
       "41           [20, 20]             [20, 20]  [50, 24]  [3, 3]  99.586044   \n",
       "40           [20, 20]             [20, 20]  [80, 24]  [3, 3]  99.704317   \n",
       "29           [10, 10]             [20, 20]  [50, 12]  [3, 3]  98.846836   \n",
       "44           [20, 20]             [20, 20]  [50, 12]  [3, 3]  98.492017   \n",
       "14             [5, 5]             [20, 20]  [50, 12]  [3, 3]  97.959787   \n",
       "25           [10, 10]             [20, 20]  [80, 24]  [3, 3]  99.763454   \n",
       "42           [20, 20]             [20, 20]  [10, 24]  [3, 3]  98.817268   \n",
       "\n",
       "     test_acc  \n",
       "18  59.366391  \n",
       "3   59.504132  \n",
       "17  62.121212  \n",
       "32  62.258953  \n",
       "2   62.809917  \n",
       "31  63.085399  \n",
       "19  63.774105  \n",
       "1   64.187328  \n",
       "4   64.187328  \n",
       "23  64.187328  \n",
       "30  64.600551  \n",
       "33  64.600551  \n",
       "0   64.876033  \n",
       "38  65.013774  \n",
       "9   65.151515  \n",
       "16  65.564738  \n",
       "34  65.840220  \n",
       "7   66.253444  \n",
       "5   66.666667  \n",
       "20  66.942149  \n",
       "8   67.217631  \n",
       "6   67.217631  \n",
       "15  67.630854  \n",
       "39  67.906336  \n",
       "24  67.906336  \n",
       "36  68.181818  \n",
       "22  68.457300  \n",
       "21  68.595041  \n",
       "37  69.008264  \n",
       "13  69.008264  \n",
       "28  69.696970  \n",
       "35  69.834711  \n",
       "43  70.110193  \n",
       "12  70.523416  \n",
       "26  70.661157  \n",
       "27  70.798898  \n",
       "11  71.074380  \n",
       "10  71.349862  \n",
       "41  71.349862  \n",
       "40  71.487603  \n",
       "29  71.625344  \n",
       "44  71.625344  \n",
       "14  72.314050  \n",
       "25  72.589532  \n",
       "42  74.104683  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('test_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam: Epoch 10 Loss 0.457\n",
      "adam: Epoch 20 Loss 0.173\n",
      "adam: Epoch 30 Loss 0.094\n",
      "adam: Epoch 40 Loss 0.067\n",
      "adam: Epoch 50 Loss 0.067\n",
      "adam: Epoch 60 Loss 0.047\n",
      "adam: Epoch 70 Loss 0.056\n",
      "adam: Epoch 80 Loss 0.033\n",
      "adam: Epoch 90 Loss 0.043\n",
      "adam: Epoch 100 Loss 0.036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN1D(\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): Conv1d(1, 20, kernel_size=(10,), stride=(3,))\n",
       "    (1): Conv1d(20, 20, kernel_size=(24,), stride=(3,))\n",
       "  )\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=200, out_features=20, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make_conv_and_fc_layers(self, n_inputs, n_hiddens_per_conv_layer, n_hiddens_per_fc_layer, n_outputs,patch_size_per_conv_layer, stride_per_conv_layer):\n",
    "cnnet1 = CNN1D(Xtrain.shape[-1], [20,20], [20,20], 2, [10,24], [3,3], device=device)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "cnnet1.train(Xtrain, Ttrain, batch_size, n_epochs, learning_rate, method='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pulses')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnnet1.error_trace = [e.detach().numpy() for e in cnnet1.error_trace]\n",
    "plt.plot(cnnet1.error_trace, label='Pytorch')\n",
    "plt.title('Pulses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y_classes, T):\n",
    "    class_names = np.unique(T)\n",
    "    table = []\n",
    "    for true_class in class_names:\n",
    "        row = []\n",
    "        for Y_class in class_names:\n",
    "            row.append(100 * np.mean(Y_classes[T == true_class] == Y_class))\n",
    "        table.append(row)\n",
    "    conf_matrix = pd.DataFrame(table, index=class_names, columns=class_names)\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy in percent correct: 98.97\n",
      "Train accuracy percent to beat: 0.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>98.724954</td>\n",
       "      <td>1.275046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.806916</td>\n",
       "      <td>99.193084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           -1          1\n",
       "-1  98.724954   1.275046\n",
       " 1   0.806916  99.193084"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes, _ = cnnet1.use(Xtrain)\n",
    "perc_correct = 100 * np.mean(Classes == Ttrain)\n",
    "print(f'Train accuracy in percent correct: {perc_correct:.2f}')\n",
    "print(f'Train accuracy percent to beat: {dataBalance[-1]:.2f}')\n",
    "confusion_matrix(Classes, Ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in percent correct: 70.99\n",
      "Test accuracy percent to beat: 0.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>78.236915</td>\n",
       "      <td>21.763085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.288089</td>\n",
       "      <td>63.711911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           -1          1\n",
       "-1  78.236915  21.763085\n",
       " 1  36.288089  63.711911"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classes, _ = cnnet1.use(Xval)\n",
    "perc_correct = 100 * np.mean(Classes == Tval)\n",
    "print(f'Test accuracy in percent correct: {perc_correct:.2f}')\n",
    "print(f'Test accuracy percent to beat: {dataBalance[-1]:.2f}')\n",
    "confusion_matrix(Classes, Tval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Discussion\n",
    "\n",
    "It was somewhat of a struggle, however I would say that ultimately this analysis was a success. Initially I was getting results of ~50% accuracy on the test set with almost 100% accuracy on the training set, indicating significant overfitting. Getting the model to stop overfitting was a major hurdle in which multiple hyperparameter searches were performed (to no avail), reductions in epoch loops, learning rate, and alterations in network architecture were made; Including node number, layers, step, and patch size. In the end the two major additions that helped alleviate the overfitting were adding Dropout to the model and subsampling the mitochondrially localized proteins. This caused a ~20% jump in accuracy on the test set (PLEASE NOTE: Variable names for Validation and Test set should be swapped, but are the exact same size and so interchangeable). Despite the fact that we achieved ~70% accuracy on the test set, the model is still significantly overfitting by maintaining it's ~99% accuracy on the training set. Some further investigation was done in order to break this overfitting, but nothing resulting in rescuing the testing accuracy more than what is shown here in the results. This is, however, somewhat promising for future work since there is a pattern that the model is able to discern and with a shockingly high accuracy. If I were able to break the overfitting and increase the testing accuracy further the model could end up being highly effective at protein classification. \n",
    "\n",
    "Future work on this project will continue likely in a similar vein, but with a slightly differing data set and approach. For this analysis and project I kept the data sets similar (IE, using DNA), however for classification there is a much more effective way of organizing your data for a CNN that maintains more information than just nucleotide bases. Instead of DNA, I would use protein transcripts that include amino acids (encoded by every 3 base pairs). Amino acids are an interesting choice for ML model prediction with some caveats to consider. By doing this you are effectively expanding the demensions of your data to 20 (instead of 4) this can be undesireable which can result in data sparsity, however you can collapse the dimensionality of your data back down by using amino acid subgroups as your features rather than the amino acids themselves. Many amino acids share similar properties, such as being hydrophilic or hydrophobic, positively charged or negatively charged. By building a feature matrix out of the properties of amino acids you can instead test on these amino acid subgroups where the model can look for patterns of *properties* instead of patterns of *name.* In the realm of bioinformatics this is generally considered the better approach. \n",
    "\n",
    "When compared to my original analyses of this data from CS345 and using perceptron, SVM, and randomForest, the 1D CNN was unable to beat the performance of a well tuned randomForest. That being said, I am unsure if the results are directly comparable, because even though the gene sets were the same (Arabidopsis thaliana), the data sets and how the data was presented to the models was different. I would like to continue this project beyond the scope of this class and do some more direct comparisons / tunining of the CNN models used here. Additionally I would like to try and compare a 1D CNN Vs. a 2D CNN for this data and see if that manages to handle the data any better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
